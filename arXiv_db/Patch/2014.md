# 2014

## TOC

- [2014-01](#2014-01)
- [2014-02](#2014-02)
- [2014-03](#2014-03)
- [2014-04](#2014-04)
- [2014-05](#2014-05)
- [2014-06](#2014-06)
- [2014-07](#2014-07)
- [2014-08](#2014-08)
- [2014-09](#2014-09)
- [2014-10](#2014-10)
- [2014-11](#2014-11)
- [2014-12](#2014-12)

## 2014-01

<details>

<summary>2014-01-20 14:31:24 - Spoiled Onions: Exposing Malicious Tor Exit Relays</summary>

- *Philipp Winter, Stefan Lindskog*

- `1401.4917v1` - [abs](http://arxiv.org/abs/1401.4917v1) - [pdf](http://arxiv.org/pdf/1401.4917v1)

> Several hundred Tor exit relays together push more than 1 GiB/s of network traffic. However, it is easy for exit relays to snoop and tamper with anonymised network traffic and as all relays are run by independent volunteers, not all of them are innocuous.   In this paper, we seek to expose malicious exit relays and document their actions. First, we monitored the Tor network after developing a fast and modular exit relay scanner. We implemented several scanning modules for detecting common attacks and used them to probe all exit relays over a period of four months. We discovered numerous malicious exit relays engaging in different attacks. To reduce the attack surface users are exposed to, we further discuss the design and implementation of a browser extension patch which fetches and compares suspicious X.509 certificates over independent Tor circuits.   Our work makes it possible to continuously monitor Tor exit relays. We are able to detect and thwart many man-in-the-middle attacks which makes the network safer for its users. All our code is available under a free license.

</details>

<details>

<summary>2014-01-26 11:00:46 - Painting Analysis Using Wavelets and Probabilistic Topic Models</summary>

- *Tong Wu, Gungor Polatkan, David Steel, William Brown, Ingrid Daubechies, Robert Calderbank*

- `1401.6638v1` - [abs](http://arxiv.org/abs/1401.6638v1) - [pdf](http://arxiv.org/pdf/1401.6638v1)

> In this paper, computer-based techniques for stylistic analysis of paintings are applied to the five panels of the 14th century Peruzzi Altarpiece by Giotto di Bondone. Features are extracted by combining a dual-tree complex wavelet transform with a hidden Markov tree (HMT) model. Hierarchical clustering is used to identify stylistic keywords in image patches, and keyword frequencies are calculated for sub-images that each contains many patches. A generative hierarchical Bayesian model learns stylistic patterns of keywords; these patterns are then used to characterize the styles of the sub-images; this in turn, permits to discriminate between paintings. Results suggest that such unsupervised probabilistic topic models can be useful to distill characteristic elements of style.

</details>


## 2014-02

<details>

<summary>2014-02-02 21:08:07 - Secure Debit Card Device Model</summary>

- *Ms. Rumaisah Munir*

- `1402.0247v1` - [abs](http://arxiv.org/abs/1402.0247v1) - [pdf](http://arxiv.org/pdf/1402.0247v1)

> The project envisages the implementation of an e-payment system utilizing FIPS-201 Smart Card. The system combines hardware and software modules. The hardware module takes data insertions (e.g. currency notes), processes the data and then creates connection with the smart card using serial/USB ports to perform further mathematical manipulations. The hardware interacts with servers at the back for authentication and identification of users and for data storage pertaining to a particular user. The software module manages database, handles identities, provide authentication and secure communication between the various system components. It will also provide a component to the end users. This component can be in the form of software for computer or executable binaries for PoS devices. The idea is to receive data in the embedded system from data reader and smart card. After manipulations, the updated data is imprinted on smart card memory and also updated in the back end servers maintaining database. The information to be sent to a server is sent through a PoS device which has multiple transfer mediums involving wired and un-wired mediums. The user device also acts as an updater; therefore, whenever the smart card is inserted by user, it is automatically updated by synchronizing with back-end database. The project required expertise in embedded systems, networks, java and C++ (Optional).

</details>

<details>

<summary>2014-02-09 12:13:22 - Proactive Web Server Protocol for Complaint Assessment</summary>

- *G. Vijay Kumar, Ravikumar S. Raykundaliya, Dr. P. Naga Prasad*

- `1402.1943v1` - [abs](http://arxiv.org/abs/1402.1943v1) - [pdf](http://arxiv.org/pdf/1402.1943v1)

> Vulnerability Discovery with attack Injection security threats are increasing for the server software, when software is developed, the software tested for the functionality. Due to unawareness of software vulnerabilities most of the software before pre-Release the software should be thoroughly tested for not only functionality reliability, but should be tested for the security flows (or) vulnerabilities. The approaches such as fuzzers, Fault injection, vulnerabilities scanners, static vulnerabilities analyzers, Run time prevention mechanisms and software Rejuvenation are identifying the un-patched software which is open for security threats address to solve the problem "security testing". These techniques are useful for generating attacks but cannot be extendable for the new land of attacks. The system called proactive vulnerability attack injection tool is suitable for adding new attacks injection vectors, methods to define new protocol states (or) Specification using the interface of tool includes Network server protocol specification using GUI, Attacks generator, Attack injector, monitoring module at the victim injector, monitoring module at the victim machine and the attacks injection report generation. This tool can address most of the vulnerabilities (or) security flows.

</details>

<details>

<summary>2014-02-09 18:19:59 - A Novel Approach to Detect Spam Worms Propagation with Monitoring the Footprinting</summary>

- *Rajesh R Chauhan, G S Praveen Kumar*

- `1402.1974v1` - [abs](http://arxiv.org/abs/1402.1974v1) - [pdf](http://arxiv.org/pdf/1402.1974v1)

> One of the key security threats on the Internet are the compromised machines that can be used to launch various security attacks such as spamming and spreading malware, accessing useful information and DDoS. Attackers for spamming activity are volunteer by large number of compromised machines. Our main focus is on detection of the compromised machines in a network that may be or are involved in the spamming activities; these machines are commonly known as spam zombies. Activities such as port scan, DB scan and so on are treated as malicious activity within the network. So to overcome that we develop one of the most effective spam zombie detection system within the network based on the behavior of other systems as if performing the above activities are treated as zombies machines. If any system within the network try's to gather some information about any other system then this is treated as a malicious activity and should be not allowed to do so. SYN packets are used in order to initiate communication within the network so as to establish connection. If any system try's to flood the network with these packets we can make an assumption that the system is trying to gather the information about other system. This is what called footprinting. So we will try to detect any system involved in footprinting and report to the administrator.

</details>

<details>

<summary>2014-02-16 13:07:23 - Unsupervised feature learning by augmenting single images</summary>

- *Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox*

- `1312.5242v3` - [abs](http://arxiv.org/abs/1312.5242v3) - [pdf](http://arxiv.org/pdf/1312.5242v3)

> When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).

</details>

<details>

<summary>2014-02-17 16:41:30 - Modeling correlations in spontaneous activity of visual cortex with centered Gaussian-binary deep Boltzmann machines</summary>

- *Nan Wang, Dirk Jancke, Laurenz Wiskott*

- `1312.6108v3` - [abs](http://arxiv.org/abs/1312.6108v3) - [pdf](http://arxiv.org/pdf/1312.6108v3)

> Spontaneous cortical activity -- the ongoing cortical activities in absence of intentional sensory input -- is considered to play a vital role in many aspects of both normal brain functions and mental dysfunctions. We present a centered Gaussian-binary Deep Boltzmann Machine (GDBM) for modeling the activity in early cortical visual areas and relate the random sampling in GDBMs to the spontaneous cortical activity. After training the proposed model on natural image patches, we show that the samples collected from the model's probability distribution encompass similar activity patterns as found in the spontaneous activity. Specifically, filters having the same orientation preference tend to be active together during random sampling. Our work demonstrates the centered GDBM is a meaningful model approach for basic receptive field properties and the emergence of spontaneous activity patterns in early cortical visual areas. Besides, we show empirically that centered GDBMs do not suffer from the difficulties during training as GDBMs do and can be properly trained without the layer-wise pretraining.

</details>

<details>

<summary>2014-02-17 22:05:42 - Fine-grained Patches for Java Software Upgrades</summary>

- *Eduardo R. B. Marques*

- `1402.4164v1` - [abs](http://arxiv.org/abs/1402.4164v1) - [pdf](http://arxiv.org/pdf/1402.4164v1)

> We present a novel methodology for deriving fine-grained patches of Java software. We consider an abstract-syntax tree (AST) representation of Java classes compiled to the Java Virtual Machine (JVM) format, and a difference analysis over the AST representation to derive patches. The AST representation defines an appropriate abstraction level for analyzing differences, yielding compact patches that correlate modularly to actual source code changes. The approach contrasts to other common, coarse-grained approaches, like plain binary differences, which may easily lead to disproportionately large patches. We present the main traits of the methodology, a prototype tool called aspa that implements it, and a case-study analysis on the use of aspa to derive patches for the Java 2 SE API. The case-study results illustrate that aspa patches have a significantly smaller size than patches derived by binary differencing tools.

</details>

<details>

<summary>2014-02-18 10:20:25 - Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors</summary>

- *Wiktor Mlynarski*

- `1312.4695v3` - [abs](http://arxiv.org/abs/1312.4695v3) - [pdf](http://arxiv.org/pdf/1312.4695v3)

> Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitely representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.

</details>

<details>

<summary>2014-02-19 16:00:08 - Deep learning for neuroimaging: a validation study</summary>

- *Sergey M. Plis, Devon R. Hjelm, Ruslan Salakhutdinov, Vince D. Calhoun*

- `1312.5847v3` - [abs](http://arxiv.org/abs/1312.5847v3) - [pdf](http://arxiv.org/pdf/1312.5847v3)

> Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.

</details>


## 2014-03

<details>

<summary>2014-03-02 04:18:00 - Network Traffic Decomposition for Anomaly Detection</summary>

- *Tahereh Babaie, Sanjay Chawla, Sebastien Ardon*

- `1403.0157v1` - [abs](http://arxiv.org/abs/1403.0157v1) - [pdf](http://arxiv.org/pdf/1403.0157v1)

> In this paper we focus on the detection of network anomalies like Denial of Service (DoS) attacks and port scans in a unified manner. While there has been an extensive amount of research in network anomaly detection, current state of the art methods are only able to detect one class of anomalies at the cost of others. The key tool we will use is based on the spectral decomposition of a trajectory/hankel matrix which is able to detect deviations from both between and within correlation present in the observed network traffic data. Detailed experiments on synthetic and real network traces shows a significant improvement in detection capability over competing approaches. In the process we also address the issue of robustness of anomaly detection systems in a principled fashion.

</details>

<details>

<summary>2014-03-04 05:15:42 - Network In Network</summary>

- *Min Lin, Qiang Chen, Shuicheng Yan*

- `1312.4400v3` - [abs](http://arxiv.org/abs/1312.4400v3) - [pdf](http://arxiv.org/pdf/1312.4400v3)

> We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.

</details>

<details>

<summary>2014-03-07 02:53:15 - Optimal Patching in Clustered Malware Epidemics</summary>

- *Soheil Eshghi, MHR. Khouzani, Saswati Sarkar, Santosh S. Venkatesh*

- `1403.1639v1` - [abs](http://arxiv.org/abs/1403.1639v1) - [pdf](http://arxiv.org/pdf/1403.1639v1)

> Studies on the propagation of malware in mobile networks have revealed that the spread of malware can be highly inhomogeneous. Platform diversity, contact list utilization by the malware, clustering in the network structure, etc. can also lead to differing spreading rates. In this paper, a general formal framework is proposed for leveraging such heterogeneity to derive optimal patching policies that attain the minimum aggregate cost due to the spread of malware and the surcharge of patching. Using Pontryagin's Maximum Principle for a stratified epidemic model, it is analytically proven that in the mean-field deterministic regime, optimal patch disseminations are simple single-threshold policies. Through numerical simulations, the behavior of optimal patching policies is investigated in sample topologies and their advantages are demonstrated.

</details>

<details>

<summary>2014-03-11 19:56:59 - Unsupervised Learning of Invariant Representations in Hierarchical Architectures</summary>

- *Fabio Anselmi, Joel Z. Leibo, Lorenzo Rosasco, Jim Mutch, Andrea Tacchetti, Tomaso Poggio*

- `1311.4158v5` - [abs](http://arxiv.org/abs/1311.4158v5) - [pdf](http://arxiv.org/pdf/1311.4158v5)

> The present phase of Machine Learning is characterized by supervised learning algorithms relying on large sets of labeled examples ($n \to \infty$). The next phase is likely to focus on algorithms capable of learning from very few labeled examples ($n \to 1$), like humans seem able to do. We propose an approach to this problem and describe the underlying theory, based on the unsupervised, automatic learning of a ``good'' representation for supervised learning, characterized by small sample complexity ($n$). We consider the case of visual object recognition though the theory applies to other domains. The starting point is the conjecture, proved in specific cases, that image representations which are invariant to translations, scaling and other transformations can considerably reduce the sample complexity of learning. We prove that an invariant and unique (discriminative) signature can be computed for each image patch, $I$, in terms of empirical distributions of the dot-products between $I$ and a set of templates stored during unsupervised learning. A module performing filtering and pooling, like the simple and complex cells described by Hubel and Wiesel, can compute such estimates. Hierarchical architectures consisting of this basic Hubel-Wiesel moduli inherit its properties of invariance, stability, and discriminability while capturing the compositional organization of the visual world in terms of wholes and parts. The theory extends existing deep learning convolutional architectures for image and speech recognition. It also suggests that the main computational goal of the ventral stream of visual cortex is to provide a hierarchical representation of new objects/images which is invariant to transformations, stable, and discriminative for recognition---and that this representation may be continuously learned in an unsupervised way during development and visual experience.

</details>

<details>

<summary>2014-03-25 12:32:17 - Do the Fix Ingredients Already Exist? An Empirical Inquiry into the Redundancy Assumptions of Program Repair Approaches</summary>

- *Matias Martinez, Westley Weimer, Martin Monperrus*

- `1403.6322v1` - [abs](http://arxiv.org/abs/1403.6322v1) - [pdf](http://arxiv.org/pdf/1403.6322v1)

> Much initial research on automatic program repair has focused on experimental results to probe their potential to find patches and reduce development effort. Relatively less effort has been put into understanding the hows and whys of such approaches. For example, a critical assumption of the GenProg technique is that certain bugs can be fixed by copying and re-arranging existing code. In other words, GenProg assumes that the fix ingredients already exist elsewhere in the code. In this paper, we formalize these assumptions around the concept of ''temporal redundancy''. A temporally redundant commit is only composed of what has already existed in previous commits. Our experiments show that a large proportion of commits that add existing code are temporally redundant. This validates the fundamental redundancy assumption of GenProg.

</details>


## 2014-04

<details>

<summary>2014-04-04 21:11:18 - Android Security Framework: Enabling Generic and Extensible Access Control on Android</summary>

- *Michael Backes, Sven Bugiel, Sebastian Gerling, Philipp von Styp-Rekowsky*

- `1404.1395v1` - [abs](http://arxiv.org/abs/1404.1395v1) - [pdf](http://arxiv.org/pdf/1404.1395v1)

> We introduce the Android Security Framework (ASF), a generic, extensible security framework for Android that enables the development and integration of a wide spectrum of security models in form of code-based security modules. The design of ASF reflects lessons learned from the literature on established security frameworks (such as Linux Security Modules or the BSD MAC Framework) and intertwines them with the particular requirements and challenges from the design of Android's software stack. ASF provides a novel security API that supports authors of Android security extensions in developing their modules. This overcomes the current unsatisfactory situation to provide security solutions as separate patches to the Android software stack or to embed them into Android's mainline codebase. As a result, ASF provides different practical benefits such as a higher degree of acceptance, adaptation, and maintenance of security solutions than previously possible on Android. We present a prototypical implementation of ASF and demonstrate its effectiveness and efficiency by modularizing different security models from related work, such as context-aware access control, inlined reference monitoring, and type enforcement.

</details>

<details>

<summary>2014-04-07 13:03:52 - Learning Natural Coding Conventions</summary>

- *Miltiadis Allamanis, Earl T. Barr, Christian Bird, Charles Sutton*

- `1402.4182v3` - [abs](http://arxiv.org/abs/1402.4182v3) - [pdf](http://arxiv.org/pdf/1402.4182v3)

> Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project's coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately, programmers are often unaware of coding conventions because inferring them requires a global view, one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE, a framework that learns the style of a codebase, and suggests revisions to improve stylistic consistency. NATURALIZE builds on recent work in applying statistical natural language processing to source code. We apply NATURALIZE to suggest natural identifier names and formatting conventions. We present four tools focused on ensuring natural code during development and release management, including code review. NATURALIZE achieves 94% accuracy in its top suggestions for identifier names and can even transfer knowledge about conventions across projects, leveraging a corpus of 10,968 open source projects. We used NATURALIZE to generate 18 patches for 5 open source projects: 14 were accepted.

</details>

<details>

<summary>2014-04-08 10:08:22 - Extracting a bilingual semantic grammar from FrameNet-annotated corpora</summary>

- *Dana Dannélls, Normunds Grūzītis*

- `1404.2071v1` - [abs](http://arxiv.org/abs/1404.2071v1) - [pdf](http://arxiv.org/pdf/1404.2071v1)

> We present the creation of an English-Swedish FrameNet-based grammar in Grammatical Framework. The aim of this research is to make existing framenets computationally accessible for multilingual natural language applications via a common semantic grammar API, and to facilitate the porting of such grammar to other languages. In this paper, we describe the abstract syntax of the semantic grammar while focusing on its automatic extraction possibilities. We have extracted a shared abstract syntax from ~58,500 annotated sentences in Berkeley FrameNet (BFN) and ~3,500 annotated sentences in Swedish FrameNet (SweFN). The abstract syntax defines 769 frame-specific valence patterns that cover 77.8% examples in BFN and 74.9% in SweFN belonging to the shared set of 471 frames. As a side result, we provide a unified method for comparing semantic and syntactic valence patterns across framenets.

</details>

<details>

<summary>2014-04-11 18:57:52 - Automatic Repair of Buggy If Conditions and Missing Preconditions with SMT</summary>

- *Favio Demarco, Jifeng Xuan, Daniel Le Berre, Martin Monperrus*

- `1404.3186v1` - [abs](http://arxiv.org/abs/1404.3186v1) - [pdf](http://arxiv.org/pdf/1404.3186v1)

> We present Nopol, an approach for automatically repairing buggy if conditions and missing preconditions. As input, it takes a program and a test suite which contains passing test cases modeling the expected behavior of the program and at least one failing test case embodying the bug to be repaired. It consists of collecting data from multiple instrumented test suite executions, transforming this data into a Satisfiability Modulo Theory (SMT) problem, and translating the SMT result -- if there exists one -- into a source code patch. Nopol repairs object oriented code and allows the patches to contain nullness checks as well as specific method calls.

</details>

<details>

<summary>2014-04-12 20:05:06 - Network-Oblivious Algorithms</summary>

- *Gianfranco Bilardi, Andrea Pietracaprina, Geppino Pucci, Michele Scquizzato, Francesco Silvestri*

- `1404.3318v1` - [abs](http://arxiv.org/abs/1404.3318v1) - [pdf](http://arxiv.org/pdf/1404.3318v1)

> A framework is proposed for the design and analysis of \emph{network-oblivious algorithms}, namely, algorithms that can run unchanged, yet efficiently, on a variety of machines characterized by different degrees of parallelism and communication capabilities. The framework prescribes that a network-oblivious algorithm be specified on a parallel model of computation where the only parameter is the problem's input size, and then evaluated on a model with two parameters, capturing parallelism granularity and communication latency. It is shown that, for a wide class of network-oblivious algorithms, optimality in the latter model implies optimality in the Decomposable BSP model, which is known to effectively describe a wide and significant class of parallel platforms. The proposed framework can be regarded as an attempt to port the notion of obliviousness, well established in the context of cache hierarchies, to the realm of parallel computation. Its effectiveness is illustrated by providing optimal network-oblivious algorithms for a number of key problems. Some limitations of the oblivious approach are also discussed.

</details>

<details>

<summary>2014-04-23 09:42:50 - From Quantity to Quality: Massive Molecular Dynamics Simulation of Nanostructures under Plastic Deformation in Desktop and Service Grid Distributed Computing Infrastructure</summary>

- *Olexander Gatsenko, Lev Bekenev, Evgen Pavlov, Yuri G. Gordienko*

- `1404.5764v1` - [abs](http://arxiv.org/abs/1404.5764v1) - [pdf](http://arxiv.org/pdf/1404.5764v1)

> The distributed computing infrastructure (DCI) on the basis of BOINC and EDGeS-bridge technologies for high-performance distributed computing is used for porting the sequential molecular dynamics (MD) application to its parallel version for DCI with Desktop Grids (DGs) and Service Grids (SGs). The actual metrics of the working DG-SG DCI were measured, and the normal distribution of host performances, and signs of log-normal distributions of other characteristics (CPUs, RAM, and HDD per host) were found. The practical feasibility and high efficiency of the MD simulations on the basis of DG-SG DCI were demonstrated during the experiment with the massive MD simulations for the large quantity of aluminum nanocrystals ($\sim10^2$-$10^3$). Statistical analysis (Kolmogorov-Smirnov test, moment analysis, and bootstrapping analysis) of the defect density distribution over the ensemble of nanocrystals had shown that change of plastic deformation mode is followed by the qualitative change of defect density distribution type over ensemble of nanocrystals. Some limitations (fluctuating performance, unpredictable availability of resources, etc.) of the typical DG-SG DCI were outlined, and some advantages (high efficiency, high speedup, and low cost) were demonstrated. Deploying on DG DCI allows to get new scientific $\it{quality}$ from the simulated $\it{quantity}$ of numerous configurations by harnessing sufficient computational power to undertake MD simulations in a wider range of physical parameters (configurations) in a much shorter timeframe.

</details>

<details>

<summary>2014-04-28 13:56:09 - Poisson noise reduction with non-local PCA</summary>

- *Joseph Salmon, Zachary Harmany, Charles-Alban Deledalle, Rebecca Willett*

- `1206.0338v4` - [abs](http://arxiv.org/abs/1206.0338v4) - [pdf](http://arxiv.org/pdf/1206.0338v4)

> Photon-limited imaging arises when the number of photons collected by a sensor array is small relative to the number of detector elements. Photon limitations are an important concern for many applications such as spectral imaging, night vision, nuclear medicine, and astronomy. Typically a Poisson distribution is used to model these observations, and the inherent heteroscedasticity of the data combined with standard noise removal methods yields significant artifacts. This paper introduces a novel denoising algorithm for photon-limited images which combines elements of dictionary learning and sparse patch-based representations of images. The method employs both an adaptation of Principal Component Analysis (PCA) for Poisson noise and recently developed sparsity-regularized convex optimization algorithms for photon-limited images. A comprehensive empirical evaluation of the proposed method helps characterize the performance of this approach relative to other state-of-the-art denoising methods. The results reveal that, despite its conceptual simplicity, Poisson PCA-based denoising appears to be highly competitive in very low light regimes.

</details>


## 2014-05

<details>

<summary>2014-05-11 06:38:25 - Using Tabled Logic Programming to Solve the Petrobras Planning Problem</summary>

- *Roman Barták, Neng-Fa Zhou*

- `1405.2501v1` - [abs](http://arxiv.org/abs/1405.2501v1) - [pdf](http://arxiv.org/pdf/1405.2501v1)

> Tabling has been used for some time to improve efficiency of Prolog programs by memorizing answered queries. The same idea can be naturally used to memorize visited states during search for planning. In this paper we present a planner developed in the Picat language to solve the Petrobras planning problem. Picat is a novel Prolog-like language that provides pattern matching, deterministic and non-deterministic rules, and tabling as its core modelling and solving features. We demonstrate these capabilities using the Petrobras problem, where the goal is to plan transport of cargo items from ports to platforms using vessels with limited capacity. Monte Carlo Tree Search has been so far the best technique to tackle this problem and we will show that by using tabling we can achieve much better runtime efficiency and better plan quality.

</details>

<details>

<summary>2014-05-25 12:21:34 - Learning the Irreducible Representations of Commutative Lie Groups</summary>

- *Taco Cohen, Max Welling*

- `1402.4437v2` - [abs](http://arxiv.org/abs/1402.4437v2) - [pdf](http://arxiv.org/pdf/1402.4437v2)

> We present a new probabilistic model of compact commutative Lie groups that produces invariant-equivariant and disentangled representations of data. To define the notion of disentangling, we borrow a fundamental principle from physics that is used to derive the elementary particles of a system from its symmetries. Our model employs a newfound Bayesian conjugacy relation that enables fully tractable probabilistic inference over compact commutative Lie groups -- a class that includes the groups that describe the rotation and cyclic translation of images. We train the model on pairs of transformed image patches, and show that the learned invariant representation is highly effective for classification.

</details>

<details>

<summary>2014-05-27 04:48:09 - A simple statistical analysis approach for Intrusion Detection System</summary>

- *A. A. Waskita, H. Suhartanto, P. D. Persadha, L. T. Handoko*

- `1405.7268v1` - [abs](http://arxiv.org/abs/1405.7268v1) - [pdf](http://arxiv.org/pdf/1405.7268v1)

> A novel approach to analyze statistically the network traffic raw data is proposed. The huge amount of raw data of actual network traffic from the Intrusion Detection System is analyzed to determine if a traffic is a normal or harmful one. Using the active ports in each host in a network as sensors, the system continuously monitors the incoming packets, and generates its average behaviors at different time scales including its variances. The average region of behaviors at certain time scale is then being used as the baseline of normal traffic. Deploying the exhaustive search based decission system, the system detects the incoming threats to the whole network under supervision.

</details>

<details>

<summary>2014-05-31 03:18:03 - Challenges and complexities in application of LCA approaches in the case of ICT for a sustainable future</summary>

- *Reza Farrahi Moghaddam, Fereydoun Farrahi Moghaddam, Thomas Dandres, Yves Lemieux, Réjean Samson, Mohamed Cheriet*

- `1403.2798v3` - [abs](http://arxiv.org/abs/1403.2798v3) - [pdf](http://arxiv.org/pdf/1403.2798v3)

> In this work, three of many ICT-specific challenges of LCA are discussed. First, the inconsistency versus uncertainty is reviewed with regard to the meta-technological nature of ICT. As an example, the semiconductor technologies are used to highlight the complexities especially with respect to energy and water consumption. The need for specific representations and metric to separately assess products and technologies is discussed. It is highlighted that applying product-oriented approaches would result in abandoning or disfavoring of new technologies that could otherwise help toward a better world. Second, several believed-untouchable hot spots are highlighted to emphasize on their importance and footprint. The list includes, but not limited to, i) User Computer-Interfaces (UCIs), especially screens and displays, ii) Network-Computer Interlaces (NCIs), such as electronic and optical ports, and iii) electricity power interfaces. In addition, considering cross-regional social and economic impacts, and also taking into account the marketing nature of the need for many ICT's product and services in both forms of hardware and software, the complexity of End of Life (EoL) stage of ICT products, technologies, and services is explored. Finally, the impact of smart management and intelligence, and in general software, in ICT solutions and products is highlighted. In particular, it is observed that, even using the same technology, the significance of software could be highly variable depending on the level of intelligence and awareness deployed. With examples from an interconnected network of data centers managed using Dynamic Voltage and Frequency Scaling (DVFS) technology and smart cooling systems, it is shown that the unadjusted assessments could be highly uncertain, and even inconsistent, in calculating the management component's significance on the ICT impacts.

</details>


## 2014-06

<details>

<summary>2014-06-06 18:49:56 - Computational role of eccentricity dependent cortical magnification</summary>

- *Tomaso Poggio, Jim Mutch, Leyla Isik*

- `1406.1770v1` - [abs](http://arxiv.org/abs/1406.1770v1) - [pdf](http://arxiv.org/pdf/1406.1770v1)

> We develop a sampling extension of M-theory focused on invariance to scale and translation. Quite surprisingly, the theory predicts an architecture of early vision with increasing receptive field sizes and a high resolution fovea -- in agreement with data about the cortical magnification factor, V1 and the retina. From the slope of the inverse of the magnification factor, M-theory predicts a cortical "fovea" in V1 in the order of $40$ by $40$ basic units at each receptive field size -- corresponding to a foveola of size around $26$ minutes of arc at the highest resolution, $\approx 6$ degrees at the lowest resolution. It also predicts uniform scale invariance over a fixed range of scales independently of eccentricity, while translation invariance should depend linearly on spatial frequency. Bouma's law of crowding follows in the theory as an effect of cortical area-by-cortical area pooling; the Bouma constant is the value expected if the signature responsible for recognition in the crowding experiments originates in V2. From a broader perspective, the emerging picture suggests that visual recognition under natural conditions takes place by composing information from a set of fixations, with each fixation providing recognition from a space-scale image fragment -- that is an image patch represented at a set of increasing sizes and decreasing resolutions.

</details>

<details>

<summary>2014-06-26 11:14:44 - FrameNet Resource Grammar Library for GF</summary>

- *Normunds Gruzitis, Peteris Paikens, Guntis Barzdins*

- `1406.6844v1` - [abs](http://arxiv.org/abs/1406.6844v1) - [pdf](http://arxiv.org/pdf/1406.6844v1)

> In this paper we present an ongoing research investigating the possibility and potential of integrating frame semantics, particularly FrameNet, in the Grammatical Framework (GF) application grammar development. An important component of GF is its Resource Grammar Library (RGL) that encapsulates the low-level linguistic knowledge about morphology and syntax of currently more than 20 languages facilitating rapid development of multilingual applications. In the ideal case, porting a GF application grammar to a new language would only require introducing the domain lexicon - translation equivalents that are interlinked via common abstract terms. While it is possible for a highly restricted CNL, developing and porting a less restricted CNL requires above average linguistic knowledge about the particular language, and above average GF experience. Specifying a lexicon is mostly straightforward in the case of nouns (incl. multi-word units), however, verbs are the most complex category (in terms of both inflectional paradigms and argument structure), and adding them to a GF application grammar is not a straightforward task. In this paper we are focusing on verbs, investigating the possibility of creating a multilingual FrameNet-based GF library. We propose an extension to the current RGL, allowing GF application developers to define clauses on the semantic level, thus leaving the language-specific syntactic mapping to this extension. We demonstrate our approach by reengineering the MOLTO Phrasebook application grammar.

</details>

<details>

<summary>2014-06-27 10:05:46 - Verifying Component and Connector Models against Crosscutting Structural Views</summary>

- *Shahar Maoz, Jan Oliver Ringert, Bernhard Rumpe*

- `1406.7136v1` - [abs](http://arxiv.org/abs/1406.7136v1) - [pdf](http://arxiv.org/pdf/1406.7136v1)

> The structure of component and connector (C&C) models, which are used in many application domains of software engineering, consists of components at different containment levels, their typed input and output ports, and the connectors between them. C&C views, presented in [24], can be used to specify structural properties of C&C models in an expressive and intuitive way. In this work we address the verification of a C&C model against a C&C view and present efficient (polynomial) algorithms to decide satisfaction. A unique feature of our work, not present in existing approaches to checking structural properties of C&C models, is the generation of witnesses for satisfaction/non-satisfaction and of short naturallanguage texts, which serve to explain and formally justify the verification results and point the engineer to its causes. A prototype tool and an evaluation over four example systems with multiple views, performance and scalability experiments, as well as a user study of the usefulness of the witnesses for engineers, demonstrate the contribution of our work to the state-of-the-art in component and connector modeling and analysis.

</details>


## 2014-07

<details>

<summary>2014-07-30 03:22:43 - Strategic Port Graph Rewriting: An Interactive Modelling and Analysis Framework</summary>

- *Maribel Fernández, Hélène Kirchner, Bruno Pinaud*

- `1407.7929v1` - [abs](http://arxiv.org/abs/1407.7929v1) - [pdf](http://arxiv.org/pdf/1407.7929v1)

> We present strategic portgraph rewriting as a basis for the implementation of visual modelling and analysis tools. The goal is to facilitate the specification, analysis and simulation of complex systems, using port graphs. A system is represented by an initial graph and a collection of graph rewriting rules, together with a user-defined strategy to control the application of rules. The strategy language includes constructs to deal with graph traversal and management of rewriting positions in the graph. We give a small-step operational semantics for the language, and describe its implementation in the graph transformation and visualisation tool PORGY.

</details>


## 2014-08

<details>

<summary>2014-08-09 14:23:06 - A Critical Review of "Automatic Patch Generation Learned from Human-Written Patches": Essay on the Problem Statement and the Evaluation of Automatic Software Repair</summary>

- *Martin Monperrus*

- `1408.2103v1` - [abs](http://arxiv.org/abs/1408.2103v1) - [pdf](http://arxiv.org/pdf/1408.2103v1)

> At ICSE'2013, there was the first session ever dedicated to automatic program repair. In this session, Kim et al. presented PAR, a novel template-based approach for fixing Java bugs. We strongly disagree with key points of this paper. Our critical review has two goals. First, we aim at explaining why we disagree with Kim and colleagues and why the reasons behind this disagreement are important for research on automatic software repair in general. Second, we aim at contributing to the field with a clarification of the essential ideas behind automatic software repair. In particular we discuss the main evaluation criteria of automatic software repair: understandability, correctness and completeness. We show that depending on how one sets up the repair scenario, the evaluation goals may be contradictory. Eventually, we discuss the nature of fix acceptability and its relation to the notion of software correctness.

</details>

<details>

<summary>2014-08-25 09:30:53 - Synthesis of Component and Connector Models from Crosscutting Structural Views</summary>

- *Shahar Maoz, Jan Oliver Ringert, Bernhard Rumpe*

- `1408.5696v1` - [abs](http://arxiv.org/abs/1408.5696v1) - [pdf](http://arxiv.org/pdf/1408.5696v1)

> We present component and connector (C&C) views, which specify structural properties of component and connector models in an expressive and intuitive way. C&C views provide means to abstract away direct hierarchy, direct connectivity, port names and types, and thus can crosscut the traditional boundaries of the implementation-oriented hierarchical decomposition of systems and sub-systems, and reflect the partial knowledge available to different stakeholders involved in a system's design. As a primary application for C&C views we investigate the synthesis problem: given a C&C views specification, consisting of mandatory, alternative, and negative views, construct a concrete satisfying C&C model, if one exists. We show that the problem is NP-hard and solve it, in a bounded scope, using a reduction to SAT, via Alloy. We further extend the basic problem with support for library components, specification patterns, and architectural styles. The result of synthesis can be used for further exploration, simulation, and refinement of the C&C model or, as the complete, final model itself, for direct code generation. A prototype tool and an evaluation over four example systems with multiple specifications show promising results and suggest interesting future research directions towards a comprehensive development environment for the structure of component and connector designs.

</details>

<details>

<summary>2014-08-30 00:02:34 - An Experimental Study of Cryptography Capability using Chained Key Exchange Scheme for Embedded Devices</summary>

- *Mohd Anuar Mat Isa, Habibah Hashim, Jamalul-lail Ab Manan, Syed Farid Syed Adnan, Ramlan Mahmod*

- `1409.0065v1` - [abs](http://arxiv.org/abs/1409.0065v1) - [pdf](http://arxiv.org/pdf/1409.0065v1)

> After 38 years of birthday Diffie-Hellman Key Exchange (DHKE), there are many proposed improvements in the DHKE protocol to encounter modern security issues. This protocol seems quite simple to be implemented, but it can be vulnerable to many types of attacks. In this work, we propose the Chained Key Exchange scheme as a case study to explore cryptographic computation capability of embedded microcontroller. We choose ARM RaspberryPi board as hardware platform for experimental setup. To enable RasberberryPi system on chip (SoC) to perform cryptographic computation, we modified the GNU GMP Bignum library to support a simple primitive cryptographic computation in the UBOOT firmware. The main purpose of our study is to determine whether there is any gap between cryptographic protocol-scheme (in term of theoretical) and its engineering implementation. Our scheme will be integrated with Trivial File Transfer Protocol (TFTP) application in the UBOOT firmware. Our proposed scheme in the TFTP protocol will secure the sharing of secrets and symmetric keys (e.g., AES256). After that, the symmetric encryption algorithm can be used to encrypt data in the cases of remote system updates, patching and upgrades (e.g., firmware, kernel or application).

</details>


## 2014-09

<details>

<summary>2014-09-01 07:19:40 - Analyzing Android Browser Apps for file:// Vulnerabilities</summary>

- *Daoyuan Wu, Rocky K. C. Chang*

- `1404.4553v3` - [abs](http://arxiv.org/abs/1404.4553v3) - [pdf](http://arxiv.org/pdf/1404.4553v3)

> Securing browsers in mobile devices is very challenging, because these browser apps usually provide browsing services to other apps in the same device. A malicious app installed in a device can potentially obtain sensitive information through a browser app. In this paper, we identify four types of attacks in Android, collectively known as FileCross, that exploits the vulnerable file:// to obtain users' private files, such as cookies, bookmarks, and browsing histories. We design an automated system to dynamically test 115 browser apps collected from Google Play and find that 64 of them are vulnerable to the attacks. Among them are the popular Firefox, Baidu and Maxthon browsers, and the more application-specific ones, including UC Browser HD for tablet users, Wikipedia Browser, and Kids Safe Browser. A detailed analysis of these browsers further shows that 26 browsers (23%) expose their browsing interfaces unintentionally. In response to our reports, the developers concerned promptly patched their browsers by forbidding file:// access to private file zones, disabling JavaScript execution in file:// URLs, or even blocking external file:// URLs. We employ the same system to validate the ten patches received from the developers and find one still failing to block the vulnerability.

</details>

<details>

<summary>2014-09-22 11:46:37 - MontiArc - Architectural Modeling of Interactive Distributed and Cyber-Physical Systems</summary>

- *Arne Haber, Jan Oliver Ringert, Bernhard Rumpe*

- `1409.6578v1` - [abs](http://arxiv.org/abs/1409.6578v1) - [pdf](http://arxiv.org/pdf/1409.6578v1)

> This report presents MontiArc, a modeling language for the description of Component & Connector architectures. A component is a unit executing computations and/or storing data. Information flow between components is modeled via unidirectional connectors connecting typed, directed ports of the interfaces of components. Language features of the ADL MontiArc include hierarchical decomposition of components, subtyping by structural inheritance, component type definitions and reference declarations for reuse, generic component types and configurable components, syntactic sugar for connectors, and controlled implicit creation of connections and subcomponent declarations. This technical report gives an overview of the MontiArc language and is a reference for the MontiArc grammar intended to enable reuse and extension of MontiArc and MontiArc related tools. MontiArc is implemented using the DSL framework MontiCore. Available tools include an editor with syntax highlighting and code completion as well as a simulation framework with a Java code generator.

</details>


## 2014-10

<details>

<summary>2014-10-05 13:27:27 - Technical Information on Vulnerabilities of Hypercall Handlers</summary>

- *Aleksandar Milenkoski, Marco Vieira, Bryan D. Payne, Nuno Antunes, Samuel Kounev*

- `1410.1158v1` - [abs](http://arxiv.org/abs/1410.1158v1) - [pdf](http://arxiv.org/pdf/1410.1158v1)

> Modern virtualized service infrastructures expose attack vectors that enable attacks of high severity, such as attacks targeting hypervisors. A malicious user of a guest VM (virtual machine) may execute an attack against the underlying hypervisor via hypercalls, which are software traps from a kernel of a fully or partially paravirtualized guest VM to the hypervisor. The exploitation of a vulnerability of a hypercall handler may have severe consequences such as altering hypervisor's memory, which may result in the execution of malicious code with hypervisor privilege. Despite the importance of vulnerabilities of hypercall handlers, there is not much publicly available information on them. This significantly hinders advances towards securing hypercall interfaces. In this work, we provide in-depth technical information on publicly disclosed vulnerabilities of hypercall handlers. Our vulnerability analysis is based on reverse engineering the released patches fixing the considered vulnerabilities. For each analyzed vulnerability, we provide background information essential for understanding the vulnerability, and information on the vulnerable hypercall handler and the error causing the vulnerability. We also show how the vulnerability can be triggered and discuss the state of the targeted hypervisor after the vulnerability has been triggered.

</details>

<details>

<summary>2014-10-28 19:24:11 - Code Injection Attacks on HTML5-based Mobile Apps</summary>

- *Xing Jin, Tongbo Luo, Derek G. Tsui, Wenliang Du*

- `1410.7756v1` - [abs](http://arxiv.org/abs/1410.7756v1) - [pdf](http://arxiv.org/pdf/1410.7756v1)

> HTML5-based mobile apps become more and more popular, mostly because they are much easier to be ported across different mobile platforms than native apps. HTML5-based apps are implemented using the standard web technologies, including HTML5, JavaScript and CSS; they depend on some middlewares, such as PhoneGap, to interact with the underlying OS.   Knowing that JavaScript is subject to code injection attacks, we have conducted a systematic study on HTML5-based mobile apps, trying to evaluate whether it is safe to rely on the web technologies for mobile app development. Our discoveries are quite surprising. We found out that if HTML5-based mobile apps become popular--it seems to go that direction based on the current projection--many of the things that we normally do today may become dangerous, including reading from 2D barcodes, scanning Wi-Fi access points, playing MP4 videos, pairing with Bluetooth devices, etc. This paper describes how HTML5-based apps can become vulnerable, how attackers can exploit their vulnerabilities through a variety of channels, and what damage can be achieved by the attackers. In addition to demonstrating the attacks through example apps, we have studied 186 PhoneGap plugins, used by apps to achieve a variety of functionalities, and we found that 11 are vulnerable. We also found two real HTML5-based apps that are vulnerable to the attacks.

</details>

<details>

<summary>2014-10-31 03:05:18 - Addressing the non-functional requirements of computer vision systems: A case study</summary>

- *Shannon Fenn, Alexandre Mendes, David Budden*

- `1410.8623v1` - [abs](http://arxiv.org/abs/1410.8623v1) - [pdf](http://arxiv.org/pdf/1410.8623v1)

> Computer vision plays a major role in the robotics industry, where vision data is frequently used for navigation and high-level decision making. Although there is significant research in algorithms and functional requirements, there is a comparative lack of emphasis on how best to map these abstract concepts onto an appropriate software architecture.   In this study, we distinguish between the functional and non-functional requirements of a computer vision system. Using a RoboCup humanoid robot system as a case study, we propose and develop a software architecture that fulfills the latter criteria.   The modifiability of the proposed architecture is demonstrated by detailing a number of feature detection algorithms and emphasizing which aspects of the underlying framework were modified to support their integration. To demonstrate portability, we port our vision system (designed for an application-specific DARwIn-OP humanoid robot) to a general-purpose, Raspberry Pi computer. We evaluate performance on both platforms and compare them to a vision system optimised for functional requirements only.   The architecture and implementation presented in this study provide a highly generalisable framework for computer vision system design that is of particular benefit in research and development, competition and other environments in which rapid system evolution is necessary.

</details>


## 2014-11

<details>

<summary>2014-11-04 22:48:59 - Enhancing software module reusability using port plug-ins: an experiment with the iCub robot</summary>

- *Ali Paikan, Vadim Tikhanoff, Giorgio Metta, Lorenzo Natale*

- `1411.1102v1` - [abs](http://arxiv.org/abs/1411.1102v1) - [pdf](http://arxiv.org/pdf/1411.1102v1)

> Systematically developing high--quality reusable software components is a difficult task and requires careful design to find a proper balance between potential reuse, functionalities and ease of implementation. Extendibility is an important property for software which helps to reduce cost of development and significantly boosts its reusability. This work introduces an approach to enhance components reusability by extending their functionalities using plug-ins at the level of the connection points (ports). Application--dependent functionalities such as data monitoring and arbitration can be implemented using a conventional scripting language and plugged into the ports of components. The main advantage of our approach is that it avoids to introduce application--dependent modifications to existing components, thus reducing development time and fostering the development of simpler and therefore more reusable components. Another advantage of our approach is that it reduces communication and deployment overheads as extra functionalities can be added without introducing additional modules.

</details>

<details>

<summary>2014-11-11 19:46:37 - Analysis of Applicability of ISO 9564 PIN based Authentication to Closed-Loop Mobile Payment Systems</summary>

- *Amal Saha, Sugata Sanyal*

- `1411.2939v1` - [abs](http://arxiv.org/abs/1411.2939v1) - [pdf](http://arxiv.org/pdf/1411.2939v1)

> Payment transactions initiated through a mobile device are growing and security concerns must be ad-dressed. People coming from payment card industry often talk passionately about porting ISO 9564 PIN standard based authentication in open-loop card payment to closed-loop mobile financial transactions and certification of closed-loop payment product or solution against this standard. In reality, so far this standard has not been adopted in closed-loop mobile payment authentication and applicability of this ISO standard must be studied carefully before adoption. The authors do a critical analysis of the applicability of this ISO specification and makes categorical statement about relevance of compliance to closed-loop mobile payment. Security requirements for authentication in closed-loop mobile payment systems are not standardized through ISO 9564 standard, Common Criteria, etc. Since closed-loop mobile payment is a relatively new field, the authors make a case for Common Criteria Recognition Agreement (CCRA) or other standards organization to push for publication of a mobile device-agnostic Protection Profile or standard for it, incorporating the suggested authentication approaches.

</details>

<details>

<summary>2014-11-15 02:03:14 - Deep Deconvolutional Networks for Scene Parsing</summary>

- *Rahul Mohan*

- `1411.4101v1` - [abs](http://arxiv.org/abs/1411.4101v1) - [pdf](http://arxiv.org/pdf/1411.4101v1)

> Scene parsing is an important and challenging prob- lem in computer vision. It requires labeling each pixel in an image with the category it belongs to. Tradition- ally, it has been approached with hand-engineered features from color information in images. Recently convolutional neural networks (CNNs), which automatically learn hierar- chies of features, have achieved record performance on the task. These approaches typically include a post-processing technique, such as superpixels, to produce the final label- ing. In this paper, we propose a novel network architecture that combines deep deconvolutional neural networks with CNNs. Our experiments show that deconvolutional neu- ral networks are capable of learning higher order image structure beyond edge primitives in comparison to CNNs. The new network architecture is employed for multi-patch training, introduced as part of this work. Multi-patch train- ing makes it possible to effectively learn spatial priors from scenes. The proposed approach yields state-of-the-art per- formance on four scene parsing datasets, namely Stanford Background, SIFT Flow, CamVid, and KITTI. In addition, our system has the added advantage of having a training system that can be completely automated end-to-end with- out requiring any post-processing.

</details>

<details>

<summary>2014-11-17 14:29:49 - Content and popularity analysis of Tor hidden services</summary>

- *Alex Biryukov, Ivan Pustogarov, Fabrice Thill, Ralf-Philipp Weinmann*

- `1308.6768v2` - [abs](http://arxiv.org/abs/1308.6768v2) - [pdf](http://arxiv.org/pdf/1308.6768v2)

> Tor hidden services allow running Internet services while protecting the location of the servers. Their main purpose is to enable freedom of speech even in situations in which powerful adversaries try to suppress it. However, providing location privacy and client anonymity also makes Tor hidden services an attractive platform for every kind of imaginable shady service. The ease with which Tor hidden services can be set up has spurred a huge growth of anonymously provided Internet services of both types. In this paper we analyse the landscape of Tor hidden services. We have studied Tor hidden services after collecting 39824 hidden service descriptors on 4th of Feb 2013 by exploiting protocol and implementation flaws in Tor: we scanned them for open ports; in the case of HTTP services, we analysed and classified their content. We also estimated the popularity of hidden services by looking at the request rate for hidden service descriptors by clients. We found that while the content of Tor hidden services is rather varied, the most popular hidden services are related to botnets.

</details>


## 2014-12

<details>

<summary>2014-12-03 17:09:48 - Hashing Pursuit for Online Identification of Heavy-Hitters in High-Speed Network Streams</summary>

- *Michael Kallitsis, Stilian Stoev, George Michailidis*

- `1412.6148v1` - [abs](http://arxiv.org/abs/1412.6148v1) - [pdf](http://arxiv.org/pdf/1412.6148v1)

> Distributed Denial of Service (DDoS) attacks have become more prominent recently, both in frequency of occurrence, as well as magnitude. Such attacks render key Internet resources unavailable and disrupt its normal operation. It is therefore of paramount importance to quickly identify malicious Internet activity. The DDoS threat model includes characteristics such as: (i) heavy-hitters that transmit large volumes of traffic towards "victims", (ii) persistent-hitters that send traffic, not necessarily large, to specific destinations to be used as attack facilitators, (iii) host and port scanning for compiling lists of un-secure servers to be used as attack amplifiers, etc. This conglomeration of problems motivates the development of space/time efficient summaries of data traffic streams that can be used to identify heavy-hitters associated with the above attack vectors. This paper presents a hashing-based framework and fast algorithms that take into account the large-dimensionality of the incoming network stream and can be employed to quickly identify the culprits. The algorithms and data structures proposed provide a synopsis of the network stream that is not taxing to fast-memory, and can be efficiently implemented in hardware due to simple bit-wise operations. The methods are evaluated using real-world Internet data from a large academic network.

</details>

<details>

<summary>2014-12-08 06:09:26 - Enhancing the SysLab System Model with State</summary>

- *Radu Grosu, Cornel Klein, Bernhard Rumpe*

- `1412.2461v1` - [abs](http://arxiv.org/abs/1412.2461v1) - [pdf](http://arxiv.org/pdf/1412.2461v1)

> In this report, the SYSLAB model is complemented in different ways: State-box models are provided through timed port automata, for which an operational and a corresponding denotational semantics are given. Composition is defined for components modeled in the state-box view as well as for components modeled in the black-box view. This composition is well-defined for networks of infinitely many components. To show the applicability of the model, several examples are given.

</details>

<details>

<summary>2014-12-16 00:44:37 - A representation of robotic behaviors using component port arbitration</summary>

- *Ali Paikan, Giorgio Metta, Lorenzo Natale*

- `1412.4847v1` - [abs](http://arxiv.org/abs/1412.4847v1) - [pdf](http://arxiv.org/pdf/1412.4847v1)

> Developing applications considering reactiveness, scalability and re-usability has always been at the center of attention of robotic researchers. Behavior-based architectures have been proposed as a programming paradigm to develop robust and complex behaviors as integration of simpler modules whose activities are directly modulated by sensory feedback or input from other models. The design of behavior based systems, however, becomes increasingly difficult as the complexity of the application grows. This article proposes an approach for modeling and coordinating behaviors in distributed architectures based on port arbitration which clearly separates representation of the behaviors from the composition of the software components. Therefore, based on different behavioral descriptions, the same software components can be reused to implement different applications.

</details>

<details>

<summary>2014-12-22 06:43:58 - Half-CNN: A General Framework for Whole-Image Regression</summary>

- *Jun Yuan, Bingbing Ni, Ashraf A. Kassim*

- `1412.6885v1` - [abs](http://arxiv.org/abs/1412.6885v1) - [pdf](http://arxiv.org/pdf/1412.6885v1)

> The Convolutional Neural Network (CNN) has achieved great success in image classification. The classification model can also be utilized at image or patch level for many other applications, such as object detection and segmentation. In this paper, we propose a whole-image CNN regression model, by removing the full connection layer and training the network with continuous feature maps. This is a generic regression framework that fits many applications. We demonstrate this method through two tasks: simultaneous face detection & segmentation, and scene saliency prediction. The result is comparable with other models in the respective fields, using only a small scale network. Since the regression model is trained on corresponding image / feature map pairs, there are no requirements on uniform input size as opposed to the classification model. Our framework avoids classifier design, a process that may introduce too much manual intervention in model development. Yet, it is highly correlated to the classification network and offers some in-deep review of CNN structures.

</details>

