# 2018

## TOC

- [2018-01](#2018-01)
- [2018-02](#2018-02)
- [2018-03](#2018-03)
- [2018-04](#2018-04)
- [2018-05](#2018-05)
- [2018-06](#2018-06)
- [2018-07](#2018-07)
- [2018-08](#2018-08)
- [2018-09](#2018-09)
- [2018-10](#2018-10)
- [2018-11](#2018-11)
- [2018-12](#2018-12)

## 2018-01

<details>

<summary>2018-01-05 09:37:18 - VulDeePecker: A Deep Learning-Based System for Vulnerability Detection</summary>

- *Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang, Zhijun Deng, Yuyi Zhong*

- `1801.01681v1` - [abs](http://arxiv.org/abs/1801.01681v1) - [pdf](http://arxiv.org/pdf/1801.01681v1)

> The automatic detection of software vulnerabilities is an important research problem. However, existing solutions to this problem rely on human experts to define features and often miss many vulnerabilities (i.e., incurring high false negative rate). In this paper, we initiate the study of using deep learning-based vulnerability detection to relieve human experts from the tedious and subjective task of manually defining features. Since deep learning is motivated to deal with problems that are very different from the problem of vulnerability detection, we need some guiding principles for applying deep learning to vulnerability detection. In particular, we need to find representations of software programs that are suitable for deep learning. For this purpose, we propose using code gadgets to represent programs and then transform them into vectors, where a code gadget is a number of (not necessarily consecutive) lines of code that are semantically related to each other. This leads to the design and implementation of a deep learning-based vulnerability detection system, called Vulnerability Deep Pecker (VulDeePecker). In order to evaluate VulDeePecker, we present the first vulnerability dataset for deep learning approaches. Experimental results show that VulDeePecker can achieve much fewer false negatives (with reasonable false positives) than other approaches. We further apply VulDeePecker to 3 software products (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which are not reported in the National Vulnerability Database but were "silently" patched by the vendors when releasing later versions of these products; in contrast, these vulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with.

</details>

<details>

<summary>2018-01-11 21:38:21 - Implicit LOD using points ordering for processing and visualisation in Point Cloud Servers</summary>

- *Rémi Cura, Julien Perret, Nicolas Paparoditis*

- `1602.06920v3` - [abs](http://arxiv.org/abs/1602.06920v3) - [pdf](http://arxiv.org/pdf/1602.06920v3)

> Lidar datasets now commonly reach Billions of points and are very dense. Using these point cloud becomes challenging, as the high number of points is intractable for most applications and for visualisation.In this work we propose a new paradigm to easily get a portable geometric Level Of Details (LOD) inside a Point Cloud Server.The main idea is to not store the LOD information in an external additional file, but instead to store it implicitly by exploiting the order of the points.The point cloud is divided into groups (patches). These patches are ordered so that their order gradually provides more and more details on the patch. We demonstrate the interest of our method with several classical uses of LOD, such as visualisation of massive point cloud, algorithm acceleration, fast density peak detection and correction.

</details>

<details>

<summary>2018-01-15 09:03:27 - Attack Potential in Impact and Complexity</summary>

- *Luca Allodi, Fabio Massacci*

- `1801.04703v1` - [abs](http://arxiv.org/abs/1801.04703v1) - [pdf](http://arxiv.org/pdf/1801.04703v1)

> Vulnerability exploitation is reportedly one of the main attack vectors against computer systems. Yet, most vulnerabilities remain unexploited by attackers. It is therefore of central importance to identify vulnerabilities that carry a high `potential for attack'. In this paper we rely on Symantec data on real attacks detected in the wild to identify a trade-off in the Impact and Complexity of a vulnerability, in terms of attacks that it generates; exploiting this effect, we devise a readily computable estimator of the vulnerability's Attack Potential that reliably estimates the expected volume of attacks against the vulnerability. We evaluate our estimator performance against standard patching policies by measuring foiled attacks and demanded workload expressed as the number of vulnerabilities entailed to patch. We show that our estimator significantly improves over standard patching policies by ruling out low-risk vulnerabilities, while maintaining invariant levels of coverage against attacks in the wild. Our estimator can be used as a first aid for vulnerability prioritisation to focus assessment efforts on high-potential vulnerabilities.

</details>

<details>

<summary>2018-01-23 20:33:00 - Whose Hands Are in the Finnish Cookie Jar?</summary>

- *Jukka Ruohonen, Ville Leppänen*

- `1801.07759v1` - [abs](http://arxiv.org/abs/1801.07759v1) - [pdf](http://arxiv.org/pdf/1801.07759v1)

> Web cookies are ubiquitously used to track and profile the behavior of users. Although there is a solid empirical foundation for understanding the use of cookies in the global world wide web, thus far, limited attention has been devoted for country-specific and company-level analysis of cookies. To patch this limitation in the literature, this paper investigates persistent third-party cookies used in the Finnish web. The exploratory results reveal some similarities and interesting differences between the Finnish and the global web---in particular, popular Finnish web sites are mostly owned by media companies, which have established their distinct partnerships with online advertisement companies. The results reported can be also reflected against current and future privacy regulation in the European Union.

</details>

<details>

<summary>2018-01-30 00:16:05 - Mix-and-Match Tuning for Self-Supervised Semantic Segmentation</summary>

- *Xiaohang Zhan, Ziwei Liu, Ping Luo, Xiaoou Tang, Chen Change Loy*

- `1712.00661v3` - [abs](http://arxiv.org/abs/1712.00661v3) - [pdf](http://arxiv.org/pdf/1712.00661v3)

> Deep convolutional networks for semantic image segmentation typically require large-scale labeled data, e.g. ImageNet and MS COCO, for network pre-training. To reduce annotation efforts, self-supervised semantic segmentation is recently proposed to pre-train a network without any human-provided labels. The key of this new form of learning is to design a proxy task (e.g. image colorization), from which a discriminative loss can be formulated on unlabeled data. Many proxy tasks, however, lack the critical supervision signals that could induce discriminative representation for the target image segmentation task. Thus self-supervision's performance is still far from that of supervised pre-training. In this study, we overcome this limitation by incorporating a "mix-and-match" (M&M) tuning stage in the self-supervision pipeline. The proposed approach is readily pluggable to many self-supervision methods and does not use more annotated samples than the original process. Yet, it is capable of boosting the performance of target image segmentation task to surpass fully-supervised pre-trained counterpart. The improvement is made possible by better harnessing the limited pixel-wise annotations in the target dataset. Specifically, we first introduce the "mix" stage, which sparsely samples and mixes patches from the target set to reflect rich and diverse local patch statistics of target images. A "match" stage then forms a class-wise connected graph, which can be used to derive a strong triplet-based discriminative loss for fine-tuning the network. Our paradigm follows the standard practice in existing self-supervised studies and no extra data or label is required. With the proposed M&M approach, for the first time, a self-supervision method can achieve comparable or even better performance compared to its ImageNet pre-trained counterpart on both PASCAL VOC2012 dataset and CityScapes dataset.

</details>


## 2018-02

<details>

<summary>2018-02-01 22:11:50 - Snort Intrusion Detection System with Intel Software Guard Extension (Intel SGX)</summary>

- *Dmitrii Kuvaiskii, Somnath Chakrabarti, Mona Vij*

- `1802.00508v1` - [abs](http://arxiv.org/abs/1802.00508v1) - [pdf](http://arxiv.org/pdf/1802.00508v1)

> Network Function Virtualization (NFV) promises the benefits of reduced infrastructure, personnel, and management costs by outsourcing network middleboxes to the public or private cloud. Unfortunately, running network functions in the cloud entails security challenges, especially for complex stateful services. In this paper, we describe our experiences with hardening the king of middleboxes - Intrusion Detection Systems (IDS) - using Intel Software Guard Extensions (Intel SGX) technology. Our IDS secured using Intel SGX, called SEC-IDS, is an unmodified Snort 3 with a DPDK network layer that achieves 10Gbps line rate. SEC-IDS guarantees computational integrity by running all Snort code inside an Intel SGX enclave. At the same time, SEC-IDS achieves near-native performance, with throughput close to 100 percent of vanilla Snort 3, by retaining network I/O outside of the enclave. Our experiments indicate that performance is only constrained by the modest Enclave Page Cache size available on current Intel SGX Skylake based E3 Xeon platforms. Finally, we kept the porting effort minimal by using the Graphene-SGX library OS. Only 27 Lines of Code (LoC) were modified in Snort and 178 LoC in Graphene-SGX itself.

</details>

<details>

<summary>2018-02-05 20:39:55 - Dissection of a Bug Dataset: Anatomy of 395 Patches from Defects4J</summary>

- *Victor Sobreira, Thomas Durieux, Fernanda Madeiral, Martin Monperrus, Marcelo A. Maia*

- `1801.06393v3` - [abs](http://arxiv.org/abs/1801.06393v3) - [pdf](http://arxiv.org/pdf/1801.06393v3)

> Well-designed and publicly available datasets of bugs are an invaluable asset to advance research fields such as fault localization and program repair as they allow directly and fairly comparison between competing techniques and also the replication of experiments. These datasets need to be deeply understood by researchers: the answer for questions like "which bugs can my technique handle?" and "for which bugs is my technique effective?" depends on the comprehension of properties related to bugs and their patches. However, such properties are usually not included in the datasets, and there is still no widely adopted methodology for characterizing bugs and patches. In this work, we deeply study 395 patches of the Defects4J dataset. Quantitative properties (patch size and spreading) were automatically extracted, whereas qualitative ones (repair actions and patterns) were manually extracted using a thematic analysis-based approach. We found that 1) the median size of Defects4J patches is four lines, and almost 30% of the patches contain only addition of lines; 2) 92% of the patches change only one file, and 38% has no spreading at all; 3) the top-3 most applied repair actions are addition of method calls, conditionals, and assignments, occurring in 77% of the patches; and 4) nine repair patterns were found for 95% of the patches, where the most prevalent, appearing in 43% of the patches, is on conditional blocks. These results are useful for researchers to perform advanced analysis on their techniques' results based on Defects4J. Moreover, our set of properties can be used to characterize and compare different bug datasets.

</details>

<details>

<summary>2018-02-07 17:41:25 - Learning One Convolutional Layer with Overlapping Patches</summary>

- *Surbhi Goel, Adam Klivans, Raghu Meka*

- `1802.02547v1` - [abs](http://arxiv.org/abs/1802.02547v1) - [pdf](http://arxiv.org/pdf/1802.02547v1)

> We give the first provably efficient algorithm for learning a one hidden layer convolutional network with respect to a general class of (potentially overlapping) patches. Additionally, our algorithm requires only mild conditions on the underlying distribution. We prove that our framework captures commonly used schemes from computer vision, including one-dimensional and two-dimensional "patch and stride" convolutions.   Our algorithm-- $Convotron$ -- is inspired by recent work applying isotonic regression to learning neural networks. Convotron uses a simple, iterative update rule that is stochastic in nature and tolerant to noise (requires only that the conditional mean function is a one layer convolutional network, as opposed to the realizable setting). In contrast to gradient descent, Convotron requires no special initialization or learning-rate tuning to converge to the global optimum.   We also point out that learning one hidden convolutional layer with respect to a Gaussian distribution and just $one$ disjoint patch $P$ (the other patches may be arbitrary) is $easy$ in the following sense: Convotron can efficiently recover the hidden weight vector by updating $only$ in the direction of $P$.

</details>

<details>

<summary>2018-02-07 21:43:25 - Expressive power of recurrent neural networks</summary>

- *Valentin Khrulkov, Alexander Novikov, Ivan Oseledets*

- `1711.00811v2` - [abs](http://arxiv.org/abs/1711.00811v2) - [pdf](http://arxiv.org/pdf/1711.00811v2)

> Deep neural networks are surprisingly efficient at solving practical tasks, but the theory behind this phenomenon is only starting to catch up with the practice. Numerous works show that depth is the key to this efficiency. A certain class of deep convolutional networks -- namely those that correspond to the Hierarchical Tucker (HT) tensor decomposition -- has been proven to have exponentially higher expressive power than shallow networks. I.e. a shallow network of exponential width is required to realize the same score function as computed by the deep architecture. In this paper, we prove the expressive power theorem (an exponential lower bound on the width of the equivalent shallow network) for a class of recurrent neural networks -- ones that correspond to the Tensor Train (TT) decomposition. This means that even processing an image patch by patch with an RNN can be exponentially more efficient than a (shallow) convolutional network with one hidden layer. Using theoretical results on the relation between the tensor decompositions we compare expressive powers of the HT- and TT-Networks. We also implement the recurrent TT-Networks and provide numerical evidence of their expressivity.

</details>

<details>

<summary>2018-02-10 06:35:23 - Aurora: Providing Trusted System Services for Enclaves On an Untrusted System</summary>

- *Hongliang Liang, Mingyu Li, Qiong Zhang, Yue Yu, Lin Jiang, Yixiu Chen*

- `1802.03530v1` - [abs](http://arxiv.org/abs/1802.03530v1) - [pdf](http://arxiv.org/pdf/1802.03530v1)

> Intel SGX provisions shielded executions for security-sensitive computation, but lacks support for trusted system services (TSS), such as clock, network and filesystem. This makes \textit{enclaves} vulnerable to Iago attacks~\cite{DBLP:conf/asplos/CheckowayS13} in the face of a powerful malicious system. To mitigate this problem, we present Aurora, a novel architecture that provides TSSes via a secure channel between enclaves and devices on top of an untrusted system, and implement two types of TSSes, i.e. clock and end-to-end network. We evaluate our solution by porting SQLite and OpenSSL into Aurora, experimental results show that SQLite benefits from a \textit{microsecond} accuracy trusted clock and OpenSSL gains end-to-end secure network with about 1ms overhead.

</details>

<details>

<summary>2018-02-11 01:33:33 - Understanding Convolutional Networks with APPLE : Automatic Patch Pattern Labeling for Explanation</summary>

- *Sandeep Konam, Ian Quah, Stephanie Rosenthal, Manuela Veloso*

- `1802.03675v1` - [abs](http://arxiv.org/abs/1802.03675v1) - [pdf](http://arxiv.org/pdf/1802.03675v1)

> With the success of deep learning, recent efforts have been focused on analyzing how learned networks make their classifications. We are interested in analyzing the network output based on the network structure and information flow through the network layers. We contribute an algorithm for 1) analyzing a deep network to find neurons that are 'important' in terms of the network classification outcome, and 2)automatically labeling the patches of the input image that activate these important neurons. We propose several measures of importance for neurons and demonstrate that our technique can be used to gain insight into, and explain how a network decomposes an image to make its final classification.

</details>

<details>

<summary>2018-02-19 02:05:54 - Attributed Hierarchical Port Graphs and Applications</summary>

- *Nneka Chinelo Ene, Maribel Fernández, Bruno Pinaud*

- `1802.06492v1` - [abs](http://arxiv.org/abs/1802.06492v1) - [pdf](http://arxiv.org/pdf/1802.06492v1)

> We present attributed hierarchical port graphs (AHP) as an extension of port graphs that aims at facilitating the design of modular port graph models for complex systems. AHP consist of a number of interconnected layers, where each layer defines a port graph whose nodes may link to layers further down the hierarchy; attributes are used to store user-defined data as well as visualisation and run-time system parameters. We also generalise the notion of strategic port graph rewriting (a particular kind of graph transformation system, where port graph rewriting rules are controlled by user-defined strategies) to deal with AHP following the Single Push-out approach. We outline examples of application in two areas: functional programming and financial modelling.

</details>

<details>

<summary>2018-02-26 15:23:53 - VAE with a VampPrior</summary>

- *Jakub M. Tomczak, Max Welling*

- `1705.07120v5` - [abs](http://arxiv.org/abs/1705.07120v5) - [pdf](http://arxiv.org/pdf/1705.07120v5)

> Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call "Variational Mixture of Posteriors" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague VAEs. We provide empirical studies on six datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks.

</details>

<details>

<summary>2018-02-28 16:03:45 - Learning Discriminative Multilevel Structured Dictionaries for Supervised Image Classification</summary>

- *Jeremy Aghaei Mazaheri, Elif Vural, Claude Labit, Christine Guillemot*

- `1802.10497v1` - [abs](http://arxiv.org/abs/1802.10497v1) - [pdf](http://arxiv.org/pdf/1802.10497v1)

> Sparse representations using overcomplete dictionaries have proved to be a powerful tool in many signal processing applications such as denoising, super-resolution, inpainting, compression or classification. The sparsity of the representation very much depends on how well the dictionary is adapted to the data at hand. In this paper, we propose a method for learning structured multilevel dictionaries with discriminative constraints to make them well suited for the supervised pixelwise classification of images. A multilevel tree-structured discriminative dictionary is learnt for each class, with a learning objective concerning the reconstruction errors of the image patches around the pixels over each class-representative dictionary. After the initial assignment of the class labels to image pixels based on their sparse representations over the learnt dictionaries, the final classification is achieved by smoothing the label image with a graph cut method and an erosion method. Applied to a common set of texture images, our supervised classification method shows competitive results with the state of the art.

</details>

<details>

<summary>2018-02-28 17:08:26 - When is a Convolutional Filter Easy To Learn?</summary>

- *Simon S. Du, Jason D. Lee, Yuandong Tian*

- `1709.06129v2` - [abs](http://arxiv.org/abs/1709.06129v2) - [pdf](http://arxiv.org/pdf/1709.06129v2)

> We analyze the convergence of (stochastic) gradient descent algorithm for learning a convolutional filter with Rectified Linear Unit (ReLU) activation function. Our analysis does not rely on any specific form of the input distribution and our proofs only use the definition of ReLU, in contrast with previous works that are restricted to standard Gaussian input. We show that (stochastic) gradient descent with random initialization can learn the convolutional filter in polynomial time and the convergence rate depends on the smoothness of the input distribution and the closeness of patches. To the best of our knowledge, this is the first recovery guarantee of gradient-based algorithms for convolutional filter on non-Gaussian input distributions. Our theory also justifies the two-stage learning rate strategy in deep neural networks. While our focus is theoretical, we also present experiments that illustrate our theoretical findings.

</details>


## 2018-03

<details>

<summary>2018-03-01 12:49:11 - LaVAN: Localized and Visible Adversarial Noise</summary>

- *Danny Karmon, Daniel Zoran, Yoav Goldberg*

- `1801.02608v2` - [abs](http://arxiv.org/abs/1801.02608v2) - [pdf](http://arxiv.org/pdf/1801.02608v2)

> Most works on adversarial examples for deep-learning based image classifiers use noise that, while small, covers the entire image. We explore the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. We show that it is possible to generate localized adversarial noises that cover only 2% of the pixels in the image, none of them over the main object, and that are transferable across images and locations, and successfully fool a state-of-the-art Inception v3 model with very high success rates.

</details>

<details>

<summary>2018-03-02 12:59:50 - Towards a Question Answering System over the Semantic Web</summary>

- *Dennis Diefenbach, Andreas Both, Kamal Singh, Pierre Maret*

- `1803.00832v1` - [abs](http://arxiv.org/abs/1803.00832v1) - [pdf](http://arxiv.org/pdf/1803.00832v1)

> Thanks to the development of the Semantic Web, a lot of new structured data has become available on the Web in the form of knowledge bases (KBs). Making this valuable data accessible and usable for end-users is one of the main goals of Question Answering (QA) over KBs. Most current QA systems query one KB, in one language (namely English). The existing approaches are not designed to be easily adaptable to new KBs and languages. We first introduce a new approach for translating natural language questions to SPARQL queries. It is able to query several KBs simultaneously, in different languages, and can easily be ported to other KBs and languages. In our evaluation, the impact of our approach is proven using 5 different well-known and large KBs: Wikidata, DBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely English, German, French, Italian and Spanish. Second, we show how we integrated our approach, to make it easily accessible by the research community and by end-users. To summarize, we provided a conceptional solution for multilingual, KB-agnostic Question Answering over the Semantic Web. The provided first approximation validates this concept.

</details>

<details>

<summary>2018-03-06 01:35:01 - Learning Filter Bank Sparsifying Transforms</summary>

- *Luke Pfister, Yoram Bresler*

- `1803.01980v1` - [abs](http://arxiv.org/abs/1803.01980v1) - [pdf](http://arxiv.org/pdf/1803.01980v1)

> Data is said to follow the transform (or analysis) sparsity model if it becomes sparse when acted on by a linear operator called a sparsifying transform. Several algorithms have been designed to learn such a transform directly from data, and data-adaptive sparsifying transforms have demonstrated excellent performance in signal restoration tasks. Sparsifying transforms are typically learned using small sub-regions of data called patches, but these algorithms often ignore redundant information shared between neighboring patches.   We show that many existing transform and analysis sparse representations can be viewed as filter banks, thus linking the local properties of patch-based model to the global properties of a convolutional model. We propose a new transform learning framework where the sparsifying transform is an undecimated perfect reconstruction filter bank. Unlike previous transform learning algorithms, the filter length can be chosen independently of the number of filter bank channels. Numerical results indicate filter bank sparsifying transforms outperform existing patch-based transform learning for image denoising while benefiting from additional flexibility in the design process.

</details>

<details>

<summary>2018-03-06 08:28:18 - The Earth ain't Flat: Monocular Reconstruction of Vehicles on Steep and Graded Roads from a Moving Camera</summary>

- *Junaid Ahmed Ansari, Sarthak Sharma, Anshuman Majumdar, J. Krishna Murthy, K. Madhava Krishna*

- `1803.02057v1` - [abs](http://arxiv.org/abs/1803.02057v1) - [pdf](http://arxiv.org/pdf/1803.02057v1)

> Accurate localization of other traffic participants is a vital task in autonomous driving systems. State-of-the-art systems employ a combination of sensing modalities such as RGB cameras and LiDARs for localizing traffic participants, but most such demonstrations have been confined to plain roads. We demonstrate, to the best of our knowledge, the first results for monocular object localization and shape estimation on surfaces that do not share the same plane with the moving monocular camera. We approximate road surfaces by local planar patches and use semantic cues from vehicles in the scene to initialize a local bundle-adjustment like procedure that simultaneously estimates the pose and shape of the vehicles, and the orientation of the local ground plane on which the vehicle stands as well. We evaluate the proposed approach on the KITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations. The proposed approach significantly improves the state-of-the-art for monocular object localization on arbitrarily-shaped roads.

</details>

<details>

<summary>2018-03-10 05:31:31 - Large-Scale Analysis of Framework-Specific Exceptions in Android Apps</summary>

- *Lingling Fan, Ting Su, Sen Chen, Guozhu Meng, Yang Liu, Lihua Xu, Geguang Pu, Zhendong Su*

- `1801.07009v3` - [abs](http://arxiv.org/abs/1801.07009v3) - [pdf](http://arxiv.org/pdf/1801.07009v3)

> Mobile apps have become ubiquitous. For app developers, it is a key priority to ensure their apps' correctness and reliability. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to guide developers, or help improve testing and analysis tools. However, such studies do not exist -- this paper fills this gap. Over a four-month long effort, we have collected 16,245 unique exception traces from 2,486 open-source Android apps, and observed that framework-specific exceptions account for the majority of these crashes. We then extensively investigated the 8,243 framework-specific exceptions (which took six person-months): (1) identifying their characteristics (e.g., manifestation locations, common fault categories), (2) evaluating their manifestation via state-of-the-art bug detection techniques, and (3) reviewing their fixes. Besides the insights they provide, these findings motivate and enable follow-up research on mobile apps, such as bug detection, fault localization and patch generation. In addition, to demonstrate the utility of our findings, we have optimized Stoat, a dynamic testing tool, and implemented ExLocator, an exception localization tool, for Android apps. Stoat is able to quickly uncover three previously-unknown, confirmed/fixed crashes in Gmail and Google+; ExLocator is capable of precisely locating the root causes of identified exceptions in real-world apps. Our substantial dataset is made publicly available to share with and benefit the community.

</details>

<details>

<summary>2018-03-14 22:56:31 - Machine learning-assisted virtual patching of web applications</summary>

- *Gustavo Betarte, Eduardo Giménez, Rodrigo Martínez, Álvaro Pardo*

- `1803.05529v1` - [abs](http://arxiv.org/abs/1803.05529v1) - [pdf](http://arxiv.org/pdf/1803.05529v1)

> Web applications are permanently being exposed to attacks that exploit their vulnerabilities. In this work we investigate the application of machine learning techniques to leverage Web Application Firewall (WAF), a technology that is used to detect and prevent attacks. We propose a combined approach of machine learning models, based on one-class classification and n-gram analysis, to enhance the detection and accuracy capabilities of MODSECURITY, an open source and widely used WAF. The results are promising and outperform MODSECURITY when configured with the OWASP Core Rule Set, the baseline configuration setting of a widely deployed, rule-based WAF technology. The proposed solution, combining both approaches, allow us to deploy a WAF when no training data for the application is available (using one-class classification), and an improved one using n-grams when training data is available.

</details>

<details>

<summary>2018-03-20 01:54:20 - Acoustic feature learning using cross-domain articulatory measurements</summary>

- *Qingming Tang, Weiran Wang, Karen Livescu*

- `1803.06805v2` - [abs](http://arxiv.org/abs/1803.06805v2) - [pdf](http://arxiv.org/pdf/1803.06805v2)

> Previous work has shown that it is possible to improve speech recognition by learning acoustic features from paired acoustic-articulatory data, for example by using canonical correlation analysis (CCA) or its deep extensions. One limitation of this prior work is that the learned feature models are difficult to port to new datasets or domains, and articulatory data is not available for most speech corpora. In this work we study the problem of acoustic feature learning in the setting where we have access to an external, domain-mismatched dataset of paired speech and articulatory measurements, either with or without labels. We develop methods for acoustic feature learning in these settings, based on deep variational CCA and extensions that use both source and target domain data and labels. Using this approach, we improve phonetic recognition accuracies on both TIMIT and Wall Street Journal and analyze a number of design choices.

</details>

<details>

<summary>2018-03-20 17:17:39 - Stacked Neural Networks for end-to-end ciliary motion analysis</summary>

- *Charles Lu, M. Marx, M. Zahid, C. W. Lo, C. Chennubhotla, S. P. Quinn*

- `1803.07534v1` - [abs](http://arxiv.org/abs/1803.07534v1) - [pdf](http://arxiv.org/pdf/1803.07534v1)

> Cilia are hairlike structures protruding from nearly every cell in the body. Diseases known as ciliopathies, where cilia function is disrupted, can result in a wide spectrum of disorders. However, most techniques for assessing ciliary motion rely on manual identification and tracking of cilia; this process is laborious and error-prone, and does not scale well. Even where automated ciliary motion analysis tools exist, their applicability is limited. Here, we propose an end-to-end computational machine learning pipeline that automatically identifies regions of cilia from videos, extracts patches of cilia, and classifies patients as exhibiting normal or abnormal ciliary motion. In particular, we demonstrate how convolutional LSTM are able to encode complex features while remaining sensitive enough to differentiate between a variety of motion patterns. Our framework achieves 90% with only a few hundred training epochs. We find that the combination of segmentation and classification networks in a single pipeline yields performance comparable to existing computational pipelines, while providing the additional benefit of an end-to-end, fully-automated analysis toolbox for ciliary motion.

</details>

<details>

<summary>2018-03-27 10:20:03 - ΔBreakpad: Diversified Binary Crash Reporting</summary>

- *Bert Abrath, Bart Coppens, Mohit Mishra, Jens Van den Broeck, Bjorn De Sutter*

- `1705.00713v3` - [abs](http://arxiv.org/abs/1705.00713v3) - [pdf](http://arxiv.org/pdf/1705.00713v3)

> This paper introduces {\Delta}Breakpad. It extends the Breakpad crash reporting system to handle software diversity effectively and efficiently by replicating and patching the debug information of diversified software versions. Simple adaptations to existing open source compiler tools are presented that on the one hand introduce significant amounts of diversification in the code and stack layout of ARMv7 binaries to mitigate the widespread deployment of code injection and code reuse attacks, while on the other hand still supporting accurate crash reporting. An evaluation on SPEC2006 benchmarks demonstrates that the corresponding computational, storage, and communication overheads are small.

</details>

<details>

<summary>2018-03-28 17:07:18 - Pattern Analysis with Layered Self-Organizing Maps</summary>

- *David Friedlander*

- `1803.08996v2` - [abs](http://arxiv.org/abs/1803.08996v2) - [pdf](http://arxiv.org/pdf/1803.08996v2)

> This paper defines a new learning architecture, Layered Self-Organizing Maps (LSOMs), that uses the SOM and supervised-SOM learning algorithms. The architecture is validated with the MNIST database of hand-written digit images. LSOMs are similar to convolutional neural nets (covnets) in the way they sample data, but different in the way they represent features and learn. LSOMs analyze (or generate) image patches with maps of exemplars determined by the SOM learning algorithm rather than feature maps from filter-banks learned via backprop.   LSOMs provide an alternative to features derived from covnets. Multi-layer LSOMs are trained bottom-up, without the use of backprop and therefore may be of interest as a model of the visual cortex. The results show organization at multiple levels. The algorithm appears to be resource efficient in learning, classifying and generating images. Although LSOMs can be used for classification, their validation accuracy for these exploratory runs was well below the state of the art. The goal of this article is to define the architecture and display the structures resulting from its application to the MNIST images.

</details>

<details>

<summary>2018-03-28 22:14:26 - Improvements to context based self-supervised learning</summary>

- *T. Nathan Mundhenk, Daniel Ho, Barry Y. Chen*

- `1711.06379v3` - [abs](http://arxiv.org/abs/1711.06379v3) - [pdf](http://arxiv.org/pdf/1711.06379v3)

> We develop a set of methods to improve on the results of self-supervised learning using context. We start with a baseline of patch based arrangement context learning and go from there. Our methods address some overt problems such as chromatic aberration as well as other potential problems such as spatial skew and mid-level feature neglect. We prevent problems with testing generalization on common self-supervised benchmark tests by using different datasets during our development. The results of our methods combined yield top scores on all standard self-supervised benchmarks, including classification and detection on PASCAL VOC 2007, segmentation on PASCAL VOC 2012, and "linear tests" on the ImageNet and CSAIL Places datasets. We obtain an improvement over our baseline method of between 4.0 to 7.1 percentage points on transfer learning classification tests. We also show results on different standard network architectures to demonstrate generalization as well as portability. All data, models and programs are available at: https://gdo-datasci.llnl.gov/selfsupervised/.

</details>

<details>

<summary>2018-03-30 09:51:04 - Contrast-Oriented Deep Neural Networks for Salient Object Detection</summary>

- *Guanbin Li, Yizhou Yu*

- `1803.11395v1` - [abs](http://arxiv.org/abs/1803.11395v1) - [pdf](http://arxiv.org/pdf/1803.11395v1)

> Deep convolutional neural networks have become a key element in the recent breakthrough of salient object detection. However, existing CNN-based methods are based on either patch-wise (region-wise) training and inference or fully convolutional networks. Methods in the former category are generally time-consuming due to severe storage and computational redundancies among overlapping patches. To overcome this deficiency, methods in the second category attempt to directly map a raw input image to a predicted dense saliency map in a single network forward pass. Though being very efficient, it is arduous for these methods to detect salient objects of different scales or salient regions with weak semantic information. In this paper, we develop hybrid contrast-oriented deep neural networks to overcome the aforementioned limitations. Each of our deep networks is composed of two complementary components, including a fully convolutional stream for dense prediction and a segment-level spatial pooling stream for sparse saliency inference. We further propose an attentional module that learns weight maps for fusing the two saliency predictions from these two streams. A tailored alternate scheme is designed to train these deep networks by fine-tuning pre-trained baseline models. Finally, a customized fully connected CRF model incorporating a salient contour feature embedding can be optionally applied as a post-processing step to improve spatial coherence and contour positioning in the fused result from these two streams. Extensive experiments on six benchmark datasets demonstrate that our proposed model can significantly outperform the state of the art in terms of all popular evaluation metrics.

</details>


## 2018-04

<details>

<summary>2018-04-04 12:00:22 - Analysing and Patching SPEKE in ISO/IEC</summary>

- *Feng Hao, Roberto Metere, Siamak F. Shahandashti, Changyu Dong*

- `1802.04900v2` - [abs](http://arxiv.org/abs/1802.04900v2) - [pdf](http://arxiv.org/pdf/1802.04900v2)

> Simple Password Exponential Key Exchange (SPEKE) is a well-known Password Authenticated Key Exchange (PAKE) protocol that has been used in Blackberry phones for secure messaging and Entrust's TruePass end-to-end web products. It has also been included into international standards such as ISO/IEC 11770-4 and IEEE P1363.2. In this paper, we analyse the SPEKE protocol as specified in the ISO/IEC and IEEE standards. We identify that the protocol is vulnerable to two new attacks: an impersonation attack that allows an attacker to impersonate a user without knowing the password by launching two parallel sessions with the victim, and a key-malleability attack that allows a man-in-the-middle (MITM) to manipulate the session key without being detected by the end users. Both attacks have been acknowledged by the technical committee of ISO/IEC SC 27, and ISO/IEC 11770-4 revised as a result. We propose a patched SPEKE called P-SPEKE and present a formal analysis in the Applied Pi Calculus using ProVerif to show that the proposed patch prevents both attacks. The proposed patch has been included into the latest revision of ISO/IEC 11770-4 published in 2017.

</details>

<details>

<summary>2018-04-06 22:06:25 - Optimisation of Least Squares Algorithm: A Study of Frame Based Programming Techniques in Horizontal Networks</summary>

- *C. P. E. Agbachi*

- `1804.05665v1` - [abs](http://arxiv.org/abs/1804.05665v1) - [pdf](http://arxiv.org/pdf/1804.05665v1)

> Least squares estimation, a regression technique based on minimisation of residuals, has been invaluable in bringing the best fit solutions to parameters in science and engineering. However, in dynamic environments such as in Geomatics Engineering, formation of these equations can be very challenging. And these constraints are ported and apparent in most program models, requiring users at ease with the subject matter. This paper reviews the methods of least squares approximation and examines a one-step automated approach, with error analysis, through the instrumentality of frames, object oriented programming.

</details>

<details>

<summary>2018-04-10 01:26:27 - Modeling Semantic Plausibility by Injecting World Knowledge</summary>

- *Su Wang, Greg Durrett, Katrin Erk*

- `1804.00619v3` - [abs](http://arxiv.org/abs/1804.00619v3) - [pdf](http://arxiv.org/pdf/1804.00619v3)

> Distributional data tells us that a man can swallow candy, but not that a man can swallow a paintball, since this is never attested. However both are physically plausible events. This paper introduces the task of semantic plausibility: recognizing plausible but possibly novel events. We present a new crowdsourced dataset of semantic plausibility judgments of single events such as "man swallow paintball". Simple models based on distributional representations perform poorly on this task, despite doing well on selection preference, but injecting manually elicited knowledge about entity properties provides a substantial performance boost. Our error analysis shows that our new dataset is a great testbed for semantic plausibility models: more sophisticated knowledge representation and propagation could address many of the remaining errors.

</details>

<details>

<summary>2018-04-10 09:55:10 - Evaluating Scoped Meaning Representations</summary>

- *Rik van Noord, Lasha Abzianidze, Hessel Haagsma, Johan Bos*

- `1802.08599v2` - [abs](http://arxiv.org/abs/1802.08599v2) - [pdf](http://arxiv.org/pdf/1802.08599v2)

> Semantic parsing offers many opportunities to improve natural language understanding. We present a semantically annotated parallel corpus for English, German, Italian, and Dutch where sentences are aligned with scoped meaning representations in order to capture the semantics of negation, modals, quantification, and presupposition triggers. The semantic formalism is based on Discourse Representation Theory, but concepts are represented by WordNet synsets and thematic roles by VerbNet relations. Translating scoped meaning representations to sets of clauses enables us to compare them for the purpose of semantic parser evaluation and checking translations. This is done by computing precision and recall on matching clauses, in a similar way as is done for Abstract Meaning Representations. We show that our matching tool for evaluating scoped meaning representations is both accurate and efficient. Applying this matching tool to three baseline semantic parsers yields F-scores between 43% and 54%. A pilot study is performed to automatically find changes in meaning by comparing meaning representations of translations. This comparison turns out to be an additional way of (i) finding annotation mistakes and (ii) finding instances where our semantic analysis needs to be improved.

</details>

<details>

<summary>2018-04-10 12:59:53 - Exploring Disentangled Feature Representation Beyond Face Identification</summary>

- *Yu Liu, Fangyin Wei, Jing Shao, Lu Sheng, Junjie Yan, Xiaogang Wang*

- `1804.03487v1` - [abs](http://arxiv.org/abs/1804.03487v1) - [pdf](http://arxiv.org/pdf/1804.03487v1)

> This paper proposes learning disentangled but complementary face features with minimal supervision by face identification. Specifically, we construct an identity Distilling and Dispelling Autoencoder (D2AE) framework that adversarially learns the identity-distilled features for identity verification and the identity-dispelled features to fool the verification system. Thanks to the design of two-stream cues, the learned disentangled features represent not only the identity or attribute but the complete input image. Comprehensive evaluations further demonstrate that the proposed features not only maintain state-of-the-art identity verification performance on LFW, but also acquire competitive discriminative power for face attribute recognition on CelebA and LFWA. Moreover, the proposed system is ready to semantically control the face generation/editing based on various identities and attributes in an unsupervised manner.

</details>

<details>

<summary>2018-04-10 15:01:50 - Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip Systems</summary>

- *Zihao Xiao, Jianfei Chen, Jun Zhu*

- `1804.03578v1` - [abs](http://arxiv.org/abs/1804.03578v1) - [pdf](http://arxiv.org/pdf/1804.03578v1)

> Probabilistic topic models are popular unsupervised learning methods, including probabilistic latent semantic indexing (pLSI) and latent Dirichlet allocation (LDA). By now, their training is implemented on general purpose computers (GPCs), which are flexible in programming but energy-consuming. Towards low-energy implementations, this paper investigates their training on an emerging hardware technology called the neuromorphic multi-chip systems (NMSs). NMSs are very effective for a family of algorithms called spiking neural networks (SNNs). We present three SNNs to train topic models. The first SNN is a batch algorithm combining the conventional collapsed Gibbs sampling (CGS) algorithm and an inference SNN to train LDA. The other two SNNs are online algorithms targeting at both energy- and storage-limited environments. The two online algorithms are equivalent with training LDA by using maximum-a-posterior estimation and maximizing the semi-collapsed likelihood, respectively. They use novel, tailored ordinary differential equations for stochastic optimization. We simulate the new algorithms and show that they are comparable with the GPC algorithms, while being suitable for NMS implementation. We also propose an extension to train pLSI and a method to prune the network to obey the limited fan-in of some NMSs.

</details>

<details>

<summary>2018-04-10 15:59:45 - Imagine This! Scripts to Compositions to Videos</summary>

- *Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, Aniruddha Kembhavi*

- `1804.03608v1` - [abs](http://arxiv.org/abs/1804.03608v1) - [pdf](http://arxiv.org/pdf/1804.03608v1)

> Imagining a scene described in natural language with realistic layout and appearance of entities is the ultimate test of spatial, visual, and semantic world knowledge. Towards this goal, we present the Composition, Retrieval, and Fusion Network (CRAFT), a model capable of learning this knowledge from video-caption data and applying it while generating videos from novel captions. CRAFT explicitly predicts a temporal-layout of mentioned entities (characters and objects), retrieves spatio-temporal entity segments from a video database and fuses them to generate scene videos. Our contributions include sequential training of components of CRAFT while jointly modeling layout and appearances, and losses that encourage learning compositional representations for retrieval. We evaluate CRAFT on semantic fidelity to caption, composition consistency, and visual quality. CRAFT outperforms direct pixel generation approaches and generalizes well to unseen captions and to unseen video databases with no text annotations. We demonstrate CRAFT on FLINTSTONES, a new richly annotated video-caption dataset with over 25000 videos. For a glimpse of videos generated by CRAFT, see https://youtu.be/688Vv86n0z8.

</details>

<details>

<summary>2018-04-10 17:05:53 - Probabilistic Prediction of Vehicle Semantic Intention and Motion</summary>

- *Yeping Hu, Wei Zhan, Masayoshi Tomizuka*

- `1804.03629v1` - [abs](http://arxiv.org/abs/1804.03629v1) - [pdf](http://arxiv.org/pdf/1804.03629v1)

> Accurately predicting the possible behaviors of traffic participants is an essential capability for future autonomous vehicles. The majority of current researches fix the number of driving intentions by considering only a specific scenario. However, distinct driving environments usually contain various possible driving maneuvers. Therefore, a intention prediction method that can adapt to different traffic scenarios is needed. To further improve the overall vehicle prediction performance, motion information is usually incorporated with classified intentions. As suggested in some literature, the methods that directly predict possible goal locations can achieve better performance for long-term motion prediction than other approaches due to their automatic incorporation of environment constraints. Moreover, by obtaining the temporal information of the predicted destinations, the optimal trajectories for predicted vehicles as well as the desirable path for ego autonomous vehicle could be easily generated. In this paper, we propose a Semantic-based Intention and Motion Prediction (SIMP) method, which can be adapted to any driving scenarios by using semantic-defined vehicle behaviors. It utilizes a probabilistic framework based on deep neural network to estimate the intentions, final locations, and the corresponding time information for surrounding vehicles. An exemplar real-world scenario was used to implement and examine the proposed method.

</details>

<details>

<summary>2018-04-10 17:26:54 - Semantic embeddings for program behavior patterns</summary>

- *Alexander Chistyakov, Ekaterina Lobacheva, Arseny Kuznetsov, Alexey Romanenko*

- `1804.03635v1` - [abs](http://arxiv.org/abs/1804.03635v1) - [pdf](http://arxiv.org/pdf/1804.03635v1)

> In this paper, we propose a new feature extraction technique for program execution logs. First, we automatically extract complex patterns from a program's behavior graph. Then, we embed these patterns into a continuous space by training an autoencoder. We evaluate the proposed features on a real-world malicious software detection task. We also find that the embedding space captures interpretable structures in the space of pattern parts.

</details>

<details>

<summary>2018-04-10 21:29:10 - Any-k: Anytime Top-k Tree Pattern Retrieval in Labeled Graphs</summary>

- *Xiaofeng Yang, Deepak Ajwani, Wolfgang Gatterbauer, Patrick K. Nicholson, Mirek Riedewald, Alessandra Sala*

- `1802.06060v3` - [abs](http://arxiv.org/abs/1802.06060v3) - [pdf](http://arxiv.org/pdf/1802.06060v3)

> Many problems in areas as diverse as recommendation systems, social network analysis, semantic search, and distributed root cause analysis can be modeled as pattern search on labeled graphs (also called "heterogeneous information networks" or HINs). Given a large graph and a query pattern with node and edge label constraints, a fundamental challenge is to nd the top-k matches ac- cording to a ranking function over edge and node weights. For users, it is di cult to select value k . We therefore propose the novel notion of an any-k ranking algorithm: for a given time budget, re- turn as many of the top-ranked results as possible. Then, given additional time, produce the next lower-ranked results quickly as well. It can be stopped anytime, but may have to continues until all results are returned. This paper focuses on acyclic patterns over arbitrary labeled graphs. We are interested in practical algorithms that effectively exploit (1) properties of heterogeneous networks, in particular selective constraints on labels, and (2) that the users often explore only a fraction of the top-ranked results. Our solution, KARPET, carefully integrates aggressive pruning that leverages the acyclic nature of the query, and incremental guided search. It enables us to prove strong non-trivial time and space guarantees, which is generally considered very hard for this type of graph search problem. Through experimental studies we show that KARPET achieves running times in the order of milliseconds for tree patterns on large networks with millions of nodes and edges.

</details>

<details>

<summary>2018-04-11 00:34:01 - A Semantic QA-Based Approach for Text Summarization Evaluation</summary>

- *Ping Chen, Fei Wu, Tong Wang, Wei Ding*

- `1704.06259v2` - [abs](http://arxiv.org/abs/1704.06259v2) - [pdf](http://arxiv.org/pdf/1704.06259v2)

> Many Natural Language Processing and Computational Linguistics applications involves the generation of new texts based on some existing texts, such as summarization, text simplification and machine translation. However, there has been a serious problem haunting these applications for decades, that is, how to automatically and accurately assess quality of these applications. In this paper, we will present some preliminary results on one especially useful and challenging problem in NLP system evaluation: how to pinpoint content differences of two text passages (especially for large pas-sages such as articles and books). Our idea is intuitive and very different from existing approaches. We treat one text passage as a small knowledge base, and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, we will be able to compare their content precisely. The experiment using 2007 DUC summarization corpus clearly shows promising results.

</details>

<details>

<summary>2018-04-11 09:19:09 - A web service based on RESTful API and JSON Schema/JSON Meta Schema to construct knowledge graphs</summary>

- *Adam Agocs, Jean-Marie Le Goff*

- `1804.03887v1` - [abs](http://arxiv.org/abs/1804.03887v1) - [pdf](http://arxiv.org/pdf/1804.03887v1)

> Data visualisation assists domain experts in understanding their data and helps them make critical decisions. Enhancing their cognitive insight essentially relies on the capability of combining domain-specific semantic information with concepts extracted out of the data and visualizing the resulting networks. Data scientists have the challenge of providing tools able to handle the overall network lifecycle. In this paper, we present how the combination of two powerful technologies namely the REST architecture style and JSON Schema/JSON Meta Schema enable data scientists to use a RESTful web service that permits the construction of knowledge graphs, one of the preferred representations of large and semantically rich networks.

</details>

<details>

<summary>2018-04-11 13:28:07 - Data Augmentation by Pairing Samples for Images Classification</summary>

- *Hiroshi Inoue*

- `1801.02929v2` - [abs](http://arxiv.org/abs/1801.02929v2) - [pdf](http://arxiv.org/pdf/1801.02929v2)

> Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate $N^2$ new samples from $N$ training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.

</details>

<details>

<summary>2018-04-11 13:48:08 - Emergent Communication through Negotiation</summary>

- *Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls, Stephen Clark*

- `1804.03980v1` - [abs](http://arxiv.org/abs/1804.03980v1) - [pdf](http://arxiv.org/pdf/1804.03980v1)

> Multi-agent reinforcement learning offers a way to study how communication could emerge in communities of agents needing to solve specific problems. In this paper, we study the emergence of communication in the negotiation environment, a semi-cooperative model of agent interaction. We introduce two communication protocols -- one grounded in the semantics of the game, and one which is \textit{a priori} ungrounded and is a form of cheap talk. We show that self-interested agents can use the pre-grounded communication channel to negotiate fairly, but are unable to effectively use the ungrounded channel. However, prosocial agents do learn to use cheap talk to find an optimal negotiating strategy, suggesting that cooperation is necessary for language to emerge. We also study communication behaviour in a setting where one agent interacts with agents in a community with different levels of prosociality and show how agent identifiability can aid negotiation.

</details>

<details>

<summary>2018-04-11 19:12:41 - An Easy & Collaborative RDF Data Entry Method using the Spreadsheet Metaphor</summary>

- *Markus Schröder, Christian Jilek, Jörn Hees, Sven Hertling, Andreas Dengel*

- `1804.04175v1` - [abs](http://arxiv.org/abs/1804.04175v1) - [pdf](http://arxiv.org/pdf/1804.04175v1)

> Spreadsheets are widely used by knowledge workers, especially in the industrial sector. Their methodology enables a well understood, easy and fast possibility to enter data. As filling out a spreadsheet is more accessible to common knowledge workers than defining RDF statements, in this paper, we propose an easy-to-use, zero-configuration, web-based spreadsheet editor that simultaneously transfers spreadsheet entries into RDF statements. It enables various kinds of users to easily create semantic data whether they are RDF experts or novices. The typical scenario we address focuses on creating instance data starting with an empty knowledge base that is filled incrementally. In a user study, participants were able to create more statements in shorter time, having similar or even significantly outperforming quality, compared to other approaches.

</details>

<details>

<summary>2018-04-11 20:23:23 - Learning Topics using Semantic Locality</summary>

- *Ziyi Zhao, Krittaphat Pugdeethosapol, Sheng Lin, Zhe Li, Caiwen Ding, Yanzhi Wang, Qinru Qiu*

- `1804.04205v1` - [abs](http://arxiv.org/abs/1804.04205v1) - [pdf](http://arxiv.org/pdf/1804.04205v1)

> The topic modeling discovers the latent topic probability of the given text documents. To generate the more meaningful topic that better represents the given document, we proposed a new feature extraction technique which can be used in the data preprocessing stage. The method consists of three steps. First, it generates the word/word-pair from every single document. Second, it applies a two-way TF-IDF algorithm to word/word-pair for semantic filtering. Third, it uses the K-means algorithm to merge the word pairs that have the similar semantic meaning.   Experiments are carried out on the Open Movie Database (OMDb), Reuters Dataset and 20NewsGroup Dataset. The mean Average Precision score is used as the evaluation metric. Comparing our results with other state-of-the-art topic models, such as Latent Dirichlet allocation and traditional Restricted Boltzmann Machines. Our proposed data preprocessing can improve the generated topic accuracy by up to 12.99\%.

</details>

<details>

<summary>2018-04-12 00:23:21 - Design and Implementation of Dynamic Memory Management in a Reversible Object-Oriented Programming Language</summary>

- *Martin Holm Cservenka*

- `1804.05097v1` - [abs](http://arxiv.org/abs/1804.05097v1) - [pdf](http://arxiv.org/pdf/1804.05097v1)

> The reversible object-oriented programming language (ROOPL) was presented in late 2016 and proved that object-oriented programming paradigms works in the reversible setting. The language featured simple statically scoped objects which made non-trivial programs tedious, if not impossible to write using the limited tools provided. We introduce an extension to ROOPL in form the new language ROOPL++, featuring dynamic memory management and fixed-sized arrays for increased language expressiveness. The language is a superset of ROOPL and has formally been defined by its language semantics, type system and computational universality. Considerations for reversible memory manager layouts are discussed and ultimately lead to the selection of the Buddy Memory layout. Translations of the extensions added in ROOPL++ to the reversible assembly language PISA are presented to provide garbage-free computations. The dynamic memory management extension successfully increases the expressiveness of ROOPL and as a result, shows that non-trivial reversible data structures, such as binary trees and doubly-linked lists, are feasible and do not contradict the reversible computing paradigm.

</details>

<details>

<summary>2018-04-12 00:25:45 - Training a Ranking Function for Open-Domain Question Answering</summary>

- *Phu Mon Htut, Samuel R. Bowman, Kyunghyun Cho*

- `1804.04264v1` - [abs](http://arxiv.org/abs/1804.04264v1) - [pdf](http://arxiv.org/pdf/1804.04264v1)

> In recent years, there have been amazing advances in deep learning methods for machine reading. In machine reading, the machine reader has to extract the answer from the given ground truth paragraph. Recently, the state-of-the-art machine reading models achieve human level performance in SQuAD which is a reading comprehension-style question answering (QA) task. The success of machine reading has inspired researchers to combine information retrieval with machine reading to tackle open-domain QA. However, these systems perform poorly compared to reading comprehension-style QA because it is difficult to retrieve the pieces of paragraphs that contain the answer to the question. In this study, we propose two neural network rankers that assign scores to different passages based on their likelihood of containing the answer to a given question. Additionally, we analyze the relative importance of semantic similarity and word level relevance matching in open-domain QA.

</details>

<details>

<summary>2018-04-12 07:30:19 - Clear as MUD: Generating, Validating and Applying IoT Behaviorial Profiles (Technical Report)</summary>

- *Ayyoob Hamza, Dinesha Ranathunga, H. Habibi Gharakheili, Matthew Roughan, Vijay Sivaraman*

- `1804.04358v1` - [abs](http://arxiv.org/abs/1804.04358v1) - [pdf](http://arxiv.org/pdf/1804.04358v1)

> IoT devices are increasingly being implicated in cyber-attacks, driving community concern about the risks they pose to critical infrastructure, corporations, and citizens. In order to reduce this risk, the IETF is pushing IoT vendors to develop formal specifications of the intended purpose of their IoT devices, in the form of a Manufacturer Usage Description (MUD), so that their network behavior in any operating environment can be locked down and verified rigorously.   This paper aims to assist IoT manufacturers in developing and verifying MUD profiles, while also helping adopters of these devices to ensure they are compatible with their organizational policies. Our first contribution is to develop a tool that takes the traffic trace of an arbitrary IoT device as input and automatically generates a MUD profile for it. We contribute our tool as open source, apply it to 28 consumer IoT devices, and highlight insights and challenges encountered in the process. Our second contribution is to apply a formal semantic framework that not only validates a given MUD profile for consistency, but also checks its compatibility with a given organizational policy. Finally, we apply our framework to representative organizations and selected devices, to demonstrate how MUD can reduce the effort needed for IoT acceptance testing.

</details>

<details>

<summary>2018-04-12 09:04:50 - Amobee at SemEval-2018 Task 1: GRU Neural Network with a CNN Attention Mechanism for Sentiment Classification</summary>

- *Alon Rozental, Daniel Fleischer*

- `1804.04380v1` - [abs](http://arxiv.org/abs/1804.04380v1) - [pdf](http://arxiv.org/pdf/1804.04380v1)

> This paper describes the participation of Amobee in the shared sentiment analysis task at SemEval 2018. We participated in all the English sub-tasks and the Spanish valence tasks. Our system consists of three parts: training task-specific word embeddings, training a model consisting of gated-recurrent-units (GRU) with a convolution neural network (CNN) attention mechanism and training stacking-based ensembles for each of the sub-tasks. Our algorithm reached 3rd and 1st places in the valence ordinal classification sub-tasks in English and Spanish, respectively.

</details>

<details>

<summary>2018-04-12 14:12:48 - EventKG: A Multilingual Event-Centric Temporal Knowledge Graph</summary>

- *Simon Gottschalk, Elena Demidova*

- `1804.04526v1` - [abs](http://arxiv.org/abs/1804.04526v1) - [pdf](http://arxiv.org/pdf/1804.04526v1)

> One of the key requirements to facilitate semantic analytics of information regarding contemporary and historical events on the Web, in the news and in social media is the availability of reference knowledge repositories containing comprehensive representations of events and temporal relations. Existing knowledge graphs, with popular examples including DBpedia, YAGO and Wikidata, focus mostly on entity-centric information and are insufficient in terms of their coverage and completeness with respect to events and temporal relations. EventKG presented in this paper is a multilingual event-centric temporal knowledge graph that addresses this gap. EventKG incorporates over 690 thousand contemporary and historical events and over 2.3 million temporal relations extracted from several large-scale knowledge graphs and semi-structured sources and makes them available through a canonical representation.

</details>

<details>

<summary>2018-04-12 19:09:05 - Neural Sketch Learning for Conditional Program Generation</summary>

- *Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, Chris Jermaine*

- `1703.05698v5` - [abs](http://arxiv.org/abs/1703.05698v5) - [pdf](http://arxiv.org/pdf/1703.05698v5)

> We study the problem of generating source code in a strongly typed, Java-like programming language, given a label (for example a set of API calls or types) carrying a small amount of information about the code that is desired. The generated programs are expected to respect a "realistic" relationship between programs and labels, as exemplified by a corpus of labeled programs available during training.   Two challenges in such conditional program generation are that the generated programs must satisfy a rich set of syntactic and semantic constraints, and that source code contains many low-level features that impede learning. We address these problems by training a neural generator not on code but on program sketches, or models of program syntax that abstract out names and operations that do not generalize across programs. During generation, we infer a posterior distribution over sketches, then concretize samples from this distribution into type-safe programs using combinatorial techniques. We implement our ideas in a system for generating API-heavy Java code, and show that it can often predict the entire body of a method given just a few API calls or data types that appear in the method.

</details>

<details>

<summary>2018-04-13 06:53:00 - Active Learning for Efficient Testing of Student Programs</summary>

- *Ishan Rastogi, Aditya Kanade, Shirish Shevade*

- `1804.05655v1` - [abs](http://arxiv.org/abs/1804.05655v1) - [pdf](http://arxiv.org/pdf/1804.05655v1)

> In this work, we propose an automated method to identify semantic bugs in student programs, called ATAS, which builds upon the recent advances in both symbolic execution and active learning. Symbolic execution is a program analysis technique which can generate test cases through symbolic constraint solving. Our method makes use of a reference implementation of the task as its sole input. We compare our method with a symbolic execution-based baseline on 6 programming tasks retrieved from CodeForces comprising a total of 23K student submissions. We show an average improvement of over 2.5x over the baseline in terms of runtime (thus making it more suitable for online evaluation), without a significant degradation in evaluation accuracy.

</details>

<details>

<summary>2018-04-13 07:20:44 - μ-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching</summary>

- *Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka*

- `1804.04806v1` - [abs](http://arxiv.org/abs/1804.04806v1) - [pdf](http://arxiv.org/pdf/1804.04806v1)

> NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used in deep learning. Specifically, cuDNN implements several equivalent convolution algorithms, whose performance and memory footprint may vary considerably, depending on the layer dimensions. When an algorithm is automatically selected by cuDNN, the decision is performed on a per-layer basis, and thus it often resorts to slower algorithms that fit the workspace size constraints. We present {\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides layers' mini-batch computation into several micro-batches. Based on Dynamic Programming and Integer Linear Programming, {\mu}-cuDNN enables faster algorithms by decreasing the workspace requirements. At the same time, {\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples statistical efficiency from the hardware efficiency safely. We demonstrate the effectiveness of {\mu}-cuDNN over two frameworks, Caffe and TensorFlow, achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2 GPU. These results indicate that using micro-batches can seamlessly increase the performance of deep learning, while maintaining the same memory footprint.

</details>

<details>

<summary>2018-04-13 10:30:44 - Local Word Vectors Guiding Keyphrase Extraction</summary>

- *Eirini Papagiannopoulou, Grigorios Tsoumakas*

- `1710.07503v4` - [abs](http://arxiv.org/abs/1710.07503v4) - [pdf](http://arxiv.org/pdf/1710.07503v4)

> Automated keyphrase extraction is a fundamental textual information processing task concerned with the selection of representative phrases from a document that summarize its content. This work presents a novel unsupervised method for keyphrase extraction, whose main innovation is the use of local word embeddings (in particular GloVe vectors), i.e., embeddings trained from the single document under consideration. We argue that such local representation of words and keyphrases are able to accurately capture their semantics in the context of the document they are part of, and therefore can help in improving keyphrase extraction quality. Empirical results offer evidence that indeed local representations lead to better keyphrase extraction results compared to both embeddings trained on very large third corpora or larger corpora consisting of several documents of the same scientific field and to other state-of-the-art unsupervised keyphrase extraction methods.

</details>

<details>

<summary>2018-04-13 16:10:18 - Enhanced Word Representations for Bridging Anaphora Resolution</summary>

- *Yufang Hou*

- `1803.04790v2` - [abs](http://arxiv.org/abs/1803.04790v2) - [pdf](http://arxiv.org/pdf/1803.04790v2)

> Most current models of word representations(e.g.,GloVe) have successfully captured fine-grained semantics. However, semantic similarity exhibited in these word embeddings is not suitable for resolving bridging anaphora, which requires the knowledge of associative similarity (i.e., relatedness) instead of semantic similarity information between synonyms or hypernyms. We create word embeddings (embeddings_PP) to capture such relatedness by exploring the syntactic structure of noun phrases. We demonstrate that using embeddings_PP alone achieves around 30% of accuracy for bridging anaphora resolution on the ISNotes corpus. Furthermore, we achieve a substantial gain over the state-of-the-art system (Hou et al., 2013) for bridging antecedent selection.

</details>

<details>

<summary>2018-04-15 02:21:28 - The EcoLexicon Semantic Sketch Grammar: from Knowledge Patterns to Word Sketches</summary>

- *P. León-Araúz, A. San Martín*

- `1804.05294v1` - [abs](http://arxiv.org/abs/1804.05294v1) - [pdf](http://arxiv.org/pdf/1804.05294v1)

> Many projects have applied knowledge patterns (KPs) to the retrieval of specialized information. Yet terminologists still rely on manual analysis of concordance lines to extract semantic information, since there are no user-friendly publicly available applications enabling them to find knowledge rich contexts (KRCs). To fill this void, we have created the KP-based EcoLexicon Semantic SketchGrammar (ESSG) in the well-known corpus query system Sketch Engine. For the first time, the ESSG is now publicly available inSketch Engine to query the EcoLexicon English Corpus. Additionally, reusing the ESSG in any English corpus uploaded by the user enables Sketch Engine to extract KRCs codifying generic-specific, part-whole, location, cause and function relations, because most of the KPs are domain-independent. The information is displayed in the form of summary lists (word sketches) containing the pairs of terms linked by a given semantic relation. This paper describes the process of building a KP-based sketch grammar with special focus on the last stage, namely, the evaluation with refinement purposes. We conducted an initial shallow precision and recall evaluation of the 64 English sketch grammar rules created so far for hyponymy, meronymy and causality. Precision was measured based on a random sample of concordances extracted from each word sketch type. Recall was assessed based on a random sample of concordances where known term pairs are found. The results are necessary for the improvement and refinement of the ESSG. The noise of false positives helped to further specify the rules, whereas the silence of false negatives allows us to find useful new patterns.

</details>

<details>

<summary>2018-04-15 05:50:27 - Transcribing Lyrics From Commercial Song Audio: The First Step Towards Singing Content Processing</summary>

- *Che-Ping Tsai, Yi-Lin Tuan, Lin-shan Lee*

- `1804.05306v1` - [abs](http://arxiv.org/abs/1804.05306v1) - [pdf](http://arxiv.org/pdf/1804.05306v1)

> Spoken content processing (such as retrieval and browsing) is maturing, but the singing content is still almost completely left out. Songs are human voice carrying plenty of semantic information just as speech, and may be considered as a special type of speech with highly flexible prosody. The various problems in song audio, for example the significantly changing phone duration over highly flexible pitch contours, make the recognition of lyrics from song audio much more difficult. This paper reports an initial attempt towards this goal. We collected music-removed version of English songs directly from commercial singing content. The best results were obtained by TDNN-LSTM with data augmentation with 3-fold speed perturbation plus some special approaches. The WER achieved (73.90%) was significantly lower than the baseline (96.21%), but still relatively high.

</details>

<details>

<summary>2018-04-15 21:48:28 - What Happened? Leveraging VerbNet to Predict the Effects of Actions in Procedural Text</summary>

- *Peter Clark, Bhavana Dalvi, Niket Tandon*

- `1804.05435v1` - [abs](http://arxiv.org/abs/1804.05435v1) - [pdf](http://arxiv.org/pdf/1804.05435v1)

> Our goal is to answer questions about paragraphs describing processes (e.g., photosynthesis). Texts of this genre are challenging because the effects of actions are often implicit (unstated), requiring background knowledge and inference to reason about the changing world states. To supply this knowledge, we leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the preconditions and effects of actions, and use it along with commonsense knowledge of persistence to answer questions about change. Our evaluation shows that our system, ProComp, significantly outperforms two strong reading comprehension (RC) baselines. Our contributions are two-fold: the Semantic Lexicon rulebase itself, and a demonstration of how a simulation-based approach to machine reading can outperform RC methods that rely on surface cues alone.   Since this work was performed, we have developed neural systems that outperform ProComp, described elsewhere (Dalvi et al., NAACL'18). However, the Semantic Lexicon remains a novel and potentially useful resource, and its integration with neural systems remains a currently unexplored opportunity for further improvements in machine reading about processes.

</details>

<details>

<summary>2018-04-16 03:17:34 - Locally Adaptive Learning Loss for Semantic Image Segmentation</summary>

- *Jinjiang Guo, Pengyuan Ren, Aiguo Gu, Jian Xu, Weixin Wu*

- `1802.08290v2` - [abs](http://arxiv.org/abs/1802.08290v2) - [pdf](http://arxiv.org/pdf/1802.08290v2)

> We propose a novel locally adaptive learning estimator for enhancing the inter- and intra- discriminative capabilities of Deep Neural Networks, which can be used as improved loss layer for semantic image segmentation tasks. Most loss layers compute pixel-wise cost between feature maps and ground truths, ignoring spatial layouts and interactions between neighboring pixels with same object category, and thus networks cannot be effectively sensitive to intra-class connections. Stride by stride, our method firstly conducts adaptive pooling filter operating over predicted feature maps, aiming to merge predicted distributions over a small group of neighboring pixels with same category, and then it computes cost between the merged distribution vector and their category label. Such design can make groups of neighboring predictions from same category involved into estimations on predicting correctness with respect to their category, and hence train networks to be more sensitive to regional connections between adjacent pixels based on their categories. In the experiments on Pascal VOC 2012 segmentation datasets, the consistently improved results show that our proposed approach achieves better segmentation masks against previous counterparts.

</details>

<details>

<summary>2018-04-16 08:10:46 - Analogue-digital systems and the modular decomposition of physical behaviour</summary>

- *E. J. Beggs, J. V. Tucker*

- `1804.05539v1` - [abs](http://arxiv.org/abs/1804.05539v1) - [pdf](http://arxiv.org/pdf/1804.05539v1)

> We take a fresh look at analogue-digital systems focussing on their physical behaviour. We model a general analogue-digital system as a physical process controlled by an algorithm by viewing the physical process as physical oracle to the algorithm, generalising the notion of Turing. We develop a theoretical framework for the specification and analysis of such systems that combines five semantical notions: actual physical behaviour, measured behaviour, predicted behaviour, computed behaviour and exceptional behaviour. Next, we consider the more general and applicable situation of complex processes that exhibit several distinct modes of physical behaviour. Thus, for their design, a set of mathematical models may be needed, each model having its own domain of application and representing a particular mode of behaviour or operation of physical reality with its own physical oracle. The models may be of disparate kinds and, furthermore, not all physical modes may even have a reliable model. We address the questions: How do we specify algorithms and software that monitor or govern a complex physical situation with many physical modes? How do we specify a portfolio of modes, and the computational problem of transitioning from using one mode to another mode as physical behaviour changes? We propose a general definition of an analogue-digital system with modes, and show how any diverse set of modes, with or without models, can be bound together, and how the transitions between modes can be determined, by constructing a data type and mode selection functions. We illustrate the ideas of physical modes and our theory by reflecting on simple examples, including driverless racing cars.

</details>

<details>

<summary>2018-04-16 13:59:08 - Organization and Independence or Interdependence? Study of the Neurophysiological Dynamics of Syntactic and Semantic Processing</summary>

- *Sabine Ploux, Viviane Déprez*

- `1804.05686v1` - [abs](http://arxiv.org/abs/1804.05686v1) - [pdf](http://arxiv.org/pdf/1804.05686v1)

> In this article we present a multivariate model for determining the different syntactic, semantic, and form (surface-structure) processes underlying the comprehension of simple phrases. This model is applied to EEG signals recorded during a reading task. The results show a hierarchical precedence of the neurolinguistic processes : form, then syntactic and lastly semantic processes. We also found (a) that verbs are at the heart of phrase syntax processing, (b) an interaction between syntactic movement within the phrase, and semantic processes derived from a person-centered reference frame. Eigenvectors of the multivariate model provide electrode-times profiles that separate the distinctive linguistic processes and/or highlight their interaction. The accordance of these findings with different linguistic theories are discussed.

</details>

<details>

<summary>2018-04-16 20:01:06 - Improving Implicit Discourse Relation Classification by Modeling Inter-dependencies of Discourse Units in a Paragraph</summary>

- *Zeyu Dai, Ruihong Huang*

- `1804.05918v1` - [abs](http://arxiv.org/abs/1804.05918v1) - [pdf](http://arxiv.org/pdf/1804.05918v1)

> We argue that semantic meanings of a sentence or clause can not be interpreted independently from the rest of a paragraph, or independently from all discourse relations and the overall paragraph-level discourse structure. With the goal of improving implicit discourse relation classification, we introduce a paragraph-level neural networks that model inter-dependencies between discourse units as well as discourse relation continuity and patterns, and predict a sequence of discourse relations in a paragraph. Experimental results show that our model outperforms the previous state-of-the-art systems on the benchmark corpus of PDTB.

</details>

<details>

<summary>2018-04-17 00:14:32 - Learning Joint Semantic Parsers from Disjoint Data</summary>

- *Hao Peng, Sam Thomson, Swabha Swayamdipta, Noah A. Smith*

- `1804.05990v1` - [abs](http://arxiv.org/abs/1804.05990v1) - [pdf](http://arxiv.org/pdf/1804.05990v1)

> We present a new approach to learning semantic parsers from multiple datasets, even when the target semantic formalisms are drastically different, and the underlying corpora do not overlap. We handle such "disjoint" data by treating annotations for unobserved formalisms as latent structured variables. Building on state-of-the-art baselines, we show improvements both in frame-semantic parsing and semantic dependency parsing by modeling them jointly.

</details>

<details>

<summary>2018-04-17 01:22:41 - Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses</summary>

- *Katherine A. Keith, Su Lin Blodgett, Brendan O'Connor*

- `1804.06004v1` - [abs](http://arxiv.org/abs/1804.06004v1) - [pdf](http://arxiv.org/pdf/1804.06004v1)

> Dependency parsing research, which has made significant gains in recent years, typically focuses on improving the accuracy of single-tree predictions. However, ambiguity is inherent to natural language syntax, and communicating such ambiguity is important for error analysis and better-informed downstream applications. In this work, we propose a transition sampling algorithm to sample from the full joint distribution of parse trees defined by a transition-based parsing model, and demonstrate the use of the samples in probabilistic dependency analysis. First, we define the new task of dependency path prediction, inferring syntactic substructures over part of a sentence, and provide the first analysis of performance on this task. Second, we demonstrate the usefulness of our Monte Carlo syntax marginal method for parser error analysis and calibration. Finally, we use this method to propagate parse uncertainty to two downstream information extraction applications: identifying persons killed by police and semantic role assignment.

</details>

<details>

<summary>2018-04-17 02:05:15 - Ontologies for Representing Relations among Political Agents</summary>

- *Carlos Laufer, Daniel Schwabe, Antonio Busson*

- `1804.06015v1` - [abs](http://arxiv.org/abs/1804.06015v1) - [pdf](http://arxiv.org/pdf/1804.06015v1)

> The Internet and the Web are now an integral part of the way most modern societies, and corresponding political systems, work. We regard Political systems as the formal and informal political processes by which decisions are made concerning the use, production and distribution of resources in any given society. Our focus in on the sets of agents - Persons and Organizations - that govern a society, and their relations. We present a set of ontologies aimed at characterizing different kinds of direct and indirect relations that occur within a Political System. The goal is to provide a more semantically precise basis for determining more abstract notions such as "influence".   These ontologies are being used for the "Se Liga na Politica" project, whose goal is to provide an open linked data database of Political Agents in Brazil. Whereas they are being used in a particular political system, these ontologies can be applied to different political systems.

</details>

<details>

<summary>2018-04-17 03:26:28 - ListOps: A Diagnostic Dataset for Latent Tree Learning</summary>

- *Nikita Nangia, Samuel R. Bowman*

- `1804.06028v1` - [abs](http://arxiv.org/abs/1804.06028v1) - [pdf](http://arxiv.org/pdf/1804.06028v1)

> Latent tree learning models learn to parse a sentence without syntactic supervision, and use that parse to build the sentence representation. Existing work on such models has shown that, while they perform well on tasks like sentence classification, they do not learn grammars that conform to any plausible semantic or syntactic formalism (Williams et al., 2018a). Studying the parsing ability of such models in natural language can be challenging due to the inherent complexities of natural language, like having several valid parses for a single sentence. In this paper we introduce ListOps, a toy dataset created to study the parsing ability of latent tree models. ListOps sequences are in the style of prefix arithmetic. The dataset is designed to have a single correct parsing strategy that a system needs to learn to succeed at the task. We show that the current leading latent tree models are unable to learn to parse and succeed at ListOps. These models achieve accuracies worse than purely sequential RNNs.

</details>

<details>

<summary>2018-04-17 15:54:25 - Similarity between Learning Outcomes from Course Objectives using Semantic Analysis, Blooms taxonomy and Corpus statistics</summary>

- *Atish Pawar, Vijay Mago*

- `1804.06333v1` - [abs](http://arxiv.org/abs/1804.06333v1) - [pdf](http://arxiv.org/pdf/1804.06333v1)

> The course description provided by instructors is an essential piece of information as it defines what is expected from the instructor and what he/she is going to deliver during a particular course. One of the key components of a course description is the Learning Objectives section. The contents of this section are used by program managers who are tasked to compare and match two different courses during the development of Transfer Agreements between various institutions. This research introduces the development of semantic similarity algorithms to calculate the similarity between two learning objectives of the same domain. We present a novel methodology which deals with the semantic similarity by using a previously established algorithm and integrating it with the domain corpus utilizing domain statistics. The disambiguated domain serves as a supervised learning data for the algorithm. We also introduce Bloom Index to calculate the similarity between action verbs in the Learning Objectives referring to the Blooms taxonomy.

</details>

<details>

<summary>2018-04-17 21:24:20 - Robust Machine Comprehension Models via Adversarial Training</summary>

- *Yicheng Wang, Mohit Bansal*

- `1804.06473v1` - [abs](http://arxiv.org/abs/1804.06473v1) - [pdf](http://arxiv.org/pdf/1804.06473v1)

> It is shown that many published models for the Stanford Question Answering Dataset (Rajpurkar et al., 2016) lack robustness, suffering an over 50% decrease in F1 score during adversarial evaluation based on the AddSent (Jia and Liang, 2017) algorithm. It has also been shown that retraining models on data generated by AddSent has limited effect on their robustness. We propose a novel alternative adversary-generation algorithm, AddSentDiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model for making certain superficial assumptions. Further, in order to improve robustness to AddSent's semantic perturbations (e.g., antonyms), we jointly improve the model's semantic-relationship learning capabilities in addition to our AddSentDiverse-based adversarial training data augmentation. With these additions, we show that we can make a state-of-the-art model significantly more robust, achieving a 36.5% increase in F1 score under many different types of adversarial evaluation while maintaining performance on the regular SQuAD task.

</details>

<details>

<summary>2018-04-18 00:50:56 - Diachronic Usage Relatedness (DURel): A Framework for the Annotation of Lexical Semantic Change</summary>

- *Dominik Schlechtweg, Sabine Schulte im Walde, Stefanie Eckmann*

- `1804.06517v1` - [abs](http://arxiv.org/abs/1804.06517v1) - [pdf](http://arxiv.org/pdf/1804.06517v1)

> We propose a framework that extends synchronic polysemy annotation to diachronic changes in lexical meaning, to counteract the lack of resources for evaluating computational models of lexical semantic change. Our framework exploits an intuitive notion of semantic relatedness, and distinguishes between innovative and reductive meaning changes with high inter-annotator agreement. The resulting test set for German comprises ratings from five annotators for the relatedness of 1,320 use pairs across 22 target words.

</details>

<details>

<summary>2018-04-18 06:36:14 - Polyglot Semantic Parsing in APIs</summary>

- *Kyle Richardson, Jonathan Berant, Jonas Kuhn*

- `1803.06966v2` - [abs](http://arxiv.org/abs/1803.06966v2) - [pdf](http://arxiv.org/pdf/1803.06966v2)

> Traditional approaches to semantic parsing (SP) work by training individual models for each available parallel dataset of text-meaning pairs. In this paper, we explore the idea of polyglot semantic translation, or learning semantic parsing models that are trained on multiple datasets and natural languages. In particular, we focus on translating text to code signature representations using the software component datasets of Richardson and Kuhn (2017a,b). The advantage of such models is that they can be used for parsing a wide variety of input natural languages and output programming languages, or mixed input languages, using a single unified model. To facilitate modeling of this type, we develop a novel graph-based decoding framework that achieves state-of-the-art performance on the above datasets, and apply this method to two other benchmark SP tasks.

</details>

<details>

<summary>2018-04-18 11:35:56 - NTUA-SLP at SemEval-2018 Task 3: Tracking Ironic Tweets using Ensembles of Word and Character Level Attentive RNNs</summary>

- *Christos Baziotis, Nikos Athanasiou, Pinelopi Papalampidi, Athanasia Kolovou, Georgios Paraskevopoulos, Nikolaos Ellinas, Alexandros Potamianos*

- `1804.06659v1` - [abs](http://arxiv.org/abs/1804.06659v1) - [pdf](http://arxiv.org/pdf/1804.06659v1)

> In this paper we present two deep-learning systems that competed at SemEval-2018 Task 3 "Irony detection in English tweets". We design and ensemble two independent models, based on recurrent neural networks (Bi-LSTM), which operate at the word and character level, in order to capture both the semantic and syntactic information in tweets. Our models are augmented with a self-attention mechanism, in order to identify the most informative words. The embedding layer of our word-level model is initialized with word2vec word embeddings, pretrained on a collection of 550 million English tweets. We did not utilize any handcrafted features, lexicons or external datasets as prior information and our models are trained end-to-end using back propagation on constrained data. Furthermore, we provide visualizations of tweets with annotations for the salient tokens of the attention layer that can help to interpret the inner workings of the proposed models. We ranked 2nd out of 42 teams in Subtask A and 2nd out of 31 teams in Subtask B. However, post-task-completion enhancements of our models achieve state-of-the-art results ranking 1st for both subtasks.

</details>

<details>

<summary>2018-04-18 13:23:03 - A Language for Function Signature Representations</summary>

- *Kyle Richardson*

- `1804.00987v2` - [abs](http://arxiv.org/abs/1804.00987v2) - [pdf](http://arxiv.org/pdf/1804.00987v2)

> Recent work by (Richardson and Kuhn, 2017a,b; Richardson et al., 2018) looks at semantic parser induction and question answering in the domain of source code libraries and APIs. In this brief note, we formalize the representations being learned in these studies and introduce a simple domain specific language and a systematic translation from this language to first-order logic. By recasting the target representations in terms of classical logic, we aim to broaden the applicability of existing code datasets for investigating more complex natural language understanding and reasoning problems in the software domain.

</details>

<details>

<summary>2018-04-19 08:42:32 - Learning to Extract Coherent Summary via Deep Reinforcement Learning</summary>

- *Yuxiang Wu, Baotian Hu*

- `1804.07036v1` - [abs](http://arxiv.org/abs/1804.07036v1) - [pdf](http://arxiv.org/pdf/1804.07036v1)

> Coherence plays a critical role in producing a high-quality summary from a document. In recent years, neural extractive summarization is becoming increasingly attractive. However, most of them ignore the coherence of summaries when extracting sentences. As an effort towards extracting coherent summaries, we propose a neural coherence model to capture the cross-sentence semantic and syntactic coherence patterns. The proposed neural coherence model obviates the need for feature engineering and can be trained in an end-to-end fashion using unlabeled data. Empirical results show that the proposed neural coherence model can efficiently capture the cross-sentence coherence patterns. Using the combined output of the neural coherence model and ROUGE package as the reward, we design a reinforcement learning method to train a proposed neural extractive summarizer which is named Reinforced Neural Extractive Summarization (RNES) model. The RNES model learns to optimize coherence and informative importance of the summary simultaneously. Experimental results show that the proposed RNES outperforms existing baselines and achieves state-of-the-art performance in term of ROUGE on CNN/Daily Mail dataset. The qualitative evaluation indicates that summaries produced by RNES are more coherent and readable.

</details>

<details>

<summary>2018-04-19 09:42:01 - LightRel SemEval-2018 Task 7: Lightweight and Fast Relation Classification</summary>

- *Tyler Renslow, Günter Neumann*

- `1804.08426v1` - [abs](http://arxiv.org/abs/1804.08426v1) - [pdf](http://arxiv.org/pdf/1804.08426v1)

> We present LightRel, a lightweight and fast relation classifier. Our goal is to develop a high baseline for different relation extraction tasks. By defining only very few data-internal, word-level features and external knowledge sources in the form of word clusters and word embeddings, we train a fast and simple linear classifier.

</details>

<details>

<summary>2018-04-19 11:33:48 - Introducing two Vietnamese Datasets for Evaluating Semantic Models of (Dis-)Similarity and Relatedness</summary>

- *Kim Anh Nguyen, Sabine Schulte im Walde, Ngoc Thang Vu*

- `1804.05388v2` - [abs](http://arxiv.org/abs/1804.05388v2) - [pdf](http://arxiv.org/pdf/1804.05388v2)

> We present two novel datasets for the low-resource language Vietnamese to assess models of semantic similarity: ViCon comprises pairs of synonyms and antonyms across word classes, thus offering data to distinguish between similarity and dissimilarity. ViSim-400 provides degrees of similarity across five semantic relations, as rated by human judges. The two datasets are verified through standard co-occurrence and neural network models, showing results comparable to the respective English datasets.

</details>

<details>

<summary>2018-04-19 11:40:23 - Unsupervised Prostate Cancer Detection on H&E using Convolutional Adversarial Autoencoders</summary>

- *Wouter Bulten, Geert Litjens*

- `1804.07098v1` - [abs](http://arxiv.org/abs/1804.07098v1) - [pdf](http://arxiv.org/pdf/1804.07098v1)

> We propose an unsupervised method using self-clustering convolutional adversarial autoencoders to classify prostate tissue as tumor or non-tumor without any labeled training data. The clustering method is integrated into the training of the autoencoder and requires only little post-processing. Our network trains on hematoxylin and eosin (H&E) input patches and we tested two different reconstruction targets, H&E and immunohistochemistry (IHC). We show that antibody-driven feature learning using IHC helps the network to learn relevant features for the clustering task. Our network achieves a F1 score of 0.62 using only a small set of validation labels to assign classes to clusters.

</details>

<details>

<summary>2018-04-19 11:45:07 - The Higher-Order Prover Leo-III (Extended Version)</summary>

- *Alexander Steen, Christoph Benzmüller*

- `1802.02732v2` - [abs](http://arxiv.org/abs/1802.02732v2) - [pdf](http://arxiv.org/pdf/1802.02732v2)

> The automated theorem prover Leo-III for classical higher-order logic with Henkin semantics and choice is presented. Leo-III is based on extensional higher-order paramodulation and accepts every common TPTP dialect (FOF, TFF, THF), including their recent extensions to rank-1 polymorphism (TF1, TH1). In addition, the prover natively supports almost every normal higher-order modal logic. Leo-III cooperates with first-order reasoning tools using translations to many-sorted first-order logic and produces verifiable proof certificates. The prover is evaluated on heterogeneous benchmark sets.

</details>

<details>

<summary>2018-04-19 13:02:39 - Specialising Word Vectors for Lexical Entailment</summary>

- *Ivan Vulić, Nikola Mrkšić*

- `1710.06371v2` - [abs](http://arxiv.org/abs/1710.06371v2) - [pdf](http://arxiv.org/pdf/1710.06371v2)

> We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing method that transforms any input word vector space to emphasise the asymmetric relation of lexical entailment (LE), also known as the IS-A or hyponymy-hypernymy relation. By injecting external linguistic constraints (e.g., WordNet links) into the initial vector space, the LE specialisation procedure brings true hyponymy-hypernymy pairs closer together in the transformed Euclidean space. The proposed asymmetric distance measure adjusts the norms of word vectors to reflect the actual WordNet-style hierarchy of concepts. Simultaneously, a joint objective enforces semantic similarity using the symmetric cosine distance, yielding a vector space specialised for both lexical relations at once. LEAR specialisation achieves state-of-the-art performance in the tasks of hypernymy directionality, hypernymy detection, and graded lexical entailment, demonstrating the effectiveness and robustness of the proposed asymmetric specialisation model.

</details>

<details>

<summary>2018-04-19 13:31:22 - SRL4ORL: Improving Opinion Role Labeling using Multi-task Learning with Semantic Role Labeling</summary>

- *Ana Marasović, Anette Frank*

- `1711.00768v3` - [abs](http://arxiv.org/abs/1711.00768v3) - [pdf](http://arxiv.org/pdf/1711.00768v3)

> For over a decade, machine learning has been used to extract opinion-holder-target structures from text to answer the question "Who expressed what kind of sentiment towards what?". Recent neural approaches do not outperform the state-of-the-art feature-based models for Opinion Role Labeling (ORL). We suspect this is due to the scarcity of labeled training data and address this issue using different multi-task learning (MTL) techniques with a related task which has substantially more data, i.e. Semantic Role Labeling (SRL). We show that two MTL models improve significantly over the single-task model for labeling of both holders and targets, on the development and the test sets. We found that the vanilla MTL model which makes predictions using only shared ORL and SRL features, performs the best. With deeper analysis we determine what works and what might be done to make further improvements for ORL.

</details>

<details>

<summary>2018-04-19 16:32:28 - Specifying, Monitoring, and Executing Workflows in Linked Data Environments</summary>

- *Tobias Käfer, Andreas Harth*

- `1804.05044v4` - [abs](http://arxiv.org/abs/1804.05044v4) - [pdf](http://arxiv.org/pdf/1804.05044v4)

> We present an ontology for representing workflows over components with Read-Write Linked Data interfaces and give an operational semantics to the ontology via a rule language. Workflow languages have been successfully applied for modelling behaviour in enterprise information systems, in which the data is often managed in a relational database. Linked Data interfaces have been widely deployed on the web to support data integration in very diverse domains, increasingly also in scenarios involving the Internet of Things, in which application behaviour is often specified using imperative programming languages. With our work we aim to combine workflow languages, which allow for the high-level specification of application behaviour by non-expert users, with Linked Data, which allows for decentralised data publication and integrated data access. We show that our ontology is expressive enough to cover the basic workflow patterns and demonstrate the applicability of our approach with a prototype system that observes pilots carrying out tasks in a mixed-reality aircraft cockpit. On a synthetic benchmark from the building automation domain, the runtime scales linearly with the size of the number of Internet of Things devices.

</details>

<details>

<summary>2018-04-19 16:57:25 - A Practical Acyclicity Notion for Query Answering over Horn-SRIQ Ontologies</summary>

- *David Carral, Cristina Feier, Pascal Hitzler*

- `1804.07274v1` - [abs](http://arxiv.org/abs/1804.07274v1) - [pdf](http://arxiv.org/pdf/1804.07274v1)

> Conjunctive query answering over expressive Horn Description Logic ontologies is a relevant and challenging problem which, in some cases, can be addressed by application of the chase algorithm. In this paper, we define a novel acyclicity notion which provides a sufficient condition for termination of the restricted chase over Horn-SRIQ TBoxes. We show that this notion generalizes most of the existing acyclicity conditions (both theoretically and empirically). Furthermore, this new acyclicity notion gives rise to a very efficient reasoning procedure. We provide evidence for this by providing a materialization based reasoner for acyclic ontologies which outperforms other state-of-the-art systems.

</details>

<details>

<summary>2018-04-19 17:39:45 - I/O Logic in HOL --- First Steps</summary>

- *Christoph Benzmüller, Xavier Parent*

- `1803.09681v2` - [abs](http://arxiv.org/abs/1803.09681v2) - [pdf](http://arxiv.org/pdf/1803.09681v2)

> A semantical embedding of input/output logic in classical higher-order logic is presented. This embedding enables the mechanisation and automation of reasoning tasks in input/output logic with off-the-shelf higher-order theorem provers and proof assistants. The key idea for the solution presented here results from the analysis of an inaccurate previous embedding attempt, which we will discuss as well.

</details>

<details>

<summary>2018-04-20 03:52:20 - Sentence Simplification with Memory-Augmented Neural Networks</summary>

- *Tu Vu, Baotian Hu, Tsendsuren Munkhdalai, Hong Yu*

- `1804.07445v1` - [abs](http://arxiv.org/abs/1804.07445v1) - [pdf](http://arxiv.org/pdf/1804.07445v1)

> Sentence simplification aims to simplify the content and structure of complex sentences, and thus make them easier to interpret for human readers, and easier to process for downstream NLP applications. Recent advances in neural machine translation have paved the way for novel approaches to the task. In this paper, we adapt an architecture with augmented memory capacities called Neural Semantic Encoders (Munkhdalai and Yu, 2017) for sentence simplification. Our experiments demonstrate the effectiveness of our approach on different simplification datasets, both in terms of automatic evaluation measures and human judgments.

</details>

<details>

<summary>2018-04-20 07:10:44 - Outline Objects using Deep Reinforcement Learning</summary>

- *Zhenxin Wang, Sayan Sarcar, Jingxin Liu, Yilin Zheng, Xiangshi Ren*

- `1804.04603v2` - [abs](http://arxiv.org/abs/1804.04603v2) - [pdf](http://arxiv.org/pdf/1804.04603v2)

> Image segmentation needs both local boundary position information and global object context information. The performance of the recent state-of-the-art method, fully convolutional networks, reaches a bottleneck due to the neural network limit after balancing between the two types of information simultaneously in an end-to-end training style. To overcome this problem, we divide the semantic image segmentation into temporal subtasks. First, we find a possible pixel position of some object boundary; then trace the boundary at steps within a limited length until the whole object is outlined. We present the first deep reinforcement learning approach to semantic image segmentation, called DeepOutline, which outperforms other algorithms in Coco detection leaderboard in the middle and large size person category in Coco val2017 dataset. Meanwhile, it provides an insight into a divide and conquer way by reinforcement learning on computer vision problems.

</details>

<details>

<summary>2018-04-20 09:01:41 - Visualisation and 'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure</summary>

- *Dieuwke Hupkes, Sara Veldhoen, Willem Zuidema*

- `1711.10203v2` - [abs](http://arxiv.org/abs/1711.10203v2) - [pdf](http://arxiv.org/pdf/1711.10203v2)

> We investigate how neural networks can learn and process languages with hierarchical, compositional semantics. To this end, we define the artificial task of processing nested arithmetic expressions, and study whether different types of neural networks can learn to compute their meaning. We find that recursive neural networks can find a generalising solution to this problem, and we visualise this solution by breaking it up in three steps: project, sum and squash. As a next step, we investigate recurrent neural networks, and show that a gated recurrent unit, that processes its input incrementally, also performs very well on this task. To develop an understanding of what the recurrent network encodes, visualisation techniques alone do not suffice. Therefore, we develop an approach where we formulate and test multiple hypotheses on the information encoded and processed by the network. For each hypothesis, we derive predictions about features of the hidden state representations at each time step, and train 'diagnostic classifiers' to test those predictions. Our results indicate that the networks follow a strategy similar to our hypothesised 'cumulative strategy', which explains the high accuracy of the network on novel expressions, the generalisation to longer expressions than seen in training, and the mild deterioration with increasing length. This is turn shows that diagnostic classifiers can be a useful technique for opening up the black box of neural networks. We argue that diagnostic classification, unlike most visualisation techniques, does scale up from small networks in a toy domain, to larger and deeper recurrent networks dealing with real-life data, and may therefore contribute to a better understanding of the internal dynamics of current state-of-the-art models in natural language processing.

</details>

<details>

<summary>2018-04-20 15:02:25 - Acquisition of Phrase Correspondences using Natural Deduction Proofs</summary>

- *Hitomi Yanaka, Koji Mineshima, Pascual Martinez-Gomez, Daisuke Bekki*

- `1804.07656v1` - [abs](http://arxiv.org/abs/1804.07656v1) - [pdf](http://arxiv.org/pdf/1804.07656v1)

> How to identify, extract, and use phrasal knowledge is a crucial problem for the task of Recognizing Textual Entailment (RTE). To solve this problem, we propose a method for detecting paraphrases via natural deduction proofs of semantic relations between sentence pairs. Our solution relies on a graph reformulation of partial variable unifications and an algorithm that induces subgraph alignments between meaning representations. Experiments show that our method can automatically detect various paraphrases that are absent from existing paraphrase databases. In addition, the detection of paraphrases using proof information improves the accuracy of RTE tasks.

</details>

<details>

<summary>2018-04-20 15:23:12 - Modelling customer online behaviours with neural networks: applications to conversion prediction and advertising retargeting</summary>

- *Yanwei Cui, Rogatien Tobossi, Olivia Vigouroux*

- `1804.07669v1` - [abs](http://arxiv.org/abs/1804.07669v1) - [pdf](http://arxiv.org/pdf/1804.07669v1)

> In this paper, we apply neural networks into digital marketing world for the purpose of better targeting the potential customers. To do so, we model the customer online behaviours using dedicated neural network architectures. Starting from user searched keywords in a search engine to the landing page and different following pages, until the user left the site, we model the whole visited journey with a Recurrent Neural Network (RNN), together with Convolution Neural Networks (CNN) that can take into account of the semantic meaning of user searched keywords and different visited page names. With such model, we use Monte Carlo simulation to estimate the conversion rates of each potential customer in the future visiting. We believe our concept and the preliminary promising results in this paper enable the use of largely available customer online behaviours data for advanced digital marketing analysis.

</details>

<details>

<summary>2018-04-20 16:45:26 - ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations</summary>

- *John Wieting, Kevin Gimpel*

- `1711.05732v2` - [abs](http://arxiv.org/abs/1711.05732v2) - [pdf](http://arxiv.org/pdf/1711.05732v2)

> We describe PARANMT-50M, a dataset of more than 50 million English-English sentential paraphrase pairs. We generated the pairs automatically by using neural machine translation to translate the non-English side of a large parallel corpus, following Wieting et al. (2017). Our hope is that ParaNMT-50M can be a valuable resource for paraphrase generation and can provide a rich source of semantic knowledge to improve downstream natural language understanding tasks. To show its utility, we use ParaNMT-50M to train paraphrastic sentence embeddings that outperform all supervised systems on every SemEval semantic textual similarity competition, in addition to showing how it can be used for paraphrase generation.

</details>

<details>

<summary>2018-04-20 17:58:45 - Learning Semantic Textual Similarity from Conversations</summary>

- *Yinfei Yang, Steve Yuan, Daniel Cer, Sheng-yi Kong, Noah Constant, Petr Pilar, Heming Ge, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil*

- `1804.07754v1` - [abs](http://arxiv.org/abs/1804.07754v1) - [pdf](http://arxiv.org/pdf/1804.07754v1)

> We present a novel approach to learn representations for sentence-level semantic similarity using conversational data. Our method trains an unsupervised model to predict conversational input-response pairs. The resulting sentence embeddings perform well on the semantic textual similarity (STS) benchmark and SemEval 2017's Community Question Answering (CQA) question similarity subtask. Performance is further improved by introducing multitask training combining the conversational input-response prediction task and a natural language inference task. Extensive experiments show the proposed model achieves the best performance among all neural models on the STS benchmark and is competitive with the state-of-the-art feature engineered and mixed systems in both tasks.

</details>

<details>

<summary>2018-04-21 01:48:38 - Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding</summary>

- *Lifu Huang, Kyunghyun Cho, Boliang Zhang, Heng Ji, Kevin Knight*

- `1804.07875v1` - [abs](http://arxiv.org/abs/1804.07875v1) - [pdf](http://arxiv.org/pdf/1804.07875v1)

> We construct a multilingual common semantic space based on distributional semantics, where words from multiple languages are projected into a shared space to enable knowledge and resource transfer across languages. Beyond word alignment, we introduce multiple cluster-level alignments and enforce the word clusters to be consistently distributed across multiple languages. We exploit three signals for clustering: (1) neighbor words in the monolingual word embedding space; (2) character-level information; and (3) linguistic properties (e.g., apposition, locative suffix) derived from linguistic structure knowledge bases available for thousands of languages. We introduce a new cluster-consistent correlational neural network to construct the common semantic space by aligning words as well as clusters. Intrinsic evaluation on monolingual and multilingual QVEC tasks shows our approach achieves significantly higher correlation with linguistic features than state-of-the-art multi-lingual embedding learning methods do. Using low-resource language name tagging as a case study for extrinsic evaluation, our approach achieves up to 24.5\% absolute F-score gain over the state of the art.

</details>

<details>

<summary>2018-04-21 17:21:28 - Fine-grained Entity Typing through Increased Discourse Context and Adaptive Classification Thresholds</summary>

- *Sheng Zhang, Kevin Duh, Benjamin Van Durme*

- `1804.08000v1` - [abs](http://arxiv.org/abs/1804.08000v1) - [pdf](http://arxiv.org/pdf/1804.08000v1)

> Fine-grained entity typing is the task of assigning fine-grained semantic types to entity mentions. We propose a neural architecture which learns a distributional semantic representation that leverages a greater amount of semantic context -- both document and sentence level information -- than prior work. We find that additional context improves performance, with further improvements gained by utilizing adaptive classification thresholds. Experiments show that our approach without reliance on hand-crafted features achieves the state-of-the-art results on three benchmark datasets.

</details>

<details>

<summary>2018-04-21 21:59:24 - A Channel-based Exact Inference Algorithm for Bayesian Networks</summary>

- *Bart Jacobs*

- `1804.08032v1` - [abs](http://arxiv.org/abs/1804.08032v1) - [pdf](http://arxiv.org/pdf/1804.08032v1)

> This paper describes a new algorithm for exact Bayesian inference that is based on a recently proposed compositional semantics of Bayesian networks in terms of channels. The paper concentrates on the ideas behind this algorithm, involving a linearisation (`stretching') of the Bayesian network, followed by a combination of forward state transformation and backward predicate transformation, while evidence is accumulated along the way. The performance of a prototype implementation of the algorithm in Python is briefly compared to a standard implementation (pgmpy): first results show competitive performance.

</details>

<details>

<summary>2018-04-21 22:15:36 - Cross-lingual Semantic Parsing</summary>

- *Sheng Zhang, Kevin Duh, Benjamin Van Durme*

- `1804.08037v1` - [abs](http://arxiv.org/abs/1804.08037v1) - [pdf](http://arxiv.org/pdf/1804.08037v1)

> We introduce the task of cross-lingual semantic parsing: mapping content provided in a source language into a meaning representation based on a target language. We present: (1) a meaning representation designed to allow systems to target varying levels of structural complexity (shallow to deep analysis), (2) an evaluation metric to measure the similarity between system output and reference meaning representations, (3) an end-to-end model with a novel copy mechanism that supports intrasentential coreference, and (4) an evaluation dataset where experiments show our model outperforms strong baselines by at least 1.18 F1 score.

</details>

<details>

<summary>2018-04-22 00:53:20 - HeteroMed: Heterogeneous Information Network for Medical Diagnosis</summary>

- *Anahita Hosseini, Ting Chen, Wenjun Wu, Yizhou Sun, Majid Sarrafzadeh*

- `1804.08052v1` - [abs](http://arxiv.org/abs/1804.08052v1) - [pdf](http://arxiv.org/pdf/1804.08052v1)

> With the recent availability of Electronic Health Records (EHR) and great opportunities they offer for advancing medical informatics, there has been growing interest in mining EHR for improving quality of care. Disease diagnosis due to its sensitive nature, huge costs of error, and complexity has become an increasingly important focus of research in past years. Existing studies model EHR by capturing co-occurrence of clinical events to learn their latent embeddings. However, relations among clinical events carry various semantics and contribute differently to disease diagnosis which gives precedence to a more advanced modeling of heterogeneous data types and relations in EHR data than existing solutions. To address these issues, we represent how high-dimensional EHR data and its rich relationships can be suitably translated into HeteroMed, a heterogeneous information network for robust medical diagnosis. Our modeling approach allows for straightforward handling of missing values and heterogeneity of data. HeteroMed exploits metapaths to capture higher level and semantically important relations contributing to disease diagnosis. Furthermore, it employs a joint embedding framework to tailor clinical event representations to the disease diagnosis goal. To the best of our knowledge, this is the first study to use Heterogeneous Information Network for modeling clinical data and disease diagnosis. Experimental results of our study show superior performance of HeteroMed compared to prior methods in prediction of exact diagnosis codes and general disease cohorts. Moreover, HeteroMed outperforms baseline models in capturing similarities of clinical events which are examined qualitatively through case studies.

</details>

<details>

<summary>2018-04-22 05:08:52 - Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation</summary>

- *Tiancheng Zhao, Kyusong Lee, Maxine Eskenazi*

- `1804.08069v1` - [abs](http://arxiv.org/abs/1804.08069v1) - [pdf](http://arxiv.org/pdf/1804.08069v1)

> The encoder-decoder dialog model is one of the most prominent methods used to build dialog systems in complex domains. Yet it is limited because it cannot output interpretable actions as in traditional systems, which hinders humans from understanding its generation process. We present an unsupervised discrete sentence representation learning method that can integrate with any existing encoder-decoder dialog models for interpretable response generation. Building upon variational autoencoders (VAEs), we present two novel models, DI-VAE and DI-VST that improve VAEs and can discover interpretable semantics via either auto encoding or context predicting. Our methods have been validated on real-world dialog datasets to discover semantic representations and enhance encoder-decoder models with interpretable generation.

</details>

<details>

<summary>2018-04-22 05:26:08 - Decoupled Networks</summary>

- *Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang, James M. Rehg, Le Song*

- `1804.08071v1` - [abs](http://arxiv.org/abs/1804.08071v1) - [pdf](http://arxiv.org/pdf/1804.08071v1)

> Inner product-based convolution has been a central component of convolutional neural networks (CNNs) and the key to learning visual representations. Inspired by the observation that CNN-learned features are naturally decoupled with the norm of features corresponding to the intra-class variation and the angle corresponding to the semantic difference, we propose a generic decoupled learning framework which models the intra-class variation and semantic difference independently. Specifically, we first reparametrize the inner product to a decoupled form and then generalize it to the decoupled convolution operator which serves as the building block of our decoupled networks. We present several effective instances of the decoupled convolution operator. Each decoupled operator is well motivated and has an intuitive geometric interpretation. Based on these decoupled operators, we further propose to directly learn the operator from data. Extensive experiments show that such decoupled reparameterization renders significant performance gain with easier convergence and stronger robustness.

</details>

<details>

<summary>2018-04-22 11:01:08 - IIIDYT at SemEval-2018 Task 3: Irony detection in English tweets</summary>

- *Edison Marrese-Taylor, Suzana Ilic, Jorge A. Balazs, Yutaka Matsuo, Helmut Prendinger*

- `1804.08094v1` - [abs](http://arxiv.org/abs/1804.08094v1) - [pdf](http://arxiv.org/pdf/1804.08094v1)

> In this paper we introduce our system for the task of Irony detection in English tweets, a part of SemEval 2018. We propose representation learning approach that relies on a multi-layered bidirectional LSTM, without using external features that provide additional semantic information. Although our model is able to outperform the baseline in the validation set, our results show limited generalization power over the test set. Given the limited size of the dataset, we think the usage of more pre-training schemes would greatly improve the obtained results.

</details>

<details>

<summary>2018-04-23 06:33:53 - Progressive refinement: a method of coarse-to-fine image parsing using stacked network</summary>

- *Jiagao Hu, Zhengxing Sun, Yunhan Sun, Jinlong Shi*

- `1804.08256v1` - [abs](http://arxiv.org/abs/1804.08256v1) - [pdf](http://arxiv.org/pdf/1804.08256v1)

> To parse images into fine-grained semantic parts, the complex fine-grained elements will put it in trouble when using off-the-shelf semantic segmentation networks. In this paper, for image parsing task, we propose to parse images from coarse to fine with progressively refined semantic classes. It is achieved by stacking the segmentation layers in a segmentation network several times. The former segmentation module parses images at a coarser-grained level, and the result will be feed to the following one to provide effective contextual clues for the finer-grained parsing. To recover the details of small structures, we add skip connections from shallow layers of the network to fine-grained parsing modules. As for the network training, we merge classes in groundtruth to get coarse-to-fine label maps, and train the stacked network with these hierarchical supervision end-to-end. Our coarse-to-fine stacked framework can be injected into many advanced neural networks to improve the parsing results. Extensive evaluations on several public datasets including face parsing and human parsing well demonstrate the superiority of our method.

</details>

<details>

<summary>2018-04-23 06:52:13 - Clinical Assistant Diagnosis for Electronic Medical Record Based on Convolutional Neural Network</summary>

- *Zhongliang Yang, Yongfeng Huang, Yiran Jiang, Yuxi Sun, Yu-Jin Zhan, Pengcheng Luo*

- `1804.08261v1` - [abs](http://arxiv.org/abs/1804.08261v1) - [pdf](http://arxiv.org/pdf/1804.08261v1)

> Automatically extracting useful information from electronic medical records along with conducting disease diagnoses is a promising task for both clinical decision support(CDS) and neural language processing(NLP). Most of the existing systems are based on artificially constructed knowledge bases, and then auxiliary diagnosis is done by rule matching. In this study, we present a clinical intelligent decision approach based on Convolutional Neural Networks(CNN), which can automatically extract high-level semantic information of electronic medical records and then perform automatic diagnosis without artificial construction of rules or knowledge bases. We use collected 18,590 copies of the real-world clinical electronic medical records to train and test the proposed model. Experimental results show that the proposed model can achieve 98.67\% accuracy and 96.02\% recall, which strongly supports that using convolutional neural network to automatically learn high-level semantic features of electronic medical records and then conduct assist diagnosis is feasible and effective.

</details>

<details>

<summary>2018-04-23 07:21:21 - NLITrans at SemEval-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension</summary>

- *Tim Niven, Hung-Yu Kao*

- `1804.08266v1` - [abs](http://arxiv.org/abs/1804.08266v1) - [pdf](http://arxiv.org/pdf/1804.08266v1)

> The Argument Reasoning Comprehension Task requires significant language understanding and complex reasoning over world knowledge. We focus on transfer of a sentence encoder to bootstrap more complicated models given the small size of the dataset. Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching. This model achieves mean test set accuracy of 64.43%. Encoder transfer yields a significant gain to our best model over random initialization. Independent warrant matching effectively doubles the size of the dataset and provides additional regularization. We demonstrate that regularization comes from ignoring statistical correlations between warrant features and position. We also report an experiment with our best model that only matches warrants to reasons, ignoring claims. Relatively low performance degradation suggests that our model is not necessarily learning the intended task.

</details>

<details>

<summary>2018-04-23 08:44:04 - A Semantic Framework for the Security Analysis of Ethereum smart contracts</summary>

- *Ilya Grishchenko, Matteo Maffei, Clara Schneidewind*

- `1802.08660v2` - [abs](http://arxiv.org/abs/1802.08660v2) - [pdf](http://arxiv.org/pdf/1802.08660v2)

> Smart contracts are programs running on cryptocurrency (e.g., Ethereum) blockchains, whose popularity stem from the possibility to perform financial transactions, such as payments and auctions, in a distributed environment without need for any trusted third party. Given their financial nature, bugs or vulnerabilities in these programs may lead to catastrophic consequences, as witnessed by recent attacks. Unfortunately, programming smart contracts is a delicate task that requires strong expertise: Ethereum smart contracts are written in Solidity, a dedicated language resembling JavaScript, and shipped over the blockchain in the EVM bytecode format. In order to rigorously verify the security of smart contracts, it is of paramount importance to formalize their semantics as well as the security properties of interest, in particular at the level of the bytecode being executed.   In this paper, we present the first complete small-step semantics of EVM bytecode, which we formalize in the F* proof assistant, obtaining executable code that we successfully validate against the official Ethereum test suite. Furthermore, we formally define for the first time a number of central security properties for smart contracts, such as call integrity, atomicity, and independence from miner controlled parameters. This formalization relies on a combination of hyper- and safety properties. Along this work, we identified various mistakes and imprecisions in existing semantics and verification tools for Ethereum smart contracts, thereby demonstrating once more the importance of rigorous semantic foundations for the design of security verification techniques.

</details>

<details>

<summary>2018-04-23 09:32:46 - Deep Generative Model for Joint Alignment and Word Representation</summary>

- *Miguel Rios, Wilker Aziz, Khalil Sima'an*

- `1802.05883v3` - [abs](http://arxiv.org/abs/1802.05883v3) - [pdf](http://arxiv.org/pdf/1802.05883v3)

> This work exploits translation data as a source of semantically relevant learning signal for models of word representation. In particular, we exploit equivalence through translation as a form of distributed context and jointly learn how to embed and align with a deep generative model. Our EmbedAlign model embeds words in their complete observed context and learns by marginalisation of latent lexical alignments. Besides, it embeds words as posterior probability densities, rather than point estimates, which allows us to compare words in context using a measure of overlap between distributions (e.g. KL divergence). We investigate our model's performance on a range of lexical semantics tasks achieving competitive results on several standard benchmarks including natural language inference, paraphrasing, and text similarity.

</details>

<details>

<summary>2018-04-23 10:46:28 - Taskonomy: Disentangling Task Transfer Learning</summary>

- *Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra Malik, Silvio Savarese*

- `1804.08328v1` - [abs](http://arxiv.org/abs/1804.08328v1) - [pdf](http://arxiv.org/pdf/1804.08328v1)

> Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity.   We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and probing this taxonomical structure including a solver that users can employ to devise efficient supervision policies for their use cases.

</details>

<details>

<summary>2018-04-23 11:18:47 - Semantic Parsing with Syntax- and Table-Aware SQL Generation</summary>

- *Yibo Sun, Duyu Tang, Nan Duan, Jianshu Ji, Guihong Cao, Xiaocheng Feng, Bing Qin, Ting Liu, Ming Zhou*

- `1804.08338v1` - [abs](http://arxiv.org/abs/1804.08338v1) - [pdf](http://arxiv.org/pdf/1804.08338v1)

> We present a generative model to map natural language questions into SQL queries. Existing neural network based approaches typically generate a SQL query word-by-word, however, a large portion of the generated results are incorrect or not executable due to the mismatch between question words and table contents. Our approach addresses this problem by considering the structure of table and the syntax of SQL language. The quality of the generated SQL query is significantly improved through (1) learning to replicate content from column names, cells or SQL keywords; and (2) improving the generation of WHERE clause by leveraging the column-cell relation. Experiments are conducted on WikiSQL, a recently released dataset with the largest question-SQL pairs. Our approach significantly improves the state-of-the-art execution accuracy from 69.0% to 74.4%.

</details>

<details>

<summary>2018-04-23 14:51:46 - Object Counts! Bringing Explicit Detections Back into Image Captioning</summary>

- *Josiah Wang, Pranava Madhyastha, Lucia Specia*

- `1805.00314v1` - [abs](http://arxiv.org/abs/1805.00314v1) - [pdf](http://arxiv.org/pdf/1805.00314v1)

> The use of explicit object detectors as an intermediate step to image captioning - which used to constitute an essential stage in early work - is often bypassed in the currently dominant end-to-end approaches, where the language model is conditioned directly on a mid-level image embedding. We argue that explicit detections provide rich semantic information, and can thus be used as an interpretable representation to better understand why end-to-end image captioning systems work well. We provide an in-depth analysis of end-to-end image captioning by exploring a variety of cues that can be derived from such object detections. Our study reveals that end-to-end image captioning systems rely on matching image representations to generate captions, and that encoding the frequency, size and position of objects are complementary and all play a role in forming a good image representation. It also reveals that different object categories contribute in different ways towards image captioning.

</details>

<details>

<summary>2018-04-23 21:29:30 - Can Eye Movement Data Be Used As Ground Truth For Word Embeddings Evaluation?</summary>

- *Amir Bakarov*

- `1804.08749v1` - [abs](http://arxiv.org/abs/1804.08749v1) - [pdf](http://arxiv.org/pdf/1804.08749v1)

> In recent years a certain success in the task of modeling lexical semantics was obtained with distributional semantic models. Nevertheless, the scientific community is still unaware what is the most reliable evaluation method for these models. Some researchers argue that the only possible gold standard could be obtained from neuro-cognitive resources that store information about human cognition. One of such resources is eye movement data on silent reading. The goal of this work is to test the hypothesis of whether such data could be used to evaluate distributional semantic models on different languages. We propose experiments with English and Russian eye movement datasets (Provo Corpus, GECO and Russian Sentence Corpus), word vectors (Skip-Gram models trained on national corpora and Web corpora) and word similarity datasets of Russian and English assessed by humans in order to find the existence of correlation between embeddings and eye movement data and test the hypothesis that this correlation is language independent. As a result, we found that the validity of the hypothesis being tested could be questioned.

</details>

<details>

<summary>2018-04-24 08:10:07 - SIRIUS-LTG-UiO at SemEval-2018 Task 7: Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers</summary>

- *Farhad Nooralahzadeh, Lilja Øvrelid, Jan Tore Lønning*

- `1804.08887v1` - [abs](http://arxiv.org/abs/1804.08887v1) - [pdf](http://arxiv.org/pdf/1804.08887v1)

> This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path (sdp) between two entities, then we introduce a convolutional neural network (CNN) which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for relation classification on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on clean data, it obtained F1 scores of 37.4 and 33.6 for each phase. Our system ranks 3rd in all three sub-tasks of the shared task.

</details>

<details>

<summary>2018-04-24 15:09:04 - End-to-end weakly-supervised semantic alignment</summary>

- *Ignacio Rocco, Relja Arandjelović, Josef Sivic*

- `1712.06861v2` - [abs](http://arxiv.org/abs/1712.06861v2) - [pdf](http://arxiv.org/pdf/1712.06861v2)

> We tackle the task of semantic alignment where the goal is to compute dense semantic correspondence aligning two images depicting objects of the same category. This is a challenging task due to large intra-class variation, changes in viewpoint and background clutter. We present the following three principal contributions. First, we develop a convolutional neural network architecture for semantic alignment that is trainable in an end-to-end manner from weak image-level supervision in the form of matching image pairs. The outcome is that parameters are learnt from rich appearance variation present in different but semantically related images without the need for tedious manual annotation of correspondences at training time. Second, the main component of this architecture is a differentiable soft inlier scoring module, inspired by the RANSAC inlier scoring procedure, that computes the quality of the alignment based on only geometrically consistent correspondences thereby reducing the effect of background clutter. Third, we demonstrate that the proposed approach achieves state-of-the-art performance on multiple standard benchmarks for semantic alignment.

</details>

<details>

<summary>2018-04-24 15:39:41 - Word and Phrase Translation with word2vec</summary>

- *Stefan Jansen*

- `1705.03127v4` - [abs](http://arxiv.org/abs/1705.03127v4) - [pdf](http://arxiv.org/pdf/1705.03127v4)

> Word and phrase tables are key inputs to machine translations, but costly to produce. New unsupervised learning methods represent words and phrases in a high-dimensional vector space, and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements. The information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows matching relative positions across two monolingual vector spaces. This method aims to identify high-quality candidates for word and phrase translation more cost-effectively from unlabeled data.   This paper expands the scope of previous attempts of bilingual translation to four languages (English, German, Spanish, and French). It shows how to process the source data, train a neural network to learn the high-dimensional embeddings for individual languages and expands the framework for testing their quality beyond the English language. Furthermore, it shows how to learn bilingual transformation matrices and obtain candidates for word and phrase translation, and assess their quality.

</details>

<details>

<summary>2018-04-25 02:31:40 - Exploiting Partially Annotated Data for Temporal Relation Extraction</summary>

- *Qiang Ning, Zhongzhi Yu, Chuchu Fan, Dan Roth*

- `1804.08420v2` - [abs](http://arxiv.org/abs/1804.08420v2) - [pdf](http://arxiv.org/pdf/1804.08420v2)

> Annotating temporal relations (TempRel) between events described in natural language is known to be labor intensive, partly because the total number of TempRels is quadratic in the number of events. As a result, only a small number of documents are typically annotated, limiting the coverage of various lexical/semantic phenomena. In order to improve existing approaches, one possibility is to make use of the readily available, partially annotated data (P as in partial) that cover more documents. However, missing annotations in P are known to hurt, rather than help, existing systems. This work is a case study in exploring various usages of P for TempRel extraction. Results show that despite missing annotations, P is still a useful supervision signal for this task within a constrained bootstrapping learning framework. The system described in this system is publicly available.

</details>

<details>

<summary>2018-04-25 16:30:57 - Cross-Modal Retrieval with Implicit Concept Association</summary>

- *Yale Song, Mohammad Soleymani*

- `1804.04318v2` - [abs](http://arxiv.org/abs/1804.04318v2) - [pdf](http://arxiv.org/pdf/1804.04318v2)

> Traditional cross-modal retrieval assumes explicit association of concepts across modalities, where there is no ambiguity in how the concepts are linked to each other, e.g., when we do the image search with a query "dogs", we expect to see dog images. In this paper, we consider a different setting for cross-modal retrieval where data from different modalities are implicitly linked via concepts that must be inferred by high-level reasoning; we call this setting implicit concept association. To foster future research in this setting, we present a new dataset containing 47K pairs of animated GIFs and sentences crawled from the web, in which the GIFs depict physical or emotional reactions to the scenarios described in the text (called "reaction GIFs"). We report on a user study showing that, despite the presence of implicit concept association, humans are able to identify video-sentence pairs with matching concepts, suggesting the feasibility of our task. Furthermore, we propose a novel visual-semantic embedding network based on multiple instance learning. Unlike traditional approaches, we compute multiple embeddings from each modality, each representing different concepts, and measure their similarity by considering all possible combinations of visual-semantic embeddings in the framework of multiple instance learning. We evaluate our approach on two video-sentence datasets with explicit and implicit concept association and report competitive results compared to existing approaches on cross-modal retrieval.

</details>

<details>

<summary>2018-04-26 00:43:49 - Hierarchical Density Order Embeddings</summary>

- *Ben Athiwaratkun, Andrew Gordon Wilson*

- `1804.09843v1` - [abs](http://arxiv.org/abs/1804.09843v1) - [pdf](http://arxiv.org/pdf/1804.09843v1)

> By representing words with probability densities rather than point vectors, probabilistic word embeddings can capture rich and interpretable semantic information and uncertainty. The uncertainty information can be particularly meaningful in capturing entailment relationships -- whereby general words such as "entity" correspond to broad distributions that encompass more specific words such as "animal" or "instrument". We introduce density order embeddings, which learn hierarchical representations through encapsulation of probability densities. In particular, we propose simple yet effective loss functions and distance metrics, as well as graph-based schemes to select negative samples to better learn hierarchical density representations. Our approach provides state-of-the-art performance on the WordNet hypernym relationship prediction task and the challenging HyperLex lexical entailment dataset -- while retaining a rich and interpretable density representation.

</details>

<details>

<summary>2018-04-26 08:57:38 - Analysis of Service-oriented Modeling Approaches for Viewpoint-specific Model-driven Development of Microservice Architecture</summary>

- *Florian Rademacher, Sabine Sachweh, Albert Zündorf*

- `1804.09946v1` - [abs](http://arxiv.org/abs/1804.09946v1) - [pdf](http://arxiv.org/pdf/1804.09946v1)

> Microservice Architecture (MSA) is a novel service-based architectural style for distributed software systems. Compared to Service-oriented Architecture (SOA), MSA puts a stronger focus on self-containment of services. Each microservice is responsible for realizing exactly one business or technological capability that is distinct from other services' capabilities. Additionally, on the implementation and operation level, microservices are self-contained in that they are developed, tested, deployed and operated independently from each other. Next to these characteristics that distinguish MSA from SOA, both architectural styles rely on services as building blocks of distributed software architecture and hence face similar challenges regarding, e.g., service identification, composition and provisioning. However, in contrast to MSA, SOA may rely on an extensive body of knowledge to tackle these challenges. Thus, due to both architectural styles being service-based, the question arises to what degree MSA might draw on existing findings of SOA research and practice. In this paper we address this question in the field of Model-driven Development (MDD) for design and operation of service-based architectures. Therefore, we present an analysis of existing MDD approaches to SOA, which comprises the identification and semantic clustering of modeling concepts for SOA design and operation. For each concept cluster, the analysis assesses its applicability to MDD of MSA (MSA-MDD) and assigns it to a specific modeling viewpoint. The goal of the presented analysis is to provide a conceptual foundation for an MSA-MDD metamodel.

</details>

<details>

<summary>2018-04-26 16:38:56 - CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning</summary>

- *Yuxin Peng, Jinwei Qi, Yuxin Yuan*

- `1710.05106v2` - [abs](http://arxiv.org/abs/1710.05106v2) - [pdf](http://arxiv.org/pdf/1710.05106v2)

> It is known that the inconsistent distribution and representation of different modalities, such as image and text, cause the heterogeneity gap that makes it challenging to correlate such heterogeneous data. Generative adversarial networks (GANs) have shown its strong ability of modeling data distribution and learning discriminative representation, existing GANs-based works mainly focus on generative problem to generate new data. We have different goal, aim to correlate heterogeneous data, by utilizing the power of GANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs to learn discriminative common representation for bridging heterogeneity gap. The main contributions are: (1) Cross-modal GANs architecture is proposed to model joint distribution over data of different modalities. The inter-modality and intra-modality correlation can be explored simultaneously in generative and discriminative models. Both of them beat each other to promote cross-modal correlation learning. (2) Cross-modal convolutional autoencoders with weight-sharing constraint are proposed to form generative model. They can not only exploit cross-modal correlation for learning common representation, but also preserve reconstruction information for capturing semantic consistency within each modality. (3) Cross-modal adversarial mechanism is proposed, which utilizes two kinds of discriminative models to simultaneously conduct intra-modality and inter-modality discrimination. They can mutually boost to make common representation more discriminative by adversarial training process. To the best of our knowledge, our proposed CM-GANs approach is the first to utilize GANs to perform cross-modal common representation learning. Experiments are conducted to verify the performance of our proposed approach on cross-modal retrieval paradigm, compared with 10 methods on 3 cross-modal datasets.

</details>

<details>

<summary>2018-04-27 16:49:41 - The Logical Essentials of Bayesian Reasoning</summary>

- *Bart Jacobs, Fabio Zanasi*

- `1804.01193v2` - [abs](http://arxiv.org/abs/1804.01193v2) - [pdf](http://arxiv.org/pdf/1804.01193v2)

> This chapter offers an accessible introduction to the channel-based approach to Bayesian probability theory. This framework rests on algebraic and logical foundations, inspired by the methodologies of programming language semantics. It offers a uniform, structured and expressive language for describing Bayesian phenomena in terms of familiar programming concepts, like channel, predicate transformation and state transformation. The introduction also covers inference in Bayesian networks, which will be modelled by a suitable calculus of string diagrams.

</details>

<details>

<summary>2018-04-27 20:44:49 - An Unsupervised Word Sense Disambiguation System for Under-Resourced Languages</summary>

- *Dmitry Ustalov, Denis Teslenko, Alexander Panchenko, Mikhail Chernoskutov, Chris Biemann, Simone Paolo Ponzetto*

- `1804.10686v1` - [abs](http://arxiv.org/abs/1804.10686v1) - [pdf](http://arxiv.org/pdf/1804.10686v1)

> In this paper, we present Watasense, an unsupervised system for word sense disambiguation. Given a sentence, the system chooses the most relevant sense of each input word with respect to the semantic similarity between the given sentence and the synset constituting the sense of the target word. Watasense has two modes of operation. The sparse mode uses the traditional vector space model to estimate the most similar word sense corresponding to its context. The dense mode, instead, uses synset embeddings to cope with the sparsity problem. We describe the architecture of the present system and also conduct its evaluation on three different lexical semantic resources for Russian. We found that the dense mode substantially outperforms the sparse one on all datasets according to the adjusted Rand index.

</details>

<details>

<summary>2018-04-28 01:19:51 - Data-Driven Methods for Solving Algebra Word Problems</summary>

- *Benjamin Robaidek, Rik Koncel-Kedziorski, Hannaneh Hajishirzi*

- `1804.10718v1` - [abs](http://arxiv.org/abs/1804.10718v1) - [pdf](http://arxiv.org/pdf/1804.10718v1)

> We explore contemporary, data-driven techniques for solving math word problems over recent large-scale datasets. We show that well-tuned neural equation classifiers can outperform more sophisticated models such as sequence to sequence and self-attention across these datasets. Our error analysis indicates that, while fully data driven models show some promise, semantic and world knowledge is necessary for further advances.

</details>

<details>

<summary>2018-04-28 09:12:38 - Specifying and Verbalising Answer Set Programs in Controlled Natural Language</summary>

- *Rolf Schwitter*

- `1804.10765v1` - [abs](http://arxiv.org/abs/1804.10765v1) - [pdf](http://arxiv.org/pdf/1804.10765v1)

> We show how a bi-directional grammar can be used to specify and verbalise answer set programs in controlled natural language. We start from a program specification in controlled natural language and translate this specification automatically into an executable answer set program. The resulting answer set program can be modified following certain naming conventions and the revised version of the program can then be verbalised in the same subset of natural language that was used as specification language. The bi-directional grammar is parametrised for processing and generation, deals with referring expressions, and exploits symmetries in the data structure of the grammar rules whenever these grammar rules need to be duplicated. We demonstrate that verbalisation requires sentence planning in order to aggregate similar structures with the aim to improve the readability of the generated specification. Without modifications, the generated specification is always semantically equivalent to the original one; our bi-directional grammar is the first one that allows for semantic round-tripping in the context of controlled natural language processing. This paper is under consideration for acceptance in TPLP.

</details>

<details>

<summary>2018-04-29 12:49:29 - OPA2Vec: combining formal and informal content of biomedical ontologies to improve similarity-based prediction</summary>

- *Fatima Zohra Smaili, Xin Gao, Robert Hoehndorf*

- `1804.10922v1` - [abs](http://arxiv.org/abs/1804.10922v1) - [pdf](http://arxiv.org/pdf/1804.10922v1)

> Motivation: Ontologies are widely used in biology for data annotation, integration, and analysis. In addition to formally structured axioms, ontologies contain meta-data in the form of annotation axioms which provide valuable pieces of information that characterize ontology classes. Annotations commonly used in ontologies include class labels, descriptions, or synonyms. Despite being a rich source of semantic information, the ontology meta-data are generally unexploited by ontology-based analysis methods such as semantic similarity measures. Results: We propose a novel method, OPA2Vec, to generate vector representations of biological entities in ontologies by combining formal ontology axioms and annotation axioms from the ontology meta-data. We apply a Word2Vec model that has been pre-trained on PubMed abstracts to produce feature vectors from our collected data. We validate our method in two different ways: first, we use the obtained vector representations of proteins as a similarity measure to predict protein-protein interaction (PPI) on two different datasets. Second, we evaluate our method on predicting gene-disease associations based on phenotype similarity by generating vector representations of genes and diseases using a phenotype ontology, and applying the obtained vectors to predict gene-disease associations. These two experiments are just an illustration of the possible applications of our method. OPA2Vec can be used to produce vector representations of any biomedical entity given any type of biomedical ontology. Availability: https://github.com/bio-ontology-research-group/opa2vec Contact: robert.hoehndorf@kaust.edu.sa and xin.gao@kaust.edu.sa.

</details>

<details>

<summary>2018-04-29 21:20:43 - Semi-parametric Image Synthesis</summary>

- *Xiaojuan Qi, Qifeng Chen, Jiaya Jia, Vladlen Koltun*

- `1804.10992v1` - [abs](http://arxiv.org/abs/1804.10992v1) - [pdf](http://arxiv.org/pdf/1804.10992v1)

> We present a semi-parametric approach to photographic image synthesis from semantic layouts. The approach combines the complementary strengths of parametric and nonparametric techniques. The nonparametric component is a memory bank of image segments constructed from a training set of images. Given a novel semantic layout at test time, the memory bank is used to retrieve photographic references that are provided as source material to a deep network. The synthesis is performed by a deep network that draws on the provided photographic material. Experiments on multiple semantic segmentation datasets show that the presented approach yields considerably more realistic images than recent purely parametric techniques. The results are shown in the supplementary video at https://youtu.be/U4Q98lenGLQ

</details>

<details>

<summary>2018-04-30 09:54:12 - Fast and scalable learning of neuro-symbolic representations of biomedical knowledge</summary>

- *Asan Agibetov, Matthias Samwald*

- `1804.11105v1` - [abs](http://arxiv.org/abs/1804.11105v1) - [pdf](http://arxiv.org/pdf/1804.11105v1)

> In this work we address the problem of fast and scalable learning of neuro-symbolic representations for general biological knowledge. Based on a recently published comprehensive biological knowledge graph (Alshahrani, 2017) that was used for demonstrating neuro-symbolic representation learning, we show how to train fast (under 1 minute) log-linear neural embeddings of the entities. We utilize these representations as inputs for machine learning classifiers to enable important tasks such as biological link prediction. Classifiers are trained by concatenating learned entity embeddings to represent entity relations, and training classifiers on the concatenated embeddings to discern true relations from automatically generated negative examples. Our simple embedding methodology greatly improves on classification error compared to previously published state-of-the-art results, yielding a maximum increase of $+0.28$ F-measure and $+0.22$ ROC AUC scores for the most difficult biological link prediction problem. Finally, our embedding approach is orders of magnitude faster to train ($\leq$ 1 minute vs. hours), much more economical in terms of embedding dimensions ($d=50$ vs. $d=512$), and naturally encodes the directionality of the asymmetric biological relations, that can be controlled by the order with which we concatenate the embeddings.

</details>

<details>

<summary>2018-04-30 12:14:32 - Cross-Modal Retrieval in the Cooking Context: Learning Semantic Text-Image Embeddings</summary>

- *Micael Carvalho, Rémi Cadène, David Picard, Laure Soulier, Nicolas Thome, Matthieu Cord*

- `1804.11146v1` - [abs](http://arxiv.org/abs/1804.11146v1) - [pdf](http://arxiv.org/pdf/1804.11146v1)

> Designing powerful tools that support cooking activities has rapidly gained popularity due to the massive amounts of available data, as well as recent advances in machine learning that are capable of analyzing them. In this paper, we propose a cross-modal retrieval model aligning visual and textual data (like pictures of dishes and their recipes) in a shared representation space. We describe an effective learning scheme, capable of tackling large-scale problems, and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs. We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.

</details>

<details>

<summary>2018-04-30 13:03:57 - DeepBugs: A Learning Approach to Name-based Bug Detection</summary>

- *Michael Pradel, Koushik Sen*

- `1805.11683v1` - [abs](http://arxiv.org/abs/1805.11683v1) - [pdf](http://arxiv.org/pdf/1805.11683v1)

> Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a semantic representation and which automatically learns bug detectors instead of manually writing them. We formulate bug detection as a binary classification problem and train a classifier that distinguishes correct from incorrect code. To address the challenge that effectively learning a bug detector requires examples of both correct and incorrect code, we create likely incorrect code examples from an existing corpus of code through simple code transformations. A novel insight learned from our work is that learning from artificially seeded bugs yields bug detectors that are effective at finding bugs in real-world code. We implement our idea into a framework for learning-based and name-based bug detection. Three bug detectors built on top of the framework detect accidentally swapped function arguments, incorrect binary operators, and incorrect operands in binary operations. Applying the approach to a corpus of 150,000 JavaScript files yields bug detectors that have a high accuracy (between 89% and 95%), are very efficient (less than 20 milliseconds per analyzed file), and reveal 102 programming mistakes (with 68% true positive rate) in real-world code.

</details>

<details>

<summary>2018-04-30 13:56:12 - Temporal Aspects of Smart Contracts for Financial Derivatives</summary>

- *Christopher D. Clack, Gabriel Vanca*

- `1805.11677v1` - [abs](http://arxiv.org/abs/1805.11677v1) - [pdf](http://arxiv.org/pdf/1805.11677v1)

> Implementing smart contracts to automate the performance of high-value over-the-counter (OTC) financial derivatives is a formidable challenge. Due to the regulatory framework and the scale of financial risk if a contract were to go wrong, the performance of these contracts must be enforceable in law and there is an absolute requirement that the smart contract will be faithful to the intentions of the parties as expressed in the original legal documentation. Formal methods provide an attractive route for validation and assurance, and here we present early results from an investigation of the semantics of industry-standard legal documentation for OTC derivatives. We explain the need for a formal representation that combines temporal, deontic and operational aspects, and focus on the requirements for the temporal aspects as derived from the legal text. The relevance of this work extends beyond OTC derivatives and is applicable to understanding the temporal semantics of a wide range of legal documentation.

</details>

<details>

<summary>2018-04-30 14:19:07 - XFO: Toward Programming Rich Semantic Models</summary>

- *Robert B. Allen, Teryn K. Jones*

- `1805.11050v1` - [abs](http://arxiv.org/abs/1805.11050v1) - [pdf](http://arxiv.org/pdf/1805.11050v1)

> We have proposed that ontologies and programming languages should be more closely aligned. Specifically, we have argued that the Basic Formal Ontology (BFO2) has many features that are consistent with object-oriented analysis, design, and modeling. Here, we describe the eXtended Formal Ontology (XFO), a programming environment we developed to support semantic modeling. We then use XFO to implement a Traffic Light Microworld and discuss more complex applications.

</details>

<details>

<summary>2018-04-30 16:17:14 - A Formal Transformation Method for Automated Fault Tree Generation from a UML Activity Model</summary>

- *Charles Dickerson, Rosmira Roslan, Siyuan Ji*

- `1804.11296v1` - [abs](http://arxiv.org/abs/1804.11296v1) - [pdf](http://arxiv.org/pdf/1804.11296v1)

> Fault analysis and resolution of faults should be part of any end-to-end system development process. This paper is concerned with developing a formal transformation method that maps control flows modeled in UML Activities to semantically equivalent Fault Trees. The transformation method developed features the use of propositional calculus and probability theory. Fault Propagation Chains are introduced to facilitate the transformation method. An overarching metamodel comprised of transformations between models is developed and is applied to an understood Traffic Management System of Systems problem to demonstrate the approach. In this way, the relational structure of the system behavior model is reflected in the structure of the Fault Tree. The paper concludes with a discussion of limitations of the transformation method and proposes approaches to extend it to object flows, State Machines and functional allocations.

</details>

<details>

<summary>2018-04-30 19:26:40 - OhioState at SemEval-2018 Task 7: Exploiting Data Augmentation for Relation Classification in Scientific Papers using Piecewise Convolutional Neural Networks</summary>

- *Dushyanta Dhyani*

- `1802.08949v2` - [abs](http://arxiv.org/abs/1802.08949v2) - [pdf](http://arxiv.org/pdf/1802.08949v2)

> We describe our system for SemEval-2018 Shared Task on Semantic Relation Extraction and Classification in Scientific Papers where we focus on the Classification task. Our simple piecewise convolution neural encoder performs decently in an end to end manner. A simple inter-task data augmentation signifi- cantly boosts the performance of the model. Our best-performing systems stood 8th out of 20 teams on the classification task on noisy data and 12th out of 28 teams on the classification task on clean data.

</details>

<details>

<summary>2018-04-30 21:00:03 - Syntactic Patterns Improve Information Extraction for Medical Search</summary>

- *Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova, Byron Wallace*

- `1805.00097v1` - [abs](http://arxiv.org/abs/1805.00097v1) - [pdf](http://arxiv.org/pdf/1805.00097v1)

> Medical professionals search the published literature by specifying the type of patients, the medical intervention(s) and the outcome measure(s) of interest. In this paper we demonstrate how features encoding syntactic patterns improve the performance of state-of-the-art sequence tagging models (both linear and neural) for information extraction of these medically relevant categories. We present an analysis of the type of patterns exploited, and the semantic space induced for these, i.e., the distributed representations learned for identified multi-token patterns. We show that these learned representations differ substantially from those of the constituent unigrams, suggesting that the patterns capture contextual information that is otherwise lost.

</details>

<details>

<summary>2018-04-30 22:30:23 - Types for Information Flow Control: Labeling Granularity and Semantic Models</summary>

- *Vineet Rajani, Deepak Garg*

- `1805.00120v1` - [abs](http://arxiv.org/abs/1805.00120v1) - [pdf](http://arxiv.org/pdf/1805.00120v1)

> Language-based information flow control (IFC) tracks dependencies within a program using sensitivity labels and prohibits public outputs from depending on secret inputs. In particular, literature has proposed several type systems for tracking these dependencies. On one extreme, there are fine-grained type systems (like Flow Caml) that label all values individually and track dependence at the level of individual values. On the other extreme are coarse-grained type systems (like HLIO) that track dependence coarsely, by associating a single label with an entire computation context and not labeling all values individually.   In this paper, we show that, despite their glaring differences, both these styles are, in fact, equally expressive. To do this, we show a semantics- and type-preserving translation from a coarse-grained type system to a fine-grained one and vice-versa. The forward translation isn't surprising, but the backward translation is: It requires a construct to arbitrarily limit the scope of a context label in the coarse-grained type system (e.g., HLIO's "toLabeled" construct). As a separate contribution, we show how to extend work on logical relation models of IFC types to higher-order state. We build such logical relations for both the fine-grained type system and the coarse-grained type system. We use these relations to prove the two type systems and our translations between them sound.

</details>


## 2018-05

<details>

<summary>2018-05-01 02:14:00 - Memory-augmented Dialogue Management for Task-oriented Dialogue Systems</summary>

- *Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing Chen, Xiaoyan Zhu*

- `1805.00150v1` - [abs](http://arxiv.org/abs/1805.00150v1) - [pdf](http://arxiv.org/pdf/1805.00150v1)

> Dialogue management (DM) decides the next action of a dialogue system according to the current dialogue state, and thus plays a central role in task-oriented dialogue systems. Since dialogue management requires to have access to not only local utterances, but also the global semantics of the entire dialogue session, modeling the long-range history information is a critical issue. To this end, we propose a novel Memory-Augmented Dialogue management model (MAD) which employs a memory controller and two additional memory structures, i.e., a slot-value memory and an external memory. The slot-value memory tracks the dialogue state by memorizing and updating the values of semantic slots (for instance, cuisine, price, and location), and the external memory augments the representation of hidden states of traditional recurrent neural networks through storing more context information. To update the dialogue state efficiently, we also propose slot-level attention on user utterances to extract specific semantic information for each slot. Experiments show that our model can obtain state-of-the-art performance and outperforms existing baselines.

</details>

<details>

<summary>2018-05-01 05:52:12 - An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols</summary>

- *Chaitanya Kulkarni, Wei Xu, Alan Ritter, Raghu Machiraju*

- `1805.00195v1` - [abs](http://arxiv.org/abs/1805.00195v1) - [pdf](http://arxiv.org/pdf/1805.00195v1)

> We describe an effort to annotate a corpus of natural language instructions consisting of 622 wet lab protocols to facilitate automatic or semi-automatic conversion of protocols into a machine-readable format and benefit biological research. Experimental results demonstrate the utility of our corpus for developing machine learning approaches to shallow semantic parsing of instructional texts. We make our annotated Wet Lab Protocol Corpus available to the research community.

</details>

<details>

<summary>2018-05-01 09:16:53 - Nugget Proposal Networks for Chinese Event Detection</summary>

- *Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun*

- `1805.00249v1` - [abs](http://arxiv.org/abs/1805.00249v1) - [pdf](http://arxiv.org/pdf/1805.00249v1)

> Neural network based models commonly regard event detection as a word-wise classification task, which suffer from the mismatch problem between words and event triggers, especially in languages without natural word delimiters such as Chinese. In this paper, we propose Nugget Proposal Networks (NPNs), which can solve the word-trigger mismatch problem by directly proposing entire trigger nuggets centered at each character regardless of word boundaries. Specifically, NPNs perform event detection in a character-wise paradigm, where a hybrid representation for each character is first learned to capture both structural and semantic information from both characters and words. Then based on learned representations, trigger nuggets are proposed and categorized by exploiting character compositional structures of Chinese event triggers. Experiments on both ACE2005 and TAC KBP 2017 datasets show that NPNs significantly outperform the state-of-the-art methods.

</details>

<details>

<summary>2018-05-01 09:39:19 - Joint Bootstrapping Machines for High Confidence Relation Extraction</summary>

- *Pankaj Gupta, Benjamin Roth, Hinrich Schütze*

- `1805.00254v1` - [abs](http://arxiv.org/abs/1805.00254v1) - [pdf](http://arxiv.org/pdf/1805.00254v1)

> Semi-supervised bootstrapping techniques for relationship extraction from text iteratively expand a set of initial seed instances. Due to the lack of labeled data, a key challenge in bootstrapping is semantic drift: if a false positive instance is added during an iteration, then all following iterations are contaminated. We introduce BREX, a new bootstrapping method that protects against such contamination by highly effective confidence assessment. This is achieved by using entity and template seeds jointly (as opposed to just one as in previous work), by expanding entities and templates in parallel and in a mutually constraining fashion in each iteration and by introducing higherquality similarity measures for templates. Experimental results show that BREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the art for four relationships.

</details>

<details>

<summary>2018-05-01 11:08:00 - Capturing Ambiguity in Crowdsourcing Frame Disambiguation</summary>

- *Anca Dumitrache, Lora Aroyo, Chris Welty*

- `1805.00270v1` - [abs](http://arxiv.org/abs/1805.00270v1) - [pdf](http://arxiv.org/pdf/1805.00270v1)

> FrameNet is a computational linguistics resource composed of semantic frames, high-level concepts that represent the meanings of words. In this paper, we present an approach to gather frame disambiguation annotations in sentences using a crowdsourcing approach with multiple workers per sentence to capture inter-annotator disagreement. We perform an experiment over a set of 433 sentences annotated with frames from the FrameNet corpus, and show that the aggregated crowd annotations achieve an F1 score greater than 0.67 as compared to expert linguists. We highlight cases where the crowd annotation was correct even though the expert is in disagreement, arguing for the need to have multiple annotators per sentence. Most importantly, we examine cases in which crowd workers could not agree, and demonstrate that these cases exhibit ambiguity, either in the sentence, frame, or the task itself, and argue that collapsing such cases to a single, discrete truth value (i.e. correct or incorrect) is inappropriate, creating arbitrary targets for machine learning.

</details>

<details>

<summary>2018-05-01 12:21:50 - Multitask Parsing Across Semantic Representations</summary>

- *Daniel Hershcovich, Omri Abend, Ari Rappoport*

- `1805.00287v1` - [abs](http://arxiv.org/abs/1805.00287v1) - [pdf](http://arxiv.org/pdf/1805.00287v1)

> The ability to consolidate information of different types is at the core of intelligence, and has tremendous practical value in allowing learning for one task to benefit from generalizations learned for others. In this paper we tackle the challenging task of improving semantic parsing performance, taking UCCA parsing as a test case, and AMR, SDP and Universal Dependencies (UD) parsing as auxiliary tasks. We experiment on three languages, using a uniform transition-based system and learning architecture for all parsing tasks. Despite notable conceptual, formal and domain differences, we show that multitask learning significantly improves UCCA parsing in both in-domain and out-of-domain settings.

</details>

<details>

<summary>2018-05-01 20:59:31 - Algorithms for Semantic Segmentation of Multispectral Remote Sensing Imagery using Deep Learning</summary>

- *Ronald Kemker, Carl Salvaggio, Christopher Kanan*

- `1703.06452v3` - [abs](http://arxiv.org/abs/1703.06452v3) - [pdf](http://arxiv.org/pdf/1703.06452v3)

> Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.

</details>

<details>

<summary>2018-05-02 00:13:28 - Fused Deep Neural Networks for Efficient Pedestrian Detection</summary>

- *Xianzhi Du, Mostafa El-Khamy, Vlad I. Morariu, Jungwon Lee, Larry Davis*

- `1805.08688v1` - [abs](http://arxiv.org/abs/1805.08688v1) - [pdf](http://arxiv.org/pdf/1805.08688v1)

> In this paper, we present an efficient pedestrian detection system, designed by fusion of multiple deep neural network (DNN) systems. Pedestrian candidates are first generated by a single shot convolutional multi-box detector at different locations with various scales and aspect ratios. The candidate generator is designed to provide the majority of ground truth pedestrian annotations at the cost of a large number of false positives. Then, a classification system using the idea of ensemble learning is deployed to improve the detection accuracy. The classification system further classifies the generated candidates based on opinions of multiple deep verification networks and a fusion network which utilizes a novel soft-rejection fusion method to adjust the confidence in the detection results. To improve the training of the deep verification networks, a novel soft-label method is devised to assign floating point labels to the generated pedestrian candidates. A deep context aggregation semantic segmentation network also provides pixel-level classification of the scene and its results are softly fused with the detection results by the single shot detector. Our pedestrian detector compared favorably to state-of-art methods on all popular pedestrian detection datasets. For example, our fused DNN has better detection accuracy on the Caltech Pedestrian dataset than all previous state of art methods, while also being the fastest. We significantly improved the log-average miss rate on the Caltech pedestrian dataset to 7.67% and achieved the new state-of-the-art.

</details>

<details>

<summary>2018-05-02 03:55:10 - Semantic Channel and Shannon's Channel Mutually Match for Multi-Label Classification</summary>

- *Chenguang Lu*

- `1805.01288v1` - [abs](http://arxiv.org/abs/1805.01288v1) - [pdf](http://arxiv.org/pdf/1805.01288v1)

> A group of transition probability functions form a Shannon's channel whereas a group of truth functions form a semantic channel. Label learning is to let semantic channels match Shannon's channels and label selection is to let Shannon's channels match semantic channels. The Channel Matching (CM) algorithm is provided for multi-label classification. This algorithm adheres to maximum semantic information criterion which is compatible with maximum likelihood criterion and regularized least squares criterion. If samples are very large, we can directly convert Shannon's channels into semantic channels by the third kind of Bayes' theorem; otherwise, we can train truth functions with parameters by sampling distributions. A label may be a Boolean function of some atomic labels. For simplifying learning, we may only obtain the truth functions of some atomic label. For a given label, instances are divided into three kinds (positive, negative, and unclear) instead of two kinds as in popular studies so that the problem with binary relevance is avoided. For each instance, the classifier selects a compound label with most semantic information or richest connotation. As a predictive model, the semantic channel does not change with the prior probability distribution (source) of instances. It still works when the source is changed. The classifier changes with the source, and hence can overcome class-imbalance problem. It is shown that the old population's increasing will change the classifier for label "Old" and has been impelling the semantic evolution of "Old". The CM iteration algorithm for unseen instance classification is introduced.

</details>

<details>

<summary>2018-05-02 07:58:55 - Functional ASP with Intensional Sets: Application to Gelfond-Zhang Aggregates</summary>

- *Pedro Cabalar, Jorge Fandinno, Luis Fariñas del Cerro, David Pearce*

- `1805.00660v1` - [abs](http://arxiv.org/abs/1805.00660v1) - [pdf](http://arxiv.org/pdf/1805.00660v1)

> In this paper, we propose a variant of Answer Set Programming (ASP) with evaluable functions that extends their application to sets of objects, something that allows a fully logical treatment of aggregates. Formally, we start from the syntax of First Order Logic with equality and the semantics of Quantified Equilibrium Logic with evaluable functions (QELF). Then, we proceed to incorporate a new kind of logical term, intensional set (a construct commonly used to denote the set of objects characterised by a given formula), and to extend QELF semantics for this new type of expression. In our extended approach, intensional sets can be arbitrarily used as predicate or function arguments or even nested inside other intensional sets, just as regular first-order logical terms. As a result, aggregates can be naturally formed by the application of some evaluable function (count, sum, maximum, etc) to a set of objects expressed as an intensional set. This approach has several advantages. First, while other semantics for aggregates depend on some syntactic transformation (either via a reduct or a formula translation), the QELF interpretation treats them as regular evaluable functions, providing a compositional semantics and avoiding any kind of syntactic restriction. Second, aggregates can be explicitly defined now within the logical language by the simple addition of formulas that fix their meaning in terms of multiple applications of some (commutative and associative) binary operation. For instance, we can use recursive rules to define sum in terms of integer addition. Last, but not least, we prove that the semantics we obtain for aggregates coincides with the one defined by Gelfond and Zhang for the Alog language, when we restrict to that syntactic fragment. (Under consideration for acceptance in TPLP)

</details>

<details>

<summary>2018-05-02 08:47:38 - Text to Image Synthesis Using Generative Adversarial Networks</summary>

- *Cristian Bodnar*

- `1805.00676v1` - [abs](http://arxiv.org/abs/1805.00676v1) - [pdf](http://arxiv.org/pdf/1805.00676v1)

> Generating images from natural language is one of the primary applications of recent conditional generative models. Besides testing our ability to model conditional, highly dimensional distributions, text to image synthesis has many exciting and practical applications such as photo editing or computer-aided content creation. Recent progress has been made using Generative Adversarial Networks (GANs). This material starts with a gentle introduction to these topics and discusses the existent state of the art models. Moreover, I propose Wasserstein GAN-CLS, a new model for conditional image generation based on the Wasserstein distance which offers guarantees of stability. Then, I show how the novel loss function of Wasserstein GAN-CLS can be used in a Conditional Progressive Growing GAN. In combination with the proposed loss, the model boosts by 7.07% the best Inception Score (on the Caltech birds dataset) of the models which use only the sentence-level visual semantics. The only model which performs better than the Conditional Wasserstein Progressive Growing GAN is the recently proposed AttnGAN which uses word-level visual semantics as well.

</details>

<details>

<summary>2018-05-02 11:03:52 - Exploring Emoji Usage and Prediction Through a Temporal Variation Lens</summary>

- *Francesco Barbieri, Luis Marujo, Pradeep Karuturi, William Brendel, Horacio Saggion*

- `1805.00731v1` - [abs](http://arxiv.org/abs/1805.00731v1) - [pdf](http://arxiv.org/pdf/1805.00731v1)

> The frequent use of Emojis on social media platforms has created a new form of multimodal social interaction. Developing methods for the study and representation of emoji semantics helps to improve future multimodal communication systems. In this paper, we explore the usage and semantics of emojis over time. We compare emoji embeddings trained on a corpus of different seasons and show that some emojis are used differently depending on the time of the year. Moreover, we propose a method to take into account the time information for emoji prediction systems, outperforming state-of-the-art systems. We show that, using the time information, the accuracy of some emojis can be significantly improved.

</details>

<details>

<summary>2018-05-03 01:57:31 - Scalable Semantic Querying of Text</summary>

- *Xiaolan Wang, Aaron Feng, Behzad Golshan, Alon Halevy, George Mihaila, Hidekazu Oiwa, Wang-Chiew Tan*

- `1805.01083v1` - [abs](http://arxiv.org/abs/1805.01083v1) - [pdf](http://arxiv.org/pdf/1805.01083v1)

> We present the KOKO system that takes declarative information extraction to a new level by incorporating advances in natural language processing techniques in its extraction language. KOKO is novel in that its extraction language simultaneously supports conditions on the surface of the text and on the structure of the dependency parse tree of sentences, thereby allowing for more refined extractions. KOKO also supports conditions that are forgiving to linguistic variation of expressing concepts and allows to aggregate evidence from the entire document in order to filter extractions.   To scale up, KOKO exploits a multi-indexing scheme and heuristics for efficient extractions. We extensively evaluate KOKO over publicly available text corpora. We show that KOKO indices take up the smallest amount of space, are notably faster and more effective than a number of prior indexing schemes. Finally, we demonstrate KOKO's scale up on a corpus of 5 million Wikipedia articles.

</details>

<details>

<summary>2018-05-03 09:57:13 - Simplified SPARQL REST API - CRUD on JSON Object Graphs via URI Paths</summary>

- *Markus Schröder, Jörn Hees, Ansgar Bernardi, Daniel Ewert, Peter Klotz, Steffen Stadtmüller*

- `1805.01825v1` - [abs](http://arxiv.org/abs/1805.01825v1) - [pdf](http://arxiv.org/pdf/1805.01825v1)

> Within the Semantic Web community, SPARQL is one of the predominant languages to query and update RDF knowledge. However, the complexity of SPARQL, the underlying graph structure and various encodings are common sources of confusion for Semantic Web novices.   In this paper we present a general purpose approach to convert any given SPARQL endpoint into a simple to use REST API. To lower the initial hurdle, we represent the underlying graph as an interlinked view of nested JSON objects that can be traversed by the API path.

</details>

<details>

<summary>2018-05-03 15:23:28 - Multi-label Class-imbalanced Action Recognition in Hockey Videos via 3D Convolutional Neural Networks</summary>

- *Konstantin Sozykin, Stanislav Protasov, Adil Khan, Rasheed Hussain, Jooyoung Lee*

- `1709.01421v2` - [abs](http://arxiv.org/abs/1709.01421v2) - [pdf](http://arxiv.org/pdf/1709.01421v2)

> Automatic analysis of the video is one of most complex problems in the fields of computer vision and machine learning. A significant part of this research deals with (human) activity recognition (HAR) since humans, and the activities that they perform, generate most of the video semantics. Video-based HAR has applications in various domains, but one of the most important and challenging is HAR in sports videos. Some of the major issues include high inter- and intra-class variations, large class imbalance, the presence of both group actions and single player actions, and recognizing simultaneous actions, i.e., the multi-label learning problem. Keeping in mind these challenges and the recent success of CNNs in solving various computer vision problems, in this work, we implement a 3D CNN based multi-label deep HAR system for multi-label class-imbalanced action recognition in hockey videos. We test our system for two different scenarios: an ensemble of $k$ binary networks vs. a single $k$-output network, on a publicly available dataset. We also compare our results with the system that was originally designed for the chosen dataset. Experimental results show that the proposed approach performs better than the existing solution.

</details>

<details>

<summary>2018-05-04 08:11:09 - Cross-lingual Candidate Search for Biomedical Concept Normalization</summary>

- *Roland Roller, Madeleine Kittner, Dirk Weissenborn, Ulf Leser*

- `1805.01646v1` - [abs](http://arxiv.org/abs/1805.01646v1) - [pdf](http://arxiv.org/pdf/1805.01646v1)

> Biomedical concept normalization links concept mentions in texts to a semantically equivalent concept in a biomedical knowledge base. This task is challenging as concepts can have different expressions in natural languages, e.g. paraphrases, which are not necessarily all present in the knowledge base. Concept normalization of non-English biomedical text is even more challenging as non-English resources tend to be much smaller and contain less synonyms. To overcome the limitations of non-English terminologies we propose a cross-lingual candidate search for concept normalization using a character-based neural translation model trained on a multilingual biomedical terminology. Our model is trained with Spanish, French, Dutch and German versions of UMLS. The evaluation of our model is carried out on the French Quaero corpus, showing that it outperforms most teams of CLEF eHealth 2015 and 2016. Additionally, we compare performance to commercial translators on Spanish, French, Dutch and German versions of Mantra. Our model performs similarly well, but is free of charge and can be run locally. This is particularly important for clinical NLP applications as medical documents underlay strict privacy restrictions.

</details>

<details>

<summary>2018-05-04 12:25:09 - Multi-Task Learning for Argumentation Mining in Low-Resource Settings</summary>

- *Claudia Schulz, Steffen Eger, Johannes Daxenberger, Tobias Kahse, Iryna Gurevych*

- `1804.04083v3` - [abs](http://arxiv.org/abs/1804.04083v3) - [pdf](http://arxiv.org/pdf/1804.04083v3)

> We investigate whether and where multi-task learning (MTL) can improve performance on NLP problems related to argumentation mining (AM), in particular argument component identification. Our results show that MTL performs particularly well (and better than single-task learning) when little training data is available for the main task, a common scenario in AM. Our findings challenge previous assumptions that conceptualizations across AM datasets are divergent and that MTL is difficult for semantic or higher-level tasks.

</details>

<details>

<summary>2018-05-04 13:40:07 - Dynamic Control Flow in Large-Scale Machine Learning</summary>

- *Yuan Yu, Martín Abadi, Paul Barham, Eugene Brevdo, Mike Burrows, Andy Davis, Jeff Dean, Sanjay Ghemawat, Tim Harley, Peter Hawkins, Michael Isard, Manjunath Kudlur, Rajat Monga, Derek Murray, Xiaoqiang Zheng*

- `1805.01772v1` - [abs](http://arxiv.org/abs/1805.01772v1) - [pdf](http://arxiv.org/pdf/1805.01772v1)

> Many recent machine learning models rely on fine-grained dynamic control flow for training and inference. In particular, models based on recurrent neural networks and on reinforcement learning depend on recurrence relations, data-dependent conditional execution, and other features that call for dynamic control flow. These applications benefit from the ability to make rapid control-flow decisions across a set of computing devices in a distributed system. For performance, scalability, and expressiveness, a machine learning system must support dynamic control flow in distributed and heterogeneous environments.   This paper presents a programming model for distributed machine learning that supports dynamic control flow. We describe the design of the programming model, and its implementation in TensorFlow, a distributed machine learning system. Our approach extends the use of dataflow graphs to represent machine learning models, offering several distinctive features. First, the branches of conditionals and bodies of loops can be partitioned across many machines to run on a set of heterogeneous devices, including CPUs, GPUs, and custom ASICs. Second, programs written in our model support automatic differentiation and distributed gradient computations, which are necessary for training machine learning models that use control flow. Third, our choice of non-strict semantics enables multiple loop iterations to execute in parallel across machines, and to overlap compute and I/O operations.   We have done our work in the context of TensorFlow, and it has been used extensively in research and production. We evaluate it using several real-world applications, and demonstrate its performance and scalability.

</details>

<details>

<summary>2018-05-04 19:48:36 - A Rank-Based Similarity Metric for Word Embeddings</summary>

- *Enrico Santus, Hongmin Wang, Emmanuele Chersoni, Yue Zhang*

- `1805.01923v1` - [abs](http://arxiv.org/abs/1805.01923v1) - [pdf](http://arxiv.org/pdf/1805.01923v1)

> Word Embeddings have recently imposed themselves as a standard for representing word meaning in NLP. Semantic similarity between word pairs has become the most common evaluation benchmark for these representations, with vector cosine being typically used as the only similarity metric. In this paper, we report experiments with a rank-based metric for WE, which performs comparably to vector cosine in similarity estimation and outperforms it in the recently-introduced and challenging task of outlier detection, thus suggesting that rank-based measures can improve clustering quality.

</details>

<details>

<summary>2018-05-04 20:30:53 - Learning to Represent Programs with Graphs</summary>

- *Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi*

- `1711.00740v3` - [abs](http://arxiv.org/abs/1711.00740v3) - [pdf](http://arxiv.org/pdf/1711.00740v3)

> Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.   In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.

</details>

<details>

<summary>2018-05-05 07:53:47 - Process Algebraic Architectural Description Languages: Generalizing Component-Oriented Mismatch Detection in the Presence of Nonsynchronous Communications</summary>

- *Marco Bernardo, Edoardo Bontà, Alessandro Aldini*

- `1805.11676v1` - [abs](http://arxiv.org/abs/1805.11676v1) - [pdf](http://arxiv.org/pdf/1805.11676v1)

> In the original paper, we showed how to enhance the expressiveness of a typical process algebraic architectural description language by including the capability of representing nonsynchronous communications. In particular, we extended the language by means of additional qualifiers enabling the designer to distinguish among synchronous, semi-synchronous, and asynchronous ports. Moreover, we showed how to modify techniques for detecting coordination mismatches such as the compatibility check for star topologies and the interoperability check for cycle topologies, in such a way that those two checks are applicable also in the presence of nonsynchronous communications. In this addendum, we generalize those results by showing that it is possible to verify in a component-oriented way an arbitrary property of a certain class (not only deadlock) over an entire architectural type having an arbitrary topology (not only stars and cycles) by considering also behavioral variations, exogenous variations, endogenous variations, and multiplicity variations, so to deal with the possible presence of nonsynchronous communications. The proofs are at the basis of some results mentioned in the book "A Process Algebraic Approach to Software Architecture Design" by Alessandro Aldini, Marco Bernardo, and Flavio Corradini, published by Springer in 2010.

</details>

<details>

<summary>2018-05-06 10:07:13 - Context Spaces as the Cornerstone of a Near-Transparent & Self-Reorganizing Semantic Desktop</summary>

- *Christian Jilek, Markus Schröder, Sven Schwarz, Heiko Maus, Andreas Dengel*

- `1805.02181v1` - [abs](http://arxiv.org/abs/1805.02181v1) - [pdf](http://arxiv.org/pdf/1805.02181v1)

> Existing Semantic Desktops are still reproached for being too complicated to use or not scaling well. Besides, a real "killer app" is still missing. In this paper, we present a new prototype inspired by NEPOMUK and its successors having a semantic graph and ontologies as its basis. In addition, we introduce the idea of context spaces that users can directly interact with and work on. To make them available in all applications without further ado, the system is transparently integrated using mostly standard protocols complemented by a sidebar for advanced features. By exploiting collected context information and applying Managed Forgetting features (like hiding, condensation or deletion), the system is able to dynamically reorganize itself, which also includes a kind of tidy-up-itself functionality. We therefore expect it to be more scalable while providing new levels of user support. An early prototype has been implemented and is presented in this demo.

</details>

<details>

<summary>2018-05-06 17:58:48 - On the Evaluation of Semantic Phenomena in Neural Machine Translation Using Natural Language Inference</summary>

- *Adam Poliak, Yonatan Belinkov, James Glass, Benjamin Van Durme*

- `1804.09779v2` - [abs](http://arxiv.org/abs/1804.09779v2) - [pdf](http://arxiv.org/pdf/1804.09779v2)

> We propose a process for investigating the extent to which sentence representations arising from neural machine translation (NMT) systems encode distinct semantic phenomena. We use these representations as features to train a natural language inference (NLI) classifier based on datasets recast from existing semantic annotations. In applying this process to a representative NMT system, we find its encoder appears most suited to supporting inferences at the syntax-semantics interface, as compared to anaphora resolution requiring world-knowledge. We conclude with a discussion on the merits and potential deficiencies of the existing process, and how it may be improved and extended as a broader framework for evaluating semantic coverage.

</details>

<details>

<summary>2018-05-06 18:35:48 - Construction of the Literature Graph in Semantic Scholar</summary>

- *Waleed Ammar, Dirk Groeneveld, Chandra Bhagavatula, Iz Beltagy, Miles Crawford, Doug Downey, Jason Dunkelberger, Ahmed Elgohary, Sergey Feldman, Vu Ha, Rodney Kinney, Sebastian Kohlmeier, Kyle Lo, Tyler Murray, Hsu-Han Ooi, Matthew Peters, Joanna Power, Sam Skjonsberg, Lucy Lu Wang, Chris Wilhelm, Zheng Yuan, Madeleine van Zuylen, Oren Etzioni*

- `1805.02262v1` - [abs](http://arxiv.org/abs/1805.02262v1) - [pdf](http://arxiv.org/pdf/1805.02262v1)

> We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery. The resulting literature graph consists of more than 280M nodes, representing papers, authors, entities and various interactions between them (e.g., authorships, citations, entity mentions). We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task. The methods described in this paper are used to enable semantic features in www.semanticscholar.org

</details>

<details>

<summary>2018-05-07 11:14:07 - Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations</summary>

- *Vered Shwartz, Ido Dagan*

- `1805.02442v1` - [abs](http://arxiv.org/abs/1805.02442v1) - [pdf](http://arxiv.org/pdf/1805.02442v1)

> Revealing the implicit semantic relation between the constituents of a noun-compound is important for many NLP applications. It has been addressed in the literature either as a classification task to a set of pre-defined relations or by producing free text paraphrases explicating the relations. Most existing paraphrasing methods lack the ability to generalize, and have a hard time interpreting infrequent or new noun-compounds. We propose a neural model that generalizes better by representing paraphrases in a continuous space, generalizing for both unseen noun-compounds and rare paraphrases. Our model helps improving performance on both the noun-compound paraphrasing and classification tasks.

</details>

<details>

<summary>2018-05-08 15:14:20 - Fast Feature Extraction with CNNs with Pooling Layers</summary>

- *Christian Bailer, Tewodros Habtegebrial, Kiran varanasi, Didier Stricker*

- `1805.03096v1` - [abs](http://arxiv.org/abs/1805.03096v1) - [pdf](http://arxiv.org/pdf/1805.03096v1)

> In recent years, many publications showed that convolutional neural network based features can have a superior performance to engineered features. However, not much effort was taken so far to extract local features efficiently for a whole image. In this paper, we present an approach to compute patch-based local feature descriptors efficiently in presence of pooling and striding layers for whole images at once. Our approach is generic and can be applied to nearly all existing network architectures. This includes networks for all local feature extraction tasks like camera calibration, Patchmatching, optical flow estimation and stereo matching. In addition, our approach can be applied to other patch-based approaches like sliding window object detection and recognition. We complete our paper with a speed benchmark of popular CNN based feature extraction approaches applied on a whole image, with and without our speedup, and example code (for Torch) that shows how an arbitrary CNN architecture can be easily converted by our approach.

</details>

<details>

<summary>2018-05-09 09:41:51 - Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks</summary>

- *Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith, Nils Y. Hammerla*

- `1805.03435v1` - [abs](http://arxiv.org/abs/1805.03435v1) - [pdf](http://arxiv.org/pdf/1805.03435v1)

> Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. We provide a simple yet rigorous explanation for this behaviour by introducing the concept of an optimal representation space, in which semantically close symbols are mapped to representations that are close under a similarity measure induced by the model's objective function. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.

</details>

<details>

<summary>2018-05-09 13:56:12 - Reference-less Measure of Faithfulness for Grammatical Error Correction</summary>

- *Leshem Choshen, Omri Abend*

- `1804.03824v4` - [abs](http://arxiv.org/abs/1804.03824v4) - [pdf](http://arxiv.org/pdf/1804.03824v4)

> We propose USim, a semantic measure for Grammatical Error Correction (GEC) that measures the semantic faithfulness of the output to the source, thereby complementing existing reference-less measures (RLMs) for measuring the output's grammaticality. USim operates by comparing the semantic symbolic structure of the source and the correction, without relying on manually-curated references. Our experiments establish the validity of USim, by showing that (1) semantic annotation can be consistently applied to ungrammatical text; (2) valid corrections obtain a high USim similarity score to the source; and (3) invalid corrections obtain a lower score.

</details>

<details>

<summary>2018-05-10 03:39:32 - Learning Domain-Sensitive and Sentiment-Aware Word Embeddings</summary>

- *Bei Shi, Zihao Fu, Lidong Bing, Wai Lam*

- `1805.03801v1` - [abs](http://arxiv.org/abs/1805.03801v1) - [pdf](http://arxiv.org/pdf/1805.03801v1)

> Word embeddings have been widely used in sentiment classification because of their efficacy for semantic representations of words. Given reviews from different domains, some existing methods for word embeddings exploit sentiment information, but they cannot produce domain-sensitive embeddings. On the other hand, some other existing methods can generate domain-sensitive word embeddings, but they cannot distinguish words with similar contexts but opposite sentiment polarity. We propose a new method for learning domain-sensitive and sentiment-aware embeddings that simultaneously capture the information of sentiment semantics and domain sensitivity of individual words. Our method can automatically determine and produce domain-common embeddings and domain-specific embeddings. The differentiation of domain-common and domain-specific words enables the advantage of data augmentation of common semantics from multiple domains and capture the varied semantics of specific words from different domains at the same time. Experimental results show that our model provides an effective way to learn domain-sensitive and sentiment-aware word embeddings which benefit sentiment classification at both sentence level and lexicon term level.

</details>

<details>

<summary>2018-05-10 09:26:03 - Loss-Calibrated Approximate Inference in Bayesian Neural Networks</summary>

- *Adam D. Cobb, Stephen J. Roberts, Yarin Gal*

- `1805.03901v1` - [abs](http://arxiv.org/abs/1805.03901v1) - [pdf](http://arxiv.org/pdf/1805.03901v1)

> Current approaches in approximate inference for Bayesian neural networks minimise the Kullback-Leibler divergence to approximate the true posterior over the weights. However, this approximation is without knowledge of the final application, and therefore cannot guarantee optimal predictions for a given task. To make more suitable task-specific approximations, we introduce a new loss-calibrated evidence lower bound for Bayesian neural networks in the context of supervised learning, informed by Bayesian decision theory. By introducing a lower bound that depends on a utility function, we ensure that our approximation achieves higher utility than traditional methods for applications that have asymmetric utility functions. Furthermore, in using dropout inference, we highlight that our new objective is identical to that of standard dropout neural networks, with an additional utility-dependent penalty term. We demonstrate our new loss-calibrated model with an illustrative medical example and a restricted model capacity experiment, and highlight failure modes of the comparable weighted cross entropy approach. Lastly, we demonstrate the scalability of our method to real world applications with per-pixel semantic segmentation on an autonomous driving data set.

</details>

<details>

<summary>2018-05-10 15:58:09 - Regularizing Output Distribution of Abstractive Chinese Social Media Text Summarization for Improved Semantic Consistency</summary>

- *Bingzhen Wei, Xuancheng Ren, Xu Sun, Yi Zhang, Xiaoyan Cai, Qi Su*

- `1805.04033v1` - [abs](http://arxiv.org/abs/1805.04033v1) - [pdf](http://arxiv.org/pdf/1805.04033v1)

> Abstractive text summarization is a highly difficult problem, and the sequence-to-sequence model has shown success in improving the performance on the task. However, the generated summaries are often inconsistent with the source content in semantics. In such cases, when generating summaries, the model selects semantically unrelated words with respect to the source content as the most probable output. The problem can be attributed to heuristically constructed training data, where summaries can be unrelated to the source content, thus containing semantically unrelated words and spurious word correspondence. In this paper, we propose a regularization approach for the sequence-to-sequence model and make use of what the model has learned to regularize the learning objective to alleviate the effect of the problem. In addition, we propose a practical human evaluation method to address the problem that the existing automatic evaluation method does not evaluate the semantic consistency with the source content properly. Experimental results demonstrate the effectiveness of the proposed approach, which outperforms almost all the existing models. Especially, the proposed approach improves the semantic consistency by 4\% in terms of human evaluation.

</details>

<details>

<summary>2018-05-10 20:05:59 - Computational Social Choice Meets Databases</summary>

- *Benny Kimelfeld, Phokion G. Kolaitis, Julia Stoyanovich*

- `1805.04156v1` - [abs](http://arxiv.org/abs/1805.04156v1) - [pdf](http://arxiv.org/pdf/1805.04156v1)

> We develop a novel framework that aims to create bridges between the computational social choice and the database management communities. This framework enriches the tasks currently supported in computational social choice with relational database context, thus making it possible to formulate sophisticated queries about voting rules, candidates, voters, issues, and positions. At the conceptual level, we give rigorous semantics to queries in this framework by introducing the notions of necessary answers and possible answers to queries. At the technical level, we embark on an investigation of the computational complexity of the necessary answers. We establish a number of results about the complexity of the necessary answers of conjunctive queries involving positional scoring rules that contrast sharply with earlier results about the complexity of the necessary winners.

</details>

<details>

<summary>2018-05-10 20:42:52 - Joint Embedding of Words and Labels for Text Classification</summary>

- *Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen, Xinyuan Zhang, Ricardo Henao, Lawrence Carin*

- `1805.04174v1` - [abs](http://arxiv.org/abs/1805.04174v1) - [pdf](http://arxiv.org/pdf/1805.04174v1)

> Word embeddings are effective intermediate representations for capturing semantic regularities between words, when learning the representations of text sequences. We propose to view text classification as a label-word joint embedding problem: each label is embedded in the same space with the word vectors. We introduce an attention framework that measures the compatibility of embeddings between text sequences and labels. The attention is learned on a training set of labeled samples to ensure that, given a text sequence, the relevant words are weighted higher than the irrelevant ones. Our method maintains the interpretability of word embeddings, and enjoys a built-in ability to leverage alternative sources of information, in addition to input text sequences. Extensive results on the several large text datasets show that the proposed framework outperforms the state-of-the-art methods by a large margin, in terms of both accuracy and speed.

</details>

<details>

<summary>2018-05-11 00:43:59 - Behavior Analysis of NLI Models: Uncovering the Influence of Three Factors on Robustness</summary>

- *Vicente Ivan Sanchez Carmona, Jeff Mitchell, Sebastian Riedel*

- `1805.04212v1` - [abs](http://arxiv.org/abs/1805.04212v1) - [pdf](http://arxiv.org/pdf/1805.04212v1)

> Natural Language Inference is a challenging task that has received substantial attention, and state-of-the-art models now achieve impressive test set performance in the form of accuracy scores. Here, we go beyond this single evaluation metric to examine robustness to semantically-valid alterations to the input data. We identify three factors - insensitivity, polarity and unseen pairs - and compare their impact on three SNLI models under a variety of conditions. Our results demonstrate a number of strengths and weaknesses in the models' ability to generalise to new in-domain instances. In particular, while strong performance is possible on unseen hypernyms, unseen antonyms are more challenging for all the models. More generally, the models suffer from an insensitivity to certain small but semantically significant alterations, and are also often influenced by simple statistical correlations between words and training labels. Overall, we show that evaluations of NLI models can benefit from studying the influence of factors intrinsic to the models or found in the dataset used.

</details>

<details>

<summary>2018-05-11 01:34:52 - Deep RNNs Encode Soft Hierarchical Syntax</summary>

- *Terra Blevins, Omer Levy, Luke Zettlemoyer*

- `1805.04218v1` - [abs](http://arxiv.org/abs/1805.04218v1) - [pdf](http://arxiv.org/pdf/1805.04218v1)

> We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision.

</details>

<details>

<summary>2018-05-11 03:31:40 - Digital Cardan Grille: A Modern Approach for Information Hiding</summary>

- *Jia Liu, Tanping Zhou, Zhuo Zhang, Yan Ke, Yu Lei, Minqing Zhang, Xiaoyuan Yang*

- `1803.09219v2` - [abs](http://arxiv.org/abs/1803.09219v2) - [pdf](http://arxiv.org/pdf/1803.09219v2)

> In this paper, a new framework for construction of Cardan grille for information hiding is proposed. Based on the semantic image inpainting technique, the stego image are driven by secret messages directly. A mask called Digital Cardan Grille (DCG) for determining the hidden location is introduced to hide the message. The message is written to the corrupted region that needs to be filled in the corrupted image in advance. Then the corrupted image with secret message is feeded into a Generative Adversarial Network (GAN) for semantic completion. The adversarial game not only reconstruct the corrupted image , but also generate a stego image which contains the logic rationality of image content. The experimental results verify the feasibility of the proposed method.

</details>

<details>

<summary>2018-05-11 03:36:32 - Neural Machine Translation for Bilingually Scarce Scenarios: A Deep Multi-task Learning Approach</summary>

- *Poorya Zaremoodi, Gholamreza Haffari*

- `1805.04237v1` - [abs](http://arxiv.org/abs/1805.04237v1) - [pdf](http://arxiv.org/pdf/1805.04237v1)

> Neural machine translation requires large amounts of parallel training text to learn a reasonable-quality translation model. This is particularly inconvenient for language pairs for which enough parallel text is not available. In this paper, we use monolingual linguistic resources in the source side to address this challenging problem based on a multi-task learning approach. More specifically, we scaffold the machine translation task on auxiliary tasks including semantic parsing, syntactic parsing, and named-entity recognition. This effectively injects semantic and/or syntactic knowledge into the translation model, which would otherwise require a large amount of training bitext. We empirically evaluate and show the effectiveness of our multi-task learning approach on three translation tasks: English-to-French, English-to-Farsi, and English-to-Vietnamese.

</details>

<details>

<summary>2018-05-11 09:02:29 - Incentivized Delivery Network of IoT Software Updates Based on Trustless Proof-of-Distribution</summary>

- *Oded Leiba, Yechiav Yitzchak, Ron Bitton, Asaf Nadler, Asaf Shabtai*

- `1805.04282v1` - [abs](http://arxiv.org/abs/1805.04282v1) - [pdf](http://arxiv.org/pdf/1805.04282v1)

> The prevalence of IoT devices makes them an ideal target for attackers. To reduce the risk of attacks vendors routinely deliver security updates (patches) for their devices. The delivery of security updates becomes challenging due to the issue of scalability as the number of devices may grow much quicker than vendors' distribution systems. Previous studies have suggested a permissionless and decentralized blockchain-based network in which nodes can host and deliver security updates, thus the addition of new nodes scales out the network. However, these studies do not provide an incentive for nodes to join the network, making it unlikely for nodes to freely contribute their hosting space, bandwidth, and computation resources. In this paper, we propose a novel decentralized IoT software update delivery network in which participating nodes referred to as distributors) are compensated by vendors with digital currency for delivering updates to devices. Upon the release of a new security update, a vendor will make a commitment to provide digital currency to distributors that deliver the update; the commitment will be made with the use of smart contracts, and hence will be public, binding, and irreversible. The smart contract promises compensation to any distributor that provides proof-of-distribution, which is unforgeable proof that a single update was delivered to a single device. A distributor acquires the proof-of-distribution by exchanging a security update for a device signature using the Zero-Knowledge Contingent Payment (ZKCP) trustless data exchange protocol. Eliminating the need for trust between the security update distributor and the security consumer (IoT device) by providing fair compensation, can significantly increase the number of distributors, thus facilitating rapid scale out.

</details>

<details>

<summary>2018-05-11 13:41:54 - A Sensorimotor Perspective on Grounding the Semantic of Simple Visual Features</summary>

- *Alban Laflaquière*

- `1805.04396v1` - [abs](http://arxiv.org/abs/1805.04396v1) - [pdf](http://arxiv.org/pdf/1805.04396v1)

> In Machine Learning and Robotics, the semantic content of visual features is usually provided to the system by a human who interprets its content. On the contrary, strictly unsupervised approaches have difficulties relating the statistics of sensory inputs to their semantic content without also relying on prior knowledge introduced in the system. We proposed in this paper to tackle this problem from a sensorimotor perspective. In line with the Sensorimotor Contingencies Theory, we make the fundamental assumption that the semantic content of sensory inputs at least partially stems from the way an agent can actively transform it. We illustrate our approach by formalizing how simple visual features can induce invariants in a naive agent's sensorimotor experience, and evaluate it on a simple simulated visual system. Without any a priori knowledge about the way its sensorimotor information is encoded, we show how an agent can characterize the uniformity and edge-ness of the visual features it interacts with.

</details>

<details>

<summary>2018-05-11 17:57:40 - Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems</summary>

- *Svetlana Kiritchenko, Saif M. Mohammad*

- `1805.04508v1` - [abs](http://arxiv.org/abs/1805.04508v1) - [pdf](http://arxiv.org/pdf/1805.04508v1)

> Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems. Further, there is no benchmark dataset for examining inappropriate biases in systems. Here for the first time, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We use the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 'Affect in Tweets'. We find that several of the systems show statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available.

</details>

<details>

<summary>2018-05-11 22:09:37 - Confidence Modeling for Neural Semantic Parsing</summary>

- *Li Dong, Chris Quirk, Mirella Lapata*

- `1805.04604v1` - [abs](http://arxiv.org/abs/1805.04604v1) - [pdf](http://arxiv.org/pdf/1805.04604v1)

> In this work we focus on confidence modeling for neural semantic parsers which are built upon sequence-to-sequence models. We outline three major causes of uncertainty, and design various metrics to quantify these factors. These metrics are then used to estimate confidence scores that indicate whether model predictions are likely to be correct. Beyond confidence estimation, we identify which parts of the input contribute to uncertain predictions allowing users to interpret their model, and verify or refine its input. Experimental results show that our confidence model significantly outperforms a widely used method that relies on posterior probability, and improves the quality of interpretation compared to simply relying on attention scores.

</details>

<details>

<summary>2018-05-12 00:26:29 - Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</summary>

- *Urvashi Khandelwal, He He, Peng Qi, Dan Jurafsky*

- `1805.04623v1` - [abs](http://arxiv.org/abs/1805.04623v1) - [pdf](http://arxiv.org/pdf/1805.04623v1)

> We know very little about how neural language models (LM) use prior linguistic context. In this paper, we investigate the role of context in an LSTM LM, through ablation studies. Specifically, we analyze the increase in perplexity when prior context words are shuffled, replaced, or dropped. On two standard datasets, Penn Treebank and WikiText-2, we find that the model is capable of using about 200 tokens of context on average, but sharply distinguishes nearby context (recent 50 tokens) from the distant history. The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic. We further find that the neural caching model (Grave et al., 2017b) especially helps the LSTM to copy words from within this distant context. Overall, our analysis not only provides a better understanding of how neural LMs use their context, but also sheds light on recent success from cache-based models.

</details>

<details>

<summary>2018-05-12 02:29:42 - Proceedings Joint Workshop on Handling IMPlicit and EXplicit knowledge in formal system development (IMPEX) and Formal and Model-Driven Techniques for Developing Trustworthy Systems (FM&MDD)</summary>

- *Régine Laleau, Dominique Méry, Shin Nakajima, Elena Troubitsyna*

- `1805.04636v1` - [abs](http://arxiv.org/abs/1805.04636v1) - [pdf](http://arxiv.org/pdf/1805.04636v1)

> This volume contains the joint proceedings of IMPEX 2017, the first workshop on Handling IMPlicit and EXplicit knowledge in formal system development and FM&MDD, the second workshop on Formal and Model-Driven Techniques for Developing Trustworthy Systems (FM&MDD) held together on November 16, 2017 in Xi'an, China, as part of ICFEM 2017, 19th International Conference on Formal Engineering Methods.   IMPEX emphasises mechanisms for reducing heterogeneity of models induced by the absence of explicit semantics expression in the formal techniques used to specify these models. More precisely, the meeting targets to highlight the advances in handling both implicit and explicit semantics in formal system developments.   The aims of FM&MDD are to advance the understanding in the area of developing and applying formal and model-driven techniques for designing trustworthy systems, to discuss the emerging issues in the area, to improve the dialog between different research communities and between academia and industry, to discuss a roadmap of the future research in the area and to create a forum for discussing and disseminating the new ideas and the research results in the area

</details>

<details>

<summary>2018-05-12 03:08:58 - Weight Initialization in Neural Language Models</summary>

- *Ameet Deshpande, Vedant Somani*

- `1805.06503v1` - [abs](http://arxiv.org/abs/1805.06503v1) - [pdf](http://arxiv.org/pdf/1805.06503v1)

> Semantic Similarity is an important application which finds its use in many downstream NLP applications. Though the task is mathematically defined, semantic similarity's essence is to capture the notions of similarity impregnated in humans. Machines use some heuristics to calculate the similarity between words, but these are typically corpus dependent or are useful for specific domains. The difference between Semantic Similarity and Semantic Relatedness motivates the development of new algorithms. For a human, the word car and road are probably as related as car and bus. But this may not be the case for computational methods. Ontological methods are good at encoding Semantic Similarity and Vector Space models are better at encoding Semantic Relatedness. There is a dearth of methods which leverage ontologies to create better vector representations. The aim of this proposal is to explore in the direction of a hybrid method which combines statistical/vector space methods like Word2Vec and Ontological methods like WordNet to leverage the advantages provided by both.

</details>

<details>

<summary>2018-05-12 05:27:45 - Backpropagating through Structured Argmax using a SPIGOT</summary>

- *Hao Peng, Sam Thomson, Noah A. Smith*

- `1805.04658v1` - [abs](http://arxiv.org/abs/1805.04658v1) - [pdf](http://arxiv.org/pdf/1805.04658v1)

> We introduce the structured projection of intermediate gradients optimization technique (SPIGOT), a new method for backpropagating through neural networks that include hard-decision structured predictions (e.g., parsing) in intermediate layers. SPIGOT requires no marginal inference, unlike structured attention networks (Kim et al., 2017) and some reinforcement learning-inspired solutions (Yogatama et al., 2017). Like so-called straight-through estimators (Hinton, 2012), SPIGOT defines gradient-like quantities associated with intermediate nondifferentiable operations, allowing backpropagation before and after them; SPIGOT's proxy aims to ensure that, after a parameter update, the intermediate structure will remain well-formed.   We experiment on two structured NLP pipelines: syntactic-then-semantic dependency parsing, and semantic parsing followed by sentiment classification. We show that training with SPIGOT leads to a larger improvement on the downstream task than a modularly-trained pipeline, the straight-through estimator, and structured attention, reaching a new state of the art on semantic dependency parsing.

</details>

<details>

<summary>2018-05-12 15:24:32 - Analogical Reasoning on Chinese Morphological and Semantic Relations</summary>

- *Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, Xiaoyong Du*

- `1805.06504v1` - [abs](http://arxiv.org/abs/1805.06504v1) - [pdf](http://arxiv.org/pdf/1805.06504v1)

> Analogical reasoning is effective in capturing linguistic regularities. This paper proposes an analogical reasoning task on Chinese. After delving into Chinese lexical knowledge, we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.

</details>

<details>

<summary>2018-05-12 22:06:17 - Coarse-to-Fine Decoding for Neural Semantic Parsing</summary>

- *Li Dong, Mirella Lapata*

- `1805.04793v1` - [abs](http://arxiv.org/abs/1805.04793v1) - [pdf](http://arxiv.org/pdf/1805.04793v1)

> Semantic parsing aims at mapping natural language utterances into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over. Then, we fill in missing details by taking into account the natural language input and the sketch itself. Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.

</details>

<details>

<summary>2018-05-13 01:07:32 - Zero-Shot Dialog Generation with Cross-Domain Latent Actions</summary>

- *Tiancheng Zhao, Maxine Eskenazi*

- `1805.04803v1` - [abs](http://arxiv.org/abs/1805.04803v1) - [pdf](http://arxiv.org/pdf/1805.04803v1)

> This paper introduces zero-shot dialog generation (ZSDG), as a step towards neural dialog systems that can instantly generalize to new situations with minimal data. ZSDG enables an end-to-end generative dialog system to generalize to a new domain for which only a domain description is provided and no training dialogs are available. Then a novel learning framework, Action Matching, is proposed. This algorithm can learn a cross-domain embedding space that models the semantics of dialog responses which, in turn, lets a neural dialog generation model generalize to new domains. We evaluate our methods on a new synthetic dialog dataset, and an existing human-human dialog dataset. Results show that our method has superior performance in learning dialog models that rapidly adapt their behavior to new domains and suggests promising future research.

</details>

<details>

<summary>2018-05-13 12:23:44 - Autoencoder as Assistant Supervisor: Improving Text Representation for Chinese Social Media Text Summarization</summary>

- *Shuming Ma, Xu Sun, Junyang Lin, Houfeng Wang*

- `1805.04869v1` - [abs](http://arxiv.org/abs/1805.04869v1) - [pdf](http://arxiv.org/pdf/1805.04869v1)

> Most of the current abstractive text summarization models are based on the sequence-to-sequence model (Seq2Seq). The source content of social media is long and noisy, so it is difficult for Seq2Seq to learn an accurate semantic representation. Compared with the source content, the annotated summary is short and well written. Moreover, it shares the same meaning as the source content. In this work, we supervise the learning of the representation of the source content with that of the summary. In implementation, we regard a summary autoencoder as an assistant supervisor of Seq2Seq. Following previous work, we evaluate our model on a popular Chinese social media dataset. Experimental results show that our model achieves the state-of-the-art performances on the benchmark dataset.

</details>

<details>

<summary>2018-05-13 16:08:57 - Comprehensive Supersense Disambiguation of English Prepositions and Possessives</summary>

- *Nathan Schneider, Jena D. Hwang, Vivek Srikumar, Jakob Prange, Austin Blodgett, Sarah R. Moeller, Aviram Stern, Adi Bitan, Omri Abend*

- `1805.04905v1` - [abs](http://arxiv.org/abs/1805.04905v1) - [pdf](http://arxiv.org/pdf/1805.04905v1)

> Semantic relations are often signaled with prepositional or possessive marking--but extreme polysemy bedevils their analysis and automatic interpretation. We introduce a new annotation scheme, corpus, and task for the disambiguation of prepositions and possessives in English. Unlike previous approaches, our annotations are comprehensive with respect to types and tokens of these markers; use broadly applicable supersense classes rather than fine-grained dictionary definitions; unite prepositions and possessives under the same class inventory; and distinguish between a marker's lexical contribution and the role it marks in the context of a predicate or scene. Strong interannotator agreement rates, as well as encouraging disambiguation results with established supervised methods, speak to the viability of the scheme and task.

</details>

<details>

<summary>2018-05-14 02:20:07 - Word learning and the acquisition of syntactic--semantic overhypotheses</summary>

- *Jon Gauthier, Roger Levy, Joshua B. Tenenbaum*

- `1805.04988v1` - [abs](http://arxiv.org/abs/1805.04988v1) - [pdf](http://arxiv.org/pdf/1805.04988v1)

> Children learning their first language face multiple problems of induction: how to learn the meanings of words, and how to build meaningful phrases from those words according to syntactic rules. We consider how children might solve these problems efficiently by solving them jointly, via a computational model that learns the syntax and semantics of multi-word utterances in a grounded reference game. We select a well-studied empirical case in which children are aware of patterns linking the syntactic and semantic properties of words --- that the properties picked out by base nouns tend to be related to shape, while prenominal adjectives tend to refer to other properties such as color. We show that children applying such inductive biases are accurately reflecting the statistics of child-directed speech, and that inducing similar biases in our computational model captures children's behavior in a classic adjective learning experiment. Our model incorporating such biases also demonstrates a clear data efficiency in learning, relative to a baseline model that learns without forming syntax-sensitive overhypotheses of word meaning. Thus solving a more complex joint inference problem may make the full problem of language acquisition easier, not harder.

</details>

<details>

<summary>2018-05-14 12:41:51 - LUCON: Data Flow Control for Message-Based IoT Systems</summary>

- *Julian Schütte, Gerd Stefan Brost*

- `1805.05887v1` - [abs](http://arxiv.org/abs/1805.05887v1) - [pdf](http://arxiv.org/pdf/1805.05887v1)

> Today's emerging Industrial Internet of Things (IIoT) scenarios are characterized by the exchange of data between services across enterprises. Traditional access and usage control mechanisms are only able to determine if data may be used by a subject, but lack an understanding of how it may be used. The ability to control the way how data is processed is however crucial for enterprises to guarantee (and provide evidence of) compliant processing of critical data, as well as for users who need to control if their private data may be analyzed or linked with additional information - a major concern in IoT applications processing personal information. In this paper, we introduce LUCON, a data-centric security policy framework for distributed systems that considers data flows by controlling how messages may be routed across services and how they are combined and processed. LUCON policies prevent information leaks, bind data usage to obligations, and enforce data flows across services. Policy enforcement is based on a dynamic taint analysis at runtime and an upfront static verification of message routes against policies. We discuss the semantics of these two complementing enforcement models and illustrate how LUCON policies are compiled from a simple policy language into a first-order logic representation. We demonstrate the practical application of LUCON in a real-world IoT middleware and discuss its integration into Apache Camel. Finally, we evaluate the runtime impact of LUCON and discuss performance and scalability aspects.

</details>

<details>

<summary>2018-05-14 16:56:36 - AMR Parsing as Graph Prediction with Latent Alignment</summary>

- *Chunchuan Lyu, Ivan Titov*

- `1805.05286v1` - [abs](http://arxiv.org/abs/1805.05286v1) - [pdf](http://arxiv.org/pdf/1805.05286v1)

> Abstract meaning representations (AMRs) are broad-coverage sentence-level semantic representations. AMRs represent sentences as rooted labeled directed acyclic graphs. AMR parsing is challenging partly due to the lack of annotated alignments between nodes in the graphs and words in the corresponding sentences. We introduce a neural parser which treats alignments as latent variables within a joint probabilistic model of concepts, relations and alignments. As exact inference requires marginalizing over alignments and is infeasible, we use the variational auto-encoding framework and a continuous relaxation of the discrete alignments. We show that joint modeling is preferable to using a pipeline of align and parse. The parser achieves the best reported results on the standard benchmark (74.4% on LDC2016E25).

</details>

<details>

<summary>2018-05-14 17:23:54 - The Reincarnation of Grille Cipher: A Generative Approach</summary>

- *Jia Liu, Yan Ke, Yu Lei, Jun Li, Yaojie Wang, Yiliang Han, Minqing Zhang, Xiaoyuan Yang*

- `1804.06514v3` - [abs](http://arxiv.org/abs/1804.06514v3) - [pdf](http://arxiv.org/pdf/1804.06514v3)

> In order to keep the data secret, various techniques have been implemented to encrypt and decrypt the secret data. Cryptography is committed to the security of content, i.e. it cannot be restored with a given ciphertext. Steganography is to hiding the existence of a communication channel within a stego. However, it has been difficult to construct a cipher (cypher) that simultaneously satisfy both channel and content security for secure communication. Inspired by the Cardan grille, this paper presents a new generative framework for grille cipher. A digital cardan grille is used for message encryption and decryption. The ciphertext is directly sampled by a powerful generator without an explicit cover. Message loss and prior loss are proposed for penalizing message extraction error and unrealistic ciphertext. Jensen-Shannon Divergence is introduced as new criteria for channel security. A simple practical data-driven grille cipher is proposed using semantic image inpainting and generative adversarial network. Experimental results demonstrate the promising of the proposed method.

</details>

<details>

<summary>2018-05-14 18:04:28 - NASH: Toward End-to-End Neural Architecture for Generative Semantic Hashing</summary>

- *Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin Wang, Lawrence Carin, Ricardo Henao*

- `1805.05361v1` - [abs](http://arxiv.org/abs/1805.05361v1) - [pdf](http://arxiv.org/pdf/1805.05361v1)

> Semantic hashing has become a powerful paradigm for fast similarity search in many information retrieval systems. While fairly successful, previous techniques generally require two-stage training, and the binary constraints are handled ad-hoc. In this paper, we present an end-to-end Neural Architecture for Semantic Hashing (NASH), where the binary hashing codes are treated as Bernoulli latent variables. A neural variational inference framework is proposed for training, where gradients are directly back-propagated through the discrete latent variable to optimize the hash function. We also draw connections between proposed method and rate-distortion theory, which provides a theoretical foundation for the effectiveness of the proposed framework. Experimental results on three public datasets demonstrate that our method significantly outperforms several state-of-the-art models on both unsupervised and supervised scenarios.

</details>

<details>

<summary>2018-05-14 18:50:11 - Large-Scale QA-SRL Parsing</summary>

- *Nicholas FitzGerald, Julian Michael, Luheng He, Luke Zettlemoyer*

- `1805.05377v1` - [abs](http://arxiv.org/abs/1805.05377v1) - [pdf](http://arxiv.org/pdf/1805.05377v1)

> We present a new large-scale corpus of Question-Answer driven Semantic Role Labeling (QA-SRL) annotations, and the first high-quality QA-SRL parser. Our corpus, QA-SRL Bank 2.0, consists of over 250,000 question-answer pairs for over 64,000 sentences across 3 domains and was gathered with a new crowd-sourcing scheme that we show has high precision and good recall at modest cost. We also present neural models for two QA-SRL subtasks: detecting argument spans for a predicate and generating questions to label the semantic relationship. The best models achieve question accuracy of 82.6% and span-level accuracy of 77.6% (under human evaluation) on the full pipelined QA-SRL prediction task. They can also, as we show, be used to gather additional annotations at low cost.

</details>

<details>

<summary>2018-05-14 19:11:33 - A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors</summary>

- *Mikhail Khodak, Nikunj Saunshi, Yingyu Liang, Tengyu Ma, Brandon Stewart, Sanjeev Arora*

- `1805.05388v1` - [abs](http://arxiv.org/abs/1805.05388v1) - [pdf](http://arxiv.org/pdf/1805.05388v1)

> Motivations like domain adaptation, transfer learning, and feature learning have fueled interest in inducing embeddings for rare or unseen words, n-grams, synsets, and other textual features. This paper introduces a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings. Our method relies mainly on a linear transformation that is efficiently learnable using pretrained word vectors and linear regression. This transform is applicable on the fly in the future when a new text feature or rare word is encountered, even if only a single usage example is available. We introduce a new dataset showing how the a la carte method requires fewer examples of words in context to learn high-quality embeddings and we obtain state-of-the-art results on a nonce task and some unsupervised document classification tasks.

</details>

<details>

<summary>2018-05-15 01:19:40 - Domain Analysis & Description - The Implicit and Explicit Semantics Problem</summary>

- *Dines Bjørner*

- `1805.05516v1` - [abs](http://arxiv.org/abs/1805.05516v1) - [pdf](http://arxiv.org/pdf/1805.05516v1)

> A domain analysis & description calculus is introduced. It is shown to alleviate the issue of implicit semantics. The claim is made that domain descriptions, whether informal, or as also here, formal, amount to an explicit semantics for what is otherwise implicit if not described.

</details>

<details>

<summary>2018-05-15 01:19:48 - Explicit Modelling of Physical Measures: From Event-B to Java</summary>

- *J Paul Gibson, Dominique Méry*

- `1805.05517v1` - [abs](http://arxiv.org/abs/1805.05517v1) - [pdf](http://arxiv.org/pdf/1805.05517v1)

> The increasing development of cyber-physical systems (CPSs) requires modellers to represent and reason about physical values. This paper addresses two major, inter-related, aspects that arise when modelling physical measures. Firstly, there is often a heterogeneity of representation; for example: speed can be represented in many different units (mph, kph, mps, etc. . . ). Secondly, there is incoherence in composition; for example: adding a speed to a temperature would provide a meaningless result in the physical world, even though such a purely mathematical operation is meaningful in the abstract. These aspects are problematic when implicit semantics - concerned with measurements - in CPSs are not explicit (enough) in the requirements, design and implementation models. We present an engineering approach for explicitly modelling measurements during all phases of formal system development. We illustrate this by moving from Event-B models to Java implementations, via object oriented design.

</details>

<details>

<summary>2018-05-15 04:49:55 - Simplifying Sentences with Sequence to Sequence Models</summary>

- *Alexander Mathews, Lexing Xie, Xuming He*

- `1805.05557v1` - [abs](http://arxiv.org/abs/1805.05557v1) - [pdf](http://arxiv.org/pdf/1805.05557v1)

> We simplify sentences with an attentive neural network sequence to sequence model, dubbed S4. The model includes a novel word-copy mechanism and loss function to exploit linguistic similarities between the original and simplified sentences. It also jointly uses pre-trained and fine-tuned word embeddings to capture the semantics of complex sentences and to mitigate the effects of limited data. When trained and evaluated on pairs of sentences from thousands of news articles, we observe a 8.8 point improvement in BLEU score over a sequence to sequence baseline; however, learning word substitutions remains difficult. Such sequence to sequence models are promising for other text generation tasks such as style transfer.

</details>

<details>

<summary>2018-05-15 06:21:02 - Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension</summary>

- *Liang Wang, Meng Sun, Wei Zhao, Kewei Shen, Jingming Liu*

- `1803.00191v5` - [abs](http://arxiv.org/abs/1803.00191v5) - [pdf](http://arxiv.org/pdf/1803.00191v5)

> This paper describes our system for SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. We use Three-way Attentive Networks (TriAN) to model interactions between the passage, question and answers. To incorporate commonsense knowledge, we augment the input with relation embedding from the graph of general knowledge ConceptNet (Speer et al., 2017). As a result, our system achieves state-of-the-art performance with 83.95% accuracy on the official test data. Code is publicly available at https://github.com/intfloat/commonsense-rc

</details>

<details>

<summary>2018-05-15 11:50:11 - Attack Trees in Isabelle</summary>

- *Florian Kammüller*

- `1803.06494v2` - [abs](http://arxiv.org/abs/1803.06494v2) - [pdf](http://arxiv.org/pdf/1803.06494v2)

> In this paper, we present a proof theory for attack trees. Attack trees are a well established and useful model for the construction of attacks on systems since they allow a stepwise exploration of high level attacks in application scenarios. Using the expressiveness of Higher Order Logic in Isabelle, we succeed in developing a generic theory of attack trees with a state-based semantics based on Kripke structures and CTL. The resulting framework allows mechanically supported logic analysis of the meta-theory of the proof calculus of attack trees and at the same time the developed proof theory enables application to case studies. A central correctness and completeness result proved in Isabelle establishes a connection between the notion of attack tree validity and CTL. The application is illustrated on the example of a healthcare IoT system and GDPR compliance verification.

</details>

<details>

<summary>2018-05-15 17:45:25 - CLINIQA: A Machine Intelligence Based Clinical Question Answering System</summary>

- *M A H Zahid, Ankush Mittal, R. C. Joshi, G. Atluri*

- `1805.05927v1` - [abs](http://arxiv.org/abs/1805.05927v1) - [pdf](http://arxiv.org/pdf/1805.05927v1)

> The recent developments in the field of biomedicine have made large volumes of biomedical literature available to the medical practitioners. Due to the large size and lack of efficient searching strategies, medical practitioners struggle to obtain necessary information available in the biomedical literature. Moreover, the most sophisticated search engines of age are not intelligent enough to interpret the clinicians' questions. These facts reflect the urgent need of an information retrieval system that accepts the queries from medical practitioners' in natural language and returns the answers quickly and efficiently. In this paper, we present an implementation of a machine intelligence based CLINIcal Question Answering system (CLINIQA) to answer medical practitioner's questions. The system was rigorously evaluated on different text mining algorithms and the best components for the system were selected. The system makes use of Unified Medical Language System for semantic analysis of both questions and medical documents. In addition, the system employs supervised machine learning algorithms for classification of the documents, identifying the focus of the question and answer selection. Effective domain-specific heuristics are designed for answer ranking. The performance evaluation on hundred clinical questions shows the effectiveness of our approach.

</details>

<details>

<summary>2018-05-15 18:30:34 - ClaiRE at SemEval-2018 Task 7 - Extended Version</summary>

- *Lena Hettinger, Alexander Dallmann, Albin Zehe, Thomas Niebler, Andreas Hotho*

- `1804.05825v3` - [abs](http://arxiv.org/abs/1804.05825v3) - [pdf](http://arxiv.org/pdf/1804.05825v3)

> In this paper we describe our post-evaluation results for SemEval-2018 Task 7 on clas- sification of semantic relations in scientific literature for clean (subtask 1.1) and noisy data (subtask 1.2). This is an extended ver- sion of our workshop paper (Hettinger et al., 2018) including further technical details (Sec- tions 3.2 and 4.3) and changes made to the preprocessing step in the post-evaluation phase (Section 2.1). Due to these changes Classification of Relations using Embeddings (ClaiRE) achieved an improved F1 score of 75.11% for the first subtask and 81.44% for the second.

</details>

<details>

<summary>2018-05-15 20:05:58 - Author Commitment and Social Power: Automatic Belief Tagging to Infer the Social Context of Interactions</summary>

- *Vinodkumar Prabhakaran, Premkumar Ganeshkumar, Owen Rambow*

- `1805.06016v1` - [abs](http://arxiv.org/abs/1805.06016v1) - [pdf](http://arxiv.org/pdf/1805.06016v1)

> Understanding how social power structures affect the way we interact with one another is of great interest to social scientists who want to answer fundamental questions about human behavior, as well as to computer scientists who want to build automatic methods to infer the social contexts of interactions. In this paper, we employ advancements in extra-propositional semantics extraction within NLP to study how author commitment reflects the social context of an interaction. Specifically, we investigate whether the level of commitment expressed by individuals in an organizational interaction reflects the hierarchical power structures they are part of. We find that subordinates use significantly more instances of non-commitment than superiors. More importantly, we also find that subordinates attribute propositions to other agents more often than superiors do --- an aspect that has not been studied before. Finally, we show that enriching lexical features with commitment labels captures important distinctions in social meanings.

</details>

<details>

<summary>2018-05-16 04:17:18 - Narrative Modeling with Memory Chains and Semantic Supervision</summary>

- *Fei Liu, Trevor Cohn, Timothy Baldwin*

- `1805.06122v1` - [abs](http://arxiv.org/abs/1805.06122v1) - [pdf](http://arxiv.org/pdf/1805.06122v1)

> Story comprehension requires a deep semantic understanding of the narrative, making it a challenging task. Inspired by previous studies on ROC Story Cloze Test, we propose a novel method, tracking various semantic aspects with external neural memory chains while encouraging each to focus on a particular semantic aspect. Evaluated on the task of story ending prediction, our model demonstrates superior performance to a collection of competitive baselines, setting a new state of the art.

</details>

<details>

<summary>2018-05-16 07:10:55 - Semantic Structure and Interpretability of Word Embeddings</summary>

- *Lutfi Kerem Senel, Ihsan Utlu, Veysel Yucesoy, Aykut Koc, Tolga Cukur*

- `1711.00331v3` - [abs](http://arxiv.org/abs/1711.00331v3) - [pdf](http://arxiv.org/pdf/1711.00331v3)

> Dense word embeddings, which encode semantic meanings of words to low dimensional vector spaces have become very popular in natural language processing (NLP) research due to their state-of-the-art performances in many NLP tasks. Word embeddings are substantially successful in capturing semantic relations among words, so a meaningful semantic structure must be present in the respective vector spaces. However, in many cases, this semantic structure is broadly and heterogeneously distributed across the embedding dimensions, which makes interpretation a big challenge. In this study, we propose a statistical method to uncover the latent semantic structure in the dense word embeddings. To perform our analysis we introduce a new dataset (SEMCAT) that contains more than 6500 words semantically grouped under 110 categories. We further propose a method to quantify the interpretability of the word embeddings; the proposed method is a practical alternative to the classical word intrusion test that requires human intervention.

</details>

<details>

<summary>2018-05-16 16:38:38 - CASCADE: Contextual Sarcasm Detection in Online Discussion Forums</summary>

- *Devamanyu Hazarika, Soujanya Poria, Sruthi Gorantla, Erik Cambria, Roger Zimmermann, Rada Mihalcea*

- `1805.06413v1` - [abs](http://arxiv.org/abs/1805.06413v1) - [pdf](http://arxiv.org/pdf/1805.06413v1)

> The literature in automated sarcasm detection has mainly focused on lexical, syntactic and semantic-level analysis of text. However, a sarcastic sentence can be expressed with contextual presumptions, background and commonsense knowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector) that adopts a hybrid approach of both content and context-driven modeling for sarcasm detection in online social media discussions. For the latter, CASCADE aims at extracting contextual information from the discourse of a discussion thread. Also, since the sarcastic nature and form of expression can vary from person to person, CASCADE utilizes user embeddings that encode stylometric and personality features of the users. When used along with content-based feature extractors such as Convolutional Neural Networks (CNNs), we see a significant boost in the classification performance on a large Reddit corpus.

</details>

<details>

<summary>2018-05-16 18:31:45 - Impact of Batch Size on Stopping Active Learning for Text Classification</summary>

- *Garrett Beatty, Ethan Kochis, Michael Bloodgood*

- `1801.07887v2` - [abs](http://arxiv.org/abs/1801.07887v2) - [pdf](http://arxiv.org/pdf/1801.07887v2)

> When using active learning, smaller batch sizes are typically more efficient from a learning efficiency perspective. However, in practice due to speed and human annotator considerations, the use of larger batch sizes is necessary. While past work has shown that larger batch sizes decrease learning efficiency from a learning curve perspective, it remains an open question how batch size impacts methods for stopping active learning. We find that large batch sizes degrade the performance of a leading stopping method over and above the degradation that results from reduced learning efficiency. We analyze this degradation and find that it can be mitigated by changing the window size parameter of how many past iterations of learning are taken into account when making the stopping decision. We find that when using larger batch sizes, stopping methods are more effective when smaller window sizes are used.

</details>

<details>

<summary>2018-05-16 19:16:47 - Support Vector Machine Active Learning Algorithms with Query-by-Committee versus Closest-to-Hyperplane Selection</summary>

- *Michael Bloodgood*

- `1801.07875v2` - [abs](http://arxiv.org/abs/1801.07875v2) - [pdf](http://arxiv.org/pdf/1801.07875v2)

> This paper investigates and evaluates support vector machine active learning algorithms for use with imbalanced datasets, which commonly arise in many applications such as information extraction applications. Algorithms based on closest-to-hyperplane selection and query-by-committee selection are combined with methods for addressing imbalance such as positive amplification based on prevalence statistics from initial random samples. Three algorithms (ClosestPA, QBagPA, and QBoostPA) are presented and carefully evaluated on datasets for text classification and relation extraction. The ClosestPA algorithm is shown to consistently outperform the other two in a variety of ways and insights are provided as to why this is the case.

</details>

<details>

<summary>2018-05-16 20:41:33 - Composite Semantic Relation Classification</summary>

- *Siamak Barzegar, Andre Freitas, Siegfried Handschuh, Brian Davis*

- `1805.06521v1` - [abs](http://arxiv.org/abs/1805.06521v1) - [pdf](http://arxiv.org/pdf/1805.06521v1)

> Different semantic interpretation tasks such as text entailment and question answering require the classification of semantic relations between terms or entities within text. However, in most cases it is not possible to assign a direct semantic relation between entities/terms. This paper proposes an approach for composite semantic relation classification, extending the traditional semantic relation classification task. Different from existing approaches, which use machine learning models built over lexical and distributional word vector features, the proposed model uses the combination of a large commonsense knowledge base of binary relations, a distributional navigational algorithm and sequence classification to provide a solution for the composite semantic relation classification problem.

</details>

<details>

<summary>2018-05-16 20:43:45 - Semantic Relatedness for All (Languages): A Comparative Analysis of Multilingual Semantic Relatedness Using Machine Translation</summary>

- *Andre Freitas, Siamak Barzegar, Juliano Efson Sales, Siegfried Handschuh, Brian Davis*

- `1805.06522v1` - [abs](http://arxiv.org/abs/1805.06522v1) - [pdf](http://arxiv.org/pdf/1805.06522v1)

> This paper provides a comparative analysis of the performance of four state-of-the-art distributional semantic models (DSMs) over 11 languages, contrasting the native language-specific models with the use of machine translation over English-based DSMs. The experimental results show that there is a significant improvement (average of 16.7% for the Spearman correlation) by using state-of-the-art machine translation approaches. The results also show that the benefit of using the most informative corpus outweighs the possible errors introduced by the machine translation. For all languages, the combination of machine translation over the Word2Vec English distributional model provided the best results consistently (average Spearman correlation of 0.68).

</details>

<details>

<summary>2018-05-16 20:53:21 - End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition</summary>

- *Samet Oymak, Mahdi Soltanolkotabi*

- `1805.06523v1` - [abs](http://arxiv.org/abs/1805.06523v1) - [pdf](http://arxiv.org/pdf/1805.06523v1)

> In this paper we study the problem of learning the weights of a deep convolutional neural network. We consider a network where convolutions are carried out over non-overlapping patches with a single kernel in each layer. We develop an algorithm for simultaneously learning all the kernels from the training data. Our approach dubbed Deep Tensor Decomposition (DeepTD) is based on a rank-1 tensor decomposition. We theoretically investigate DeepTD under a realizable model for the training data where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted convolutional kernels. We show that DeepTD is data-efficient and provably works as soon as the sample size exceeds the total number of convolutional weights in the network. We carry out a variety of numerical experiments to investigate the effectiveness of DeepTD and verify our theoretical findings.

</details>

<details>

<summary>2018-05-16 21:06:59 - DINFRA: A One Stop Shop for Computing Multilingual Semantic Relatedness</summary>

- *Siamak Barzegar, Juliano Efson Sales, Andre Freitas, Siegfried Handschuh, Brian Davis*

- `1805.09644v1` - [abs](http://arxiv.org/abs/1805.09644v1) - [pdf](http://arxiv.org/pdf/1805.09644v1)

> This demonstration presents an infrastructure for computing multilingual semantic relatedness and correlation for twelve natural languages by using three distributional semantic models (DSMs). Our demonsrator - DInfra (Distributional Infrastructure) provides researchers and developers with a highly useful platform for processing large-scale corpora and conducting experiments with distributional semantics. We integrate several multilingual DSMs in our webservice so the end user can obtain a result without worrying about the complexities involved in building DSMs. Our webservice allows the users to have easy access to a wide range of comparisons of DSMs with different parameters. In addition, users can configure and access DSM parameters using an easy to use API.

</details>

<details>

<summary>2018-05-16 22:50:17 - Defoiling Foiled Image Captions</summary>

- *Pranava Madhyastha, Josiah Wang, Lucia Specia*

- `1805.06549v1` - [abs](http://arxiv.org/abs/1805.06549v1) - [pdf](http://arxiv.org/pdf/1805.06549v1)

> We address the task of detecting foiled image captions, i.e. identifying whether a caption contains a word that has been deliberately replaced by a semantically similar word, thus rendering it inaccurate with respect to the image being described. Solving this problem should in principle require a fine-grained understanding of images to detect linguistically valid perturbations in captions. In such contexts, encoding sufficiently descriptive image information becomes a key challenge. In this paper, we demonstrate that it is possible to solve this task using simple, interpretable yet powerful representations based on explicit object information. Our models achieve state-of-the-art performance on a standard dataset, with scores exceeding those achieved by humans on the task. We also measure the upper-bound performance of our models using gold standard annotations. Our analysis reveals that the simpler model performs well even without image information, suggesting that the dataset contains strong linguistic bias.

</details>

<details>

<summary>2018-05-17 09:19:35 - Evolutionary RL for Container Loading</summary>

- *S Saikia, R Verma, P Agarwal, G Shroff, L Vig, A Srinivasan*

- `1805.06664v1` - [abs](http://arxiv.org/abs/1805.06664v1) - [pdf](http://arxiv.org/pdf/1805.06664v1)

> Loading the containers on the ship from a yard, is an impor- tant part of port operations. Finding the optimal sequence for the loading of containers, is known to be computationally hard and is an example of combinatorial optimization, which leads to the application of simple heuristics in practice. In this paper, we propose an approach which uses a mix of Evolutionary Strategies and Reinforcement Learning (RL) tech- niques to find an approximation of the optimal solution. The RL based agent uses the Policy Gradient method, an evolutionary reward strategy and a Pool of good (not-optimal) solutions to find the approximation. We find that the RL agent learns near-optimal solutions that outperforms the heuristic solutions. We also observe that the RL agent assisted with a pool generalizes better for unseen problems than an RL agent without a pool. We present our results on synthetic data as well as on subsets of real-world problems taken from container terminal. The results validate that our approach does comparatively better than the heuristics solutions available, and adapts to unseen problems better.

</details>

<details>

<summary>2018-05-17 10:33:54 - PDNet: Semantic Segmentation integrated with a Primal-Dual Network for Document binarization</summary>

- *Kalyan Ram Ayyalasomayajula, Filip Malmberg, Anders Brun*

- `1801.08694v3` - [abs](http://arxiv.org/abs/1801.08694v3) - [pdf](http://arxiv.org/pdf/1801.08694v3)

> Binarization of digital documents is the task of classifying each pixel in an image of the document as belonging to the background (parchment/paper) or foreground (text/ink). Historical documents are often subjected to degradations, that make the task challenging. In the current work a deep neural network architecture is proposed that combines a fully convolutional network with an unrolled primal-dual network that can be trained end-to-end to achieve state of the art binarization on four out of seven datasets. Document binarization is formulated as an energy minimization problem. A fully convolutional neural network is trained for semantic segmentation of pixels that provides labeling cost associated with each pixel. This cost estimate is refined along the edges to compensate for any over or under estimation of the foreground class using a primal-dual approach. We provide necessary overview on proximal operator that facilitates theoretical underpinning required to train a primal-dual network using a gradient descent algorithm. Numerical instabilities encountered due to the recurrent nature of primal-dual approach are handled. We provide experimental results on document binarization competition dataset along with network changes and hyperparameter tuning required for stability and performance of the network. The network when pre-trained on synthetic dataset performs better as per the competition metrics.

</details>

<details>

<summary>2018-05-17 16:12:16 - Auxiliary Tasks in Multi-task Learning</summary>

- *Lukas Liebel, Marco Körner*

- `1805.06334v2` - [abs](http://arxiv.org/abs/1805.06334v2) - [pdf](http://arxiv.org/pdf/1805.06334v2)

> Multi-task convolutional neural networks (CNNs) have shown impressive results for certain combinations of tasks, such as single-image depth estimation (SIDE) and semantic segmentation. This is achieved by pushing the network towards learning a robust representation that generalizes well to different atomic tasks. We extend this concept by adding auxiliary tasks, which are of minor relevance for the application, to the set of learned tasks. As a kind of additional regularization, they are expected to boost the performance of the ultimately desired main tasks. To study the proposed approach, we picked vision-based road scene understanding (RSU) as an exemplary application. Since multi-task learning requires specialized datasets, particularly when using extensive sets of tasks, we provide a multi-modal dataset for multi-task RSU, called synMT. More than 2.5 $\cdot$ 10^5 synthetic images, annotated with 21 different labels, were acquired from the video game Grand Theft Auto V (GTA V). Our proposed deep multi-task CNN architecture was trained on various combination of tasks using synMT. The experiments confirmed that auxiliary tasks can indeed boost network performance, both in terms of final results and training time.

</details>

<details>

<summary>2018-05-17 19:01:47 - Evaluating Compositionality in Sentence Embeddings</summary>

- *Ishita Dasgupta, Demi Guo, Andreas Stuhlmüller, Samuel J. Gershman, Noah D. Goodman*

- `1802.04302v2` - [abs](http://arxiv.org/abs/1802.04302v2) - [pdf](http://arxiv.org/pdf/1802.04302v2)

> An important challenge for human-like AI is compositional semantics. Recent research has attempted to address this by using deep neural networks to learn vector space embeddings of sentences, which then serve as input to other tasks. We present a new dataset for one such task, `natural language inference' (NLI), that cannot be solved using only word-level knowledge and requires some compositionality. We find that the performance of state of the art sentence embeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We analyze the decision rules learned by InferSent and find that they are consistent with simple heuristics that are ecologically valid in its training dataset. Further, we find that augmenting training with our dataset improves test performance on our dataset without loss of performance on the original training dataset. This highlights the importance of structured datasets in better understanding and improving AI systems.

</details>

<details>

<summary>2018-05-17 21:00:03 - Neural User Simulation for Corpus-based Policy Optimisation for Spoken Dialogue Systems</summary>

- *Florian Kreyssig, Inigo Casanueva, Pawel Budzianowski, Milica Gasic*

- `1805.06966v1` - [abs](http://arxiv.org/abs/1805.06966v1) - [pdf](http://arxiv.org/pdf/1805.06966v1)

> User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems. For this task the Agenda-Based User Simulator (ABUS) is often used. The ABUS is based on hand-crafted rules and its output is in semantic form. Issues arise from both properties such as limited diversity and the inability to interface a text-level belief tracker. This paper introduces the Neural User Simulator (NUS) whose behaviour is learned from a corpus and which generates natural language, hence needing a less labelled dataset than simulators generating a semantic output. In comparison to much of the past work on this topic, which evaluates user simulators on corpus-based metrics, we use the NUS to train the policy of a reinforcement learning based Spoken Dialogue System. The NUS is compared to the ABUS by evaluating the policies that were trained using the simulators. Cross-model evaluation is performed i.e. training on one simulator and testing on the other. Furthermore, the trained policies are tested on real users. In both evaluation tasks the NUS outperformed the ABUS.

</details>

<details>

<summary>2018-05-17 21:35:56 - Using Statistical and Semantic Models for Multi-Document Summarization</summary>

- *Divyanshu Daiya, Anukarsh Singh, Mukesh Jadon*

- `1805.04579v2` - [abs](http://arxiv.org/abs/1805.04579v2) - [pdf](http://arxiv.org/pdf/1805.04579v2)

> We report a series of experiments with different semantic models on top of various statistical models for extractive text summarization. Though statistical models may better capture word co-occurrences and distribution around the text, they fail to detect the context and the sense of sentences /words as a whole. Semantic models help us gain better insight into the context of sentences. We show that how tuning weights between different models can help us achieve significant results on various benchmarks. Learning pre-trained vectors used in semantic models further, on given corpus, can give addition spike in performance. Using weighing techniques in between different statistical models too further refines our result. For Statistical models, we have used TF/IDF, TextRAnk, Jaccard/Cosine Similarities. For Semantic Models, we have used WordNet-based Model and proposed two models based on Glove Vectors and Facebook's InferSent. We tested our approach on DUC 2004 dataset, generating 100-word summaries. We have discussed the system, algorithms, analysis and also proposed and tested possible improvements. ROUGE scores were used to compare to other summarizers.

</details>

<details>

<summary>2018-05-18 11:09:28 - Style Obfuscation by Invariance</summary>

- *Chris Emmery, Enrique Manjavacas, Grzegorz Chrupała*

- `1805.07143v1` - [abs](http://arxiv.org/abs/1805.07143v1) - [pdf](http://arxiv.org/pdf/1805.07143v1)

> The task of obfuscating writing style using sequence models has previously been investigated under the framework of obfuscation-by-transfer, where the input text is explicitly rewritten in another style. These approaches also often lead to major alterations to the semantic content of the input. In this work, we propose obfuscation-by-invariance, and investigate to what extent models trained to be explicitly style-invariant preserve semantics. We evaluate our architectures on parallel and non-parallel corpora, and compare automatic and human evaluations on the obfuscated sentences. Our experiments show that style classifier performance can be reduced to chance level, whilst the automatic evaluation of the output is seemingly equal to models applying style-transfer. However, based on human evaluation we demonstrate a trade-off between the level of obfuscation and the observed quality of the output in terms of meaning preservation and grammaticality.

</details>

<details>

<summary>2018-05-18 16:17:39 - Unsupervised Semantic Frame Induction using Triclustering</summary>

- *Dmitry Ustalov, Alexander Panchenko, Andrei Kutuzov, Chris Biemann, Simone Paolo Ponzetto*

- `1805.04715v2` - [abs](http://arxiv.org/abs/1805.04715v2) - [pdf](http://arxiv.org/pdf/1805.04715v2)

> We use dependency triples automatically extracted from a Web-scale corpus to perform unsupervised semantic frame induction. We cast the frame induction problem as a triclustering problem that is a generalization of clustering for triadic data. Our replicable benchmarks demonstrate that the proposed graph-based approach, Triframes, shows state-of-the art results on this task on a FrameNet-derived dataset and performing on par with competitive methods on a verb class clustering task.

</details>

<details>

<summary>2018-05-18 18:14:19 - Semantic Adversarial Deep Learning</summary>

- *Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia*

- `1804.07045v2` - [abs](http://arxiv.org/abs/1804.07045v2) - [pdf](http://arxiv.org/pdf/1804.07045v2)

> Fueled by massive amounts of data, models produced by machine-learning (ML) algorithms, especially deep neural networks, are being used in diverse domains where trustworthiness is a concern, including automotive systems, finance, health care, natural language processing, and malware detection. Of particular concern is the use of ML algorithms in cyber-physical systems (CPS), such as self-driving cars and aviation, where an adversary can cause serious consequences. However, existing approaches to generating adversarial examples and devising robust ML algorithms mostly ignore the semantics and context of the overall system containing the ML component. For example, in an autonomous vehicle using deep learning for perception, not every adversarial example for the neural network might lead to a harmful consequence. Moreover, one may want to prioritize the search for adversarial examples towards those that significantly modify the desired semantics of the overall system. Along the same lines, existing algorithms for constructing robust ML algorithms ignore the specification of the overall system. In this paper, we argue that the semantics and specification of the overall system has a crucial role to play in this line of research. We present preliminary research results that support this claim.

</details>

<details>

<summary>2018-05-19 00:56:23 - Generating Bilingual Pragmatic Color References</summary>

- *Will Monroe, Jennifer Hu, Andrew Jong, Christopher Potts*

- `1803.03917v2` - [abs](http://arxiv.org/abs/1803.03917v2) - [pdf](http://arxiv.org/pdf/1803.03917v2)

> Contextual influences on language often exhibit substantial cross-lingual regularities; for example, we are more verbose in situations that require finer distinctions. However, these regularities are sometimes obscured by semantic and syntactic differences. Using a newly-collected dataset of color reference games in Mandarin Chinese (which we release to the public), we confirm that a variety of constructions display the same sensitivity to contextual difficulty in Chinese and English. We then show that a neural speaker agent trained on bilingual data with a simple multitask learning approach displays more human-like patterns of context dependence and is more pragmatically informative than its monolingual Chinese counterpart. Moreover, this is not at the expense of language-specific semantic understanding: the resulting speaker model learns the different basic color term systems of English and Chinese (with noteworthy cross-lingual influences), and it can identify synonyms between the two languages using vector analogy operations on its output layer, despite having no exposure to parallel data.

</details>

<details>

<summary>2018-05-21 00:27:05 - A Text Analysis of Federal Reserve meeting minutes</summary>

- *Harish Gandhi Ramachandran, Dan DeRose Jr*

- `1805.07851v1` - [abs](http://arxiv.org/abs/1805.07851v1) - [pdf](http://arxiv.org/pdf/1805.07851v1)

> Recent developments in monetary policy by the Federal Reserve has created a need for an objective method of communication analysis.Using methods developed for text analysis, we present a novel technique of analysis which creates a semantic space defined by various policymakers public comments and places the committee consensus in the appropriate location. Its then possible to determine which member of the committee is most closely aligned with the committee consensus over time and create a foundation for further actionable research.

</details>

<details>

<summary>2018-05-21 02:23:49 - Learning Device Models with Recurrent Neural Networks</summary>

- *John Clemens*

- `1805.07869v1` - [abs](http://arxiv.org/abs/1805.07869v1) - [pdf](http://arxiv.org/pdf/1805.07869v1)

> Recurrent neural networks (RNNs) are powerful constructs capable of modeling complex systems, up to and including Turing Machines. However, learning such complex models from finite training sets can be difficult. In this paper we empirically show that RNNs can learn models of computer peripheral devices through input and output state observation. This enables automated development of functional software-only models of hardware devices. Such models are applicable to any number of tasks, including device validation, driver development, code de-obfuscation, and reverse engineering. We show that the same RNN structure successfully models six different devices from simple test circuits up to a 16550 UART serial port, and verify that these models are capable of producing equivalent output to real hardware.

</details>

<details>

<summary>2018-05-21 03:54:39 - Sentence Modeling via Multiple Word Embeddings and Multi-level Comparison for Semantic Textual Similarity</summary>

- *Huy Nguyen Tien, Minh Nguyen Le, Yamasaki Tomohiro, Izuha Tatsuya*

- `1805.07882v1` - [abs](http://arxiv.org/abs/1805.07882v1) - [pdf](http://arxiv.org/pdf/1805.07882v1)

> Different word embedding models capture different aspects of linguistic properties. This inspired us to propose a model (M-MaxLSTM-CNN) for employing multiple sets of word embeddings for evaluating sentence similarity/relation. Representing each word by multiple word embeddings, the MaxLSTM-CNN encoder generates a novel sentence embedding. We then learn the similarity/relation between our sentence embeddings via Multi-level comparison. Our method M-MaxLSTM-CNN consistently shows strong performances in several tasks (i.e., measure textual similarity, identify paraphrase, recognize textual entailment). According to the experimental results on STS Benchmark dataset and SICK dataset from SemEval, M-MaxLSTM-CNN outperforms the state-of-the-art methods for textual similarity tasks. Our model does not use hand-crafted features (e.g., alignment features, Ngram overlaps, dependency features) as well as does not require pre-trained word embeddings to have the same dimension.

</details>

<details>

<summary>2018-05-21 05:13:02 - Understand Functionality and Dimensionality of Vector Embeddings: the Distributional Hypothesis, the Pairwise Inner Product Loss and Its Bias-Variance Trade-off</summary>

- *Zi Yin*

- `1803.00502v4` - [abs](http://arxiv.org/abs/1803.00502v4) - [pdf](http://arxiv.org/pdf/1803.00502v4)

> Vector embedding is a foundational building block of many deep learning models, especially in natural language processing. In this paper, we present a theoretical framework for understanding the effect of dimensionality on vector embeddings. We observe that the distributional hypothesis, a governing principle of statistical semantics, requires a natural unitary-invariance for vector embeddings. Motivated by the unitary-invariance observation, we propose the Pairwise Inner Product (PIP) loss, a unitary-invariant metric on the similarity between two embeddings. We demonstrate that the PIP loss captures the difference in functionality between embeddings, and that the PIP loss is tightly connect with two basic properties of vector embeddings, namely similarity and compositionality. By formulating the embedding training process as matrix factorization with noise, we reveal a fundamental bias-variance trade-off between the signal spectrum and noise power in the dimensionality selection process. This bias-variance trade-off sheds light on many empirical observations which have not been thoroughly explained, for example the existence of an optimal dimensionality. Moreover, we discover two new results about vector embeddings, namely their robustness against over-parametrization and their forward stability. The bias-variance trade-off of the PIP loss explicitly answers the fundamental open problem of dimensionality selection for vector embeddings.

</details>

<details>

<summary>2018-05-21 10:10:16 - Aff2Vec: Affect--Enriched Distributional Word Representations</summary>

- *Sopan Khosla, Niyati Chhaya, Kushal Chawla*

- `1805.07966v1` - [abs](http://arxiv.org/abs/1805.07966v1) - [pdf](http://arxiv.org/pdf/1805.07966v1)

> Human communication includes information, opinions, and reactions. Reactions are often captured by the affective-messages in written as well as verbal communications. While there has been work in affect modeling and to some extent affective content generation, the area of affective word distributions in not well studied. Synsets and lexica capture semantic relationships across words. These models however lack in encoding affective or emotional word interpretations. Our proposed model, Aff2Vec provides a method for enriched word embeddings that are representative of affective interpretations of words. Aff2Vec outperforms the state--of--the--art in intrinsic word-similarity tasks. Further, the use of Aff2Vec representations outperforms baseline embeddings in downstream natural language understanding tasks including sentiment analysis, personality detection, and frustration prediction.

</details>

<details>

<summary>2018-05-21 19:57:23 - Halo: Learning Semantics-Aware Representations for Cross-Lingual Information Extraction</summary>

- *Hongyuan Mei, Sheng Zhang, Kevin Duh, Benjamin Van Durme*

- `1805.08271v1` - [abs](http://arxiv.org/abs/1805.08271v1) - [pdf](http://arxiv.org/pdf/1805.08271v1)

> Cross-lingual information extraction (CLIE) is an important and challenging task, especially in low resource scenarios. To tackle this challenge, we propose a training method, called Halo, which enforces the local region of each hidden state of a neural model to only generate target tokens with the same semantic structure tag. This simple but powerful technique enables a neural model to learn semantics-aware representations that are robust to noise, without introducing any extra parameter, thus yielding better generalization in both high and low resource settings.

</details>

<details>

<summary>2018-05-21 21:36:09 - Character-based Neural Networks for Sentence Pair Modeling</summary>

- *Wuwei Lan, Wei Xu*

- `1805.08297v1` - [abs](http://arxiv.org/abs/1805.08297v1) - [pdf](http://arxiv.org/pdf/1805.08297v1)

> Sentence pair modeling is critical for many NLP tasks, such as paraphrase identification, semantic textual similarity, and natural language inference. Most state-of-the-art neural models for these tasks rely on pretrained word embedding and compose sentence-level semantics in varied ways; however, few works have attempted to verify whether we really need pretrained embeddings in these tasks. In this paper, we study how effective subword-level (character and character n-gram) representations are in sentence pair modeling. Though it is well-known that subword models are effective in tasks with single sentence input, including language modeling and machine translation, they have not been systematically studied in sentence pair modeling tasks where the semantic and string similarities between texts matter. Our experiments show that subword models without any pretrained word embedding can achieve new state-of-the-art results on two social media datasets and competitive results on news data for paraphrase identification.

</details>

<details>

<summary>2018-05-22 02:07:32 - Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators</summary>

- *Shereen Oraby, Lena Reed, Shubhangi Tandon, T. S. Sharath, Stephanie Lukin, Marilyn Walker*

- `1805.08352v1` - [abs](http://arxiv.org/abs/1805.08352v1) - [pdf](http://arxiv.org/pdf/1805.08352v1)

> Natural language generators for task-oriented dialogue must effectively realize system dialogue actions and their associated semantics. In many applications, it is also desirable for generators to control the style of an utterance. To date, work on task-oriented neural generation has primarily focused on semantic fidelity rather than achieving stylistic goals, while work on style has been done in contexts where it is difficult to measure content preservation. Here we present three different sequence-to-sequence models and carefully test how well they disentangle content and style. We use a statistical generator, Personage, to synthesize a new corpus of over 88,000 restaurant domain utterances whose style varies according to models of personality, giving us total control over both the semantic content and the stylistic variation in the training data. We then vary the amount of explicit stylistic supervision given to the three models. We show that our most explicit model can simultaneously achieve high fidelity to both semantic and stylistic goals: this model adds a context vector of 36 stylistic parameters as input to the hidden state of the encoder at each time step, showing the benefits of explicit stylistic supervision, even when the amount of training data is large.

</details>

<details>

<summary>2018-05-22 04:26:46 - Learning and Transferring IDs Representation in E-commerce</summary>

- *Kui Zhao, Yuechuan Li, Zhaoqian Shuai, Cheng Yang*

- `1712.08289v4` - [abs](http://arxiv.org/abs/1712.08289v4) - [pdf](http://arxiv.org/pdf/1712.08289v4)

> Many machine intelligence techniques are developed in E-commerce and one of the most essential components is the representation of IDs, including user ID, item ID, product ID, store ID, brand ID, category ID etc. The classical encoding based methods (like one-hot encoding) are inefficient in that it suffers sparsity problems due to its high dimension, and it cannot reflect the relationships among IDs, either homogeneous or heterogeneous ones. In this paper, we propose an embedding based framework to learn and transfer the representation of IDs. As the implicit feedbacks of users, a tremendous amount of item ID sequences can be easily collected from the interactive sessions. By jointly using these informative sequences and the structural connections among IDs, all types of IDs can be embedded into one low-dimensional semantic space. Subsequently, the learned representations are utilized and transferred in four scenarios: (i) measuring the similarity between items, (ii) transferring from seen items to unseen items, (iii) transferring across different domains, (iv) transferring across different tasks. We deploy and evaluate the proposed approach in Hema App and the results validate its effectiveness.

</details>

<details>

<summary>2018-05-22 04:41:37 - Joint Image Captioning and Question Answering</summary>

- *Jialin Wu, Zeyuan Hu, Raymond J. Mooney*

- `1805.08389v1` - [abs](http://arxiv.org/abs/1805.08389v1) - [pdf](http://arxiv.org/pdf/1805.08389v1)

> Answering visual questions need acquire daily common knowledge and model the semantic connection among different parts in images, which is too difficult for VQA systems to learn from images with the only supervision from answers. Meanwhile, image captioning systems with beam search strategy tend to generate similar captions and fail to diversely describe images. To address the aforementioned issues, we present a system to have these two tasks compensate with each other, which is capable of jointly producing image captions and answering visual questions. In particular, we utilize question and image features to generate question-related captions and use the generated captions as additional features to provide new knowledge to the VQA system. For image captioning, our system attains more informative results in term of the relative improvements on VQA tasks as well as competitive results using automated metrics. Applying our system to the VQA tasks, our results on VQA v2 dataset achieve 65.8% using generated captions and 69.1% using annotated captions in validation set and 68.4% in the test-standard set. Further, an ensemble of 10 models results in 69.7% in the test-standard split.

</details>

<details>

<summary>2018-05-22 05:38:44 - Modularizing Behavioral and Architectural Crosscutting Concerns in Formal Component-Based Systems - Application to the Behavior Interaction Priority Framework</summary>

- *Antoine El-Hokayem, Yliès Falcone, Mohamad Jaber*

- `1805.08406v1` - [abs](http://arxiv.org/abs/1805.08406v1) - [pdf](http://arxiv.org/pdf/1805.08406v1)

> We define a method to modularize crosscutting concerns in Component-Based Systems (CBSs) expressed using the Behavior Interaction Priority (BIP) framework. Our method is inspired from the Aspect Oriented Programming (AOP) paradigm which was initially conceived to support the separation of concerns during the development of monolithic systems. BIP has a formal operational semantics and makes a clear separation between architecture and behavior to allow for compositional and incremental design and analysis of systems. We distinguish local from global aspects. Local aspects model concerns at the component level and are used to refine the behavior of components. Global aspects model concerns at the architecture level, and hence refine communications (synchronization and data transfer) between components. We formalize local and global aspects as well as their composition and integration into a BIP system through rigorous transformation primitives. We present AOP-BIP, a tool for Aspect-Oriented Programming of BIP systems, demonstrate its use to modularize logging, security, and fault tolerance in a network protocol, and discuss its possible use in runtime verification of CBSs.

</details>

<details>

<summary>2018-05-22 07:59:53 - Paracompositionality, MWEs and Argument Substitution</summary>

- *Cem Bozsahin, Arzu Burcu Guven*

- `1805.08438v1` - [abs](http://arxiv.org/abs/1805.08438v1) - [pdf](http://arxiv.org/pdf/1805.08438v1)

> Multi-word expressions, verb-particle constructions, idiomatically combining phrases, and phrasal idioms have something in common: not all of their elements contribute to the argument structure of the predicate implicated by the expression.   Radically lexicalized theories of grammar that avoid string-, term-, logical form-, and tree-writing, and categorial grammars that avoid wrap operation, make predictions about the categories involved in verb-particles and phrasal idioms. They may require singleton types, which can only substitute for one value, not just for one kind of value. These types are asymmetric: they can be arguments only. They also narrowly constrain the kind of semantic value that can correspond to such syntactic categories. Idiomatically combining phrases do not subcategorize for singleton types, and they exploit another locally computable and compositional property of a correspondence, that every syntactic expression can project its head word. Such MWEs can be seen as empirically realized categorial possibilities, rather than lacuna in a theory of lexicalizable syntactic categories.

</details>

<details>

<summary>2018-05-22 10:23:39 - Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis</summary>

- *Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, Pushmeet Kohli*

- `1805.04276v2` - [abs](http://arxiv.org/abs/1805.04276v2) - [pdf](http://arxiv.org/pdf/1805.04276v2)

> Program synthesis is the task of automatically generating a program consistent with a specification. Recent years have seen proposal of a number of neural approaches for program synthesis, many of which adopt a sequence generation paradigm similar to neural machine translation, in which sequence-to-sequence models are trained to maximize the likelihood of known reference programs. While achieving impressive results, this strategy has two key limitations. First, it ignores Program Aliasing: the fact that many different programs may satisfy a given specification (especially with incomplete specifications such as a few input-output examples). By maximizing the likelihood of only a single reference program, it penalizes many semantically correct programs, which can adversely affect the synthesizer performance. Second, this strategy overlooks the fact that programs have a strict syntax that can be efficiently checked. To address the first limitation, we perform reinforcement learning on top of a supervised model with an objective that explicitly maximizes the likelihood of generating semantically correct programs. For addressing the second limitation, we introduce a training procedure that directly maximizes the probability of generating syntactically correct programs that fulfill the specification. We show that our contributions lead to improved accuracy of the models, especially in cases where the training data is limited.

</details>

<details>

<summary>2018-05-22 11:54:16 - OK Google, What Is Your Ontology? Or: Exploring Freebase Classification to Understand Google's Knowledge Graph</summary>

- *Niel Chah*

- `1805.03885v2` - [abs](http://arxiv.org/abs/1805.03885v2) - [pdf](http://arxiv.org/pdf/1805.03885v2)

> This paper reconstructs the Freebase data dumps to understand the underlying ontology behind Google's semantic search feature. The Freebase knowledge base was a major Semantic Web and linked data technology that was acquired by Google in 2010 to support the Google Knowledge Graph, the backend for Google search results that include structured answers to queries instead of a series of links to external resources. After its shutdown in 2016, Freebase is contained in a data dump of 1.9 billion Resource Description Format (RDF) triples. A recomposition of the Freebase ontology will be analyzed in relation to concepts and insights from the literature on classification by Bowker and Star. This paper will explore how the Freebase ontology is shaped by many of the forces that also shape classification systems through a deep dive into the ontology and a small correlational study. These findings will provide a glimpse into the proprietary blackbox Knowledge Graph and what is meant by Google's mission to "organize the world's information and make it universally accessible and useful".

</details>

<details>

<summary>2018-05-22 17:03:19 - UnibucKernel: A kernel-based learning method for complex word identification</summary>

- *Andrei M. Butnaru, Radu Tudor Ionescu*

- `1803.07602v4` - [abs](http://arxiv.org/abs/1803.07602v4) - [pdf](http://arxiv.org/pdf/1803.07602v4)

> In this paper, we present a kernel-based learning approach for the 2018 Complex Word Identification (CWI) Shared Task. Our approach is based on combining multiple low-level features, such as character n-grams, with high-level semantic features that are either automatically learned using word embeddings or extracted from a lexical knowledge base, namely WordNet. After feature extraction, we employ a kernel method for the learning phase. The feature matrix is first transformed into a normalized kernel matrix. For the binary classification task (simple versus complex), we employ Support Vector Machines. For the regression task, in which we have to predict the complexity level of a word (a word is more complex if it is labeled as complex by more annotators), we employ v-Support Vector Regression. We applied our approach only on the three English data sets containing documents from Wikipedia, WikiNews and News domains. Our best result during the competition was the third place on the English Wikipedia data set. However, in this paper, we also report better post-competition results.

</details>

<details>

<summary>2018-05-22 18:35:28 - Deformable Part Networks</summary>

- *Ziming Zhang, Rongmei Lin, Alan Sullivan*

- `1805.08808v1` - [abs](http://arxiv.org/abs/1805.08808v1) - [pdf](http://arxiv.org/pdf/1805.08808v1)

> In this paper we propose novel Deformable Part Networks (DPNs) to learn {\em pose-invariant} representations for 2D object recognition. In contrast to the state-of-the-art pose-aware networks such as CapsNet \cite{sabour2017dynamic} and STN \cite{jaderberg2015spatial}, DPNs can be naturally {\em interpreted} as an efficient solver for a challenging detection problem, namely Localized Deformable Part Models (LDPMs) where localization is introduced to DPMs as another latent variable for searching for the best poses of objects over all pixels and (predefined) scales. In particular we construct DPNs as sequences of such LDPM units to model the semantic and spatial relations among the deformable parts as hierarchical composition and spatial parsing trees. Empirically our 17-layer DPN can outperform both CapsNets and STNs significantly on affNIST \cite{sabour2017dynamic}, for instance, by 19.19\% and 12.75\%, respectively, with better generalization and better tolerance to affine transformations.

</details>

<details>

<summary>2018-05-23 00:18:42 - Enhancing Chinese Intent Classification by Dynamically Integrating Character Features into Word Embeddings with Ensemble Techniques</summary>

- *Ruixi Lin, Charles Costello, Charles Jankowski*

- `1805.08914v1` - [abs](http://arxiv.org/abs/1805.08914v1) - [pdf](http://arxiv.org/pdf/1805.08914v1)

> Intent classification has been widely researched on English data with deep learning approaches that are based on neural networks and word embeddings. The challenge for Chinese intent classification stems from the fact that, unlike English where most words are made up of 26 phonologic alphabet letters, Chinese is logographic, where a Chinese character is a more basic semantic unit that can be informative and its meaning does not vary too much in contexts. Chinese word embeddings alone can be inadequate for representing words, and pre-trained embeddings can suffer from not aligning well with the task at hand. To account for the inadequacy and leverage Chinese character information, we propose a low-effort and generic way to dynamically integrate character embedding based feature maps with word embedding based inputs, whose resulting word-character embeddings are stacked with a contextual information extraction module to further incorporate context information for predictions. On top of the proposed model, we employ an ensemble method to combine single models and obtain the final result. The approach is data-independent without relying on external sources like pre-trained word embeddings. The proposed model outperforms baseline models and existing methods.

</details>

<details>

<summary>2018-05-23 09:54:38 - Empirical Analysis of Foundational Distinctions in Linked Open Data</summary>

- *Luigi Asprino, Valerio Basile, Paolo Ciancarini, Valentina Presutti*

- `1803.09840v2` - [abs](http://arxiv.org/abs/1803.09840v2) - [pdf](http://arxiv.org/pdf/1803.09840v2)

> The Web and its Semantic extension (i.e. Linked Open Data) contain open global-scale knowledge and make it available to potentially intelligent machines that want to benefit from it. Nevertheless, most of Linked Open Data lack ontological distinctions and have sparse axiomatisation. For example, distinctions such as whether an entity is inherently a class or an individual, or whether it is a physical object or not, are hardly expressed in the data, although they have been largely studied and formalised by foundational ontologies (e.g. DOLCE, SUMO). These distinctions belong to common sense too, which is relevant for many artificial intelligence tasks such as natural language understanding, scene recognition, and the like. There is a gap between foundational ontologies, that often formalise or are inspired by pre-existing philosophical theories and are developed with a top-down approach, and Linked Open Data that mostly derive from existing databases or crowd-based effort (e.g. DBpedia, Wikidata). We investigate whether machines can learn foundational distinctions over Linked Open Data entities, and if they match common sense. We want to answer questions such as "does the DBpedia entity for dog refer to a class or to an instance?". We report on a set of experiments based on machine learning and crowdsourcing that show promising results.

</details>

<details>

<summary>2018-05-23 11:04:46 - Grounding the Semantics of Part-of-Day Nouns Worldwide using Twitter</summary>

- *David Vilares, Carlos Gómez-Rodríguez*

- `1805.09055v1` - [abs](http://arxiv.org/abs/1805.09055v1) - [pdf](http://arxiv.org/pdf/1805.09055v1)

> The usage of part-of-day nouns, such as 'night', and their time-specific greetings ('good night'), varies across languages and cultures. We show the possibilities that Twitter offers for studying the semantics of these terms and its variability between countries. We mine a worldwide sample of multilingual tweets with temporal greetings, and study how their frequencies vary in relation with local time. The results provide insights into the semantics of these temporal expressions and the cultural and sociological factors influencing their usage.

</details>

<details>

<summary>2018-05-23 13:34:51 - RDF2Vec-based Classification of Ontology Alignment Changes</summary>

- *Matthias Jurisch, Bodo Igler*

- `1805.09145v1` - [abs](http://arxiv.org/abs/1805.09145v1) - [pdf](http://arxiv.org/pdf/1805.09145v1)

> When ontologies cover overlapping topics, the overlap can be represented using ontology alignments. These alignments need to be continuously adapted to changing ontologies. Especially for large ontologies this is a costly task often consisting of manual work. Finding changes that do not lead to an adaption of the alignment can potentially make this process significantly easier. This work presents an approach to finding these changes based on RDF embeddings and common classification techniques. To examine the feasibility of this approach, an evaluation on a real-world dataset is presented. In this evaluation, the best classifiers reached a precision of 0.8.

</details>

<details>

<summary>2018-05-23 19:20:43 - Embedding Syntax and Semantics of Prepositions via Tensor Decomposition</summary>

- *Hongyu Gong, Suma Bhat, Pramod Viswanath*

- `1805.09389v1` - [abs](http://arxiv.org/abs/1805.09389v1) - [pdf](http://arxiv.org/pdf/1805.09389v1)

> Prepositions are among the most frequent words in English and play complex roles in the syntax and semantics of sentences. Not surprisingly, they pose well-known difficulties in automatic processing of sentences (prepositional attachment ambiguities and idiosyncratic uses in phrases). Existing methods on preposition representation treat prepositions no different from content words (e.g., word2vec and GloVe). In addition, recent studies aiming at solving prepositional attachment and preposition selection problems depend heavily on external linguistic resources and use dataset-specific word representations. In this paper we use word-triple counts (one of the triples being a preposition) to capture a preposition's interaction with its attachment and complement. We then derive preposition embeddings via tensor decomposition on a large unlabeled corpus. We reveal a new geometry involving Hadamard products and empirically demonstrate its utility in paraphrasing phrasal verbs. Furthermore, our preposition embeddings are used as simple features in two challenging downstream tasks: preposition selection and prepositional attachment disambiguation. We achieve results comparable to or better than the state-of-the-art on multiple standardized datasets.

</details>

<details>

<summary>2018-05-24 16:43:45 - HotFlip: White-Box Adversarial Examples for Text Classification</summary>

- *Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou*

- `1712.06751v2` - [abs](http://arxiv.org/abs/1712.06751v2) - [pdf](http://arxiv.org/pdf/1712.06751v2)

> We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well.

</details>

<details>

<summary>2018-05-24 18:50:36 - A Bug Bounty Perspective on the Disclosure of Web Vulnerabilities</summary>

- *Jukka Ruohonen, Luca Allodi*

- `1805.09850v1` - [abs](http://arxiv.org/abs/1805.09850v1) - [pdf](http://arxiv.org/pdf/1805.09850v1)

> Bug bounties have become increasingly popular in recent years. This paper discusses bug bounties by framing these theoretically against so-called platform economy. Empirically the interest is on the disclosure of web vulnerabilities through the Open Bug Bounty (OBB) platform between 2015 and late 2017. According to the empirical results based on a dataset covering nearly 160 thousand web vulnerabilities, (i) OBB has been successful as a community-based platform for the dissemination of web vulnerabilities. The platform has also attracted many productive hackers, (ii) but there exists a large productivity gap, which likely relates to (iii) a knowledge gap and the use of automated tools for web vulnerability discovery. While the platform (iv) has been exceptionally fast to evaluate new vulnerability submissions, (v) the patching times of the web vulnerabilities disseminated have been long. With these empirical results and the accompanying theoretical discussion, the paper contributes to the small but rapidly growing amount of research on bug bounties. In addition, the paper makes a practical contribution by discussing the business models behind bug bounties from the viewpoints of platforms, ecosystems, and vulnerability markets.

</details>

<details>

<summary>2018-05-25 07:36:50 - User Interface Design Smell: Automatic Detection and Refactoring of Blob Listeners</summary>

- *Arnaud Blouin, Valéria Lelli, Benoit Baudry, Fabien Coulon*

- `1703.10674v3` - [abs](http://arxiv.org/abs/1703.10674v3) - [pdf](http://arxiv.org/pdf/1703.10674v3)

> User Interfaces (UIs) intensively rely on event-driven programming: widgets send UI events, which capture users' interactions, to dedicated objects called controllers. Controllers use several UI listeners that handle these events to produce UI commands. First, we reveal the presence of design smells in the code that describes and controls UIs. Second, we demonstrate that specific code analyses are necessary to analyze and refactor UI code, because of its coupling with the rest of the code. We conducted an empirical study on four large Java Swing and SWT open-source software systems. We study to what extent the number of UI commands that a UI listener can produce has an impact on the change- and fault-proneness of the UI listener code. We develop a static code analysis for detecting UI commands in the code. We identify a new type of design smell, called Blob Listener that characterizes UI listeners that can produce more than two UI commands. We propose a systematic static code analysis procedure that searches for Blob Listeners that we implement in InspectorGuidget. We conducted experiments on the four software systems for which we manually identified 53 instances of Blob Listener. InspectorGuidget successfully detected 52 Blob Listeners out of 53. The results exhibit a precision of 81.25% and a recall of 98.11%. We then developed a semi-automatically and behavior-preserving refactoring process to remove Blob Listeners. 49.06% of the 53 Blob Listeners were automatically refactored. Patches for JabRef, and FreeCol have been accepted and merged. Discussions with developers of the four software systems assess the relevance of the Blob Listener. This work shows that UI code also suffers from design smells that have to be identified and characterized. We argue that studies have to be conducted to find other UI design smells and tools that analyze UI code must be developed.

</details>

<details>

<summary>2018-05-25 17:02:03 - Few-Shot Segmentation Propagation with Guided Networks</summary>

- *Kate Rakelly, Evan Shelhamer, Trevor Darrell, Alexei A. Efros, Sergey Levine*

- `1806.07373v1` - [abs](http://arxiv.org/abs/1806.07373v1) - [pdf](http://arxiv.org/pdf/1806.07373v1)

> Learning-based methods for visual segmentation have made progress on particular types of segmentation tasks, but are limited by the necessary supervision, the narrow definitions of fixed tasks, and the lack of control during inference for correcting errors. To remedy the rigidity and annotation burden of standard approaches, we address the problem of few-shot segmentation: given few image and few pixel supervision, segment any images accordingly. We propose guided networks, which extract a latent task representation from any amount of supervision, and optimize our architecture end-to-end for fast, accurate few-shot segmentation. Our method can switch tasks without further optimization and quickly update when given more guidance. We report the first results for segmentation from one pixel per concept and show real-time interactive video segmentation. Our unified approach propagates pixel annotations across space for interactive segmentation, across time for video segmentation, and across scenes for semantic segmentation. Our guided segmentor is state-of-the-art in accuracy for the amount of annotation and time. See http://github.com/shelhamer/revolver for code, models, and more details.

</details>

<details>

<summary>2018-05-25 17:36:51 - Duluth UROP at SemEval-2018 Task 2: Multilingual Emoji Prediction with Ensemble Learning and Oversampling</summary>

- *Shuning Jin, Ted Pedersen*

- `1805.10267v1` - [abs](http://arxiv.org/abs/1805.10267v1) - [pdf](http://arxiv.org/pdf/1805.10267v1)

> This paper describes the Duluth UROP systems that participated in SemEval--2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers using Naive Bayes, Logistic Regression, and Random Forests. We used unigram and bigram features and tried to offset the skewness of the data through the use of oversampling. Our task evaluation results place us 19th of 48 systems in the English evaluation, and 5th of 21 in the Spanish. After the evaluation we realized that some simple changes to preprocessing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the English evaluation, and second in the Spanish.

</details>

<details>

<summary>2018-05-25 17:44:03 - UMDuluth-CS8761 at SemEval-2018 Task 9: Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings</summary>

- *Arshia Z. Hassan, Manikya S. Vallabhajosyula, Ted Pedersen*

- `1805.10271v1` - [abs](http://arxiv.org/abs/1805.10271v1) - [pdf](http://arxiv.org/pdf/1805.10271v1)

> Hypernym Discovery is the task of identifying potential hypernyms for a given term. A hypernym is a more generalized word that is super-ordinate to more specific words. This paper explores several approaches that rely on co-occurrence frequencies of word pairs, Hearst Patterns based on regular expressions, and word embeddings created from the UMBC corpus. Our system Babbage participated in Subtask 1A for English and placed 6th of 19 systems when identifying concept hypernyms, and 12th of 18 systems for entity hypernyms.

</details>

<details>

<summary>2018-05-25 17:48:20 - UMDSub at SemEval-2018 Task 2: Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding</summary>

- *Zhenduo Wang, Ted Pedersen*

- `1805.10274v1` - [abs](http://arxiv.org/abs/1805.10274v1) - [pdf](http://arxiv.org/pdf/1805.10274v1)

> This paper describes the UMDSub system that participated in Task 2 of SemEval-2018. We developed a system that predicts an emoji given the raw text in a English tweet. The system is a Multi-channel Convolutional Neural Network based on subword embeddings for the representation of tweets. This model improves on character or word based methods by about 2\%. Our system placed 21st of 48 participating systems in the official evaluation.

</details>

<details>

<summary>2018-05-25 23:13:41 - Modeling Language Vagueness in Privacy Policies using Deep Neural Networks</summary>

- *Fei Liu, Nicole Lee Fella, Kexin Liao*

- `1805.10393v1` - [abs](http://arxiv.org/abs/1805.10393v1) - [pdf](http://arxiv.org/pdf/1805.10393v1)

> Website privacy policies are too long to read and difficult to understand. The over-sophisticated language makes privacy notices to be less effective than they should be. People become even less willing to share their personal information when they perceive the privacy policy as vague. This paper focuses on decoding vagueness from a natural language processing perspective. While thoroughly identifying the vague terms and their linguistic scope remains an elusive challenge, in this work we seek to learn vector representations of words in privacy policies using deep neural networks. The vector representations are fed to an interactive visualization tool (LSTMVis) to test on their ability to discover syntactically and semantically related vague terms. The approach holds promise for modeling and understanding language vagueness.

</details>

<details>

<summary>2018-05-25 23:46:11 - Toward Abstractive Summarization Using Semantic Representations</summary>

- *Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman Sadeh, Noah A. Smith*

- `1805.10399v1` - [abs](http://arxiv.org/abs/1805.10399v1) - [pdf](http://arxiv.org/pdf/1805.10399v1)

> We present a novel abstractive summarization framework that draws on the recent development of a treebank for the Abstract Meaning Representation (AMR). In this framework, the source text is parsed to a set of AMR graphs, the graphs are transformed into a summary graph, and then text is generated from the summary graph. We focus on the graph-to-graph transformation that reduces the source semantic graph into a summary graph, making use of an existing AMR parser and assuming the eventual availability of an AMR-to-text generator. The framework is data-driven, trainable, and not specifically designed for a particular domain. Experiments on gold-standard AMR annotations and system parses show promising results. Code is available at: https://github.com/summarization

</details>

<details>

<summary>2018-05-26 13:30:58 - Automatic Annotation of Locative and Directional Expressions in Arabic</summary>

- *Rita Hijazi, Amani Sabra, Moustafa Al-Hajj*

- `1805.06344v2` - [abs](http://arxiv.org/abs/1805.06344v2) - [pdf](http://arxiv.org/pdf/1805.06344v2)

> In this paper, we introduce a rule-based approach to annotate Locative and Directional Expressions in Arabic natural language text. The annotation is based on a constructed semantic map of the spatiality domain. Challenges are twofold: first, we need to study how locative and directional expressions are expressed linguistically in these texts; and second, we need to automatically annotate the relevant textual segments accordingly. The research method we will use in this article is analytic-descriptive. We will validate this approach on specific novel rich with these expressions and show that it has very promising results. We will be using NOOJ as a software tool to implement finite-state transducers to annotate linguistic elements according to Locative and Directional Expressions. In conclusion, NOOJ allowed us to write linguistic rules for the automatic annotation in Arabic text of Locative and Directional Expressions.

</details>

<details>

<summary>2018-05-26 20:55:39 - Natural Language Inference over Interaction Space</summary>

- *Yichen Gong, Heng Luo, Jian Zhang*

- `1709.04348v2` - [abs](http://arxiv.org/abs/1709.04348v2) - [pdf](http://arxiv.org/pdf/1709.04348v2)

> Natural Language Inference (NLI) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis. We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space. We show that an interaction tensor (attention weight) contains semantic information to solve natural language inference, and a denser interaction tensor contains richer semantic information. One instance of such architecture, Densely Interactive Inference Network (DIIN), demonstrates the state-of-the-art performance on large scale NLI copora and large-scale NLI alike corpus. It's noteworthy that DIIN achieve a greater than 20% error reduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to the strongest published system.

</details>

<details>

<summary>2018-05-26 21:12:59 - DeepScores -- A Dataset for Segmentation, Detection and Classification of Tiny Objects</summary>

- *Lukas Tuggener, Ismail Elezi, Jürgen Schmidhuber, Marcello Pelillo, Thilo Stadelmann*

- `1804.00525v2` - [abs](http://arxiv.org/abs/1804.00525v2) - [pdf](http://arxiv.org/pdf/1804.00525v2)

> We present the DeepScores dataset with the goal of advancing the state-of-the-art in small objects recognition, and by placing the question of object recognition in the context of scene understanding. DeepScores contains high quality images of musical scores, partitioned into 300,000 sheets of written music that contain symbols of different shapes and sizes. With close to a hundred millions of small objects, this makes our dataset not only unique, but also the largest public dataset. DeepScores comes with ground truth for object classification, detection and semantic segmentation. DeepScores thus poses a relevant challenge for computer vision in general, beyond the scope of optical music recognition (OMR) research. We present a detailed statistical analysis of the dataset, comparing it with other computer vision datasets like Caltech101/256, PASCAL VOC, SUN, SVHN, ImageNet, MS-COCO, smaller computer vision datasets, as well as with other OMR datasets. Finally, we provide baseline performances for object classification and give pointers to future research based on this dataset.

</details>

<details>

<summary>2018-05-27 06:55:15 - Semantic Explanations of Predictions</summary>

- *Freddy Lecue, Jiewen Wu*

- `1805.10587v1` - [abs](http://arxiv.org/abs/1805.10587v1) - [pdf](http://arxiv.org/pdf/1805.10587v1)

> The main objective of explanations is to transmit knowledge to humans. This work proposes to construct informative explanations for predictions made from machine learning models. Motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classification prediction and ones representative of the models. Subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. These concepts are filtered and ranked to produce informative explanations that improves human understanding. The main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.

</details>

<details>

<summary>2018-05-27 13:36:15 - Question Answering over Freebase via Attentive RNN with Similarity Matrix based CNN</summary>

- *Yingqi Qu, Jie Liu, Liangyi Kang, Qinfeng Shi, Dan Ye*

- `1804.03317v3` - [abs](http://arxiv.org/abs/1804.03317v3) - [pdf](http://arxiv.org/pdf/1804.03317v3)

> With the rapid growth of knowledge bases (KBs), question answering over knowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of the existing KBQA methods follow so called encoder-compare framework. They map the question and the KB facts to a common embedding space, in which the similarity between the question vector and the fact vectors can be conveniently computed. This, however, inevitably loses original words interaction information. To preserve more original information, we propose an attentive recurrent neural network with similarity matrix based convolutional neural network (AR-SMCNN) model, which is able to capture comprehensive hierarchical information utilizing the advantages of both RNN and CNN. We use RNN to capture semantic-level correlation by its sequential modeling nature, and use an attention mechanism to keep track of the entities and relations simultaneously. Meanwhile, we use a similarity matrix based CNN with two-directions pooling to extract literal-level words interaction matching utilizing CNNs strength of modeling spatial correlation among data. Moreover, we have developed a new heuristic extension method for entity detection, which significantly decreases the effect of noise. Our method has outperformed the state-of-the-arts on SimpleQuestion benchmark in both accuracy and efficiency.

</details>

<details>

<summary>2018-05-27 20:55:50 - Legal Document Retrieval using Document Vector Embeddings and Deep Learning</summary>

- *Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, Amal Shehan Perera, Vindula Jayawardana, Dimuthu Lakmal, Madhavi Perera*

- `1805.10685v1` - [abs](http://arxiv.org/abs/1805.10685v1) - [pdf](http://arxiv.org/pdf/1805.10685v1)

> Domain specific information retrieval process has been a prominent and ongoing research in the field of natural language processing. Many researchers have incorporated different techniques to overcome the technical and domain specificity and provide a mature model for various domains of interest. The main bottleneck in these studies is the heavy coupling of domain experts, that makes the entire process to be time consuming and cumbersome. In this study, we have developed three novel models which are compared against a golden standard generated via the on line repositories provided, specifically for the legal domain. The three different models incorporated vector space representations of the legal domain, where document vector generation was done in two different mechanisms and as an ensemble of the above two. This study contains the research being carried out in the process of representing legal case documents into different vector spaces, whilst incorporating semantic word measures and natural language processing techniques. The ensemble model built in this study, shows a significantly higher accuracy level, which indeed proves the need for incorporation of domain specific semantic similarity measures into the information retrieval process. This study also shows, the impact of varying distribution of the word similarity measures, against varying document vector dimensions, which can lead to improvements in the process of legal information retrieval.

</details>

<details>

<summary>2018-05-27 23:23:17 - A Formal Model of the Safety-Critical Java Level 2 Paradigm</summary>

- *Matt Luckcuck, Ana Cavalcanti, Andy Wellings*

- `1805.10711v1` - [abs](http://arxiv.org/abs/1805.10711v1) - [pdf](http://arxiv.org/pdf/1805.10711v1)

> Safety-Critical Java (SCJ) introduces a new programming paradigm for applications that must be certified. The SCJ specification (JSR 302) is an Open Group Standard, but it does not include verification techniques. Previous work has addressed verification for SCJ Level~1 programs. We support the much more complex SCJ Level~2 programs, which allows the programming of highly concurrent multi-processor applications with Java threads, and wait and notify mechanisms. We present a formal model of SCJ Level~2 that captures the state and behaviour of both SCJ programs and the SCJ API. This is the first formal semantics of the SCJ Level~2 paradigm and is an essential ingredient in the development of refinement-based reasoning techniques for SCJ Level~2 programs. We show how our models can be used to prove properties of the SCJ API and applications.

</details>

<details>

<summary>2018-05-28 10:19:38 - Inducing Grammars with and for Neural Machine Translation</summary>

- *Ke Tran, Yonatan Bisk*

- `1805.10850v1` - [abs](http://arxiv.org/abs/1805.10850v1) - [pdf](http://arxiv.org/pdf/1805.10850v1)

> Machine translation systems require semantic knowledge and grammatical understanding. Neural machine translation (NMT) systems often assume this information is captured by an attention mechanism and a decoder that ensures fluency. Recent work has shown that incorporating explicit syntax alleviates the burden of modeling both types of knowledge. However, requiring parses is expensive and does not explore the question of what syntax a model needs during translation. To address both of these issues we introduce a model that simultaneously translates while inducing dependency trees. In this way, we leverage the benefits of structure while investigating what syntax NMT must induce to maximize performance. We show that our dependency trees are 1. language pair dependent and 2. improve translation quality.

</details>

<details>

<summary>2018-05-28 15:48:39 - Resolving Event Coreference with Supervised Representation Learning and Clustering-Oriented Regularization</summary>

- *Kian Kenyon-Dean, Jackie Chi Kit Cheung, Doina Precup*

- `1805.10985v1` - [abs](http://arxiv.org/abs/1805.10985v1) - [pdf](http://arxiv.org/pdf/1805.10985v1)

> We present an approach to event coreference resolution by developing a general framework for clustering that uses supervised representation learning. We propose a neural network architecture with novel Clustering-Oriented Regularization (CORE) terms in the objective function. These terms encourage the model to create embeddings of event mentions that are amenable to clustering. We then use agglomerative clustering on these embeddings to build event coreference chains. For both within- and cross-document coreference on the ECB+ corpus, our model obtains better results than models that require significantly more pre-annotated information. This work provides insight and motivating results for a new general approach to solving coreference and clustering problems with representation learning.

</details>

<details>

<summary>2018-05-28 16:05:39 - Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation</summary>

- *Han Guo, Ramakanth Pasunuru, Mohit Bansal*

- `1805.11004v1` - [abs](http://arxiv.org/abs/1805.11004v1) - [pdf](http://arxiv.org/pdf/1805.11004v1)

> An accurate abstractive summary of a document should contain all its salient information and should be logically entailed by the input document. We improve these important aspects of abstractive summarization via multi-task learning with the auxiliary tasks of question generation and entailment generation, where the former teaches the summarization model how to look for salient questioning-worthy details, and the latter teaches the model how to rewrite a summary which is a directed-logical subset of the input document. We also propose novel multi-task architectures with high-level (semantic) layer-specific sharing across multiple encoder and decoder layers of the three tasks, as well as soft-sharing mechanisms (and show performance ablations and analysis examples of each contribution). Overall, we achieve statistically significant improvements over the state-of-the-art on both the CNN/DailyMail and Gigaword datasets, as well as on the DUC-2002 transfer setup. We also present several quantitative and qualitative analysis studies of our model's learned saliency and entailment skills.

</details>

<details>

<summary>2018-05-28 17:01:37 - Flexible and accurate inference and learning for deep generative models</summary>

- *Eszter Vertes, Maneesh Sahani*

- `1805.11051v1` - [abs](http://arxiv.org/abs/1805.11051v1) - [pdf](http://arxiv.org/pdf/1805.11051v1)

> We introduce a new approach to learning in hierarchical latent-variable generative models called the "distributed distributional code Helmholtz machine", which emphasises flexibility and accuracy in the inferential process. In common with the original Helmholtz machine and later variational autoencoder algorithms (but unlike adverserial methods) our approach learns an explicit inference or "recognition" model to approximate the posterior distribution over the latent variables. Unlike in these earlier methods, the posterior representation is not limited to a narrow tractable parameterised form (nor is it represented by samples). To train the generative and recognition models we develop an extended wake-sleep algorithm inspired by the original Helmholtz Machine. This makes it possible to learn hierarchical latent models with both discrete and continuous variables, where an accurate posterior representation is essential. We demonstrate that the new algorithm outperforms current state-of-the-art methods on synthetic, natural image patch and the MNIST data sets.

</details>

<details>

<summary>2018-05-28 19:22:09 - Unsupervised Learning of Word-Sequence Representations from Scratch via Convolutional Tensor Decomposition</summary>

- *Furong Huang, Animashree Anandkumar*

- `1606.03153v3` - [abs](http://arxiv.org/abs/1606.03153v3) - [pdf](http://arxiv.org/pdf/1606.03153v3)

> Unsupervised text embeddings extraction is crucial for text understanding in machine learning. Word2Vec and its variants have received substantial success in mapping words with similar syntactic or semantic meaning to vectors close to each other. However, extracting context-aware word-sequence embedding remains a challenging task. Training over large corpus is difficult as labels are difficult to get. More importantly, it is challenging for pre-trained models to obtain word-sequence embeddings that are universally good for all downstream tasks or for any new datasets. We propose a two-phased ConvDic+DeconvDec framework to solve the problem by combining a word-sequence dictionary learning model with a word-sequence embedding decode model. We propose a convolutional tensor decomposition mechanism to learn good word-sequence phrase dictionary in the learning phase. It is proved to be more accurate and much more efficient than the popular alternating minimization method. In the decode phase, we introduce a deconvolution framework that is immune to the problem of varying sentence lengths. The word-sequence embeddings we extracted using ConvDic+DeconvDec are universally good for a few downstream tasks we test on. The framework requires neither pre-training nor prior/outside information.

</details>

<details>

<summary>2018-05-29 03:39:35 - Table-to-Text: Describing Table Region with Natural Language</summary>

- *Junwei Bao, Duyu Tang, Nan Duan, Zhao Yan, Yuanhua Lv, Ming Zhou, Tiejun Zhao*

- `1805.11234v1` - [abs](http://arxiv.org/abs/1805.11234v1) - [pdf](http://arxiv.org/pdf/1805.11234v1)

> In this paper, we present a generative model to generate a natural language sentence describing a table region, e.g., a row. The model maps a row from a table to a continuous vector and then generates a natural language sentence by leveraging the semantics of a table. To deal with rare words appearing in a table, we develop a flexible copying mechanism that selectively replicates contents from the table in the output sequence. Extensive experiments demonstrate the accuracy of the model and the power of the copying mechanism. On two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the current state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to 39.12, respectively. Furthermore, we introduce an open-domain dataset WIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our model achieves a BLEU-4 score of 38.23, which outperforms template based and language model based approaches.

</details>

<details>

<summary>2018-05-29 06:45:02 - Disentangling by Partitioning: A Representation Learning Framework for Multimodal Sensory Data</summary>

- *Wei-Ning Hsu, James Glass*

- `1805.11264v1` - [abs](http://arxiv.org/abs/1805.11264v1) - [pdf](http://arxiv.org/pdf/1805.11264v1)

> Multimodal sensory data resembles the form of information perceived by humans for learning, and are easy to obtain in large quantities. Compared to unimodal data, synchronization of concepts between modalities in such data provides supervision for disentangling the underlying explanatory factors of each modality. Previous work leveraging multimodal data has mainly focused on retaining only the modality-invariant factors while discarding the rest. In this paper, we present a partitioned variational autoencoder (PVAE) and several training objectives to learn disentangled representations, which encode not only the shared factors, but also modality-dependent ones, into separate latent variables. Specifically, PVAE integrates a variational inference framework and a multimodal generative model that partitions the explanatory factors and conditions only on the relevant subset of them for generation. We evaluate our model on two parallel speech/image datasets, and demonstrate its ability to learn disentangled representations by qualitatively exploring within-modality and cross-modality conditional generation with semantics and styles specified by examples. For quantitative analysis, we evaluate the classification accuracy of automatically discovered semantic units. Our PVAE can achieve over 99% accuracy on both modalities.

</details>

<details>

<summary>2018-05-29 06:52:29 - Multi-hop Inference for Sentence-level TextGraphs: How Challenging is Meaningfully Combining Information for Science Question Answering?</summary>

- *Peter Jansen*

- `1805.11267v1` - [abs](http://arxiv.org/abs/1805.11267v1) - [pdf](http://arxiv.org/pdf/1805.11267v1)

> Question Answering for complex questions is often modeled as a graph construction or traversal task, where a solver must build or traverse a graph of facts that answer and explain a given question. This "multi-hop" inference has been shown to be extremely challenging, with few models able to aggregate more than two facts before being overwhelmed by "semantic drift", or the tendency for long chains of facts to quickly drift off topic. This is a major barrier to current inference models, as even elementary science questions require an average of 4 to 6 facts to answer and explain. In this work we empirically characterize the difficulty of building or traversing a graph of sentences connected by lexical overlap, by evaluating chance sentence aggregation quality through 9,784 manually-annotated judgments across knowledge graphs built from three free-text corpora (including study guides and Simple Wikipedia). We demonstrate semantic drift tends to be high and aggregation quality low, at between 0.04% and 3%, and highlight scenarios that maximize the likelihood of meaningfully combining information.

</details>

<details>

<summary>2018-05-29 09:15:26 - CNN-Based Detection of Generic Constrast Adjustment with JPEG Post-processing</summary>

- *Mauro Barni, Andrea Costanzo, Ehsan Nowroozi, Benedetta Tondi*

- `1805.11318v1` - [abs](http://arxiv.org/abs/1805.11318v1) - [pdf](http://arxiv.org/pdf/1805.11318v1)

> Detection of contrast adjustments in the presence of JPEG postprocessing is known to be a challenging task. JPEG post processing is often applied innocently, as JPEG is the most common image format, or it may correspond to a laundering attack, when it is purposely applied to erase the traces of manipulation. In this paper, we propose a CNN-based detector for generic contrast adjustment, which is robust to JPEG compression. The proposed system relies on a patch-based Convolutional Neural Network (CNN), trained to distinguish pristine images from contrast adjusted images, for some selected adjustment operators of different nature. Robustness to JPEG compression is achieved by training the CNN with JPEG examples, compressed over a range of Quality Factors (QFs). Experimental results show that the detector works very well and scales well with respect to the adjustment type, yielding very good performance under a large variety of unseen tonal adjustments.

</details>

<details>

<summary>2018-05-29 10:41:08 - Fully Statistical Neural Belief Tracking</summary>

- *Nikola Mrkšić, Ivan Vulić*

- `1805.11350v1` - [abs](http://arxiv.org/abs/1805.11350v1) - [pdf](http://arxiv.org/pdf/1805.11350v1)

> This paper proposes an improvement to the existing data-driven Neural Belief Tracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT model uses a hand-crafted belief state update mechanism which involves an expensive manual retuning step whenever the model is deployed to a new dialogue domain. We show that this update mechanism can be learned jointly with the semantic decoding and context modelling parts of the NBT model, eliminating the last rule-based module from this DST framework. We propose two different statistical update mechanisms and show that dialogue dynamics can be modelled with a very small number of additional model parameters. In our DST evaluation over three languages, we show that this model achieves competitive performance and provides a robust framework for building resource-light DST models.

</details>

<details>

<summary>2018-05-29 13:44:19 - AMR Dependency Parsing with a Typed Semantic Algebra</summary>

- *Jonas Groschwitz, Matthias Lindemann, Meaghan Fowlie, Mark Johnson, Alexander Koller*

- `1805.11465v1` - [abs](http://arxiv.org/abs/1805.11465v1) - [pdf](http://arxiv.org/pdf/1805.11465v1)

> We present a semantic parser for Abstract Meaning Representations which learns to parse strings into tree representations of the compositional structure of an AMR graph. This allows us to use standard neural techniques for supertagging and dependency tree parsing, constrained by a linguistically principled type system. We present two approximative decoding algorithms, which achieve state-of-the-art accuracy and outperform strong baselines.

</details>

<details>

<summary>2018-05-29 15:42:02 - Limitless HTTP in an HTTPS World: Inferring the Semantics of the HTTPS Protocol without Decryption</summary>

- *Blake Anderson, Andrew Chi, Scott Dunlop, David McGrew*

- `1805.11544v1` - [abs](http://arxiv.org/abs/1805.11544v1) - [pdf](http://arxiv.org/pdf/1805.11544v1)

> We present new analytic techniques for inferring HTTP semantics from passive observations of HTTPS that can infer the value of important fields including the status-code, Content-Type, and Server, and the presence or absence of several additional HTTP header fields, e.g., Cookie and Referer. Our goals are twofold: to better understand the limitations of the confidentiality of HTTPS, and to explore benign uses of traffic analysis such as application troubleshooting and malware detection that could replace HTTPS interception and static private keys in some scenarios. We found that our techniques improve the efficacy of malware detection, but they do not enable more powerful website fingerprinting attacks against Tor. Our broader set of results raises concerns about the confidentiality goals of TLS relative to a user's expectation of privacy, warranting future research.   We apply our methods to the semantics of both HTTP/1.1 and HTTP/2 on data collected from automated runs of Firefox 58.0, Chrome 63.0, and Tor Browser 7.0.11 in a lab setting, and from applications running in a malware sandbox. We obtain ground truth plaintext for a diverse set of applications from the malware sandbox by extracting the key material needed for decryption from RAM post-execution. We developed an iterative approach to simultaneously solve several multi-class (field values) and binary (field presence) classification problems, and we show that our inference algorithm achieves an unweighted $F_1$ score greater than 0.900 for most HTTP fields examined.

</details>

<details>

<summary>2018-05-29 17:29:55 - Polyglot Semantic Role Labeling</summary>

- *Phoebe Mulcaire, Swabha Swayamdipta, Noah Smith*

- `1805.11598v1` - [abs](http://arxiv.org/abs/1805.11598v1) - [pdf](http://arxiv.org/pdf/1805.11598v1)

> Previous approaches to multilingual semantic dependency parsing treat languages independently, without exploiting the similarities between semantic structures across languages. We experiment with a new approach where we combine resources from a pair of languages in the CoNLL 2009 shared task to build a polyglot semantic role labeler. Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a monolingual baseline. Analysis of the polyglot model shows it to be advantageous in lower-resource settings.

</details>

<details>

<summary>2018-05-29 17:41:52 - Automatic Identification of Arabic expressions related to future events in Lebanon's economy</summary>

- *Moustafa Al-Hajj, Amani Sabra*

- `1805.11603v1` - [abs](http://arxiv.org/abs/1805.11603v1) - [pdf](http://arxiv.org/pdf/1805.11603v1)

> In this paper, we propose a method to automatically identify future events in Lebanon's economy from Arabic texts. Challenges are threefold: first, we need to build a corpus of Arabic texts that covers Lebanon's economy; second, we need to study how future events are expressed linguistically in these texts; and third, we need to automatically identify the relevant textual segments accordingly. We will validate this method on a constructed corpus form the web and show that it has very promising results. To do so, we will be using SLCSAS, a system for semantic analysis, based on the Contextual Explorer method, and "AlKhalil Morpho Sys" system for morpho-syntactic analysis.

</details>

<details>

<summary>2018-05-29 17:54:52 - Semantically-informed distance and similarity measures for paraphrase plagiarism identification</summary>

- *Miguel A. Álvarez-Carmona, Marc Franco-Salvador, Esaú Villatoro-Tello, Manuel Montes-y-Gómez, Paolo Rosso, Luis Villaseñor-Pineda*

- `1805.11611v1` - [abs](http://arxiv.org/abs/1805.11611v1) - [pdf](http://arxiv.org/pdf/1805.11611v1)

> Paraphrase plagiarism identification represents a very complex task given that plagiarized texts are intentionally modified through several rewording techniques. Accordingly, this paper introduces two new measures for evaluating the relatedness of two given texts: a semantically-informed similarity measure and a semantically-informed edit distance. Both measures are able to extract semantic information from either an external resource or a distributed representation of words, resulting in informative features for training a supervised classifier for detecting paraphrase plagiarism. Obtained results indicate that the proposed metrics are consistently good in detecting different types of paraphrase plagiarism. In addition, results are very competitive against state-of-the art methods having the advantage of representing a much more simple but equally effective solution.

</details>

<details>

<summary>2018-05-30 09:15:57 - EmotionLines: An Emotion Corpus of Multi-Party Conversations</summary>

- *Sheng-Yeh Chen, Chao-Chun Hsu, Chuan-Chun Kuo, Ting-Hao, Huang, Lun-Wei Ku*

- `1802.08379v2` - [abs](http://arxiv.org/abs/1802.08379v2) - [pdf](http://arxiv.org/pdf/1802.08379v2)

> Feeling emotion is a critical characteristic to distinguish people from machines. Among all the multi-modal resources for emotion detection, textual datasets are those containing the least additional information in addition to semantics, and hence are adopted widely for testing the developed systems. However, most of the textual emotional datasets consist of emotion labels of only individual words, sentences or documents, which makes it challenging to discuss the contextual flow of emotions. In this paper, we introduce EmotionLines, the first dataset with emotions labeling on all utterances in each dialogue only based on their textual content. Dialogues in EmotionLines are collected from Friends TV scripts and private Facebook messenger dialogues. Then one of seven emotions, six Ekman's basic emotions plus the neutral emotion, is labeled on each utterance by 5 Amazon MTurkers. A total of 29,245 utterances from 2,000 dialogues are labeled in EmotionLines. We also provide several strong baselines for emotion detection models on EmotionLines in this paper.

</details>

<details>

<summary>2018-05-30 09:26:16 - Tile2Vec: Unsupervised representation learning for spatially distributed data</summary>

- *Neal Jean, Sherrie Wang, Anshul Samar, George Azzari, David Lobell, Stefano Ermon*

- `1805.02855v2` - [abs](http://arxiv.org/abs/1805.02855v2) - [pdf](http://arxiv.org/pdf/1805.02855v2)

> Geospatial analysis lacks methods like the word vector representations and pre-trained networks that significantly boost performance across a wide range of natural language and computer vision tasks. To fill this gap, we introduce Tile2Vec, an unsupervised representation learning algorithm that extends the distributional hypothesis from natural language -- words appearing in similar contexts tend to have similar meanings -- to spatially distributed data. We demonstrate empirically that Tile2Vec learns semantically meaningful representations on three datasets. Our learned representations significantly improve performance in downstream classification tasks and, similar to word vectors, visual analogies can be obtained via simple arithmetic in the latent space.

</details>

<details>

<summary>2018-05-30 12:21:12 - Unsupervised detection of diachronic word sense evolution</summary>

- *Jean-François Delpech*

- `1805.11295v2` - [abs](http://arxiv.org/abs/1805.11295v2) - [pdf](http://arxiv.org/pdf/1805.11295v2)

> Most words have several senses and connotations which evolve in time due to semantic shift, so that closely related words may gain different or even opposite meanings over the years. This evolution is very relevant to the study of language and of cultural changes, but the tools currently available for diachronic semantic analysis have significant, inherent limitations and are not suitable for real-time analysis. In this article, we demonstrate how the linearity of random vectors techniques enables building time series of congruent word embeddings (or semantic spaces) which can then be compared and combined linearly without loss of precision over any time period to detect diachronic semantic shifts. We show how this approach yields time trajectories of polysemous words such as amazon or apple, enables following semantic drifts and gender bias across time, reveals the shifting instantiations of stable concepts such as hurricane or president. This very fast, linear approach can easily be distributed over many processors to follow in real time streams of social media such as Twitter or Facebook; the resulting, time-dependent semantic spaces can then be combined at will by simple additions or subtractions.

</details>

<details>

<summary>2018-05-30 13:22:02 - Character-Level Models versus Morphology in Semantic Role Labeling</summary>

- *Gözde Gül Şahin, Mark Steedman*

- `1805.11937v1` - [abs](http://arxiv.org/abs/1805.11937v1) - [pdf](http://arxiv.org/pdf/1805.11937v1)

> Character-level models have become a popular approach specially for their accessibility and ability to handle unseen data. However, little is known on their ability to reveal the underlying morphological structure of a word, which is a crucial skill for high-level semantic analysis tasks, such as semantic role labeling (SRL). In this work, we train various types of SRL models that use word, character and morphology level information and analyze how performance of characters compare to words and morphology for several languages. We conduct an in-depth error analysis for each morphological typology and analyze the strengths and limitations of character-level models that relate to out-of-domain data, training data size, long range dependencies and model complexity. Our exhaustive analyses shed light on important characteristics of character-level models and their semantic capability.

</details>

<details>

<summary>2018-05-30 15:47:05 - The Coming Era of AlphaHacking? A Survey of Automatic Software Vulnerability Detection, Exploitation and Patching Techniques</summary>

- *Tiantian Ji, Yue Wu, Chang Wang, Xi Zhang, Zhongru Wang*

- `1805.11001v2` - [abs](http://arxiv.org/abs/1805.11001v2) - [pdf](http://arxiv.org/pdf/1805.11001v2)

> With the success of the Cyber Grand Challenge (CGC) sponsored by DARPA, the topic of Autonomous Cyber Reasoning System (CRS) has recently attracted extensive attention from both industry and academia. Utilizing automated system to detect, exploit and patch software vulnerabilities seems so attractive because of its scalability and cost-efficiency compared with the human expert based solution. In this paper, we give an extensive survey of former representative works related to the underlying technologies of a CRS, including vulnerability detection, exploitation and patching. As an important supplement, we then review several pioneer studies that explore the potential of machine learning technologies in this field, and point out that the future development of Autonomous CRS is inseparable from machine learning.

</details>

<details>

<summary>2018-05-30 15:56:22 - End-to-end named entity extraction from speech</summary>

- *Sahar Ghannay, Antoine Caubrière, Yannick Estève, Antoine Laurent, Emmanuel Morin*

- `1805.12045v1` - [abs](http://arxiv.org/abs/1805.12045v1) - [pdf](http://arxiv.org/pdf/1805.12045v1)

> Named entity recognition (NER) is among SLU tasks that usually extract semantic information from textual documents. Until now, NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propagation, metric to tune ASR systems sub-optimal in regards to the final task, reduced space search at the ASR output level...) and it is known that more integrated approaches outperform sequential ones, when they can be applied. In this paper, we present a first study of end-to-end approach that directly extracts named entities from speech, though a unique neural architecture. On a such way, a joint optimization is able for both ASR and NER. Experiments are carried on French data easily accessible, composed of data distributed in several evaluation campaign. Experimental results show that this end-to-end approach provides better results (F-measure=0.69 on test data) than a classical pipeline approach to detect named entity categories (F-measure=0.65).

</details>

<details>

<summary>2018-05-30 17:56:32 - Amnestic Forgery: an Ontology of Conceptual Metaphors</summary>

- *Aldo Gangemi, Mehwish Alam, Valentina Presutti*

- `1805.12115v1` - [abs](http://arxiv.org/abs/1805.12115v1) - [pdf](http://arxiv.org/pdf/1805.12115v1)

> This paper presents Amnestic Forgery, an ontology for metaphor semantics, based on MetaNet, which is inspired by the theory of Conceptual Metaphor. Amnestic Forgery reuses and extends the Framester schema, as an ideal ontology design framework to deal with both semiotic and referential aspects of frames, roles, mappings, and eventually blending. The description of the resource is supplied by a discussion of its applications, with examples taken from metaphor generation, and the referential problems of metaphoric mappings. Both schema and data are available from the Framester SPARQL endpoint.

</details>

<details>

<summary>2018-05-31 01:17:43 - Historical collaborative geocoding</summary>

- *Rémi Cura, Bertrand Dumenieu, Nathalie Abadie, Benoit Costes, Julien Perret, Maurizio Gribaudi*

- `1703.07138v4` - [abs](http://arxiv.org/abs/1703.07138v4) - [pdf](http://arxiv.org/pdf/1703.07138v4)

> The latest developments in digital have provided large data sets that can increasingly easily be accessed and used. These data sets often contain indirect localisation information, such as historical addresses. Historical geocoding is the process of transforming the indirect localisation information to direct localisation that can be placed on a map, which enables spatial analysis and cross-referencing. Many efficient geocoders exist for current addresses, but they do not deal with the temporal aspect and are based on a strict hierarchy (..., city, street, house number) that is hard or impossible to use with historical data. Indeed historical data are full of uncertainties (temporal aspect, semantic aspect, spatial precision, confidence in historical source, ...) that can not be resolved, as there is no way to go back in time to check. We propose an open source, open data, extensible solution for geocoding that is based on the building of gazetteers composed of geohistorical objects extracted from historical topographical maps. Once the gazetteers are available, geocoding an historical address is a matter of finding the geohistorical object in the gazetteers that is the best match to the historical address. The matching criteriae are customisable and include several dimensions (fuzzy semantic, fuzzy temporal, scale, spatial precision ...). As the goal is to facilitate historical work, we also propose web-based user interfaces that help geocode (one address or batch mode) and display over current or historical topographical maps, so that they can be checked and collaboratively edited. The system is tested on Paris city for the 19-20th centuries, shows high returns rate and is fast enough to be used interactively.

</details>

<details>

<summary>2018-05-31 17:56:14 - AllenNLP: A Deep Semantic Natural Language Processing Platform</summary>

- *Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Peters, Michael Schmitz, Luke Zettlemoyer*

- `1803.07640v2` - [abs](http://arxiv.org/abs/1803.07640v2) - [pdf](http://arxiv.org/pdf/1803.07640v2)

> This paper describes AllenNLP, a platform for research on deep learning methods in natural language understanding. AllenNLP is designed to support researchers who want to build novel language understanding models quickly and easily. It is built on top of PyTorch, allowing for dynamic computation graphs, and provides (1) a flexible data API that handles intelligent batching and padding, (2) high-level abstractions for common operations in working with text, and (3) a modular and extensible experiment framework that makes doing good science easy. It also includes reference implementations of high quality approaches for both core semantic problems (e.g. semantic role labeling (Palmer et al., 2005)) and language understanding applications (e.g. machine comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source effort maintained by engineers and researchers at the Allen Institute for Artificial Intelligence.

</details>

<details>

<summary>2018-05-31 18:42:26 - Following High-level Navigation Instructions on a Simulated Quadcopter with Imitation Learning</summary>

- *Valts Blukis, Nataly Brukhim, Andrew Bennett, Ross A. Knepper, Yoav Artzi*

- `1806.00047v1` - [abs](http://arxiv.org/abs/1806.00047v1) - [pdf](http://arxiv.org/pdf/1806.00047v1)

> We introduce a method for following high-level navigation instructions by mapping directly from images, instructions and pose estimates to continuous low-level velocity commands for real-time control. The Grounded Semantic Mapping Network (GSMN) is a fully-differentiable neural network architecture that builds an explicit semantic map in the world reference frame by incorporating a pinhole camera projection model within the network. The information stored in the map is learned from experience, while the local-to-world transformation is computed explicitly. We train the model using DAggerFM, a modified variant of DAgger that trades tabular convergence guarantees for improved training speed and memory use. We test GSMN in virtual environments on a realistic quadcopter simulator and show that incorporating an explicit mapping and grounding modules allows GSMN to outperform strong neural baselines and almost reach an expert policy performance. Finally, we analyze the learned map representations and show that using an explicit map leads to an interpretable instruction-following model.

</details>

<details>

<summary>2018-05-31 18:53:15 - Interpretable Set Functions</summary>

- *Andrew Cotter, Maya Gupta, Heinrich Jiang, James Muller, Taman Narayan, Serena Wang, Tao Zhu*

- `1806.00050v1` - [abs](http://arxiv.org/abs/1806.00050v1) - [pdf](http://arxiv.org/pdf/1806.00050v1)

> We propose learning flexible but interpretable functions that aggregate a variable-length set of permutation-invariant feature vectors to predict a label. We use a deep lattice network model so we can architect the model structure to enhance interpretability, and add monotonicity constraints between inputs-and-outputs. We then use the proposed set function to automate the engineering of dense, interpretable features from sparse categorical features, which we call semantic feature engine. Experiments on real-world data show the achieved accuracy is similar to deep sets or deep neural networks, and is easier to debug and understand.

</details>

<details>

<summary>2018-05-31 22:31:39 - DesignBIP: A Design Studio for Modeling and Generating Systems with BIP</summary>

- *Anastasia Mavridou, Joseph Sifakis, Janos Sztipanovits*

- `1805.09919v2` - [abs](http://arxiv.org/abs/1805.09919v2) - [pdf](http://arxiv.org/pdf/1805.09919v2)

> The Behavior-Interaction-Priority (BIP) framework, rooted in rigorous semantics, allows the construction of systems that are correct-by-design. BIP has been effectively used for the construction and analysis of large systems such as robot controllers and satellite on-board software. Nevertheless, the specification of BIP models is done in a purely textual manner without any code editor support. To facilitate the specification of BIP models, we present DesignBIP, a web-based, collaborative, version-controlled design studio. To promote model scaling and reusability of BIP models, we use a graphical language for modeling parameterized BIP models with rigorous semantics. We present the various services provided by the design studio, including model editors, code editors, consistency checking mechanisms, code generators, and integration with the JavaBIP tool-set.

</details>


## 2018-06

<details>

<summary>2018-06-01 00:10:04 - Sea surface temperature prediction and reconstruction using patch-level neural network representations</summary>

- *Said Ouala, Cedric Herzet, Ronan Fablet*

- `1806.00144v1` - [abs](http://arxiv.org/abs/1806.00144v1) - [pdf](http://arxiv.org/pdf/1806.00144v1)

> The forecasting and reconstruction of ocean and atmosphere dynamics from satellite observation time series are key challenges. While model-driven representations remain the classic approaches, data-driven representations become more and more appealing to benefit from available large-scale observation and simulation datasets. In this work we investigate the relevance of recently introduced bilinear residual neural network representations, which mimic numerical integration schemes such as Runge-Kutta, for the forecasting and assimilation of geophysical fields from satellite-derived remote sensing data. As a case-study, we consider satellite-derived Sea Surface Temperature time series off South Africa, which involves intense and complex upper ocean dynamics. Our numerical experiments demonstrate that the proposed patch-level neural-network-based representations outperform other data-driven models, including analog schemes, both in terms of forecasting and missing data interpolation performance with a relative gain up to 50\% for highly dynamic areas.

</details>

<details>

<summary>2018-06-01 16:35:08 - A Classification approach towards Unsupervised Learning of Visual Representations</summary>

- *Aditya Vora*

- `1806.00428v1` - [abs](http://arxiv.org/abs/1806.00428v1) - [pdf](http://arxiv.org/pdf/1806.00428v1)

> In this paper, we present a technique for unsupervised learning of visual representations. Specifically, we train a model for foreground and background classification task, in the process of which it learns visual representations. Foreground and background patches for training come af- ter mining for such patches from hundreds and thousands of unlabelled videos available on the web which we ex- tract using a proposed patch extraction algorithm. With- out using any supervision, with just using 150, 000 unla- belled videos and the PASCAL VOC 2007 dataset, we train a object recognition model that achieves 45.3 mAP which is close to the best performing unsupervised feature learn- ing technique whereas better than many other proposed al- gorithms. The code for patch extraction is implemented in Matlab and available open source at the following link .

</details>

<details>

<summary>2018-06-01 23:29:24 - Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps</summary>

- *Simon S. Du, Surbhi Goel*

- `1805.07798v2` - [abs](http://arxiv.org/abs/1805.07798v2) - [pdf](http://arxiv.org/pdf/1805.07798v2)

> We propose a new algorithm to learn a one-hidden-layer convolutional neural network where both the convolutional weights and the outputs weights are parameters to be learned. Our algorithm works for a general class of (potentially overlapping) patches, including commonly used structures for computer vision tasks. Our algorithm draws ideas from (1) isotonic regression for learning neural networks and (2) landscape analysis of non-convex matrix factorization problems. We believe these findings may inspire further development in designing provable algorithms for learning neural networks and other complex models.

</details>

<details>

<summary>2018-06-02 01:52:39 - SemTK: An Ontology-first, Open Source Semantic Toolkit for Managing and Querying Knowledge Graphs</summary>

- *Paul Cuddihy, Justin McHugh, Jenny Weisenberg Williams, Varish Mulwad, Kareem S. Aggour*

- `1710.11531v2` - [abs](http://arxiv.org/abs/1710.11531v2) - [pdf](http://arxiv.org/pdf/1710.11531v2)

> The relatively recent adoption of Knowledge Graphs as an enabling technology in multiple high-profile artificial intelligence and cognitive applications has led to growing interest in the Semantic Web technology stack. Many semantics-related tools, however, are focused on serving experts with a deep understanding of semantic technologies. For example, triplification of relational data is available but there is no open source tool that allows a user unfamiliar with OWL/RDF to import data into a semantic triple store in an intuitive manner. Further, many tools require users to have a working understanding of SPARQL to query data. Casual users interested in benefiting from the power of Knowledge Graphs have few tools available for exploring, querying, and managing semantic data. We present SemTK, the Semantics Toolkit, a user-friendly suite of tools that allow both expert and non-expert semantics users convenient ingestion of relational data, simplified query generation, and more. The exploration of ontologies and instance data is performed through SPARQLgraph, an intuitive web-based user interface in SemTK understandable and navigable by a lay user. The open source version of SemTK is available at http://semtk.research.ge.com

</details>

<details>

<summary>2018-06-02 06:33:47 - Does the brain represent words? An evaluation of brain decoding studies of language understanding</summary>

- *Jon Gauthier, Anna Ivanova*

- `1806.00591v1` - [abs](http://arxiv.org/abs/1806.00591v1) - [pdf](http://arxiv.org/pdf/1806.00591v1)

> Language decoding studies have identified word representations which can be used to predict brain activity in response to novel words and sentences (Anderson et al., 2016; Pereira et al., 2018). The unspoken assumption of these studies is that, during processing, linguistic information is transformed into some shared semantic space, and those semantic representations are then used for a variety of linguistic and non-linguistic tasks. We claim that current studies vastly underdetermine the content of these representations, the algorithms which the brain deploys to produce and consume them, and the computational tasks which they are designed to solve. We illustrate this indeterminacy with an extension of the sentence-decoding experiment of Pereira et al. (2018), showing how standard evaluations fail to distinguish between language processing models which deploy different mechanisms and which are optimized to solve very different tasks. We conclude by suggesting changes to the brain decoding paradigm which can support stronger claims of neural representation.

</details>

<details>

<summary>2018-06-02 11:44:01 - Recurrent Neural Network-Based Semantic Variational Autoencoder for Sequence-to-Sequence Learning</summary>

- *Myeongjun Jang, Seungwan Seo, Pilsung Kang*

- `1802.03238v2` - [abs](http://arxiv.org/abs/1802.03238v2) - [pdf](http://arxiv.org/pdf/1802.03238v2)

> Sequence-to-sequence (Seq2seq) models have played an important role in the recent success of various natural language processing methods, such as machine translation, text summarization, and speech recognition. However, current Seq2seq models have trouble preserving global latent information from a long sequence of words. Variational autoencoder (VAE) alleviates this problem by learning a continuous semantic space of the input sentence. However, it does not solve the problem completely. In this paper, we propose a new recurrent neural network (RNN)-based Seq2seq model, RNN semantic variational autoencoder (RNN--SVAE), to better capture the global latent information of a sequence of words. To reflect the meaning of words in a sentence properly, without regard to its position within the sentence, we construct a document information vector using the attention information between the final state of the encoder and every prior hidden state. Then, the mean and standard deviation of the continuous semantic space are learned by using this vector to take advantage of the variational method. By using the document information vector to find the semantic space of the sentence, it becomes possible to better capture the global latent feature of the sentence. Experimental results of three natural language tasks (i.e., language modeling, missing word imputation, paraphrase identification) confirm that the proposed RNN--SVAE yields higher performance than two benchmark models.

</details>

<details>

<summary>2018-06-02 18:46:50 - Hierarchical Attention-Based Recurrent Highway Networks for Time Series Prediction</summary>

- *Yunzhe Tao, Lin Ma, Weizhong Zhang, Jian Liu, Wei Liu, Qiang Du*

- `1806.00685v1` - [abs](http://arxiv.org/abs/1806.00685v1) - [pdf](http://arxiv.org/pdf/1806.00685v1)

> Time series prediction has been studied in a variety of domains. However, it is still challenging to predict future series given historical observations and past exogenous data. Existing methods either fail to consider the interactions among different components of exogenous variables which may affect the prediction accuracy, or cannot model the correlations between exogenous data and target data. Besides, the inherent temporal dynamics of exogenous data are also related to the target series prediction, and thus should be considered as well. To address these issues, we propose an end-to-end deep learning model, i.e., Hierarchical attention-based Recurrent Highway Network (HRHN), which incorporates spatio-temporal feature extraction of exogenous variables and temporal dynamics modeling of target variables into a single framework. Moreover, by introducing the hierarchical attention mechanism, HRHN can adaptively select the relevant exogenous features in different semantic levels. We carry out comprehensive empirical evaluations with various methods over several datasets, and show that HRHN outperforms the state of the arts in time series prediction, especially in capturing sudden changes and sudden oscillations of time series.

</details>

<details>

<summary>2018-06-02 22:41:28 - An Interpretable Deep Hierarchical Semantic Convolutional Neural Network for Lung Nodule Malignancy Classification</summary>

- *Shiwen Shen, Simon X. Han, Denise R. Aberle, Alex A. T. Bui, Willliam Hsu*

- `1806.00712v1` - [abs](http://arxiv.org/abs/1806.00712v1) - [pdf](http://arxiv.org/pdf/1806.00712v1)

> While deep learning methods are increasingly being applied to tasks such as computer-aided diagnosis, these models are difficult to interpret, do not incorporate prior domain knowledge, and are often considered as a "black-box." The lack of model interpretability hinders them from being fully understood by target users such as radiologists. In this paper, we present a novel interpretable deep hierarchical semantic convolutional neural network (HSCNN) to predict whether a given pulmonary nodule observed on a computed tomography (CT) scan is malignant. Our network provides two levels of output: 1) low-level radiologist semantic features, and 2) a high-level malignancy prediction score. The low-level semantic outputs quantify the diagnostic features used by radiologists and serve to explain how the model interprets the images in an expert-driven manner. The information from these low-level tasks, along with the representations learned by the convolutional layers, are then combined and used to infer the high-level task of predicting nodule malignancy. This unified architecture is trained by optimizing a global loss function including both low- and high-level tasks, thereby learning all the parameters within a joint framework. Our experimental results using the Lung Image Database Consortium (LIDC) show that the proposed method not only produces interpretable lung cancer predictions but also achieves significantly better results compared to common 3D CNN approaches.

</details>

<details>

<summary>2018-06-03 02:03:11 - Closed-loop Bayesian Semantic Data Fusion for Collaborative Human-Autonomy Target Search</summary>

- *Luke Burks, Ian Loefgren, Luke Barbier, Jeremy Muesing, Jamison McGinley, Sousheel Vunnam, Nisar Ahmed*

- `1806.00727v1` - [abs](http://arxiv.org/abs/1806.00727v1) - [pdf](http://arxiv.org/pdf/1806.00727v1)

> In search applications, autonomous unmanned vehicles must be able to efficiently reacquire and localize mobile targets that can remain out of view for long periods of time in large spaces. As such, all available information sources must be actively leveraged -- including imprecise but readily available semantic observations provided by humans. To achieve this, this work develops and validates a novel collaborative human-machine sensing solution for dynamic target search. Our approach uses continuous partially observable Markov decision process (CPOMDP) planning to generate vehicle trajectories that optimally exploit imperfect detection data from onboard sensors, as well as semantic natural language observations that can be specifically requested from human sensors. The key innovation is a scalable hierarchical Gaussian mixture model formulation for efficiently solving CPOMDPs with semantic observations in continuous dynamic state spaces. The approach is demonstrated and validated with a real human-robot team engaged in dynamic indoor target search and capture scenarios on a custom testbed.

</details>

<details>

<summary>2018-06-03 08:35:28 - Extrofitting: Enriching Word Representation and its Vector Space with Semantic Lexicons</summary>

- *Hwiyeol Jo, Stanley Jungkyu Choi*

- `1804.07946v2` - [abs](http://arxiv.org/abs/1804.07946v2) - [pdf](http://arxiv.org/pdf/1804.07946v2)

> We propose post-processing method for enriching not only word representation but also its vector space using semantic lexicons, which we call extrofitting. The method consists of 3 steps as follows: (i) Expanding 1 or more dimension(s) on all the word vectors, filling with their representative value. (ii) Transferring semantic knowledge by averaging each representative values of synonyms and filling them in the expanded dimension(s). These two steps make representations of the synonyms close together. (iii) Projecting the vector space using Linear Discriminant Analysis, which eliminates the expanded dimension(s) with semantic knowledge. When experimenting with GloVe, we find that our method outperforms Faruqui's retrofitting on some of word similarity task. We also report further analysis on our method in respect to word vector dimensions, vocabulary size as well as other well-known pretrained word vectors (e.g., Word2Vec, Fasttext).

</details>

<details>

<summary>2018-06-03 14:56:42 - Admissible Abstractions for Near-optimal Task and Motion Planning</summary>

- *William Vega-Brown, Nicholas Roy*

- `1806.00805v1` - [abs](http://arxiv.org/abs/1806.00805v1) - [pdf](http://arxiv.org/pdf/1806.00805v1)

> We define an admissibility condition for abstractions expressed using angelic semantics and show that these conditions allow us to accelerate planning while preserving the ability to find the optimal motion plan. We then derive admissible abstractions for two motion planning domains with continuous state. We extract upper and lower bounds on the cost of concrete motion plans using local metric and topological properties of the problem domain. These bounds guide the search for a plan while maintaining performance guarantees. We show that abstraction can dramatically reduce the complexity of search relative to a direct motion planner. Using our abstractions, we find near-optimal motion plans in planning problems involving $10^{13}$ states without using a separate task planner.

</details>

<details>

<summary>2018-06-04 01:07:37 - An unsupervised and customizable misspelling generator for mining noisy health-related text sources</summary>

- *Abeed Sarker, Graciela Gonzalez-Hernandez*

- `1806.00910v1` - [abs](http://arxiv.org/abs/1806.00910v1) - [pdf](http://arxiv.org/pdf/1806.00910v1)

> In this paper, we present a customizable datacentric system that automatically generates common misspellings for complex health-related terms. The spelling variant generator relies on a dense vector model learned from large unlabeled text, which is used to find semantically close terms to the original/seed keyword, followed by the filtering of terms that are lexically dissimilar beyond a given threshold. The process is executed recursively, converging when no new terms similar (lexically and semantically) to the seed keyword are found. Weighting of intra-word character sequence similarities allows further problem-specific customization of the system. On a dataset prepared for this study, our system outperforms the current state-of-the-art for medication name variant generation with best F1-score of 0.69 and F1/4-score of 0.78. Extrinsic evaluation of the system on a set of cancer-related terms showed an increase of over 67% in retrieval rate from Twitter posts when the generated variants are included. Our proposed spelling variant generator has several advantages over the current state-of-the-art and other types of variant generators-(i) it is capable of filtering out lexically similar but semantically dissimilar terms, (ii) the number of variants generated is low as many low-frequency and ambiguous misspellings are filtered out, and (iii) the system is fully automatic, customizable and easily executable. While the base system is fully unsupervised, we show how supervision maybe employed to adjust weights for task-specific customization. The performance and significant relative simplicity of our proposed approach makes it a much needed misspelling generation resource for health-related text mining from noisy sources. The source code for the system has been made publicly available for research purposes.

</details>

<details>

<summary>2018-06-04 11:03:11 - Topic Modelling of Empirical Text Corpora: Validity, Reliability, and Reproducibility in Comparison to Semantic Maps</summary>

- *Tobias Hecking, Loet Leydesdorff*

- `1806.01045v1` - [abs](http://arxiv.org/abs/1806.01045v1) - [pdf](http://arxiv.org/pdf/1806.01045v1)

> Using the 6,638 case descriptions of societal impact submitted for evaluation in the Research Excellence Framework (REF 2014), we replicate the topic model (Latent Dirichlet Allocation or LDA) made in this context and compare the results with factor-analytic results using a traditional word-document matrix (Principal Component Analysis or PCA). Removing a small fraction of documents from the sample, for example, has on average a much larger impact on LDA than on PCA-based models to the extent that the largest distortion in the case of PCA has less effect than the smallest distortion of LDA-based models. In terms of semantic coherence, however, LDA models outperform PCA-based models. The topic models inform us about the statistical properties of the document sets under study, but the results are statistical and should not be used for a semantic interpretation - for example, in grant selections and micro-decision making, or scholarly work-without follow-up using domain-specific semantic maps.

</details>

<details>

<summary>2018-06-04 16:16:37 - Do Neural Network Cross-Modal Mappings Really Bridge Modalities?</summary>

- *Guillem Collell, Marie-Francine Moens*

- `1805.07616v2` - [abs](http://arxiv.org/abs/1805.07616v2) - [pdf](http://arxiv.org/pdf/1805.07616v2)

> Feed-forward networks are widely used in cross-modal applications to bridge modalities by mapping distributed vectors of one modality to the other, or to a shared space. The predicted vectors are then used to perform e.g., retrieval or labeling. Thus, the success of the whole system relies on the ability of the mapping to make the neighborhood structure (i.e., the pairwise similarities) of the predicted vectors akin to that of the target vectors. However, whether this is achieved has not been investigated yet. Here, we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and vision-to-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.

</details>

<details>

<summary>2018-06-04 19:06:14 - C-BPMN: A Context Aware BPMN for Modeling Complex Business Process</summary>

- *Debarpita Santra, Sankhayan Choudhury*

- `1806.01333v1` - [abs](http://arxiv.org/abs/1806.01333v1) - [pdf](http://arxiv.org/pdf/1806.01333v1)

> A complex business process demands adaptability as it has been highly influenced by the contextual information. The contextual information declares the underlying semantics on which the process logic depends. Thus one of the challenges of a business process modeling is to include the context sensitivity within the modeling itself. BPMN is the widely accepted tool in this field. All the process modeling languages like EPC, UML, BPMN are not able to express the context awareness as required. In this paper an attempt has been made to offer a means for modeling a complex business process with necessary contextual information. We have proposed a context model in terms of a graph, extended the existing BPMN by adding new construct and integrated the said components to achieve our goal. The methodology as stated certainly offers necessary understandability, maintainability and the adaptability as a whole. Moreover the model is validated using Colored Petri Net and is expected to behave properly in a real life environment.

</details>

<details>

<summary>2018-06-04 21:15:01 - Hierarchical Text Generation and Planning for Strategic Dialogue</summary>

- *Denis Yarats, Mike Lewis*

- `1712.05846v2` - [abs](http://arxiv.org/abs/1712.05846v2) - [pdf](http://arxiv.org/pdf/1712.05846v2)

> End-to-end models for goal-orientated dialogue are challenging to train, because linguistic and strategic aspects are entangled in latent state vectors. We introduce an approach to learning representations of messages in dialogues by maximizing the likelihood of subsequent sentences and actions, which decouples the semantics of the dialogue utterance from its linguistic realization. We then use these latent sentence representations for hierarchical language generation, planning and reinforcement learning. Experiments show that our approach increases the end-task reward achieved by the model, improves the effectiveness of long-term planning using rollouts, and allows self-play reinforcement learning to improve decision making without diverging from human language. Our hierarchical latent-variable model outperforms previous work both linguistically and strategically.

</details>

<details>

<summary>2018-06-05 07:34:02 - Multi-Task Active Learning for Neural Semantic Role Labeling on Low Resource Conversational Corpus</summary>

- *Fariz Ikhwantri, Samuel Louvan, Kemal Kurniawan, Bagas Abisena, Valdi Rachman, Alfan Farizki Wicaksono, Rahmad Mahendra*

- `1806.01523v1` - [abs](http://arxiv.org/abs/1806.01523v1) - [pdf](http://arxiv.org/pdf/1806.01523v1)

> Most Semantic Role Labeling (SRL) approaches are supervised methods which require a significant amount of annotated corpus, and the annotation requires linguistic expertise. In this paper, we propose a Multi-Task Active Learning framework for Semantic Role Labeling with Entity Recognition (ER) as the auxiliary task to alleviate the need for extensive data and use additional information from ER to help SRL. We evaluate our approach on Indonesian conversational dataset. Our experiments show that multi-task active learning can outperform single-task active learning method and standard multi-task learning. According to our results, active learning is more efficient by using 12% less of training data compared to passive learning in both single-task and multi-task setting. We also introduce a new dataset for SRL in Indonesian conversational domain to encourage further research in this area.

</details>

<details>

<summary>2018-06-05 12:02:11 - Explaining Away Syntactic Structure in Semantic Document Representations</summary>

- *Erik Holmer, Andreas Marfurt*

- `1806.01620v1` - [abs](http://arxiv.org/abs/1806.01620v1) - [pdf](http://arxiv.org/pdf/1806.01620v1)

> Most generative document models act on bag-of-words input in an attempt to focus on the semantic content and thereby partially forego syntactic information. We argue that it is preferable to keep the original word order intact and explicitly account for the syntactic structure instead. We propose an extension to the Neural Variational Document Model (Miao et al., 2016) that does exactly that to separate local (syntactic) context from the global (semantic) representation of the document. Our model builds on the variational autoencoder framework to define a generative document model based on next-word prediction. We name our approach Sequence-Aware Variational Autoencoder since in contrast to its predecessor, it operates on the true input sequence. In a series of experiments we observe stronger topicality of the learned representations as well as increased robustness to syntactic noise in our training data.

</details>

<details>

<summary>2018-06-05 12:41:14 - Deep Gaussian Processes with Convolutional Kernels</summary>

- *Vinayak Kumar, Vaibhav Singh, P. K. Srijith, Andreas Damianou*

- `1806.01655v1` - [abs](http://arxiv.org/abs/1806.01655v1) - [pdf](http://arxiv.org/pdf/1806.01655v1)

> Deep Gaussian processes (DGPs) provide a Bayesian non-parametric alternative to standard parametric deep learning models. A DGP is formed by stacking multiple GPs resulting in a well-regularized composition of functions. The Bayesian framework that equips the model with attractive properties, such as implicit capacity control and predictive uncertainty, makes it at the same time challenging to combine with a convolutional structure. This has hindered the application of DGPs in computer vision tasks, an area where deep parametric models (i.e. CNNs) have made breakthroughs. Standard kernels used in DGPs such as radial basis functions (RBFs) are insufficient for handling pixel variability in raw images. In this paper, we build on the recent convolutional GP to develop Convolutional DGP (CDGP) models which effectively capture image level features through the use of convolution kernels, therefore opening up the way for applying DGPs to computer vision tasks. Our model learns local spatial influence and outperforms strong GP based baselines on multi-class image classification. We also consider various constructions of convolution kernel over the image patches, analyze the computational trade-offs and provide an efficient framework for convolutional DGP models. The experimental results on image data such as MNIST, rectangles-image, CIFAR10 and Caltech101 demonstrate the effectiveness of the proposed approaches.

</details>

<details>

<summary>2018-06-05 19:00:35 - Performance Evaluation of Deep Learning Networks for Semantic Segmentation of Traffic Stereo-Pair Images</summary>

- *Vlad Taran, Nikita Gordienko, Yuriy Kochura, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko*

- `1806.01896v1` - [abs](http://arxiv.org/abs/1806.01896v1) - [pdf](http://arxiv.org/pdf/1806.01896v1)

> Semantic image segmentation is one the most demanding task, especially for analysis of traffic conditions for self-driving cars. Here the results of application of several deep learning architectures (PSPNet and ICNet) for semantic image segmentation of traffic stereo-pair images are presented. The images from Cityscapes dataset and custom urban images were analyzed as to the segmentation accuracy and image inference time. For the models pre-trained on Cityscapes dataset, the inference time was equal in the limits of standard deviation, but the segmentation accuracy was different for various cities and stereo channels even. The distributions of accuracy (mean intersection over union - mIoU) values for each city and channel are asymmetric, long-tailed, and have many extreme outliers, especially for PSPNet network in comparison to ICNet network. Some statistical properties of these distributions (skewness, kurtosis) allow us to distinguish these two networks and open the question about relations between architecture of deep learning networks and statistical distribution of the predicted results (mIoU here). The results obtained demonstrated the different sensitivity of these networks to: (1) the local street view peculiarities in different cities that should be taken into account during the targeted fine tuning the models before their practical applications, (2) the right and left data channels in stereo-pairs. For both networks, the difference in the predicted results (mIoU here) for the right and left data channels in stereo-pairs is out of the limits of statistical error in relation to mIoU values. It means that the traffic stereo pairs can be effectively used not only for depth calculations (as it is usually used), but also as an additional data channel that can provide much more information about scene objects than simple duplication of the same street view images.

</details>

<details>

<summary>2018-06-06 15:42:22 - The Limitations of Cross-language Word Embeddings Evaluation</summary>

- *Amir Bakarov, Roman Suvorov, Ilya Sochenkov*

- `1806.02253v1` - [abs](http://arxiv.org/abs/1806.02253v1) - [pdf](http://arxiv.org/pdf/1806.02253v1)

> The aim of this work is to explore the possible limitations of existing methods of cross-language word embeddings evaluation, addressing the lack of correlation between intrinsic and extrinsic cross-language evaluation methods. To prove this hypothesis, we construct English-Russian datasets for extrinsic and intrinsic evaluation tasks and compare performances of 5 different cross-language models on them. The results say that the scores even on different intrinsic benchmarks do not correlate to each other. We can conclude that the use of human references as ground truth for cross-language word embeddings is not proper unless one does not understand how do native speakers process semantics in their cognition.

</details>

<details>

<summary>2018-06-06 16:20:24 - Deploying Deep Ranking Models for Search Verticals</summary>

- *Rohan Ramanath, Gungor Polatkan, Liqin Xu, Harold Lee, Bo Hu, Shan Zhou*

- `1806.02281v1` - [abs](http://arxiv.org/abs/1806.02281v1) - [pdf](http://arxiv.org/pdf/1806.02281v1)

> In this paper, we present an architecture executing a complex machine learning model such as a neural network capturing semantic similarity between a query and a document; and deploy to a real-world production system serving 500M+users. We present the challenges that arise in a real-world system and how we solve them. We demonstrate that our architecture provides competitive modeling capability without any significant performance impact to the system in terms of latency. Our modular solution and insights can be used by other real-world search systems to realize and productionize recent gains in neural networks.

</details>

<details>

<summary>2018-06-06 20:51:06 - Human-aided Multi-Entity Bayesian Networks Learning from Relational Data</summary>

- *Cheol Young Park, Kathryn Blackmond Laskey*

- `1806.02421v1` - [abs](http://arxiv.org/abs/1806.02421v1) - [pdf](http://arxiv.org/pdf/1806.02421v1)

> An Artificial Intelligence (AI) system is an autonomous system which emulates human mental and physical activities such as Observe, Orient, Decide, and Act, called the OODA process. An AI system performing the OODA process requires a semantically rich representation to handle a complex real world situation and ability to reason under uncertainty about the situation. Multi-Entity Bayesian Networks (MEBNs) combines First-Order Logic with Bayesian Networks for representing and reasoning about uncertainty in complex, knowledge-rich domains. MEBN goes beyond standard Bayesian networks to enable reasoning about an unknown number of entities interacting with each other in various types of relationships, a key requirement for the OODA process of an AI system. MEBN models have heretofore been constructed manually by a domain expert. However, manual MEBN modeling is labor-intensive and insufficiently agile. To address these problems, an efficient method is needed for MEBN modeling. One of the methods is to use machine learning to learn a MEBN model in whole or in part from data. In the era of Big Data, data-rich environments, characterized by uncertainty and complexity, have become ubiquitous. The larger the data sample is, the more accurate the results of the machine learning approach can be. Therefore, machine learning has potential to improve the quality of MEBN models as well as the effectiveness for MEBN modeling. In this research, we study a MEBN learning framework to develop a MEBN model from a combination of domain expert's knowledge and data. To evaluate the MEBN learning framework, we conduct an experiment to compare the MEBN learning framework and the existing manual MEBN modeling in terms of development efficiency.

</details>

<details>

<summary>2018-06-07 03:47:46 - AIQL: Enabling Efficient Attack Investigation from System Monitoring Data</summary>

- *Peng Gao, Xusheng Xiao, Zhichun Li, Kangkook Jee, Fengyuan Xu, Sanjeev R. Kulkarni, Prateek Mittal*

- `1806.02290v2` - [abs](http://arxiv.org/abs/1806.02290v2) - [pdf](http://arxiv.org/pdf/1806.02290v2)

> The need for countering Advanced Persistent Threat (APT) attacks has led to the solutions that ubiquitously monitor system activities in each host, and perform timely attack investigation over the monitoring data for analyzing attack provenance. However, existing query systems based on relational databases and graph databases lack language constructs to express key properties of major attack behaviors, and often execute queries inefficiently since their semantics-agnostic design cannot exploit the properties of system monitoring data to speed up query execution.   To address this problem, we propose a novel query system built on top of existing monitoring tools and databases, which is designed with novel types of optimizations to support timely attack investigation. Our system provides (1) domain-specific data model and storage for scaling the storage, (2) a domain-specific query language, Attack Investigation Query Language (AIQL) that integrates critical primitives for attack investigation, and (3) an optimized query engine based on the characteristics of the data and the semantics of the queries to efficiently schedule the query execution. We deployed our system in NEC Labs America comprising 150 hosts and evaluated it using 857 GB of real system monitoring data (containing 2.5 billion events). Our evaluations on a real-world APT attack and a broad set of attack behaviors show that our system surpasses existing systems in both efficiency (124x over PostgreSQL, 157x over Neo4j, and 16x over Greenplum) and conciseness (SQL, Neo4j Cypher, and Splunk SPL contain at least 2.4x more constraints than AIQL).

</details>

<details>

<summary>2018-06-07 14:38:08 - Efficient semantic image segmentation with superpixel pooling</summary>

- *Mathijs Schuurmans, Maxim Berman, Matthew B. Blaschko*

- `1806.02705v1` - [abs](http://arxiv.org/abs/1806.02705v1) - [pdf](http://arxiv.org/pdf/1806.02705v1)

> In this work, we evaluate the use of superpixel pooling layers in deep network architectures for semantic segmentation. Superpixel pooling is a flexible and efficient replacement for other pooling strategies that incorporates spatial prior information. We propose a simple and efficient GPU-implementation of the layer and explore several designs for the integration of the layer into existing network architectures. We provide experimental results on the IBSR and Cityscapes dataset, demonstrating that superpixel pooling can be leveraged to consistently increase network accuracy with minimal computational overhead. Source code is available at https://github.com/bermanmaxim/superpixPool

</details>

<details>

<summary>2018-06-07 20:57:22 - Probabilistic FastText for Multi-Sense Word Embeddings</summary>

- *Ben Athiwaratkun, Andrew Gordon Wilson, Anima Anandkumar*

- `1806.02901v1` - [abs](http://arxiv.org/abs/1806.02901v1) - [pdf](http://arxiv.org/pdf/1806.02901v1)

> We introduce Probabilistic FastText, a new model for word embeddings that can capture multiple word senses, sub-word structure, and uncertainty information. In particular, we represent each word with a Gaussian mixture density, where the mean of a mixture component is given by the sum of n-grams. This representation allows the model to share statistical strength across sub-word structures (e.g. Latin roots), producing accurate representations of rare, misspelt, or even unseen words. Moreover, each component of the mixture can capture a different word sense. Probabilistic FastText outperforms both FastText, which has no probabilistic model, and dictionary-level probabilistic embeddings, which do not incorporate subword structures, on several word-similarity benchmarks, including English RareWord and foreign language datasets. We also achieve state-of-art performance on benchmarks that measure ability to discern different meanings. Thus, the proposed model is the first to achieve multi-sense representations while having enriched semantics on rare words.

</details>

<details>

<summary>2018-06-08 00:05:58 - A Semantic Loss Function for Deep Learning with Symbolic Knowledge</summary>

- *Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck*

- `1711.11157v2` - [abs](http://arxiv.org/abs/1711.11157v2) - [pdf](http://arxiv.org/pdf/1711.11157v2)

> This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.

</details>

<details>

<summary>2018-06-08 05:33:34 - Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms</summary>

- *Yi Wu, Siddharth Srivastava, Nicholas Hay, Simon Du, Stuart Russell*

- `1806.02027v3` - [abs](http://arxiv.org/abs/1806.02027v3) - [pdf](http://arxiv.org/pdf/1806.02027v3)

> Despite the recent successes of probabilistic programming languages (PPLs) in AI applications, PPLs offer only limited support for random variables whose distributions combine discrete and continuous elements. We develop the notion of measure-theoretic Bayesian networks (MTBNs) and use it to provide more general semantics for PPLs with arbitrarily many random variables defined over arbitrary measure spaces. We develop two new general sampling algorithms that are provably correct under the MTBN framework: the lexicographic likelihood weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF), a specialized algorithm for state-space models. We further integrate MTBNs into a widely used PPL system, BLOG, and verify the effectiveness of the new inference algorithms through representative examples.

</details>

<details>

<summary>2018-06-08 12:55:37 - Text Classification based on Word Subspace with Term-Frequency</summary>

- *Erica K. Shimomoto, Lincon S. Souza, Bernardo B. Gatto, Kazuhiro Fukui*

- `1806.03125v1` - [abs](http://arxiv.org/abs/1806.03125v1) - [pdf](http://arxiv.org/pdf/1806.03125v1)

> Text classification has become indispensable due to the rapid increase of text in digital form. Over the past three decades, efforts have been made to approach this task using various learning algorithms and statistical models based on bag-of-words (BOW) features. Despite its simple implementation, BOW features lack semantic meaning representation. To solve this problem, neural networks started to be employed to learn word vectors, such as the word2vec. Word2vec embeds word semantic structure into vectors, where the angle between vectors indicates the meaningful similarity between words. To measure the similarity between texts, we propose the novel concept of word subspace, which can represent the intrinsic variability of features in a set of word vectors. Through this concept, it is possible to model text from word vectors while holding semantic information. To incorporate the word frequency directly in the subspace model, we further extend the word subspace to the term-frequency (TF) weighted word subspace. Based on these new concepts, text classification can be performed under the mutual subspace method (MSM) framework. The validity of our modeling is shown through experiments on the Reuters text database, comparing the results to various state-of-art algorithms.

</details>

<details>

<summary>2018-06-08 23:26:22 - CS-VQA: Visual Question Answering with Compressively Sensed Images</summary>

- *Li-Chi Huang, Kuldeep Kulkarni, Anik Jha, Suhas Lohit, Suren Jayasuriya, Pavan Turaga*

- `1806.03379v1` - [abs](http://arxiv.org/abs/1806.03379v1) - [pdf](http://arxiv.org/pdf/1806.03379v1)

> Visual Question Answering (VQA) is a complex semantic task requiring both natural language processing and visual recognition. In this paper, we explore whether VQA is solvable when images are captured in a sub-Nyquist compressive paradigm. We develop a series of deep-network architectures that exploit available compressive data to increasing degrees of accuracy, and show that VQA is indeed solvable in the compressed domain. Our results show that there is nominal degradation in VQA performance when using compressive measurements, but that accuracy can be recovered when VQA pipelines are used in conjunction with state-of-the-art deep neural networks for CS reconstruction. The results presented yield important implications for resource-constrained VQA applications.

</details>

<details>

<summary>2018-06-09 07:37:52 - Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech</summary>

- *Yu-An Chung, James Glass*

- `1803.08976v2` - [abs](http://arxiv.org/abs/1803.08976v2) - [pdf](http://arxiv.org/pdf/1803.08976v2)

> In this paper, we propose a novel deep neural network architecture, Speech2Vec, for learning fixed-length vector representations of audio segments excised from a speech corpus, where the vectors contain semantic information pertaining to the underlying spoken words, and are close to other vectors in the embedding space if their corresponding underlying spoken words are semantically similar. The proposed model can be viewed as a speech version of Word2Vec. Its design is based on a RNN Encoder-Decoder framework, and borrows the methodology of skipgrams or continuous bag-of-words for training. Learning word embeddings directly from speech enables Speech2Vec to make use of the semantic information carried by speech that does not exist in plain text. The learned word embeddings are evaluated and analyzed on 13 widely used word similarity benchmarks, and outperform word embeddings learned by Word2Vec from the transcriptions.

</details>

<details>

<summary>2018-06-09 07:38:27 - An Encoder-Decoder Framework Translating Natural Language to Database Queries</summary>

- *Ruichu Cai, Boyan Xu, Xiaoyan Yang, Zhenjie Zhang, Zijian Li, Zhihao Liang*

- `1711.06061v2` - [abs](http://arxiv.org/abs/1711.06061v2) - [pdf](http://arxiv.org/pdf/1711.06061v2)

> Machine translation is going through a radical revolution, driven by the explosive development of deep learning techniques using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). In this paper, we consider a special case in machine translation problems, targeting to convert natural language into Structured Query Language (SQL) for data retrieval over relational database. Although generic CNN and RNN learn the grammar structure of SQL when trained with sufficient samples, the accuracy and training efficiency of the model could be dramatically improved, when the translation model is deeply integrated with the grammar rules of SQL. We present a new encoder-decoder framework, with a suite of new approaches, including new semantic features fed into the encoder, grammar-aware states injected into the memory of decoder, as well as recursive state management for sub-queries. These techniques help the neural network better focus on understanding semantics of operations in natural language and save the efforts on SQL grammar learning. The empirical evaluation on real world database and queries show that our approach outperform state-of-the-art solution by a significant margin.

</details>

<details>

<summary>2018-06-09 11:48:23 - Robust Semantic Segmentation with Ladder-DenseNet Models</summary>

- *Ivan Krešo, Marin Oršić, Petra Bevandić, Siniša Šegvić*

- `1806.03465v1` - [abs](http://arxiv.org/abs/1806.03465v1) - [pdf](http://arxiv.org/pdf/1806.03465v1)

> We present semantic segmentation experiments with a model capable to perform predictions on four benchmark datasets: Cityscapes, ScanNet, WildDash and KITTI. We employ a ladder-style convolutional architecture featuring a modified DenseNet-169 model in the downsampling datapath, and only one convolution in each stage of the upsampling datapath. Due to limited computing resources, we perform the training only on Cityscapes Fine train+val, ScanNet train, WildDash val and KITTI train. We evaluate the trained model on the test subsets of the four benchmarks in concordance with the guidelines of the Robust Vision Challenge ROB 2018. The performed experiments reveal several interesting findings which we describe and discuss.

</details>

<details>

<summary>2018-06-09 16:07:02 - Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction</summary>

- *Siyuan Qi, Baoxiong Jia, Song-Chun Zhu*

- `1806.03497v1` - [abs](http://arxiv.org/abs/1806.03497v1) - [pdf](http://arxiv.org/pdf/1806.03497v1)

> Future predictions on sequence data (e.g., videos or audios) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled. This generalized Earley parser integrates a grammar parser with a classifier to find the optimal segmentation and labels, and makes top-down future predictions. Experiments show that our method significantly outperforms other approaches for future human activity prediction.

</details>

<details>

<summary>2018-06-09 21:22:59 - Application of Correlation Indices on Intrusion Detection Systems: Protecting the Power Grid Against Coordinated Attacks</summary>

- *Christian Moya, Junho Hong, Jiankang Wang*

- `1806.03544v1` - [abs](http://arxiv.org/abs/1806.03544v1) - [pdf](http://arxiv.org/pdf/1806.03544v1)

> The future power grid will be characterized by the pervasive use of heterogeneous and non-proprietary information and communication technology, which exposes the power grid to a broad scope of cyber-attacks. In particular, Monitoring-Control Attacks (MCA) --i.e., attacks in which adversaries manipulate control decisions by fabricating measurement signals in the feedback loop-- are highly threatening. This is because, MCAs are (i) more likely to happen with greater attack surface and lower cost, (ii) difficult to detect by hiding in measurement signals, and (iii) capable of inflicting severe consequences by coordinating attack resources. To defend against MCAs, we have developed a semantic analysis framework for Intrusion Detection Systems (IDS) in power grids. The framework consists of two parts running in parallel: a Correlation Index Generator (CIG), which indexes correlated MCAs, and a Correlation Knowledge-Base~(CKB), which is updated aperiodically with attacks' Correlation Indices (CI). The framework has the advantage of detecting MCAs and estimating attack consequences with promising runtime and detection accuracy. To evaluate the performance of the framework, we computed its false alarm rates under different attack scenarios.

</details>

<details>

<summary>2018-06-10 15:29:18 - Global Encoding for Abstractive Summarization</summary>

- *Junyang Lin, Xu Sun, Shuming Ma, Qi Su*

- `1805.03989v2` - [abs](http://arxiv.org/abs/1805.03989v2) - [pdf](http://arxiv.org/pdf/1805.03989v2)

> In neural abstractive summarization, the conventional sequence-to-sequence (seq2seq) model often suffers from repetition and semantic irrelevance. To tackle the problem, we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. It consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. Evaluations on the LCSTS and the English Gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of reducing repetition.

</details>

<details>

<summary>2018-06-11 12:45:13 - Securing the Internet of Things in the Age of Machine Learning and Software-defined Networking</summary>

- *Francesco Restuccia, Salvatore D'Oro, Tommaso Melodia*

- `1803.05022v2` - [abs](http://arxiv.org/abs/1803.05022v2) - [pdf](http://arxiv.org/pdf/1803.05022v2)

> The Internet of Things (IoT) realizes a vision where billions of interconnected devices are deployed just about everywhere, from inside our bodies to the most remote areas of the globe. As the IoT will soon pervade every aspect of our lives and will be accessible from anywhere, addressing critical IoT security threats is now more important than ever. Traditional approaches where security is applied as an afterthought and as a "patch" against known attacks are insufficient. Indeed, next-generation IoT challenges will require a new secure-by-design vision, where threats are addressed proactively and IoT devices learn to dynamically adapt to different threats. To this end, machine learning and software-defined networking will be key to provide both reconfigurability and intelligence to the IoT devices. In this paper, we first provide a taxonomy and survey the state of the art in IoT security research, and offer a roadmap of concrete research challenges related to the application of machine learning and software-defined networking to address existing and next-generation IoT security threats.

</details>

<details>

<summary>2018-06-11 23:24:11 - Accurate and Robust Neural Networks for Security Related Applications Exampled by Face Morphing Attacks</summary>

- *Clemens Seibold, Wojciech Samek, Anna Hilsmann, Peter Eisert*

- `1806.04265v1` - [abs](http://arxiv.org/abs/1806.04265v1) - [pdf](http://arxiv.org/pdf/1806.04265v1)

> Artificial neural networks tend to learn only what they need for a task. A manipulation of the training data can counter this phenomenon. In this paper, we study the effect of different alterations of the training data, which limit the amount and position of information that is available for the decision making. We analyze the accuracy and robustness against semantic and black box attacks on the networks that were trained on different training data modifications for the particular example of morphing attacks. A morphing attack is an attack on a biometric facial recognition system where the system is fooled to match two different individuals with the same synthetic face image. Such a synthetic image can be created by aligning and blending images of the two individuals that should be matched with this image.

</details>

<details>

<summary>2018-06-11 23:44:45 - Understanding Patch-Based Learning by Explaining Predictions</summary>

- *Christopher Anders, Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller*

- `1806.06926v1` - [abs](http://arxiv.org/abs/1806.06926v1) - [pdf](http://arxiv.org/pdf/1806.06926v1)

> Deep networks are able to learn highly predictive models of video data. Due to video length, a common strategy is to train them on small video snippets. We apply the deep Taylor / LRP technique to understand the deep network's classification decisions, and identify a "border effect": a tendency of the classifier to look mainly at the bordering frames of the input. This effect relates to the step size used to build the video snippet, which we can then tune in order to improve the classifier's accuracy without retraining the model. To our knowledge, this is the the first work to apply the deep Taylor / LRP technique on any video analyzing neural network.

</details>

<details>

<summary>2018-06-12 00:28:50 - The NES Music Database: A multi-instrumental dataset with expressive performance attributes</summary>

- *Chris Donahue, Huanru Henry Mao, Julian McAuley*

- `1806.04278v1` - [abs](http://arxiv.org/abs/1806.04278v1) - [pdf](http://arxiv.org/pdf/1806.04278v1)

> Existing research on music generation focuses on composition, but often ignores the expressive performance characteristics required for plausible renditions of resultant pieces. In this paper, we introduce the Nintendo Entertainment System Music Database (NES-MDB), a large corpus allowing for separate examination of the tasks of composition and performance. NES-MDB contains thousands of multi-instrumental songs composed for playback by the compositionally-constrained NES audio synthesizer. For each song, the dataset contains a musical score for four instrument voices as well as expressive attributes for the dynamics and timbre of each voice. Unlike datasets comprised of General MIDI files, NES-MDB includes all of the information needed to render exact acoustic performances of the original compositions. Alongside the dataset, we provide a tool that renders generated compositions as NES-style audio by emulating the device's audio processor. Additionally, we establish baselines for the tasks of composition, which consists of learning the semantics of composing for the NES synthesizer, and performance, which involves finding a mapping between a composition and realistic expressive attributes.

</details>

<details>

<summary>2018-06-12 03:59:47 - Sound Patch Generation for Vulnerabilities</summary>

- *Zhen Huang, David Lie*

- `1711.11136v2` - [abs](http://arxiv.org/abs/1711.11136v2) - [pdf](http://arxiv.org/pdf/1711.11136v2)

> Security vulnerabilities are among the most critical software defects in existence. As such, they require patches that are correct and quickly deployed. This motivates an automatic patch generation method that emphasizes both soundness and wide applicability. To address this challenge, we propose Senx, which uses three novel patch generation techniques to create patches for out-of-bounds read/write vulnerabilities. Senx uses symbolic execution to extract expressions from the source code of a target application to synthesize patches. To reduce the runtime overhead of patches, it uses loop cloning and access range analysis to analyze loops involved in these vulnerabilities and elevate patches outside of loops. For vulnerabilities that span multiple functions, Senx uses expression translation to translate expressions and place them in a function scope where all values are available to create the patch. This enables Senx to patch vulnerabilities with complex loops and interprocedural dependencies that previous semantics-based patch generation systems cannot handle.   We have implemented a prototype using this approach. Our evaluation shows that the patches generated by Senx successfully fix 76% of 42 real-world vulnerabilities from 11 applications including various tools or libraries for manipulating graphics/media files, a programming language interpreter, a relational database engine, a collection of programming tools for creating and managing binary programs, and a collection of basic file, shell, and text manipulation tools. All patches that Senx produces are sound, and Senx correctly aborts patch generations in cases where its analysis will fall short.

</details>

<details>

<summary>2018-06-12 04:27:00 - Learning Representations and Generative Models for 3D Point Clouds</summary>

- *Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, Leonidas Guibas*

- `1707.02392v3` - [abs](http://arxiv.org/abs/1707.02392v3) - [pdf](http://arxiv.org/pdf/1707.02392v3)

> Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.

</details>

<details>

<summary>2018-06-12 15:42:21 - Production-Driven Patch Generation and Validation</summary>

- *Thomas Durieux, Youssef Hamadi, Martin Monperrus*

- `1609.06848v2` - [abs](http://arxiv.org/abs/1609.06848v2) - [pdf](http://arxiv.org/pdf/1609.06848v2)

> We envision a world where the developer would receive each morning in her GitHub dashboard a list of potential patches that fix certain production failures. For this, we propose a novel program repair scheme, with the unique feature of being applicable to production directly. We present the design and implementation of a prototype system for Java, called Itzal, that performs patch generation for uncaught exceptions in production. We have performed two empirical experiments to validate our system: the first one on 34 failures from 14 different software applications, the second one on 16 seeded failures in 3 real open-source e-commerce applications for which we have set up a realistic user traffic. This validates the novel and disruptive idea of using program repair directly in production.

</details>

<details>

<summary>2018-06-12 15:49:14 - Deep Learning to Detect Redundant Method Comments</summary>

- *Annie Louis, Santanu Kumar Dash, Earl T. Barr, Charles Sutton*

- `1806.04616v1` - [abs](http://arxiv.org/abs/1806.04616v1) - [pdf](http://arxiv.org/pdf/1806.04616v1)

> Comments in software are critical for maintenance and reuse. But apart from prescriptive advice, there is little practical support or quantitative understanding of what makes a comment useful. In this paper, we introduce the task of identifying comments which are uninformative about the code they are meant to document. To address this problem, we introduce the notion of comment entailment from code, high entailment indicating that a comment's natural language semantics can be inferred directly from the code. Although not all entailed comments are low quality, comments that are too easily inferred, for example, comments that restate the code, are widely discouraged by authorities on software style. Based on this, we develop a tool called CRAIC which scores method-level comments for redundancy. Highly redundant comments can then be expanded or alternately removed by the developer. CRAIC uses deep language models to exploit large software corpora without requiring expensive manual annotations of entailment. We show that CRAIC can perform the comment entailment task with good agreement with human judgements. Our findings also have implications for documentation tools. For example, we find that common tags in Javadoc are at least two times more predictable from code than non-Javadoc sentences, suggesting that Javadoc tags are less informative than more free-form comments

</details>

<details>

<summary>2018-06-13 10:59:33 - fMRI Semantic Category Decoding using Linguistic Encoding of Word Embeddings</summary>

- *Subba Reddy Oota, Naresh Manwani, Bapi Raju S*

- `1806.05177v1` - [abs](http://arxiv.org/abs/1806.05177v1) - [pdf](http://arxiv.org/pdf/1806.05177v1)

> The dispute of how the human brain represents conceptual knowledge has been argued in many scientific fields. Brain imaging studies have shown that the spatial patterns of neural activation in the brain are correlated with thinking about different semantic categories of words (for example, tools, animals, and buildings) or when viewing the related pictures. In this paper, we present a computational model that learns to predict the neural activation captured in functional magnetic resonance imaging (fMRI) data of test words. Unlike the models with hand-crafted features that have been used in the literature, in this paper we propose a novel approach wherein decoding models are built with features extracted from popular linguistic encodings of Word2Vec, GloVe, Meta-Embeddings in conjunction with the empirical fMRI data associated with viewing several dozen concrete nouns. We compared these models with several other models that use word features extracted from FastText, Randomly-generated features, Mitchell's 25 features [1]. The experimental results show that the predicted fMRI images using Meta-Embeddings meet the state-of-the-art performance. Although models with features from GloVe and Word2Vec predict fMRI images similar to the state-of-the-art model, model with features from Meta-Embeddings predicts significantly better. The proposed scheme that uses popular linguistic encoding offers a simple and easy approach for semantic decoding from fMRI experiments.

</details>

<details>

<summary>2018-06-13 11:01:18 - Diachronic word embeddings and semantic shifts: a survey</summary>

- *Andrey Kutuzov, Lilja Øvrelid, Terrence Szymanski, Erik Velldal*

- `1806.03537v2` - [abs](http://arxiv.org/abs/1806.03537v2) - [pdf](http://arxiv.org/pdf/1806.03537v2)

> Recent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subfield of NLP, as well as prospects and possible applications.

</details>

<details>

<summary>2018-06-13 11:19:33 - Towards Semantically Enhanced Data Understanding</summary>

- *Markus Schröder, Christian Jilek, Jörn Hees, Andreas Dengel*

- `1806.04952v1` - [abs](http://arxiv.org/abs/1806.04952v1) - [pdf](http://arxiv.org/pdf/1806.04952v1)

> In the field of machine learning, data understanding is the practice of getting initial insights in unknown datasets. Such knowledge-intensive tasks require a lot of documentation, which is necessary for data scientists to grasp the meaning of the data. Usually, documentation is separate from the data in various external documents, diagrams, spreadsheets and tools which causes considerable look up overhead. Moreover, other supporting applications are not able to consume and utilize such unstructured data. That is why we propose a methodology that uses a single semantic model that interlinks data with its documentation. Hence, data scientists are able to directly look up the connected information about the data by simply following links. Equally, they can browse the documentation which always refers to the data. Furthermore, the model can be used by other approaches providing additional support, like searching, comparing, integrating or visualizing data. To showcase our approach we also demonstrate an early prototype.

</details>

<details>

<summary>2018-06-13 12:13:23 - On the evolution of technical lag in the npm package dependency network</summary>

- *Alexandre Decan, Tom Mens, Eleni Constantinou*

- `1806.01545v2` - [abs](http://arxiv.org/abs/1806.01545v2) - [pdf](http://arxiv.org/pdf/1806.01545v2)

> Software packages developed and distributed through package managers extensively depend on other packages. These dependencies are regularly updated, for example to add new features, resolve bugs or fix security issues. In order to take full advantage of the benefits of this type of reuse, developers should keep their dependencies up to date by relying on the latest releases. In practice, however, this is not always possible, and packages lag behind with respect to the latest version of their dependencies. This phenomenon is described as technical lag in the literature. In this paper, we perform an empirical study of technical lag in the npm dependency network by investigating its evolution for over 1.4M releases of 120K packages and 8M dependencies between these releases. We explore how technical lag increases over time, taking into account the release type and the use of package dependency constraints. We also discuss how technical lag can be reduced by relying on the semantic versioning policy.

</details>

<details>

<summary>2018-06-13 13:37:34 - Visually grounded cross-lingual keyword spotting in speech</summary>

- *Herman Kamper, Michael Roth*

- `1806.05030v1` - [abs](http://arxiv.org/abs/1806.05030v1) - [pdf](http://arxiv.org/pdf/1806.05030v1)

> Recent work considered how images paired with speech can be used as supervision for building speech systems when transcriptions are not available. We ask whether visual grounding can be used for cross-lingual keyword spotting: given a text keyword in one language, the task is to retrieve spoken utterances containing that keyword in another language. This could enable searching through speech in a low-resource language using text queries in a high-resource language. As a proof-of-concept, we use English speech with German queries: we use a German visual tagger to add keyword labels to each training image, and then train a neural network to map English speech to German keywords. Without seeing parallel speech-transcriptions or translations, the model achieves a precision at ten of 58%. We show that most erroneous retrievals contain equivalent or semantically relevant keywords; excluding these would improve P@10 to 91%.

</details>

<details>

<summary>2018-06-13 16:35:32 - Generative Neural Machine Translation</summary>

- *Harshil Shah, David Barber*

- `1806.05138v1` - [abs](http://arxiv.org/abs/1806.05138v1) - [pdf](http://arxiv.org/pdf/1806.05138v1)

> We introduce Generative Neural Machine Translation (GNMT), a latent variable architecture which is designed to model the semantics of the source and target sentences. We modify an encoder-decoder translation model by adding a latent variable as a language agnostic representation which is encouraged to learn the meaning of the sentence. GNMT achieves competitive BLEU scores on pure translation tasks, and is superior when there are missing words in the source sentence. We augment the model to facilitate multilingual translation and semi-supervised learning without adding parameters. This framework significantly reduces overfitting when there is limited paired data available, and is effective for translating between pairs of languages not seen during training.

</details>

<details>

<summary>2018-06-13 23:54:17 - Stress Test Evaluation for Natural Language Inference</summary>

- *Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, Graham Neubig*

- `1806.00692v3` - [abs](http://arxiv.org/abs/1806.00692v3) - [pdf](http://arxiv.org/pdf/1806.00692v3)

> Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed "stress tests" that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area.

</details>

<details>

<summary>2018-06-14 09:25:29 - Modeling Coherence for Neural Machine Translation with Dynamic and Topic Caches</summary>

- *Shaohui Kuang, Deyi Xiong, Weihua Luo, Guodong Zhou*

- `1711.11221v3` - [abs](http://arxiv.org/abs/1711.11221v3) - [pdf](http://arxiv.org/pdf/1711.11221v3)

> Sentences in a well-formed text are connected to each other via various links to form the cohesive structure of the text. Current neural machine translation (NMT) systems translate a text in a conventional sentence-by-sentence fashion, ignoring such cross-sentence links and dependencies. This may lead to generate an incoherent target text for a coherent source text. In order to handle this issue, we propose a cache-based approach to modeling coherence for neural machine translation by capturing contextual information either from recently translated sentences or the entire document. Particularly, we explore two types of caches: a dynamic cache, which stores words from the best translation hypotheses of preceding sentences, and a topic cache, which maintains a set of target-side topical words that are semantically related to the document to be translated. On this basis, we build a new layer to score target words in these two caches with a cache-based neural model. Here the estimated probabilities from the cache-based neural model are combined with NMT probabilities into the final word prediction probabilities via a gating mechanism. Finally, the proposed cache-based neural model is trained jointly with NMT system in an end-to-end manner. Experiments and analysis presented in this paper demonstrate that the proposed cache-based model achieves substantial improvements over several state-of-the-art SMT and NMT baselines.

</details>

<details>

<summary>2018-06-14 10:59:22 - Learning Cross-lingual Distributed Logical Representations for Semantic Parsing</summary>

- *Yanyan Zou, Wei Lu*

- `1806.05461v1` - [abs](http://arxiv.org/abs/1806.05461v1) - [pdf](http://arxiv.org/pdf/1806.05461v1)

> With the development of several multilingual datasets used for semantic parsing, recent research efforts have looked into the problem of learning semantic parsers in a multilingual setup. However, how to improve the performance of a monolingual semantic parser for a specific language by leveraging data annotated in different languages remains a research question that is under-explored. In this work, we present a study to show how learning distributed representations of the logical forms from data annotated in different languages can be used for improving the performance of a monolingual semantic parser. We extend two existing monolingual semantic parsers to incorporate such cross-lingual distributed logical representations as features. Experiments show that our proposed approach is able to yield improved semantic parsing results on the standard multilingual GeoQuery dataset.

</details>

<details>

<summary>2018-06-14 12:57:13 - Humor Detection in English-Hindi Code-Mixed Social Media Content : Corpus and Baseline System</summary>

- *Ankush Khandelwal, Sahil Swami, Syed S. Akhtar, Manish Shrivastava*

- `1806.05513v1` - [abs](http://arxiv.org/abs/1806.05513v1) - [pdf](http://arxiv.org/pdf/1806.05513v1)

> The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. With increase in the number of social media users, many multilingual speakers often interchange between languages while posting on social media which is called code-mixing. It introduces some challenges in the field of linguistic analysis of social media content (Barman et al., 2014), like spelling variations and non-grammatical structures in a sentence. Past researches include detecting puns in texts (Kao et al., 2016) and humor in one-lines (Mihalcea et al., 2010) in a single language, but with the tremendous amount of code-mixed data available online, there is a need to develop techniques which detects humor in code-mixed tweets. In this paper, we analyze the task of humor detection in texts and describe a freely available corpus containing English-Hindi code-mixed tweets annotated with humorous(H) or non-humorous(N) tags. We also tagged the words in the tweets with Language tags (English/Hindi/Others). Moreover, we describe the experiments carried out on the corpus and provide a baseline classification system which distinguishes between humorous and non-humorous texts.

</details>

<details>

<summary>2018-06-14 13:11:36 - SemAxis: A Lightweight Framework to Characterize Domain-Specific Word Semantics Beyond Sentiment</summary>

- *Jisun An, Haewoon Kwak, Yong-Yeol Ahn*

- `1806.05521v1` - [abs](http://arxiv.org/abs/1806.05521v1) - [pdf](http://arxiv.org/pdf/1806.05521v1)

> Because word semantics can substantially change across communities and contexts, capturing domain-specific word semantics is an important challenge. Here, we propose SEMAXIS, a simple yet powerful framework to characterize word semantics using many semantic axes in word- vector spaces beyond sentiment. We demonstrate that SEMAXIS can capture nuanced semantic representations in multiple online communities. We also show that, when the sentiment axis is examined, SEMAXIS outperforms the state-of-the-art approaches in building domain-specific sentiment lexicons.

</details>

<details>

<summary>2018-06-14 13:11:52 - Improved Density-Based Spatio--Textual Clustering on Social Media</summary>

- *Minh D. Nguyen, Won-Yong Shin*

- `1806.05522v1` - [abs](http://arxiv.org/abs/1806.05522v1) - [pdf](http://arxiv.org/pdf/1806.05522v1)

> DBSCAN may not be sufficient when the input data type is heterogeneous in terms of textual description. When we aim to discover clusters of geo-tagged records relevant to a particular point-of-interest (POI) on social media, examining only one type of input data (e.g., the tweets relevant to a POI) may draw an incomplete picture of clusters due to noisy regions. To overcome this problem, we introduce DBSTexC, a newly defined density-based clustering algorithm using spatio--textual information. We first characterize POI-relevant and POI-irrelevant tweets as the texts that include and do not include a POI name or its semantically coherent variations, respectively. By leveraging the proportion of POI-relevant and POI-irrelevant tweets, the proposed algorithm demonstrates much higher clustering performance than the DBSCAN case in terms of $\mathcal{F}_1$ score and its variants. While DBSTexC performs exactly as DBSCAN with the textually homogeneous inputs, it far outperforms DBSCAN with the textually heterogeneous inputs. Furthermore, to further improve the clustering quality by fully capturing the geographic distribution of tweets, we present fuzzy DBSTexC (F-DBSTexC), an extension of DBSTexC, which incorporates the notion of fuzzy clustering into the DBSTexC. We then demonstrate the robustness of F-DBSTexC via intensive experiments. The computational complexity of our algorithms is also analytically and numerically shown.

</details>

<details>

<summary>2018-06-14 14:53:53 - Semantic Image Retrieval by Uniting Deep Neural Networks and Cognitive Architectures</summary>

- *Alexey Potapov, Innokentii Zhdanov, Oleg Scherbakov, Nikolai Skorobogatko, Hugo Latapie, Enzo Fenoglio*

- `1806.06946v1` - [abs](http://arxiv.org/abs/1806.06946v1) - [pdf](http://arxiv.org/pdf/1806.06946v1)

> Image and video retrieval by their semantic content has been an important and challenging task for years, because it ultimately requires bridging the symbolic/subsymbolic gap. Recent successes in deep learning enabled detection of objects belonging to many classes greatly outperforming traditional computer vision techniques. However, deep learning solutions capable of executing retrieval queries are still not available. We propose a hybrid solution consisting of a deep neural network for object detection and a cognitive architecture for query execution. Specifically, we use YOLOv2 and OpenCog. Queries allowing the retrieval of video frames containing objects of specified classes and specified spatial arrangement are implemented.

</details>

<details>

<summary>2018-06-14 16:56:44 - Grounded Textual Entailment</summary>

- *Hoa Trong Vu, Claudio Greco, Aliia Erofeeva, Somayeh Jafaritazehjan, Guido Linders, Marc Tanti, Alberto Testoni, Raffaella Bernardi, Albert Gatt*

- `1806.05645v1` - [abs](http://arxiv.org/abs/1806.05645v1) - [pdf](http://arxiv.org/pdf/1806.05645v1)

> Capturing semantic relations between sentences, such as entailment, is a long-standing challenge for computational semantics. Logic-based models analyse entailment in terms of possible worlds (interpretations, or situations) where a premise P entails a hypothesis H iff in all worlds where P is true, H is also true. Statistical models view this relationship probabilistically, addressing it in terms of whether a human would likely infer H from P. In this paper, we wish to bridge these two perspectives, by arguing for a visually-grounded version of the Textual Entailment task. Specifically, we ask whether models can perform better if, in addition to P and H, there is also an image (corresponding to the relevant "world" or "situation"). We use a multimodal version of the SNLI dataset (Bowman et al., 2015) and we compare "blind" and visually-augmented models of textual entailment. We show that visual information is beneficial, but we also conduct an in-depth error analysis that reveals that current multimodal models are not performing "grounding" in an optimal fashion.

</details>

<details>

<summary>2018-06-14 17:25:43 - Abstract Meaning Representation for Multi-Document Summarization</summary>

- *Kexin Liao, Logan Lebanoff, Fei Liu*

- `1806.05655v1` - [abs](http://arxiv.org/abs/1806.05655v1) - [pdf](http://arxiv.org/pdf/1806.05655v1)

> Generating an abstract from a collection of documents is a desirable capability for many real-world applications. However, abstractive approaches to multi-document summarization have not been thoroughly investigated. This paper studies the feasibility of using Abstract Meaning Representation (AMR), a semantic representation of natural language grounded in linguistic theory, as a form of content representation. Our approach condenses source documents to a set of summary graphs following the AMR formalism. The summary graphs are then transformed to a set of summary sentences in a surface realization step. The framework is fully data-driven and flexible. Each component can be optimized independently using small-scale, in-domain training data. We perform experiments on benchmark summarization datasets and report promising results. We also describe opportunities and challenges for advancing this line of research.

</details>

<details>

<summary>2018-06-15 06:35:47 - Three dimensional Deep Learning approach for remote sensing image classification</summary>

- *Amina Ben Hamida, A Benoit, Patrick Lambert, Chokri Ben Amar*

- `1806.05824v1` - [abs](http://arxiv.org/abs/1806.05824v1) - [pdf](http://arxiv.org/pdf/1806.05824v1)

> Recently, a variety of approaches has been enriching the field of Remote Sensing (RS) image processing and analysis. Unfortunately, existing methods remain limited faced to the rich spatio-spectral content of today's large datasets. It would seem intriguing to resort to Deep Learning (DL) based approaches at this stage with regards to their ability to offer accurate semantic interpretation of the data. However, the specificity introduced by the coexistence of spectral and spatial content in the RS datasets widens the scope of the challenges presented to adapt DL methods to these contexts. Therefore, the aim of this paper is firstly to explore the performance of DL architectures for the RS hyperspectral dataset classification and secondly to introduce a new three-dimensional DL approach that enables a joint spectral and spatial information process. A set of three-dimensional schemes is proposed and evaluated. Experimental results based on well knownhyperspectral datasets demonstrate that the proposed method is able to achieve a better classification rate than state of the art methods with lower computational costs.

</details>

<details>

<summary>2018-06-15 07:35:42 - Oreo: Detection of Clones in the Twilight Zone</summary>

- *Vaibhav Saini, Farima Farmahinifarahani, Yadong Lu, Pierre Baldi, Cristina Lopes*

- `1806.05837v1` - [abs](http://arxiv.org/abs/1806.05837v1) - [pdf](http://arxiv.org/pdf/1806.05837v1)

> Source code clones are categorized into four types of increasing difficulty of detection, ranging from purely textual (Type-1) to purely semantic (Type-4). Most clone detectors reported in the literature work well up to Type-3, which accounts for syntactic differences. In between Type-3 and Type-4, however, there lies a spectrum of clones that, although still exhibiting some syntactic similarities, are extremely hard to detect -- the Twilight Zone. Most clone detectors reported in the literature fail to operate in this zone. We present Oreo, a novel approach to source code clone detection that not only detects Type-1 to Type-3 clones accurately, but is also capable of detecting harder-to-detect clones in the Twilight Zone. Oreo is built using a combination of machine learning, information retrieval, and software metrics. We evaluate the recall of Oreo on BigCloneBench, and perform manual evaluation for precision. Oreo has both high recall and precision. More importantly, it pushes the boundary in detection of clones with moderate to weak syntactic similarity in a scalable manner.

</details>

<details>

<summary>2018-06-15 08:10:12 - Semantic Variation in Online Communities of Practice</summary>

- *Marco Del Tredici, Raquel Fernández*

- `1806.05847v1` - [abs](http://arxiv.org/abs/1806.05847v1) - [pdf](http://arxiv.org/pdf/1806.05847v1)

> We introduce a framework for quantifying semantic variation of common words in Communities of Practice and in sets of topic-related communities. We show that while some meaning shifts are shared across related communities, others are community-specific, and therefore independent from the discussed topic. We propose such findings as evidence in favour of sociolinguistic theories of socially-driven semantic variation. Results are evaluated using an independent language modelling task. Furthermore, we investigate extralinguistic features and show that factors such as prominence and dissemination of words are related to semantic variation.

</details>

<details>

<summary>2018-06-15 10:18:15 - Hierarchical Novelty Detection for Visual Object Recognition</summary>

- *Kibok Lee, Kimin Lee, Kyle Min, Yuting Zhang, Jinwoo Shin, Honglak Lee*

- `1804.00722v2` - [abs](http://arxiv.org/abs/1804.00722v2) - [pdf](http://arxiv.org/pdf/1804.00722v2)

> Deep neural networks have achieved impressive success in large-scale visual object recognition tasks with a predefined set of classes. However, recognizing objects of novel classes unseen during training still remains challenging. The problem of detecting such novel classes has been addressed in the literature, but most prior works have focused on providing simple binary or regressive decisions, e.g., the output would be "known," "novel," or corresponding confidence intervals. In this paper, we study more informative novelty detection schemes based on a hierarchical classification framework. For an object of a novel class, we aim for finding its closest super class in the hierarchical taxonomy of known classes. To this end, we propose two different approaches termed top-down and flatten methods, and their combination as well. The essential ingredients of our methods are confidence-calibrated classifiers, data relabeling, and the leave-one-out strategy for modeling novel classes under the hierarchical taxonomy. Furthermore, our method can generate a hierarchical embedding that leads to improved generalized zero-shot learning performance in combination with other commonly-used semantic embeddings.

</details>

<details>

<summary>2018-06-15 13:14:53 - Anonymous Identity-Based Encryption with Identity Recovery</summary>

- *Xuecheng Ma, Xin Wang, Dongdai Lin*

- `1806.05943v1` - [abs](http://arxiv.org/abs/1806.05943v1) - [pdf](http://arxiv.org/pdf/1806.05943v1)

> Anonymous Identity-Based Encryption can protect privacy of the receiver. However, there are some situations that we need to recover the identity of the receiver, for example a dispute occurs or the privacy mechanism is abused. In this paper, we propose a new concept, referred to as Anonymous Identity-Based Encryption with Identity Recovery(AIBEIR), which is an anonymous IBE with identity recovery property. There is a party called the Identity Recovery Manager(IRM) who has a secret key to recover the identity from the ciphertext in our scheme. We construct it with an anonymous IBE and a special IBE which we call it testable IBE. In order to ensure the semantic security in the case where the identity recovery manager is an adversary, we define a stronger semantic security model in which the adversary is given the secret key of the identity recovery manager. To our knowledge, we propose the first AIBEIR scheme and prove the security in our defined model.

</details>

<details>

<summary>2018-06-15 13:35:19 - Controllable Semantic Image Inpainting</summary>

- *Jin Xu, Yee Whye Teh*

- `1806.05953v1` - [abs](http://arxiv.org/abs/1806.05953v1) - [pdf](http://arxiv.org/pdf/1806.05953v1)

> We develop a method for user-controllable semantic image inpainting: Given an arbitrary set of observed pixels, the unobserved pixels can be imputed in a user-controllable range of possibilities, each of which is semantically coherent and locally consistent with the observed pixels. We achieve this using a deep generative model bringing together: an encoder which can encode an arbitrary set of observed pixels, latent variables which are trained to represent disentangled factors of variations, and a bidirectional PixelCNN model. We experimentally demonstrate that our method can generate plausible inpainting results matching the user-specified semantics, but is still coherent with observed pixels. We justify our choices of architecture and training regime through more experiments.

</details>

<details>

<summary>2018-06-15 21:36:10 - Teaching Machines to Code: Neural Markup Generation with Visual Attention</summary>

- *Sumeet S. Singh*

- `1802.05415v2` - [abs](http://arxiv.org/abs/1802.05415v2) - [pdf](http://arxiv.org/pdf/1802.05415v2)

> We present a neural transducer model with visual attention that learns to generate LaTeX markup of a real-world math formula given its image. Applying sequence modeling and transduction techniques that have been very successful across modalities such as natural language, image, handwriting, speech and audio; we construct an image-to-markup model that learns to produce syntactically and semantically correct LaTeX markup code over 150 words long and achieves a BLEU score of 89%; improving upon the previous state-of-art for the Im2Latex problem. We also demonstrate with heat-map visualization how attention helps in interpreting the model and can pinpoint (detect and localize) symbols on the image accurately despite having been trained without any bounding box data.

</details>

<details>

<summary>2018-06-16 13:01:49 - Retrofitting Distributional Embeddings to Knowledge Graphs with Functional Relations</summary>

- *Benjamin J. Lengerich, Andrew L. Maas, Christopher Potts*

- `1708.00112v3` - [abs](http://arxiv.org/abs/1708.00112v3) - [pdf](http://arxiv.org/pdf/1708.00112v3)

> Knowledge graphs are a versatile framework to encode richly structured data relationships, but it can be challenging to combine these graphs with unstructured data. Methods for retrofitting pre-trained entity representations to the structure of a knowledge graph typically assume that entities are embedded in a connected space and that relations imply similarity. However, useful knowledge graphs often contain diverse entities and relations (with potentially disjoint underlying corpora) which do not accord with these assumptions. To overcome these limitations, we present Functional Retrofitting, a framework that generalizes current retrofitting methods by explicitly modeling pairwise relations. Our framework can directly incorporate a variety of pairwise penalty functions previously developed for knowledge graph completion. Further, it allows users to encode, learn, and extract information about relation semantics. We present both linear and neural instantiations of the framework. Functional Retrofitting significantly outperforms existing retrofitting methods on complex knowledge graphs and loses no accuracy on simpler graphs (in which relations do imply similarity). Finally, we demonstrate the utility of the framework by predicting new drug--disease treatment pairs in a large, complex health knowledge graph.

</details>

<details>

<summary>2018-06-16 16:59:27 - Extraction Of Technical Information From Normative Documents Using Automated Methods Based On Ontologies : Application To The Iso 15531 Mandate Standard - Methodology And First Results</summary>

- *A. F. Cutting-Decelle, A. Digeon, R. I. Young, J. L. Barraud, P. Lamboley*

- `1806.02242v2` - [abs](http://arxiv.org/abs/1806.02242v2) - [pdf](http://arxiv.org/pdf/1806.02242v2)

> Problems faced by international standardization bodies become more and more crucial as the number and the size of the standards they produce increase. Sometimes, also, the lack of coordination among the committees in charge of the development of standards may lead to overlaps, mistakes or incompatibilities in the documents. The aim of this study is to present a methodology enabling an automatic extraction of the technical concepts (terms) found in normative documents, through the use of semantic tools coming from the field of language processing. The first part of the paper provides a description of the standardization world, its structure, its way of working and the problems faced; we then introduce the concepts of semantic annotation, information extraction and the software tools available in this domain. The next section explains the concept of ontology and its potential use in the field of standardization. We propose here a methodology enabling the extraction of technical information from a given normative corpus, based on a semantic annotation process done according to reference ontologies. The application to the ISO 15531 MANDATE corpus provides a first use case of the methodology described in this paper. The paper ends with the description of the first experimental results produced by this approach, and with some issues and perspectives, notably its application to other standards and, or Technical Committees and the possibility offered to create pre-defined technical dictionaries of terms.

</details>

<details>

<summary>2018-06-17 08:44:55 - Incorporating Chinese Characters of Words for Lexical Sememe Prediction</summary>

- *Huiming Jin, Hao Zhu, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Fen Lin, Leyu Lin*

- `1806.06349v1` - [abs](http://arxiv.org/abs/1806.06349v1) - [pdf](http://arxiv.org/pdf/1806.06349v1)

> Sememes are minimum semantic units of concepts in human languages, such that each word sense is composed of one or multiple sememes. Words are usually manually annotated with their sememes by linguists, and form linguistic common-sense knowledge bases widely used in various NLP tasks. Recently, the lexical sememe prediction task has been introduced. It consists of automatically recommending sememes for words, which is expected to improve annotation efficiency and consistency. However, existing methods of lexical sememe prediction typically rely on the external context of words to represent the meaning, which usually fails to deal with low-frequency and out-of-vocabulary words. To address this issue for Chinese, we propose a novel framework to take advantage of both internal character information and external context information of words. We experiment on HowNet, a Chinese sememe knowledge base, and demonstrate that our framework outperforms state-of-the-art baselines by a large margin, and maintains a robust performance even for low-frequency words.

</details>

<details>

<summary>2018-06-17 14:13:14 - Mind the gap: quantification of incomplete ablation patterns after pulmonary vein isolation using minimum path search</summary>

- *Marta Nuñez-Garcia, Oscar Camara, Mark D. O'Neill, Reza Razavi, Henry Chubb, Constantine Butakoff*

- `1806.06387v1` - [abs](http://arxiv.org/abs/1806.06387v1) - [pdf](http://arxiv.org/pdf/1806.06387v1)

> Pulmonary vein isolation (PVI) is a common procedure for the treatment of atrial fibrillation (AF). A successful isolation produces a continuous lesion (scar) completely encircling the veins that stops activation waves from propagating to the atrial body. Unfortunately, the encircling lesion is often incomplete, becoming a combination of scar and gaps of healthy tissue. These gaps are potential causes of AF recurrence, which requires a redo of the isolation procedure. Late-gadolinium enhanced cardiac magnetic resonance (LGE-CMR) is a non-invasive method that may also be used to detect gaps, but it is currently a time-consuming process, prone to high inter-observer variability. In this paper, we present a method to semi-automatically identify and quantify ablation gaps. Gap quantification is performed through minimum path search in a graph where every node is a scar patch and the edges are the geodesic distances between patches. We propose the Relative Gap Measure (RGM) to estimate the percentage of gap around a vein, which is defined as the ratio of the overall gap length and the total length of the path that encircles the vein. Additionally, an advanced version of the RGM has been developed to integrate gap quantification estimates from different scar segmentation techniques into a single figure-of-merit. Population-based statistical and regional analysis of gap distribution was performed using a standardised parcellation of the left atrium. We have evaluated our method on synthetic and clinical data from 50 AF patients who underwent PVI with radiofrequency ablation. The population-based analysis concluded that the left superior PV is more prone to lesion gaps while the left inferior PV tends to have less gaps (p<0.05 in both cases), in the processed data. This type of information can be very useful for the optimization and objective assessment of PVI interventions.

</details>

<details>

<summary>2018-06-17 16:38:48 - Measuring Semantic Coherence of a Conversation</summary>

- *Svitlana Vakulenko, Maarten de Rijke, Michael Cochez, Vadim Savenkov, Axel Polleres*

- `1806.06411v1` - [abs](http://arxiv.org/abs/1806.06411v1) - [pdf](http://arxiv.org/pdf/1806.06411v1)

> Conversational systems have become increasingly popular as a way for humans to interact with computers. To be able to provide intelligent responses, conversational systems must correctly model the structure and semantics of a conversation. We introduce the task of measuring semantic (in)coherence in a conversation with respect to background knowledge, which relies on the identification of semantic relations between concepts introduced during a conversation. We propose and evaluate graph-based and machine learning-based approaches for measuring semantic coherence using knowledge graphs, their vector space embeddings and word embedding models, as sources of background knowledge. We demonstrate how these approaches are able to uncover different coherence patterns in conversations on the Ubuntu Dialogue Corpus.

</details>

<details>

<summary>2018-06-18 02:06:46 - Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment</summary>

- *Muhao Chen, Yingtao Tian, Kai-Wei Chang, Steven Skiena, Carlo Zaniolo*

- `1806.06478v1` - [abs](http://arxiv.org/abs/1806.06478v1) - [pdf](http://arxiv.org/pdf/1806.06478v1)

> Multilingual knowledge graph (KG) embeddings provide latent semantic representations of entities and structured knowledge with cross-lingual inferences, which benefit various knowledge-driven cross-lingual NLP tasks. However, precisely learning such cross-lingual inferences is usually hindered by the low coverage of entity alignment in many KGs. Since many multilingual KGs also provide literal descriptions of entities, in this paper, we introduce an embedding-based approach which leverages a weakly aligned multilingual KG for semi-supervised cross-lingual learning using entity descriptions. Our approach performs co-training of two embedding models, i.e. a multilingual KG embedding model and a multilingual literal description embedding model. The models are trained on a large Wikipedia-based trilingual dataset where most entity alignment is unknown to training. Experimental results show that the performance of the proposed approach on the entity alignment task improves at each iteration of co-training, and eventually reaches a stage at which it significantly surpasses previous approaches. We also show that our approach has promising abilities for zero-shot entity alignment, and cross-lingual KG completion.

</details>

<details>

<summary>2018-06-18 05:58:04 - A unified strategy for implementing curiosity and empowerment driven reinforcement learning</summary>

- *Ildefons Magrans de Abril, Ryota Kanai*

- `1806.06505v1` - [abs](http://arxiv.org/abs/1806.06505v1) - [pdf](http://arxiv.org/pdf/1806.06505v1)

> Although there are many approaches to implement intrinsically motivated artificial agents, the combined usage of multiple intrinsic drives remains still a relatively unexplored research area. Specifically, we hypothesize that a mechanism capable of quantifying and controlling the evolution of the information flow between the agent and the environment could be the fundamental component for implementing a higher degree of autonomy into artificial intelligent agents. This paper propose a unified strategy for implementing two semantically orthogonal intrinsic motivations: curiosity and empowerment. Curiosity reward informs the agent about the relevance of a recent agent action, whereas empowerment is implemented as the opposite information flow from the agent to the environment that quantifies the agent's potential of controlling its own future. We show that an additional homeostatic drive is derived from the curiosity reward, which generalizes and enhances the information gain of a classical curious/heterostatic reinforcement learning agent. We show how a shared internal model by curiosity and empowerment facilitates a more efficient training of the empowerment function. Finally, we discuss future directions for further leveraging the interplay between these two intrinsic rewards.

</details>

<details>

<summary>2018-06-18 09:28:52 - Learning from Outside the Viability Kernel: Why we Should Build Robots that can Fall with Grace</summary>

- *Steve Heim, Alexander Spröwitz*

- `1806.06569v1` - [abs](http://arxiv.org/abs/1806.06569v1) - [pdf](http://arxiv.org/pdf/1806.06569v1)

> Despite impressive results using reinforcement learning to solve complex problems from scratch, in robotics this has still been largely limited to model-based learning with very informative reward functions. One of the major challenges is that the reward landscape often has large patches with no gradient, making it difficult to sample gradients effectively. We show here that the robot state-initialization can have a more important effect on the reward landscape than is generally expected. In particular, we show the counter-intuitive benefit of including initializations that are unviable, in other words initializing in states that are doomed to fail.

</details>

<details>

<summary>2018-06-18 09:31:38 - SubGram: Extending Skip-gram Word Representation with Substrings</summary>

- *Tom Kocmi, Ondřej Bojar*

- `1806.06571v1` - [abs](http://arxiv.org/abs/1806.06571v1) - [pdf](http://arxiv.org/pdf/1806.06571v1)

> Skip-gram (word2vec) is a recent method for creating vector representations of words ("distributed word representations") using a neural network. The representation gained popularity in various areas of natural language processing, because it seems to capture syntactic and semantic information about words without any explicit supervision in this respect. We propose SubGram, a refinement of the Skip-gram model to consider also the word structure during the training process, achieving large gains on the Skip-gram original test set.

</details>

<details>

<summary>2018-06-18 15:19:04 - Modularity Matters: Learning Invariant Relational Reasoning Tasks</summary>

- *Jason Jo, Vikas Verma, Yoshua Bengio*

- `1806.06765v1` - [abs](http://arxiv.org/abs/1806.06765v1) - [pdf](http://arxiv.org/pdf/1806.06765v1)

> We focus on two supervised visual reasoning tasks whose labels encode a semantic relational rule between two or more objects in an image: the MNIST Parity task and the colorized Pentomino task. The objects in the images undergo random translation, scaling, rotation and coloring transformations. Thus these tasks involve invariant relational reasoning. We report uneven performance of various deep CNN models on these two tasks. For the MNIST Parity task, we report that the VGG19 model soundly outperforms a family of ResNet models. Moreover, the family of ResNet models exhibits a general sensitivity to random initialization for the MNIST Parity task. For the colorized Pentomino task, now both the VGG19 and ResNet models exhibit sluggish optimization and very poor test generalization, hovering around 30% test error. The CNN we tested all learn hierarchies of fully distributed features and thus encode the distributed representation prior. We are motivated by a hypothesis from cognitive neuroscience which posits that the human visual cortex is modularized, and this allows the visual cortex to learn higher order invariances. To this end, we consider a modularized variant of the ResNet model, referred to as a Residual Mixture Network (ResMixNet) which employs a mixture-of-experts architecture to interleave distributed representations with more specialized, modular representations. We show that very shallow ResMixNets are capable of learning each of the two tasks well, attaining less than 2% and 1% test error on the MNIST Parity and the colorized Pentomino tasks respectively. Most importantly, the ResMixNet models are extremely parameter efficient: generalizing better than various non-modular CNNs that have over 10x the number of parameters. These experimental results support the hypothesis that modularity is a robust prior for learning invariant relational reasoning.

</details>

<details>

<summary>2018-06-18 18:13:21 - Combining Word Feature Vector Method with the Convolutional Neural Network for Slot Filling in Spoken Language Understanding</summary>

- *Ruixi Lin*

- `1806.06874v1` - [abs](http://arxiv.org/abs/1806.06874v1) - [pdf](http://arxiv.org/pdf/1806.06874v1)

> Slot filling is an important problem in Spoken Language Understanding (SLU) and Natural Language Processing (NLP), which involves identifying a user's intent and assigning a semantic concept to each word in a sentence. This paper presents a word feature vector method and combines it into the convolutional neural network (CNN). We consider 18 word features and each word feature is constructed by merging similar word labels. By introducing the concept of external library, we propose a feature set approach that is beneficial for building the relationship between a word from the training dataset and the feature. Computational results are reported using the ATIS dataset and comparisons with traditional CNN as well as bi-directional sequential CNN are also presented.

</details>

<details>

<summary>2018-06-19 15:21:37 - Dynamic Multi-Level Multi-Task Learning for Sentence Simplification</summary>

- *Han Guo, Ramakanth Pasunuru, Mohit Bansal*

- `1806.07304v1` - [abs](http://arxiv.org/abs/1806.07304v1) - [pdf](http://arxiv.org/pdf/1806.07304v1)

> Sentence simplification aims to improve readability and understandability, based on several operations such as splitting, deletion, and paraphrasing. However, a valid simplified sentence should also be logically entailed by its input sentence. In this work, we first present a strong pointer-copy mechanism based sequence-to-sequence sentence simplification model, and then improve its entailment and paraphrasing capabilities via multi-task learning with related auxiliary tasks of entailment and paraphrase generation. Moreover, we propose a novel 'multi-level' layered soft sharing approach where each auxiliary task shares different (higher versus lower) level layers of the sentence simplification model, depending on the task's semantic versus lexico-syntactic nature. We also introduce a novel multi-armed bandit based training approach that dynamically learns how to effectively switch across tasks during multi-task learning. Experiments on multiple popular datasets demonstrate that our model outperforms competitive simplification systems in SARI and FKGL automatic metrics, and human evaluation. Further, we present several ablation analyses on alternative layer sharing methods, soft versus hard sharing, dynamic multi-armed bandit sampling approaches, and our model's learned entailment and paraphrasing skills.

</details>

<details>

<summary>2018-06-19 21:06:32 - Exploring the Semantic Content of Unsupervised Graph Embeddings: An Empirical Study</summary>

- *Stephen Bonner, Ibad Kureshi, John Brennan, Georgios Theodoropoulos, Andrew Stephen McGough, Boguslaw Obara*

- `1806.07464v1` - [abs](http://arxiv.org/abs/1806.07464v1) - [pdf](http://arxiv.org/pdf/1806.07464v1)

> Graph embeddings have become a key and widely used technique within the field of graph mining, proving to be successful across a broad range of domains including social, citation, transportation and biological. Graph embedding techniques aim to automatically create a low-dimensional representation of a given graph, which captures key structural elements in the resulting embedding space. However, to date, there has been little work exploring exactly which topological structures are being learned in the embeddings process. In this paper, we investigate if graph embeddings are approximating something analogous with traditional vertex level graph features. If such a relationship can be found, it could be used to provide a theoretical insight into how graph embedding approaches function. We perform this investigation by predicting known topological features, using supervised and unsupervised methods, directly from the embedding space. If a mapping between the embeddings and topological features can be found, then we argue that the structural information encapsulated by the features is represented in the embedding space. To explore this, we present extensive experimental evaluation from five state-of-the-art unsupervised graph embedding techniques, across a range of empirical graph datasets, measuring a selection of topological features. We demonstrate that several topological features are indeed being approximated by the embedding space, allowing key insight into how graph embeddings create good representations.

</details>

<details>

<summary>2018-06-20 12:56:54 - Word Tagging with Foundational Ontology Classes: Extending the WordNet-DOLCE Mapping to Verbs</summary>

- *Vivian S. Silva, André Freitas, Siegfried Handschuh*

- `1806.07699v1` - [abs](http://arxiv.org/abs/1806.07699v1) - [pdf](http://arxiv.org/pdf/1806.07699v1)

> Semantic annotation is fundamental to deal with large-scale lexical information, mapping the information to an enumerable set of categories over which rules and algorithms can be applied, and foundational ontology classes can be used as a formal set of categories for such tasks. A previous alignment between WordNet noun synsets and DOLCE provided a starting point for ontology-based annotation, but in NLP tasks verbs are also of substantial importance. This work presents an extension to the WordNet-DOLCE noun mapping, aligning verbs according to their links to nouns denoting perdurants, transferring to the verb the DOLCE class assigned to the noun that best represents that verb's occurrence. To evaluate the usefulness of this resource, we implemented a foundational ontology-based semantic annotation framework, that assigns a high-level foundational category to each word or phrase in a text, and compared it to a similar annotation tool, obtaining an increase of 9.05% in accuracy.

</details>

<details>

<summary>2018-06-20 13:01:56 - Formal Specification & Analysis of Autonomous Systems in PrCCSL/Simulink Design Verifier</summary>

- *Eun-Young Kang, Li Huang*

- `1806.07702v1` - [abs](http://arxiv.org/abs/1806.07702v1) - [pdf](http://arxiv.org/pdf/1806.07702v1)

> Modeling and analysis of timing constraints is crucial in automotive systems. EAST-ADL is a domain specific architectural language dedicated to safety-critical automotive embedded system design. In most cases, a bounded number of violations of timing constraints in systems would not lead to system failures when the results of the violations are negligible, called Weakly-Hard (WH). We have previously specified EAST-ADL timing constraints in Clock Constraint Specification Language (CCSL) and transformed timed behaviors in CCSL into formal models amenable to model checking. Previous work is extended in this paper by including support for probabilistic analysis of timing constraints in the context of WH: Probabilistic extension of CCSL, called PrCCSL, is defined and the EAST-ADL timing constraints with stochastic properties are specified in PrCCSL. The semantics of the extended constraints in PrCCSL is translated into Proof Objective Models that can be verified using SIMULINK DESIGN VERIFIER. Furthermore, a set of mapping rules is proposed to facilitate guarantee of translation. Our approach is demonstrated on an autonomous traffic sign recognition vehicle case study.

</details>

<details>

<summary>2018-06-20 13:14:12 - Categorization of Semantic Roles for Dictionary Definitions</summary>

- *Vivian S. Silva, Siegfried Handschuh, André Freitas*

- `1806.07711v1` - [abs](http://arxiv.org/abs/1806.07711v1) - [pdf](http://arxiv.org/pdf/1806.07711v1)

> Understanding the semantic relationships between terms is a fundamental task in natural language processing applications. While structured resources that can express those relationships in a formal way, such as ontologies, are still scarce, a large number of linguistic resources gathering dictionary definitions is becoming available, but understanding the semantic structure of natural language definitions is fundamental to make them useful in semantic interpretation tasks. Based on an analysis of a subset of WordNet's glosses, we propose a set of semantic roles that compose the semantic structure of a dictionary definition, and show how they are related to the definition's syntactic configuration, identifying patterns that can be used in the development of information extraction frameworks and semantic models.

</details>

<details>

<summary>2018-06-20 13:30:51 - Semantic Relation Classification: Task Formalisation and Refinement</summary>

- *Vivian S. Silva, Manuela Hürliman, Brian Davis, Siegfried Handschuh, André Freitas*

- `1806.07721v1` - [abs](http://arxiv.org/abs/1806.07721v1) - [pdf](http://arxiv.org/pdf/1806.07721v1)

> The identification of semantic relations between terms within texts is a fundamental task in Natural Language Processing which can support applications requiring a lightweight semantic interpretation model. Currently, semantic relation classification concentrates on relations which are evaluated over open-domain data. This work provides a critique on the set of abstract relations used for semantic relation classification with regard to their ability to express relationships between terms which are found in a domain-specific corpora. Based on this analysis, this work proposes an alternative semantic relation model based on reusing and extending the set of abstract relations present in the DOLCE ontology. The resulting set of relations is well grounded, allows to capture a wide range of relations and could thus be used as a foundation for automatic classification of semantic relations.

</details>

<details>

<summary>2018-06-20 13:50:46 - Building a Knowledge Graph from Natural Language Definitions for Interpretable Text Entailment Recognition</summary>

- *Vivian S. Silva, André Freitas, Siegfried Handschuh*

- `1806.07731v1` - [abs](http://arxiv.org/abs/1806.07731v1) - [pdf](http://arxiv.org/pdf/1806.07731v1)

> Natural language definitions of terms can serve as a rich source of knowledge, but structuring them into a comprehensible semantic model is essential to enable them to be used in semantic interpretation tasks. We propose a method and provide a set of tools for automatically building a graph world knowledge base from natural language definitions. Adopting a conceptual model composed of a set of semantic roles for dictionary definitions, we trained a classifier for automatically labeling definitions, preparing the data to be later converted to a graph representation. WordNetGraph, a knowledge graph built out of noun and verb WordNet definitions according to this methodology, was successfully used in an interpretable text entailment recognition approach which uses paths in this graph to provide clear justifications for entailment decisions.

</details>

<details>

<summary>2018-06-20 16:29:01 - StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing</summary>

- *Pengcheng Yin, Chunting Zhou, Junxian He, Graham Neubig*

- `1806.07832v1` - [abs](http://arxiv.org/abs/1806.07832v1) - [pdf](http://arxiv.org/pdf/1806.07832v1)

> Semantic parsing is the task of transducing natural language (NL) utterances into formal meaning representations (MRs), commonly represented as tree structures. Annotating NL utterances with their corresponding MRs is expensive and time-consuming, and thus the limited availability of labeled data often becomes the bottleneck of data-driven, supervised models. We introduce StructVAE, a variational auto-encoding model for semisupervised semantic parsing, which learns both from limited amounts of parallel data, and readily-available unlabeled NL utterances. StructVAE models latent MRs not observed in the unlabeled data as tree-structured latent variables. Experiments on semantic parsing on the ATIS domain and Python code generation show that with extra unlabeled data, StructVAE outperforms strong supervised models.

</details>

<details>

<summary>2018-06-20 16:39:26 - The Natural Language Decathlon: Multitask Learning as Question Answering</summary>

- *Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, Richard Socher*

- `1806.08730v1` - [abs](http://arxiv.org/abs/1806.08730v1) - [pdf](http://arxiv.org/pdf/1806.08730v1)

> Deep learning has improved performance on many natural language processing (NLP) tasks individually. However, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task. We introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks: question answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, zero-shot relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution. We cast all tasks as question answering over a context. Furthermore, we present a new Multitask Question Answering Network (MQAN) jointly learns all tasks in decaNLP without any task-specific modules or parameters in the multitask setting. MQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification. We demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and performance further improves with an anti-curriculum training strategy. Though designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. We also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.

</details>

<details>

<summary>2018-06-20 20:29:24 - Ontology Alignment in the Biomedical Domain Using Entity Definitions and Context</summary>

- *Lucy Lu Wang, Chandra Bhagavatula, Mark Neumann, Kyle Lo, Chris Wilhelm, Waleed Ammar*

- `1806.07976v1` - [abs](http://arxiv.org/abs/1806.07976v1) - [pdf](http://arxiv.org/pdf/1806.07976v1)

> Ontology alignment is the task of identifying semantically equivalent entities from two given ontologies. Different ontologies have different representations of the same entity, resulting in a need to de-duplicate entities when merging ontologies. We propose a method for enriching entities in an ontology with external definition and context information, and use this additional information for ontology alignment. We develop a neural architecture capable of encoding the additional information when available, and show that the addition of external data results in an F1-score of 0.69 on the Ontology Alignment Evaluation Initiative (OAEI) largebio SNOMED-NCI subtask, comparable with the entity-level matchers in a SOTA system.

</details>

<details>

<summary>2018-06-20 20:37:28 - The Corpus Replication Task</summary>

- *Tobias Eichinger*

- `1806.07978v1` - [abs](http://arxiv.org/abs/1806.07978v1) - [pdf](http://arxiv.org/pdf/1806.07978v1)

> In the field of Natural Language Processing (NLP), we revisit the well-known word embedding algorithm word2vec. Word embeddings identify words by vectors such that the words' distributional similarity is captured. Unexpectedly, besides semantic similarity even relational similarity has been shown to be captured in word embeddings generated by word2vec, whence two questions arise. Firstly, which kind of relations are representable in continuous space and secondly, how are relations built. In order to tackle these questions we propose a bottom-up point of view. We call generating input text for which word2vec outputs target relations solving the Corpus Replication Task. Deeming generalizations of this approach to any set of relations possible, we expect solving of the Corpus Replication Task to provide partial answers to the questions.

</details>

<details>

<summary>2018-06-20 23:01:05 - Interpreting Embedding Models of Knowledge Bases: A Pedagogical Approach</summary>

- *Arthur Colombini Gusmão, Alvaro Henrique Chaim Correia, Glauber De Bona, Fabio Gagliardi Cozman*

- `1806.09504v1` - [abs](http://arxiv.org/abs/1806.09504v1) - [pdf](http://arxiv.org/pdf/1806.09504v1)

> Knowledge bases are employed in a variety of applications from natural language processing to semantic web search; alas, in practice their usefulness is hurt by their incompleteness. Embedding models attain state-of-the-art accuracy in knowledge base completion, but their predictions are notoriously hard to interpret. In this paper, we adapt "pedagogical approaches" (from the literature on neural networks) so as to interpret embedding models by extracting weighted Horn rules from them. We show how pedagogical approaches have to be adapted to take upon the large-scale relational aspects of knowledge bases and show experimentally their strengths and weaknesses.

</details>

<details>

<summary>2018-06-21 11:55:21 - Nearly Zero-Shot Learning for Semantic Decoding in Spoken Dialogue Systems</summary>

- *Lina M. Rojas-Barahona, Stefan Ultes, Pawel Budzianowski, Iñigo Casanueva, Milica Gasic, Bo-Hsiang Tseng, Steve Young*

- `1806.05484v2` - [abs](http://arxiv.org/abs/1806.05484v2) - [pdf](http://arxiv.org/pdf/1806.05484v2)

> This paper presents two ways of dealing with scarce data in semantic decoding using N-Best speech recognition hypotheses. First, we learn features by using a deep learning architecture in which the weights for the unknown and known categories are jointly optimised. Second, an unsupervised method is used for further tuning the weights. Sharing weights injects prior knowledge to unknown categories. The unsupervised tuning (i.e. the risk minimisation) improves the F-Measure when recognising nearly zero-shot data on the DSTC3 corpus. This unsupervised method can be applied subject to two assumptions: the rank of the class marginal is assumed to be known and the class-conditional scores of the classifier are assumed to follow a Gaussian distribution.

</details>

<details>

<summary>2018-06-21 12:35:23 - Metadata Enrichment of Multi-Disciplinary Digital Library: A Semantic-based Approach</summary>

- *Hussein T. Al-Natsheh, Lucie Martinet, Fabrice Muhlenbach, Fabien Rico, Djamel A. Zighed*

- `1806.08202v1` - [abs](http://arxiv.org/abs/1806.08202v1) - [pdf](http://arxiv.org/pdf/1806.08202v1)

> In the scientific digital libraries, some papers from different research communities can be described by community-dependent keywords even if they share a semantically similar topic. Articles that are not tagged with enough keyword variations are poorly indexed in any information retrieval system which limits potentially fruitful exchanges between scientific disciplines. In this paper, we introduce a novel experimentally designed pipeline for multi-label semantic-based tagging developed for open-access metadata digital libraries. The approach starts by learning from a standard scientific categorization and a sample of topic tagged articles to find semantically relevant articles and enrich its metadata accordingly. Our proposed pipeline aims to enable researchers reaching articles from various disciplines that tend to use different terminologies. It allows retrieving semantically relevant articles given a limited known variation of search terms. In addition to achieving an accuracy that is higher than an expanded query based method using a topic synonym set extracted from a semantic network, our experiments also show a higher computational scalability versus other comparable techniques. We created a new benchmark extracted from the open-access metadata of a scientific digital library and published it along with the experiment code to allow further research in the topic.

</details>

<details>

<summary>2018-06-21 18:59:05 - Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations</summary>

- *Ting Chen, Martin Renqiang Min, Yizhou Sun*

- `1806.09464v1` - [abs](http://arxiv.org/abs/1806.09464v1) - [pdf](http://arxiv.org/pdf/1806.09464v1)

> Conventional embedding methods directly associate each symbol with a continuous embedding vector, which is equivalent to applying a linear transformation based on a "one-hot" encoding of the discrete symbols. Despite its simplicity, such approach yields the number of parameters that grows linearly with the vocabulary size and can lead to overfitting. In this work, we propose a much more compact K-way D-dimensional discrete encoding scheme to replace the "one-hot" encoding. In the proposed "KD encoding", each symbol is represented by a $D$-dimensional code with a cardinality of $K$, and the final symbol embedding vector is generated by composing the code embedding vectors. To end-to-end learn semantically meaningful codes, we derive a relaxed discrete optimization approach based on stochastic gradient descent, which can be generally applied to any differentiable computational graph with an embedding layer. In our experiments with various applications from natural language processing to graph convolutional networks, the total size of the embedding layer can be reduced up to 98\% while achieving similar or better performance.

</details>

<details>

<summary>2018-06-22 01:58:44 - Paragraph-based complex networks: application to document classification and authenticity verification</summary>

- *Henrique F. de Arruda, Vanessa Q. Marinho, Luciano da F. Costa, Diego R. Amancio*

- `1806.08467v1` - [abs](http://arxiv.org/abs/1806.08467v1) - [pdf](http://arxiv.org/pdf/1806.08467v1)

> With the increasing number of texts made available on the Internet, many applications have relied on text mining tools to tackle a diversity of problems. A relevant model to represent texts is the so-called word adjacency (co-occurrence) representation, which is known to capture mainly syntactical features of texts.In this study, we introduce a novel network representation that considers the semantic similarity between paragraphs. Two main properties of paragraph networks are considered: (i) their ability to incorporate characteristics that can discriminate real from artificial, shuffled manuscripts and (ii) their ability to capture syntactical and semantic textual features. Our results revealed that real texts are organized into communities, which turned out to be an important feature for discriminating them from artificial texts. Interestingly, we have also found that, differently from traditional co-occurrence networks, the adopted representation is able to capture semantic features. Additionally, the proposed framework was employed to analyze the Voynich manuscript, which was found to be compatible with texts written in natural languages. Taken together, our findings suggest that the proposed methodology can be combined with traditional network models to improve text classification tasks.

</details>

<details>

<summary>2018-06-22 12:40:23 - Recognizing Challenging Handwritten Annotations with Fully Convolutional Networks</summary>

- *Andreas Kölsch, Ashutosh Mishra, Saurabh Varshneya, Muhammad Zeshan Afzal, Marcus Liwicki*

- `1804.00236v2` - [abs](http://arxiv.org/abs/1804.00236v2) - [pdf](http://arxiv.org/pdf/1804.00236v2)

> This paper introduces a very challenging dataset of historic German documents and evaluates Fully Convolutional Neural Network (FCNN) based methods to locate handwritten annotations of any kind in these documents. The handwritten annotations can appear in form of underlines and text by using various writing instruments, e.g., the use of pencils makes the data more challenging. We train and evaluate various end-to-end semantic segmentation approaches and report the results. The task is to classify the pixels of documents into two classes: background and handwritten annotation. The best model achieves a mean Intersection over Union (IoU) score of 95.6% on the test documents of the presented dataset. We also present a comparison of different strategies used for data augmentation and training on our presented dataset. For evaluation, we use the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout Analysis for Challenging Medieval Manuscripts.

</details>

<details>

<summary>2018-06-23 10:12:38 - A Recursive PLS (Partial Least Squares) based Approach for Enterprise Threat Management</summary>

- *Janardan Misra*

- `1806.08941v1` - [abs](http://arxiv.org/abs/1806.08941v1) - [pdf](http://arxiv.org/pdf/1806.08941v1)

> Most of the existing solutions to enterprise threat management are preventive approaches prescribing means to prevent policy violations with varying degrees of success. In this paper we consider the complementary scenario where a number of security violations have already occurred, or security threats, or vulnerabilities have been reported and a security administrator needs to generate optimal response to these security events. We present a principled approach to study and model the human expertise in responding to the emergent threats owing to these security events. A recursive Partial Least Squares based adaptive learning model is defined using a factorial analysis of the security events together with a method for estimating the effect of global context dependent semantic information used by the security administrators. Presented model is theoretically optimal and operationally recursive in nature to deal with the set of security events being generated continuously. We discuss the underlying challenges and ways in which the model could be operationalized in centralized versus decentralized, and real-time versus batch processing modes.

</details>

<details>

<summary>2018-06-24 04:18:55 - Computational Complexity of Observing Evolution in Artificial-Life Forms</summary>

- *Janardan Misra*

- `1808.03387v1` - [abs](http://arxiv.org/abs/1808.03387v1) - [pdf](http://arxiv.org/pdf/1808.03387v1)

> Observations are an essential component of the simulation based studies on artificial-evolutionary systems (AES) by which entities are identified and their behavior is observed to uncover higher-level "emergent" phenomena. Because of the heterogeneity of AES models and implicit nature of observations, precise characterization of the observation process, independent of the underlying micro-level reaction semantics of the model, is a difficult problem. Building upon the multiset based algebraic framework to characterize state-space trajectory of AES model simulations, we estimate bounds on computational resource requirements of the process of automatically discovering life-like evolutionary behavior in AES models during simulations. For illustration, we consider the case of Langton's Cellular Automata model and characterize the worst case computational complexity bounds for identifying entity and population level reproduction.

</details>

<details>

<summary>2018-06-24 08:36:23 - One-shot Learning for Question-Answering in Gaokao History Challenge</summary>

- *Zhuosheng Zhang, Hai Zhao*

- `1806.09105v1` - [abs](http://arxiv.org/abs/1806.09105v1) - [pdf](http://arxiv.org/pdf/1806.09105v1)

> Answering questions from university admission exams (Gaokao in Chinese) is a challenging AI task since it requires effective representation to capture complicated semantic relations between questions and answers. In this work, we propose a hybrid neural model for deep question-answering task from history examinations. Our model employs a cooperative gated neural network to retrieve answers with the assistance of extra labels given by a neural turing machine labeler. Empirical study shows that the labeler works well with only a small training dataset and the gated mechanism is good at fetching the semantic representation of lengthy answers. Experiments on question answering demonstrate the proposed model obtains substantial performance gains over various neural model baselines in terms of multiple evaluation metrics.

</details>

<details>

<summary>2018-06-24 13:55:48 - A Provably Correct Algorithm for Deep Learning that Actually Works</summary>

- *Eran Malach, Shai Shalev-Shwartz*

- `1803.09522v2` - [abs](http://arxiv.org/abs/1803.09522v2) - [pdf](http://arxiv.org/pdf/1803.09522v2)

> We describe a layer-by-layer algorithm for training deep convolutional networks, where each step involves gradient updates for a two layer network followed by a simple clustering algorithm. Our algorithm stems from a deep generative model that generates mages level by level, where lower resolution images correspond to latent semantic classes. We analyze the convergence rate of our algorithm assuming that the data is indeed generated according to this model (as well as additional assumptions). While we do not pretend to claim that the assumptions are realistic for natural images, we do believe that they capture some true properties of real data. Furthermore, we show that our algorithm actually works in practice (on the CIFAR dataset), achieving results in the same ballpark as that of vanilla convolutional neural networks that are being trained by stochastic gradient descent. Finally, our proof techniques may be of independent interest.

</details>

<details>

<summary>2018-06-24 16:40:07 - Dilated Temporal Fully-Convolutional Network for Semantic Segmentation of Motion Capture Data</summary>

- *Noshaba Cheema, Somayeh Hosseini, Janis Sprenger, Erik Herrmann, Han Du, Klaus Fischer, Philipp Slusallek*

- `1806.09174v1` - [abs](http://arxiv.org/abs/1806.09174v1) - [pdf](http://arxiv.org/pdf/1806.09174v1)

> Semantic segmentation of motion capture sequences plays a key part in many data-driven motion synthesis frameworks. It is a preprocessing step in which long recordings of motion capture sequences are partitioned into smaller segments. Afterwards, additional methods like statistical modeling can be applied to each group of structurally-similar segments to learn an abstract motion manifold. The segmentation task however often remains a manual task, which increases the effort and cost of generating large-scale motion databases. We therefore propose an automatic framework for semantic segmentation of motion capture data using a dilated temporal fully-convolutional network. Our model outperforms a state-of-the-art model in action segmentation, as well as three networks for sequence modeling. We further show our model is robust against high noisy training labels.

</details>

<details>

<summary>2018-06-24 18:11:02 - Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations</summary>

- *Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee, Lin-shan Lee*

- `1804.02812v2` - [abs](http://arxiv.org/abs/1804.02812v2) - [pdf](http://arxiv.org/pdf/1804.02812v2)

> Recently, cycle-consistent adversarial network (Cycle-GAN) has been successfully applied to voice conversion to a different speaker without parallel data, although in those approaches an individual model is needed for each target speaker. In this paper, we propose an adversarial learning framework for voice conversion, with which a single model can be trained to convert the voice to many different speakers, all without parallel data, by separating the speaker characteristics from the linguistic content in speech signals. An autoencoder is first trained to extract speaker-independent latent representations and speaker embedding separately using another auxiliary speaker classifier to regularize the latent representation. The decoder then takes the speaker-independent latent representation and the target speaker embedding as the input to generate the voice of the target speaker with the linguistic content of the source utterance. The quality of decoder output is further improved by patching with the residual signal produced by another pair of generator and discriminator. A target speaker set size of 20 was tested in the preliminary experiments, and very good voice quality was obtained. Conventional voice conversion metrics are reported. We also show that the speaker information has been properly reduced from the latent representations.

</details>

<details>

<summary>2018-06-25 08:57:20 - Proceedings of the 1st International Workshop on Methods and Tools for Rigorous System Design</summary>

- *Simon Bliudze, Saddek Bensalem*

- `1806.09330v1` - [abs](http://arxiv.org/abs/1806.09330v1) - [pdf](http://arxiv.org/pdf/1806.09330v1)

> This volume contains the proceedings of the 1st International Workshop on Methods and Tools for Rigorous System Design (MeTRiD 2018), held on the 15th of April, 2018 in Thessaloniki, Greece as part of ETAPS 2018, the European Joint Conferences on Theory and Practice of Software.   The term "Rigorous System Design" (RSD) denotes the design approach that is based on a formal, accountable and iterative process for deriving trustworthy and optimised implementations from models of application software, its execution platform and its external environment. Ideally, a system implementation is derived from a set of appropriate high-level models by applying a sequence of semantics-preserving transformations.   The ambition of MeTRiD is to promote the use of formal methods, in general, and the RSD approach, in particular, in the industrial applications and, reciprocally, bring the attention of the formal methods researchers to such industrial applications in order to develop realistic case-studies and guide the evolution of tools. Striving towards this ambitious goal, we have solicited contributions of three types:   - regular papers, presenting original research   - case study papers, reporting the evaluation of existing modelling, analysis, transformation and code generation formalisms and tools on realistic examples of significant size   - tool papers, describing new tool prototypes supporting the RSD flow and enhancements of existing ones   We have received 13 submissions (7 regular, 4 tool and 2 case study papers), whereof 8 have been accepted for presentation at the workshop:   - 5 regular papers   - 2 tool papers   - 1 case study paper   In this volume, these papers are complemented by an invited paper by Joseph Sifakis.

</details>

<details>

<summary>2018-06-25 13:45:57 - Context-Aware Pedestrian Motion Prediction In Urban Intersections</summary>

- *Golnaz Habibi, Nikita Jaipuria, Jonathan P. How*

- `1806.09453v1` - [abs](http://arxiv.org/abs/1806.09453v1) - [pdf](http://arxiv.org/pdf/1806.09453v1)

> This paper presents a novel context-based approach for pedestrian motion prediction in crowded, urban intersections, with the additional flexibility of prediction in similar, but new, environments. Previously, Chen et. al. combined Markovian-based and clustering-based approaches to learn motion primitives in a grid-based world and subsequently predict pedestrian trajectories by modeling the transition between learned primitives as a Gaussian Process (GP). This work extends that prior approach by incorporating semantic features from the environment (relative distance to curbside and status of pedestrian traffic lights) in the GP formulation for more accurate predictions of pedestrian trajectories over the same timescale. We evaluate the new approach on real-world data collected using one of the vehicles in the MIT Mobility On Demand fleet. The results show 12.5% improvement in prediction accuracy and a 2.65 times reduction in Area Under the Curve (AUC), which is used as a metric to quantify the span of predicted set of trajectories, such that a lower AUC corresponds to a higher level of confidence in the future direction of pedestrian motion.

</details>

<details>

<summary>2018-06-25 14:00:37 - EARL: Joint Entity and Relation Linking for Question Answering over Knowledge Graphs</summary>

- *Mohnish Dubey, Debayan Banerjee, Debanjan Chaudhuri, Jens Lehmann*

- `1801.03825v4` - [abs](http://arxiv.org/abs/1801.03825v4) - [pdf](http://arxiv.org/pdf/1801.03825v4)

> Many question answering systems over knowledge graphs rely on entity and relation linking components in order to connect the natural language input to the underlying knowledge graph. Traditionally, entity linking and relation linking have been performed either as dependent sequential tasks or as independent parallel tasks. In this paper, we propose a framework called EARL, which performs entity linking and relation linking as a joint task. EARL implements two different solution strategies for which we provide a comparative analysis in this paper: The first strategy is a formalisation of the joint entity and relation linking tasks as an instance of the Generalised Travelling Salesman Problem (GTSP). In order to be computationally feasible, we employ approximate GTSP solvers. The second strategy uses machine learning in order to exploit the connection density between nodes in the knowledge graph. It relies on three base features and re-ranking steps in order to predict entities and relations. We compare the strategies and evaluate them on a dataset with 5000 questions. Both strategies significantly outperform the current state-of-the-art approaches for entity and relation linking.

</details>

<details>

<summary>2018-06-25 15:54:45 - Mapping Unparalleled Clinical Professional and Consumer Languages with Embedding Alignment</summary>

- *Wei-Hung Weng, Peter Szolovits*

- `1806.09542v1` - [abs](http://arxiv.org/abs/1806.09542v1) - [pdf](http://arxiv.org/pdf/1806.09542v1)

> Mapping and translating professional but arcane clinical jargons to consumer language is essential to improve the patient-clinician communication. Researchers have used the existing biomedical ontologies and consumer health vocabulary dictionary to translate between the languages. However, such approaches are limited by expert efforts to manually build the dictionary, which is hard to be generalized and scalable. In this work, we utilized the embeddings alignment method for the word mapping between unparalleled clinical professional and consumer language embeddings. To map semantically similar words in two different word embeddings, we first independently trained word embeddings on both the corpus with abundant clinical professional terms and the other with mainly healthcare consumer terms. Then, we aligned the embeddings by the Procrustes algorithm. We also investigated the approach with the adversarial training with refinement. We evaluated the quality of the alignment through the similar words retrieval both by computing the model precision and as well as judging qualitatively by human. We show that the Procrustes algorithm can be performant for the professional consumer language embeddings alignment, whereas adversarial training with refinement may find some relations between two languages.

</details>

<details>

<summary>2018-06-26 00:12:14 - Computational Analysis of Insurance Complaints: GEICO Case Study</summary>

- *Amir Karami, Noelle M. Pendergraft*

- `1806.09736v1` - [abs](http://arxiv.org/abs/1806.09736v1) - [pdf](http://arxiv.org/pdf/1806.09736v1)

> The online environment has provided a great opportunity for insurance policyholders to share their complaints with respect to different services. These complaints can reveal valuable information for insurance companies who seek to improve their services; however, analyzing a huge number of online complaints is a complicated task for human and must involve computational methods to create an efficient process. This research proposes a computational approach to characterize the major topics of a large number of online complaints. Our approach is based on using the topic modeling approach to disclose the latent semantic of complaints. The proposed approach deployed on thousands of GEICO negative reviews. Analyzing 1,371 GEICO complaints indicates that there are 30 major complains in four categories: (1) customer service, (2) insurance coverage, paperwork, policy, and reports, (3) legal issues, and (4) costs, estimates, and payments. This research approach can be used in other applications to explore a large number of reviews.

</details>

<details>

<summary>2018-06-26 07:50:37 - Unveiling the semantic structure of text documents using paragraph-aware Topic Models</summary>

- *Simón Roca-Sotelo, Jerónimo Arenas-García*

- `1806.09827v1` - [abs](http://arxiv.org/abs/1806.09827v1) - [pdf](http://arxiv.org/pdf/1806.09827v1)

> Classic Topic Models are built under the Bag Of Words assumption, in which word position is ignored for simplicity. Besides, symmetric priors are typically used in most applications. In order to easily learn topics with different properties among the same corpus, we propose a new line of work in which the paragraph structure is exploited. Our proposal is based on the following assumption: in many text document corpora there are formal constraints shared across all the collection, e.g. sections. When this assumption is satisfied, some paragraphs may be related to general concepts shared by all documents in the corpus, while others would contain the genuine description of documents. Assuming each paragraph can be semantically more general, specific, or hybrid, we look for ways to measure this, transferring this distinction to topics and being able to learn what we call specific and general topics. Experiments show that this is a proper methodology to highlight certain paragraphs in structured documents at the same time we learn interesting and more diverse topics.

</details>

<details>

<summary>2018-06-26 08:54:08 - Process Network Models for Embedded System Design Based on the Real-Time BIP Execution Engine</summary>

- *Fotios Gioulekas, Peter Poplavko, Panagiotis Katsaros, Pedro Palomo*

- `1806.09850v1` - [abs](http://arxiv.org/abs/1806.09850v1) - [pdf](http://arxiv.org/pdf/1806.09850v1)

> Existing model-based processes for embedded real-time systems support the analysis of various non-functional properties, most notably schedulability, through model checking, simulation or other means. The analysis results are then used for modifying the system's design, so that the expected properties are satisfied. A rigorous model-based design flow differs in that it aims at a system implementation derived from high-level models by applying a sequence of semantics-preserving transformations. Properties established at any design step are preserved throughout the subsequent steps including the executable implementation. We introduce such a design flow using a process network model of computation for application design at a high level, which combines streaming and reactive control processing with task parallelism. The schedulability of the so-called FPPNs (Fixed Priority Process Networks) is well-studied and various solutions have been presented. This article focuses on the design flow's steps for deriving executable implementations on the BIP (Behavior - Interaction - Priority) runtime environment. FPPNs are designed using the TASTE toolset, a convenient architecture description interface. In this way, the developers do not program explicitly low-level real-time OS services and the schedulability properties are guaranteed throughout the design steps by construction. The approach has been validated on the design of a real spacecraft on-board application that has been scheduled for execution on an industrial multicore platform.

</details>

<details>

<summary>2018-06-26 11:12:58 - Manifold Structured Prediction</summary>

- *Alessandro Rudi, Carlo Ciliberto, Gian Maria Marconi, Lorenzo Rosasco*

- `1806.09908v1` - [abs](http://arxiv.org/abs/1806.09908v1) - [pdf](http://arxiv.org/pdf/1806.09908v1)

> Structured prediction provides a general framework to deal with supervised problems where the outputs have semantically rich structure. While classical approaches consider finite, albeit potentially huge, output spaces, in this paper we discuss how structured prediction can be extended to a continuous scenario. Specifically, we study a structured prediction approach to manifold valued regression. We characterize a class of problems for which the considered approach is statistically consistent and study how geometric optimization can be used to compute the corresponding estimator. Promising experimental results on both simulated and real data complete our study.

</details>

<details>

<summary>2018-06-26 19:09:19 - Semantically Enhanced Dynamic Bayesian Network for Detecting Sepsis Mortality Risk in ICU Patients with Infection</summary>

- *Tony Wang, Tom Velez, Emilia Apostolova, Tim Tschampel, Thuy L. Ngo, Joy Hardison*

- `1806.10174v1` - [abs](http://arxiv.org/abs/1806.10174v1) - [pdf](http://arxiv.org/pdf/1806.10174v1)

> Although timely sepsis diagnosis and prompt interventions in Intensive Care Unit (ICU) patients are associated with reduced mortality, early clinical recognition is frequently impeded by non-specific signs of infection and failure to detect signs of sepsis-induced organ dysfunction in a constellation of dynamically changing physiological data. The goal of this work is to identify patient at risk of life-threatening sepsis utilizing a data-centered and machine learning-driven approach. We derive a mortality risk predictive dynamic Bayesian network (DBN) guided by a customized sepsis knowledgebase and compare the predictive accuracy of the derived DBN with the Sepsis-related Organ Failure Assessment (SOFA) score, the Quick SOFA (qSOFA) score, the Simplified Acute Physiological Score (SAPS-II) and the Modified Early Warning Score (MEWS) tools.   A customized sepsis ontology was used to derive the DBN node structure and semantically characterize temporal features derived from both structured physiological data and unstructured clinical notes. We assessed the performance in predicting mortality risk of the DBN predictive model and compared performance to other models using Receiver Operating Characteristic (ROC) curves, area under curve (AUROC), calibration curves, and risk distributions.   The derived dataset consists of 24,506 ICU stays from 19,623 patients with evidence of suspected infection, with 2,829 patients deceased at discharge. The DBN AUROC was found to be 0.91, which outperformed the SOFA (0.843), qSOFA (0.66), MEWS (0.73), and SAPS-II (0.77) scoring tools. Continuous Net Reclassification Index and Integrated Discrimination Improvement analysis supported the superiority DBN. Compared with conventional rule-based risk scoring tools, the sepsis knowledgebase-driven DBN algorithm offers improved performance for predicting mortality of infected patients in ICUs.

</details>

<details>

<summary>2018-06-27 02:55:25 - The Impact of Human Factors on the Participation Decision of Reviewers in Modern Code Review</summary>

- *Shade Ruangwan, Patanamon Thongtanunam, Akinori Ihara, Kenichi Matsumoto*

- `1806.10277v1` - [abs](http://arxiv.org/abs/1806.10277v1) - [pdf](http://arxiv.org/pdf/1806.10277v1)

> Modern Code Review (MCR) plays a key role in software quality practices. In MCR process, a new patch (i.e., a set of code changes) is encouraged to be examined by reviewers in order to identify weaknesses in source code prior to an integration into main software repositories. To mitigate the risk of having future defects, prior work suggests that MCR should be performed with sufficient review participation. Indeed, recent work shows that a low number of participated reviewers is associated with poor software quality. However, there is a likely case that a new patch still suffers from poor review participation even though reviewers were invited. Hence, in this paper, we set out to investigate the factors that are associated with the participation decision of an invited reviewer. Through a case study of 230,090 patches spread across the Android, LibreOffice, OpenStack and Qt systems, we find that (1) 16%-66% of patches have at least one invited reviewer who did not respond to the review invitation; (2) human factors play an important role in predicting whether or not an invited reviewer will participate in a review; (3) a review participation rate of an invited reviewers and code authoring experience of an invited reviewer are highly associated with the participation decision of an invited reviewer. These results can help practitioners better understand about how human factors associate with the participation decision of reviewers and serve as guidelines for inviting reviewers, leading to a better inviting decision and a better reviewer participation.

</details>

<details>

<summary>2018-06-27 08:58:57 - Learning Visually-Grounded Semantics from Contrastive Adversarial Samples</summary>

- *Haoyue Shi, Jiayuan Mao, Tete Xiao, Yuning Jiang, Jian Sun*

- `1806.10348v1` - [abs](http://arxiv.org/abs/1806.10348v1) - [pdf](http://arxiv.org/pdf/1806.10348v1)

> We study the problem of grounding distributional representations of texts on the visual domain, namely visual-semantic embeddings (VSE for short). Begin with an insightful adversarial attack on VSE embeddings, we show the limitation of current frameworks and image-text datasets (e.g., MS-COCO) both quantitatively and qualitatively. The large gap between the number of possible constitutions of real-world semantics and the size of parallel data, to a large extent, restricts the model to establish the link between textual semantics and visual concepts. We alleviate this problem by augmenting the MS-COCO image captioning datasets with textual contrastive adversarial samples. These samples are synthesized using linguistic rules and the WordNet knowledge base. The construction procedure is both syntax- and semantics-aware. The samples enforce the model to ground learned embeddings to concrete concepts within the image. This simple but powerful technique brings a noticeable improvement over the baselines on a diverse set of downstream tasks, in addition to defending known-type adversarial attacks. We release the codes at https://github.com/ExplorerFreda/VSE-C.

</details>

<details>

<summary>2018-06-27 13:30:06 - Embedding Learning Through Multilingual Concept Induction</summary>

- *Philipp Dufter, Mengjie Zhao, Martin Schmitt, Alexander Fraser, Hinrich Schütze*

- `1801.06807v3` - [abs](http://arxiv.org/abs/1801.06807v3) - [pdf](http://arxiv.org/pdf/1801.06807v3)

> We present a new method for estimating vector space representations of words: embedding learning by concept induction. We test this method on a highly parallel corpus and learn semantic representations of words in 1259 different languages in a single common space. An extensive experimental evaluation on crosslingual word similarity and sentiment analysis indicates that concept-based multilingual embedding learning performs better than previous approaches.

</details>

<details>

<summary>2018-06-27 22:22:22 - On Reliability of Patch Correctness Assessment</summary>

- *Xuan Bach D. Le, Lingfeng Bao, David Lo, Xin Xia, Shanping Li*

- `1805.05983v2` - [abs](http://arxiv.org/abs/1805.05983v2) - [pdf](http://arxiv.org/pdf/1805.05983v2)

> Current state-of-the-art automatic software repair (ASR) techniques rely heavily on incomplete specifications, e.g., test suites, to generate repairs. This, however, may render ASR tools to generate incorrect repairs that do not generalize. To assess patch correctness, researchers have been following two typical ways separately: (1) Automated annotation, wherein patches are automatically labeled by an independent test suite (ITS) - a patch passing the ITS is regarded as correct or generalizable, and incorrect otherwise, (2) Author annotation, wherein authors of ASR techniques annotate correctness labels of patches generated by their and competing tools by themselves. While automated annotation fails to prove that a patch is actually correct, author annotation is prone to subjectivity. This concern has caused an on-going debate on appropriate ways to assess the effectiveness of numerous ASR techniques proposed recently. To address this concern, we propose to assess reliability of author and automated annotations on patch correctness assessment. We do this by first constructing a gold set of correctness labels for 189 randomly selected patches generated by 8 state-of-the-art ASR techniques through a user study involving 35 professional developers as independent annotators. By measuring inter-rater agreement as a proxy for annotation quality - as commonly done in the literature - we demonstrate that our constructed gold set is on par with other high-quality gold sets. We then compare labels generated by author and automated annotations with this gold set to assess reliability of the patch assessment methodologies. We subsequently report several findings and highlight implications for future studies.

</details>

<details>

<summary>2018-06-28 06:06:48 - Java Source-code Clustering: Unifying Syntactic and Semantic Features</summary>

- *Janardan Misra, Vikrant Kaulgud, Gary Titus, Annervaz KM, Shubhashis Sengupta*

- `1208.6408v3` - [abs](http://arxiv.org/abs/1208.6408v3) - [pdf](http://arxiv.org/pdf/1208.6408v3)

> This is a companion draft to paper 'Software Clustering: Unifying Syntactic and Semantic Features', in proceedings of the 19th Working Conference on Reverse Engineering (WCRE 2012). It discusses the clustering process in detail, which appeared in the paper in an abridged form. It also contains certain additional process steps which were not covered in the WCRE paper. The clustering process is described for applications with Java source-code. However, as argued in the WCRE paper, it can be seamlessly adapted to many other programming paradigms.

</details>

<details>

<summary>2018-06-28 10:48:51 - Text to brain: predicting the spatial distribution of neuroimaging observations from text reports</summary>

- *Jérôme Dockès, Demian Wassermann, Russell Poldrack, Fabian Suchanek, Bertrand Thirion, Gaël Varoquaux*

- `1806.01139v3` - [abs](http://arxiv.org/abs/1806.01139v3) - [pdf](http://arxiv.org/pdf/1806.01139v3)

> Despite the digital nature of magnetic resonance imaging, the resulting observations are most frequently reported and stored in text documents. There is a trove of information untapped in medical health records, case reports, and medical publications. In this paper, we propose to mine brain medical publications to learn the spatial distribution associated with anatomical terms. The problem is formulated in terms of minimization of a risk on distributions which leads to a least-deviation cost function. An efficient algorithm in the dual then learns the mapping from documents to brain structures. Empirical results using coordinates extracted from the brain-imaging literature show that i) models must adapt to semantic variation in the terms used to describe a given anatomical structure, ii) voxel-wise parameterization leads to higher likelihood of locations reported in unseen documents, iii) least-deviation cost outperforms least-square. As a proof of concept for our method, we use our model of spatial distributions to predict the distribution of specific neurological conditions from text-only reports.

</details>

<details>

<summary>2018-06-28 17:42:54 - Predicting CEFRL levels in learner English on the basis of metrics and full texts</summary>

- *Taylor Arnold, Nicolas Ballier, Thomas Gaillat, Paula Lissòn*

- `1806.11099v1` - [abs](http://arxiv.org/abs/1806.11099v1) - [pdf](http://arxiv.org/pdf/1806.11099v1)

> This paper analyses the contribution of language metrics and, potentially, of linguistic structures, to classify French learners of English according to levels of the Common European Framework of Reference for Languages (CEFRL). The purpose is to build a model for the prediction of learner levels as a function of language complexity features. We used the EFCAMDAT corpus, a database of one million written assignments by learners. After applying language complexity metrics on the texts, we built a representation matching the language metrics of the texts to their assigned CEFRL levels. Lexical and syntactic metrics were computed with LCA, LSA, and koRpus. Several supervised learning models were built by using Gradient Boosted Trees and Keras Neural Network methods and by contrasting pairs of CEFRL levels. Results show that it is possible to implement pairwise distinctions, especially for levels ranging from A1 to B1 (A1=>A2: 0.916 AUC and A2=>B1: 0.904 AUC). Model explanation reveals significant linguistic features for the predictiveness in the corpus. Word tokens and word types appear to play a significant role in determining levels. This shows that levels are highly dependent on specific semantic profiles.

</details>

<details>

<summary>2018-06-29 00:34:27 - Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text</summary>

- *Ayush Jaiswal, Ekraam Sabir, Wael AbdAlmageed, Premkumar Natarajan*

- `1707.01606v4` - [abs](http://arxiv.org/abs/1707.01606v4) - [pdf](http://arxiv.org/pdf/1707.01606v4)

> Real world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g. captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is, therefore, important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper, we present a novel deep learning-based approach for assessing the semantic integrity of multimedia packages containing images and captions, using a reference set of multimedia packages. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we make available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages.

</details>

<details>

<summary>2018-06-29 09:51:26 - Bias in Semantic and Discourse Interpretation</summary>

- *Nicholas Asher, Soumya Paul*

- `1806.11322v1` - [abs](http://arxiv.org/abs/1806.11322v1) - [pdf](http://arxiv.org/pdf/1806.11322v1)

> In this paper, we show how game-theoretic work on conversation combined with a theory of discourse structure provides a framework for studying interpretive bias. Interpretive bias is an essential feature of learning and understanding but also something that can be used to pervert or subvert the truth. The framework we develop here provides tools for understanding and analyzing the range of interpretive biases and the factors that contribute to them.

</details>

<details>

<summary>2018-06-29 13:53:51 - Probabilistic Analysis of Weakly-Hard Real-Time Systems</summary>

- *Eun-Young Kang, Dongrui Mu, Li Huang*

- `1807.00003v1` - [abs](http://arxiv.org/abs/1807.00003v1) - [pdf](http://arxiv.org/pdf/1807.00003v1)

> Modeling and analysis of non-functional properties, such as timing constraints, is crucial in automotive real-time embedded systems. EAST-ADL is a domain specific architectural language dedicated to safetycritical automotive embedded system design. We have previously specified EAST-ADL timing constraints in Clock Constraint Specification Language (CCSL) and proved the correctness of specification by mapping the semantics of the constraints into Uppaal models amenable to model checking. In most cases, a bounded number of violations of timing constraints in automotive systems would not lead to system failures when the results of the violations are negligible, called Weakly-Hard (WH). Previous work is extended in this paper by including support for probabilistic analysis of timing constraints in the context of WH: Probabilistic extension of CCSL, called PrCCSL, is defined and the EAST-ADL timing constraints with stochastic properties are specified in PrCCSL. The semantics of the extended constraints in PrCCSL is translated into Uppaal-SMC models for formal verification. Furthermore, a set of mapping rules is proposed to facilitate guarantee of translation. Our approach is demonstrated on an autonomous traffic sign recognition vehicle case study.

</details>

<details>

<summary>2018-06-29 20:17:16 - Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis</summary>

- *Arna Ghosh, Fabien dal Maso, Marc Roig, Georgios D Mitsis, Marie-Hélène Boudrias*

- `1805.11704v2` - [abs](http://arxiv.org/abs/1805.11704v2) - [pdf](http://arxiv.org/pdf/1805.11704v2)

> Neuroimaging data analysis often involves \emph{a-priori} selection of data features to study the underlying neural activity. Since this could lead to sub-optimal feature selection and thereby prevent the detection of subtle patterns in neural activity, data-driven methods have recently gained popularity for optimizing neuroimaging data analysis pipelines and thereby, improving our understanding of neural mechanisms. In this context, we developed a deep convolutional architecture that can identify discriminating patterns in neuroimaging data and applied it to electroencephalography (EEG) recordings collected from 25 subjects performing a hand motor task before and after a rest period or a bout of exercise. The deep network was trained to classify subjects into exercise and control groups based on differences in their EEG signals. Subsequently, we developed a novel method termed the cue-combination for Class Activation Map (ccCAM), which enabled us to identify discriminating spatio-temporal features within definite frequency bands (23--33 Hz) and assess the effects of exercise on the brain. Additionally, the proposed architecture allowed the visualization of the differences in the propagation of underlying neural activity across the cortex between the two groups, for the first time in our knowledge. Our results demonstrate the feasibility of using deep network architectures for neuroimaging analysis in different contexts such as, for the identification of robust brain biomarkers to better characterize and potentially treat neurological disorders.

</details>

<details>

<summary>2018-06-30 00:33:27 - Dynamic Neural Program Embedding for Program Repair</summary>

- *Ke Wang, Rishabh Singh, Zhendong Su*

- `1711.07163v4` - [abs](http://arxiv.org/abs/1711.07163v4) - [pdf](http://arxiv.org/pdf/1711.07163v4)

> Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difficult to capture by only considering its syntax (i.e. syntactically similar pro- grams can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural fit for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding significantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our se- mantic embedding, and show that search efficiency is also significantly improved.

</details>

<details>

<summary>2018-06-30 01:26:51 - Mammography Assessment using Multi-Scale Deep Classifiers</summary>

- *Ulzee An, Khader Shameer, Lakshmi Subramanian*

- `1807.03095v1` - [abs](http://arxiv.org/abs/1807.03095v1) - [pdf](http://arxiv.org/pdf/1807.03095v1)

> Applying deep learning methods to mammography assessment has remained a challenging topic. Dense noise with sparse expressions, mega-pixel raw data resolution, lack of diverse examples have all been factors affecting performance. The lack of pixel-level ground truths have especially limited segmentation methods in pushing beyond approximately bounding regions. We propose a classification approach grounded in high performance tissue assessment as an alternative to all-in-one localization and assessment models that is also capable of pinpointing the causal pixels. First, the objective of the mammography assessment task is formalized in the context of local tissue classifiers. Then, the accuracy of a convolutional neural net is evaluated on classifying patches of tissue with suspicious findings at varying scales, where highest obtained AUC is above $0.9$. The local evaluations of one such expert tissue classifier is used to augment the results of a heatmap regression model and additionally recover the exact causal regions at high resolution as a saliency image suitable for clinical settings.

</details>


## 2018-07

<details>

<summary>2018-07-01 04:11:18 - An Efficient Approach to Encoding Context for Spoken Language Understanding</summary>

- *Raghav Gupta, Abhinav Rastogi, Dilek Hakkani-Tur*

- `1807.00267v1` - [abs](http://arxiv.org/abs/1807.00267v1) - [pdf](http://arxiv.org/pdf/1807.00267v1)

> In task-oriented dialogue systems, spoken language understanding, or SLU, refers to the task of parsing natural language user utterances into semantic frames. Making use of context from prior dialogue history holds the key to more effective SLU. State of the art approaches to SLU use memory networks to encode context by processing multiple utterances from the dialogue at each turn, resulting in significant trade-offs between accuracy and computational efficiency. On the other hand, downstream components like the dialogue state tracker (DST) already keep track of the dialogue state, which can serve as a summary of the dialogue history. In this work, we propose an efficient approach to encoding context from prior utterances for SLU. More specifically, our architecture includes a separate recurrent neural network (RNN) based encoding module that accumulates dialogue context to guide the frame parsing sub-tasks and can be shared between SLU and DST. In our experiments, we demonstrate the effectiveness of our approach on dialogues from two domains.

</details>

<details>

<summary>2018-07-01 11:26:43 - Using Elements Of Semantic Parsing In E-Learning Environments</summary>

- *Andrii Striuk*

- `1807.00316v1` - [abs](http://arxiv.org/abs/1807.00316v1) - [pdf](http://arxiv.org/pdf/1807.00316v1)

> Possibilities for using semantic parsing to estimate the correspondence of text materials to teaching aims, correspondence of test task to theoretical materials and other problems arising during the distance course designing and educational process itself in e-learning environments.

</details>

<details>

<summary>2018-07-02 00:03:11 - EZLearn: Exploiting Organic Supervision in Large-Scale Data Annotation</summary>

- *Maxim Grechkin, Hoifung Poon, Bill Howe*

- `1709.08600v3` - [abs](http://arxiv.org/abs/1709.08600v3) - [pdf](http://arxiv.org/pdf/1709.08600v3)

> Many real-world applications require automated data annotation, such as identifying tissue origins based on gene expressions and classifying images into semantic categories. Annotation classes are often numerous and subject to changes over time, and annotating examples has become the major bottleneck for supervised learning methods. In science and other high-value domains, large repositories of data samples are often available, together with two sources of organic supervision: a lexicon for the annotation classes, and text descriptions that accompany some data samples. Distant supervision has emerged as a promising paradigm for exploiting such indirect supervision by automatically annotating examples where the text description contains a class mention in the lexicon. However, due to linguistic variations and ambiguities, such training data is inherently noisy, which limits the accuracy of this approach. In this paper, we introduce an auxiliary natural language processing system for the text modality, and incorporate co-training to reduce noise and augment signal in distant supervision. Without using any manually labeled data, our EZLearn system learned to accurately annotate data samples in functional genomics and scientific figure comprehension, substantially outperforming state-of-the-art supervised methods trained on tens of thousands of annotated examples.

</details>

<details>

<summary>2018-07-02 05:08:05 - ColdRoute: Effective Routing of Cold Questions in Stack Exchange Sites</summary>

- *Jiankai Sun, Abhinav Vishnu, Aniket Chakrabarti, Charles Siegel, Srinivasan Parthasarathy*

- `1807.00462v1` - [abs](http://arxiv.org/abs/1807.00462v1) - [pdf](http://arxiv.org/pdf/1807.00462v1)

> Routing questions in Community Question Answer services (CQAs) such as Stack Exchange sites is a well-studied problem. Yet, cold-start -- a phenomena observed when a new question is posted is not well addressed by existing approaches. Additionally, cold questions posted by new askers present significant challenges to state-of-the-art approaches. We propose ColdRoute to address these challenges. ColdRoute is able to handle the task of routing cold questions posted by new or existing askers to matching experts. Specifically, we use Factorization Machines on the one-hot encoding of critical features such as question tags and compare our approach to well-studied techniques such as CQARank and semantic matching (LDA, BoW, and Doc2Vec). Using data from eight stack exchange sites, we are able to improve upon the routing metrics (Precision$@1$, Accuracy, MRR) over the state-of-the-art models such as semantic matching by $159.5\%$,$31.84\%$, and $40.36\%$ for cold questions posted by existing askers, and $123.1\%$, $27.03\%$, and $34.81\%$ for cold questions posted by new askers respectively.

</details>

<details>

<summary>2018-07-02 10:31:05 - Sample Efficient Semantic Segmentation using Rotation Equivariant Convolutional Networks</summary>

- *Jasper Linmans, Jim Winkens, Bastiaan S. Veeling, Taco S. Cohen, Max Welling*

- `1807.00583v1` - [abs](http://arxiv.org/abs/1807.00583v1) - [pdf](http://arxiv.org/pdf/1807.00583v1)

> We propose a semantic segmentation model that exploits rotation and reflection symmetries. We demonstrate significant gains in sample efficiency due to increased weight sharing, as well as improvements in robustness to symmetry transformations. The group equivariant CNN framework is extended for segmentation by introducing a new equivariant (G->Z2)-convolution that transforms feature maps on a group to planar feature maps. Also, equivariant transposed convolution is formulated for up-sampling in an encoder-decoder network. To demonstrate improvements in sample efficiency we evaluate on multiple data regimes of a rotation-equivariant segmentation task: cancer metastases detection in histopathology images. We further show the effectiveness of exploiting more symmetries by varying the size of the group.

</details>

<details>

<summary>2018-07-02 16:29:34 - Representation Mapping: A Novel Approach to Generate High-Quality Multi-Lingual Emotion Lexicons</summary>

- *Sven Buechel, Udo Hahn*

- `1807.00775v1` - [abs](http://arxiv.org/abs/1807.00775v1) - [pdf](http://arxiv.org/pdf/1807.00775v1)

> In the past years, sentiment analysis has increasingly shifted attention to representational frameworks more expressive than semantic polarity (being positive, negative or neutral). However, these richer formats (like Basic Emotions or Valence-Arousal-Dominance, and variants therefrom), rooted in psychological research, tend to proliferate the number of representation schemes for emotion encoding. Thus, a large amount of representationally incompatible emotion lexicons has been developed by various research groups adopting one or the other emotion representation format. As a consequence, the reusability of these resources decreases as does the comparability of systems using them. In this paper, we propose to solve this dilemma by methods and tools which map different representation formats onto each other for the sake of mutual compatibility and interoperability of language resources. We present the first large-scale investigation of such representation mappings for four typologically diverse languages and find evidence that our approach produces (near-)gold quality emotion lexicons, even in cross-lingual settings. Finally, we use our models to create new lexicons for eight typologically diverse languages.

</details>

<details>

<summary>2018-07-03 07:22:54 - Building a Controlled Vocabulary for Standardizing Precision Medicine Terms</summary>

- *Meng Wu, Yan Liu, Hongyu Kang, Si Zheng, Jiao Li, Li Hou*

- `1807.01000v1` - [abs](http://arxiv.org/abs/1807.01000v1) - [pdf](http://arxiv.org/pdf/1807.01000v1)

> Rapid advances of technology and development of research in precision medicine domain have led to the production of different types of biomedical data. Standard medical vocabularies were shown to be limited in dealing with such heterogeneous data and consequently, new controlled vocabulary for data integration and normalization has been proposed. In this study, the precision medicine vocabulary (PMV), which is a controlled vocabulary for terms used in precision medicine, is built based on the method of data integration in Unified Medical Language System (UMLS). It now covers ten top semantic types of disease, drug, gene, gene variation and so on. In total of 1,372,967 concepts and 4,567,208 terms have been integrated from widely used databases related with precision medicine.

</details>

<details>

<summary>2018-07-03 10:46:07 - Deep Spatio-Temporal Random Fields for Efficient Video Segmentation</summary>

- *Siddhartha Chandra, Camille Couprie, Iasonas Kokkinos*

- `1807.03148v1` - [abs](http://arxiv.org/abs/1807.03148v1) - [pdf](http://arxiv.org/pdf/1807.03148v1)

> In this work we introduce a time- and memory-efficient method for structured prediction that couples neuron decisions across both space at time. We show that we are able to perform exact and efficient inference on a densely connected spatio-temporal graph by capitalizing on recent advances on deep Gaussian Conditional Random Fields (GCRFs). Our method, called VideoGCRF is (a) efficient, (b) has a unique global minimum, and (c) can be trained end-to-end alongside contemporary deep networks for video understanding. We experiment with multiple connectivity patterns in the temporal domain, and present empirical improvements over strong baselines on the tasks of both semantic and instance segmentation of videos.

</details>

<details>

<summary>2018-07-03 17:15:49 - Intent Generation for Goal-Oriented Dialogue Systems based on Schema.org Annotations</summary>

- *Umutcan Şimşek, Dieter Fensel*

- `1807.01292v1` - [abs](http://arxiv.org/abs/1807.01292v1) - [pdf](http://arxiv.org/pdf/1807.01292v1)

> Goal-oriented dialogue systems typically communicate with a backend (e.g. database, Web API) to complete certain tasks to reach a goal. The intents that a dialogue system can recognize are mostly included to the system by the developer statically. For an open dialogue system that can work on more than a small set of well curated data and APIs, this manual intent creation will not scalable. In this paper, we introduce a straightforward methodology for intent creation based on semantic annotation of data and services on the web. With this method, the Natural Language Understanding (NLU) module of a goal-oriented dialogue system can adapt to newly introduced APIs without requiring heavy developer involvement. We were able to extract intents and necessary slots to be filled from schema.org annotations. We were also able to create a set of initial training sentences for classifying user utterances into the generated intents. We demonstrate our approach on the NLU module of a state-of-the art dialogue system development framework.

</details>

<details>

<summary>2018-07-03 23:29:49 - Simpler but More Accurate Semantic Dependency Parsing</summary>

- *Timothy Dozat, Christopher D. Manning*

- `1807.01396v1` - [abs](http://arxiv.org/abs/1807.01396v1) - [pdf](http://arxiv.org/pdf/1807.01396v1)

> While syntactic dependency annotations concentrate on the surface or functional structure of a sentence, semantic dependency annotations aim to capture between-word relationships that are more closely related to the meaning of a sentence, using graph-structured representations. We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures. The resulting system on its own achieves state-of-the-art performance, beating the previous, substantially more complex state-of-the-art system by 0.6% labeled F1. Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9% labeled F1.

</details>

<details>

<summary>2018-07-04 08:46:21 - Double Path Networks for Sequence to Sequence Learning</summary>

- *Kaitao Song, Xu Tan, Di He, Jianfeng Lu, Tao Qin, Tie-Yan Liu*

- `1806.04856v2` - [abs](http://arxiv.org/abs/1806.04856v2) - [pdf](http://arxiv.org/pdf/1806.04856v2)

> Encoder-decoder based Sequence to Sequence learning (S2S) has made remarkable progress in recent years. Different network architectures have been used in the encoder/decoder. Among them, Convolutional Neural Networks (CNN) and Self Attention Networks (SAN) are the prominent ones. The two architectures achieve similar performances but use very different ways to encode and decode context: CNN use convolutional layers to focus on the local connectivity of the sequence, while SAN uses self-attention layers to focus on global semantics. In this work we propose Double Path Networks for Sequence to Sequence learning (DPN-S2S), which leverage the advantages of both models by using double path information fusion. During the encoding step, we develop a double path architecture to maintain the information coming from different paths with convolutional layers and self-attention layers separately. To effectively use the encoded context, we develop a cross attention module with gating and use it to automatically pick up the information needed during the decoding step. By deeply integrating the two paths with cross attention, both types of information are combined and well exploited. Experiments show that our proposed method can significantly improve the performance of sequence to sequence learning over state-of-the-art systems.

</details>

<details>

<summary>2018-07-04 13:07:53 - Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding</summary>

- *Yutai Hou, Yijia Liu, Wanxiang Che, Ting Liu*

- `1807.01554v1` - [abs](http://arxiv.org/abs/1807.01554v1) - [pdf](http://arxiv.org/pdf/1807.01554v1)

> In this paper, we study the problem of data augmentation for language understanding in task-oriented dialogue system. In contrast to previous work which augments an utterance without considering its relation with other utterances, we propose a sequence-to-sequence generation based data augmentation framework that leverages one utterance's same semantic alternatives in the training data. A novel diversity rank is incorporated into the utterance representation to make the model produce diverse utterances and these diversely augmented utterances help to improve the language understanding module. Experimental results on the Airline Travel Information System dataset and a newly created semantic frame annotation on Stanford Multi-turn, Multidomain Dialogue Dataset show that our framework achieves significant improvements of 6.38 and 10.04 F-scores respectively when only a training set of hundreds utterances is represented. Case studies also confirm that our method generates diverse utterances.

</details>

<details>

<summary>2018-07-04 22:24:50 - Feature-based reformulation of entities in triple pattern queries</summary>

- *Amar Viswanathan, Geeth de Mel, James A. Hendler*

- `1807.01801v1` - [abs](http://arxiv.org/abs/1807.01801v1) - [pdf](http://arxiv.org/pdf/1807.01801v1)

> Knowledge graphs encode uniquely identifiable entities to other entities or literal values by means of relationships, thus enabling semantically rich querying over the stored data. Typically, the semantics of such queries are often crisp thereby resulting in crisp answers. Query log statistics show that a majority of the queries issued to knowledge graphs are often entity centric queries. When a user needs additional answers the state-of-the-art in assisting users is to rewrite the original query resulting in a set of approximations. Several strategies have been proposed in past to address this. They typically move up the taxonomy to relax a specific element to a more generic element. Entities don't have a taxonomy and they end up being generalized. To address this issue, in this paper, we propose an entity centric reformulation strategy that utilizes schema information and entity features present in the graph to suggest rewrites. Once the features are identified, the entity in concern is reformulated as a set of features. Since entities can have a large number of features, we introduce strategies that select the top-k most relevant and {informative ranked features and augment them to the original query to create a valid reformulation. We then evaluate our approach by showing that our reformulation strategy produces results that are more informative when compared with state-of-the-art

</details>

<details>

<summary>2018-07-05 00:43:14 - Greedy, Joint Syntactic-Semantic Parsing with Stack LSTMs</summary>

- *Swabha Swayamdipta, Miguel Ballesteros, Chris Dyer, Noah A. Smith*

- `1606.08954v2` - [abs](http://arxiv.org/abs/1606.08954v2) - [pdf](http://arxiv.org/pdf/1606.08954v2)

> We present a transition-based parser that jointly produces syntactic and semantic dependencies. It learns a representation of the entire algorithm state, using stack long short-term memories. Our greedy inference algorithm has linear time, including feature extraction. On the CoNLL 2008--9 English shared tasks, we obtain the best published parsing performance among models that jointly learn syntax and semantics.

</details>

<details>

<summary>2018-07-05 02:20:50 - Semisupervised Learning on Heterogeneous Graphs and its Applications to Facebook News Feed</summary>

- *Cheng Ju, James Li, Bram Wasti, Shengbo Guo*

- `1805.07479v2` - [abs](http://arxiv.org/abs/1805.07479v2) - [pdf](http://arxiv.org/pdf/1805.07479v2)

> Graph-based semi-supervised learning is a fundamental machine learning problem, and has been well studied. Most studies focus on homogeneous networks (e.g. citation network, friend network). In the present paper, we propose the Heterogeneous Embedding Label Propagation (HELP) algorithm, a graph-based semi-supervised deep learning algorithm, for graphs that are characterized by heterogeneous node types. Empirically, we demonstrate the effectiveness of this method in domain classification tasks with Facebook user-domain interaction graph, and compare the performance of the proposed HELP algorithm with the state of the art algorithms. We show that the HELP algorithm improves the predictive performance across multiple tasks, together with semantically meaningful embedding that are discriminative for downstream classification or regression tasks.

</details>

<details>

<summary>2018-07-05 04:12:41 - Improving Fuzzing Using Software Complexity Metrics</summary>

- *Maksim Shudrak, Vyacheslav Zolotarev*

- `1807.01838v1` - [abs](http://arxiv.org/abs/1807.01838v1) - [pdf](http://arxiv.org/pdf/1807.01838v1)

> Vulnerable software represents a tremendous threat to modern information systems. Vulnerabilities in widespread applications may be used to spread malware, steal money and conduct target attacks. To address this problem, developers and researchers use different approaches of dynamic and static software analysis; one of these approaches is called fuzzing. Fuzzing is performed by generating and sending potentially malformed data to an application under test. Since first appearance in 1988, fuzzing has evolved a lot, but issues which addressed to effectiveness evaluation have not fully investigated until now. In our research, we propose a novel approach of fuzzing effectiveness evaluation, taking into account semantics of executed code along with a quantitative assessment. For this purpose, we use specific metrics of source code complexity assessment adapted to perform analysis of machine code. We conducted effectiveness evaluation of these metrics on 104 widespread applications with known vulnerabilities. As a result of these experiments, we were able to identify a set of metrics that are more suitable to find bugs. In addition, we conducted separate experiments on 7 applications without known vulnerabilities by using the set of metrics. The experimental results confirmed that proposed approach can be applied to increase performance of the fuzzing. Moreover, the tools helped detect two critical zero day (previously unknown) vulnerabilities in the wide-spread applications.

</details>

<details>

<summary>2018-07-05 05:50:11 - Impact of Continuous Integration on Code Reviews</summary>

- *Mohammad Masudur Rahman, Chanchal K. Roy*

- `1807.01851v1` - [abs](http://arxiv.org/abs/1807.01851v1) - [pdf](http://arxiv.org/pdf/1807.01851v1)

> Peer code review and continuous integration often interleave with each other in the modern software quality management. Although several studies investigate how non-technical factors (e.g., reviewer workload), developer participation and even patch size affect the code review process, the impact of continuous integration on code reviews is not yet properly understood. In this paper, we report an exploratory study using 578K automated build entries where we investigate the impact of automated builds on the code reviews. Our investigation suggests that successfully passed builds are more likely to encourage new code review participation in a pull request. Frequently built projects are found to be maintaining a steady level of reviewing activities over the years, which was quite missing from the rarely built projects. Experiments with 26,516 automated build entries reported that our proposed model can identify 64% of the builds that triggered new code reviews later.

</details>

<details>

<summary>2018-07-05 07:06:57 - DesignBIP: A Design Studio for Modeling and Generating Systems with BIP</summary>

- *Anastasia Mavridou, Joseph Sifakis, Janos Sztipanovits*

- `1911.08405v1` - [abs](http://arxiv.org/abs/1911.08405v1) - [pdf](http://arxiv.org/pdf/1911.08405v1)

> The Behavior-Interaction-Priority (BIP) framework, rooted in rigorous semantics, allows the construction of systems that are correct-by-design. BIP has been effectively used for the construction and analysis of large systems such as robot controllers and satellite on-board software. Nevertheless, the specification of BIP models is done in a purely textual manner without any code editor support. To facilitate the specification of BIP models, we present DesignBIP, a web-based, collaborative, version-controlled design studio. To promote model scaling and reusability of BIP models, we use a graphical language for modeling parameterized BIP models with rigorous semantics. We present the various services provided by the design studio, including model editors, code editors, consistency checking mechanisms, code generators, and integration with the JavaBIP tool-set.

</details>

<details>

<summary>2018-07-05 10:03:23 - Encoding Spatial Relations from Natural Language</summary>

- *Tiago Ramalho, Tomáš Kočiský, Frederic Besse, S. M. Ali Eslami, Gábor Melis, Fabio Viola, Phil Blunsom, Karl Moritz Hermann*

- `1807.01670v2` - [abs](http://arxiv.org/abs/1807.01670v2) - [pdf](http://arxiv.org/pdf/1807.01670v2)

> Natural language processing has made significant inroads into learning the semantics of words through distributional approaches, however representations learnt via these methods fail to capture certain kinds of information implicit in the real world. In particular, spatial relations are encoded in a way that is inconsistent with human spatial reasoning and lacking invariance to viewpoint changes. We present a system capable of capturing the semantics of spatial relations such as behind, left of, etc from natural language. Our key contributions are a novel multi-modal objective based on generating images of scenes from their textual descriptions, and a new dataset on which to train it. We demonstrate that internal representations are robust to meaning preserving transformations of descriptions (paraphrase invariance), while viewpoint invariance is an emergent property of the system.

</details>

<details>

<summary>2018-07-06 02:59:54 - Homodyne-detector-blinding attack in continuous-variable quantum key distribution</summary>

- *Hao Qin, Rupesh Kumar, Vadim Makarov, Romain Alléaume*

- `1805.01620v2` - [abs](http://arxiv.org/abs/1805.01620v2) - [pdf](http://arxiv.org/pdf/1805.01620v2)

> We propose an efficient strategy to attack a continuous-variable quantum key distribution (CV-QKD) system, that we call homodyne detector blinding. This attack strategy takes advantage of a generic vulnerability of homodyne receivers: a bright light pulse sent on the signal port can lead to a saturation of the detector electronics. While detector saturation has already been proposed to attack CV-QKD, the attack we study in this paper has the additional advantage of not requiring an eavesdropper to be phase locked with the homodyne receiver. We show that under certain conditions, an attacker can use a simple laser, incoherent with the homodyne receiver, to generate bright pulses and bias the excess noise to arbitrary small values, fully comprising CV-QKD security. These results highlight the feasibility and the impact of the detector blinding attack. We finally discuss how to design countermeasures in order to protect against this attack.

</details>

<details>

<summary>2018-07-06 06:50:03 - Generative Adversarial Perturbations</summary>

- *Omid Poursaeed, Isay Katsman, Bicheng Gao, Serge Belongie*

- `1712.02328v3` - [abs](http://arxiv.org/abs/1712.02328v3) - [pdf](http://arxiv.org/pdf/1712.02328v3)

> In this paper, we propose novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models. We present trainable deep neural networks for transforming images to adversarial perturbations. Our proposed models can produce image-agnostic and image-dependent perturbations for both targeted and non-targeted attacks. We also demonstrate that similar architectures can achieve impressive results in fooling classification and semantic segmentation models, obviating the need for hand-crafting attack methods for each task. Using extensive experiments on challenging high-resolution datasets such as ImageNet and Cityscapes, we show that our perturbations achieve high fooling rates with small perturbation norms. Moreover, our attacks are considerably faster than current iterative methods at inference time.

</details>

<details>

<summary>2018-07-06 12:49:40 - Automated essay scoring with string kernels and word embeddings</summary>

- *Mădălina Cozma, Andrei M. Butnaru, Radu Tudor Ionescu*

- `1804.07954v2` - [abs](http://arxiv.org/abs/1804.07954v2) - [pdf](http://arxiv.org/pdf/1804.07954v2)

> In this work, we present an approach based on combining string kernels and word embeddings for automatic essay scoring. String kernels capture the similarity among strings based on counting common character n-grams, which are a low-level yet powerful type of feature, demonstrating state-of-the-art results in various text classification tasks such as Arabic dialect identification or native language identification. To our best knowledge, we are the first to apply string kernels to automatically score essays. We are also the first to combine them with a high-level semantic feature representation, namely the bag-of-super-word-embeddings. We report the best performance on the Automated Student Assessment Prize data set, in both in-domain and cross-domain settings, surpassing recent state-of-the-art deep learning approaches.

</details>

<details>

<summary>2018-07-07 12:32:48 - Probabilistic AND-OR Attribute Grouping for Zero-Shot Learning</summary>

- *Yuval Atzmon, Gal Chechik*

- `1806.02664v2` - [abs](http://arxiv.org/abs/1806.02664v2) - [pdf](http://arxiv.org/pdf/1806.02664v2)

> In zero-shot learning (ZSL), a classifier is trained to recognize visual classes without any image samples. Instead, it is given semantic information about the class, like a textual description or a set of attributes. Learning from attributes could benefit from explicitly modeling structure of the attribute space. Unfortunately, learning of general structure from empirical samples is hard with typical dataset sizes.   Here we describe LAGO, a probabilistic model designed to capture natural soft and-or relations across groups of attributes. We show how this model can be learned end-to-end with a deep attribute-detection model. The soft group structure can be learned from data jointly as part of the model, and can also readily incorporate prior knowledge about groups if available. The soft and-or structure succeeds to capture meaningful and predictive structures, improving the accuracy of zero-shot learning on two of three benchmarks.   Finally, LAGO reveals a unified formulation over two ZSL approaches: DAP (Lampert et al., 2009) and ESZSL (Romera-Paredes & Torr, 2015). Interestingly, taking only one singleton group for each attribute, introduces a new soft-relaxation of DAP, that outperforms DAP by ~40.

</details>

<details>

<summary>2018-07-07 16:55:04 - Patchwork Kriging for Large-scale Gaussian Process Regression</summary>

- *Chiwoo Park, Daniel Apley*

- `1701.06655v4` - [abs](http://arxiv.org/abs/1701.06655v4) - [pdf](http://arxiv.org/pdf/1701.06655v4)

> This paper presents a new approach for Gaussian process (GP) regression for large datasets. The approach involves partitioning the regression input domain into multiple local regions with a different local GP model fitted in each region. Unlike existing local partitioned GP approaches, we introduce a technique for patching together the local GP models nearly seamlessly to ensure that the local GP models for two neighboring regions produce nearly the same response prediction and prediction error variance on the boundary between the two regions. This largely mitigates the well-known discontinuity problem that degrades the boundary accuracy of existing local partitioned GP methods. Our main innovation is to represent the continuity conditions as additional pseudo-observations that the differences between neighboring GP responses are identically zero at an appropriately chosen set of boundary input locations. To predict the response at any input location, we simply augment the actual response observations with the pseudo-observations and apply standard GP prediction methods to the augmented data. In contrast to heuristic continuity adjustments, this has an advantage of working within a formal GP framework, so that the GP-based predictive uncertainty quantification remains valid. Our approach also inherits a sparse block-like structure for the sample covariance matrix, which results in computationally efficient closed-form expressions for the predictive mean and variance. In addition, we provide a new spatial partitioning scheme based on a recursive space partitioning along local principal component directions, which makes the proposed approach applicable for regression domains having more than two dimensions. Using three spatial datasets and three higher dimensional datasets, we investigate the numerical performance of the approach and compare it to several state-of-the-art approaches.

</details>

<details>

<summary>2018-07-08 10:53:15 - Formal Semantics of Architectural Decision Models</summary>

- *Marcin Szlenk*

- `1807.02798v1` - [abs](http://arxiv.org/abs/1807.02798v1) - [pdf](http://arxiv.org/pdf/1807.02798v1)

> A software architecture is the result of multiple decisions made by a software architect. These decisions are called architectural decisions, as they bring solutions to architectural problems. Relations between decisions can be captured in architectural decision models. Such models are then a form of reusable knowledge for software architects. Several models have been described in the literature, introducing necessary concepts and relations. These concepts and relations were usually explained using natural language. Not much work has been done so far on their formal definitions. Specifically, such a definition of an architectural decision model is still missing. The purpose of this paper is filling this gap by providing the formal definition of an architectural decision model at both syntax and semantics levels. At the syntax level, different concepts and relations that are elements of a model have been mathematically defined. At the semantics level, the meaning of a model has been defined in a form of denotational semantics. The formalization not only allows for better understanding of architectural decision models but opens the possibility to reason on such models, e.g., checking their consistency - something that is very limited for the models proposed so far. A practical example of the semantics of an architectural decision model is also presented.

</details>

<details>

<summary>2018-07-08 14:04:13 - Training of Convolutional Networks on Multiple Heterogeneous Datasets for Street Scene Semantic Segmentation</summary>

- *Panagiotis Meletis, Gijs Dubbelman*

- `1803.05675v2` - [abs](http://arxiv.org/abs/1803.05675v2) - [pdf](http://arxiv.org/pdf/1803.05675v2)

> We propose a convolutional network with hierarchical classifiers for per-pixel semantic segmentation, which is able to be trained on multiple, heterogeneous datasets and exploit their semantic hierarchy. Our network is the first to be simultaneously trained on three different datasets from the intelligent vehicles domain, i.e. Cityscapes, GTSDB and Mapillary Vistas, and is able to handle different semantic level-of-detail, class imbalances, and different annotation types, i.e. dense per-pixel and sparse bounding-box labels. We assess our hierarchical approach, by comparing against flat, non-hierarchical classifiers and we show improvements in mean pixel accuracy of 13.0% for Cityscapes classes and 2.4% for Vistas classes and 32.3% for GTSDB classes. Our implementation achieves inference rates of 17 fps at a resolution of 520x706 for 108 classes running on a GPU.

</details>

<details>

<summary>2018-07-08 14:29:00 - Social network aided plagiarism detection: Social network aided plagiarism detection</summary>

- *Aljaž Zrnec, Dejan Lavbič*

- `1807.02830v1` - [abs](http://arxiv.org/abs/1807.02830v1) - [pdf](http://arxiv.org/pdf/1807.02830v1)

> The prevalence of different kinds of electronic devices and the volume of content on the Web have increased the amount of plagiarism, which is considered an unethical act. If we want to be efficient in the detection and prevention of these acts, we have to improve today's methods of discovering plagiarism. The paper presents a research study where a framework for the improved detection of plagiarism is proposed. The framework focuses on the integration of social network information, information from the Web, and an advanced semantically enriched visualization of information about authors and documents that enables the exploration of obtained data by seeking of advanced patterns of plagiarism. To support the proposed framework, a special software tool was also developed. The statistical evaluation confirmed that the employment of social network analysis and advanced visualization techniques led to improvements in the confirmation and investigation stages of the plagiarism detection process, thereby enhancing the overall efficiency of the plagiarism detection process.

</details>

<details>

<summary>2018-07-08 17:33:43 - Replicated Siamese LSTM in Ticketing System for Similarity Learning and Retrieval in Asymmetric Texts</summary>

- *Pankaj Gupta, Bernt Andrassy, Hinrich Schütze*

- `1807.02854v1` - [abs](http://arxiv.org/abs/1807.02854v1) - [pdf](http://arxiv.org/pdf/1807.02854v1)

> The goal of our industrial ticketing system is to retrieve a relevant solution for an input query, by matching with historical tickets stored in knowledge base. A query is comprised of subject and description, while a historical ticket consists of subject, description and solution. To retrieve a relevant solution, we use textual similarity paradigm to learn similarity in the query and historical tickets. The task is challenging due to significant term mismatch in the query and ticket pairs of asymmetric lengths, where subject is a short text but description and solution are multi-sentence texts. We present a novel Replicated Siamese LSTM model to learn similarity in asymmetric text pairs, that gives 22% and 7% gain (Accuracy@10) for retrieval task, respectively over unsupervised and supervised baselines. We also show that the topic and distributed semantic features for short and long texts improved both similarity learning and retrieval.

</details>

<details>

<summary>2018-07-08 20:28:54 - Reasoning about exceptions in ontologies: from the lexicographic closure to the skeptical closure</summary>

- *Laura Giordano, Valentina Gliozzi*

- `1807.02879v1` - [abs](http://arxiv.org/abs/1807.02879v1) - [pdf](http://arxiv.org/pdf/1807.02879v1)

> Reasoning about exceptions in ontologies is nowadays one of the challenges the description logics community is facing. The paper describes a preferential approach for dealing with exceptions in Description Logics, based on the rational closure. The rational closure has the merit of providing a simple and efficient approach for reasoning with exceptions, but it does not allow independent handling of the inheritance of different defeasible properties of concepts. In this work we outline a possible solution to this problem by introducing a variant of the lexicographical closure, that we call skeptical closure, which requires to construct a single base. We develop a bi-preference semantics semantics for defining a characterization of the skeptical closure.

</details>

<details>

<summary>2018-07-09 00:44:47 - Predicting Concreteness and Imageability of Words Within and Across Languages via Word Embeddings</summary>

- *Nikola Ljubešić, Darja Fišer, Anita Peti-Stantić*

- `1807.02903v1` - [abs](http://arxiv.org/abs/1807.02903v1) - [pdf](http://arxiv.org/pdf/1807.02903v1)

> The notions of concreteness and imageability, traditionally important in psycholinguistics, are gaining significance in semantic-oriented natural language processing tasks. In this paper we investigate the predictability of these two concepts via supervised learning, using word embeddings as explanatory variables. We perform predictions both within and across languages by exploiting collections of cross-lingual embeddings aligned to a single vector space. We show that the notions of concreteness and imageability are highly predictable both within and across languages, with a moderate loss of up to 20% in correlation when predicting across languages. We further show that the cross-lingual transfer via word embeddings is more efficient than the simple transfer via bilingual dictionaries.

</details>

<details>

<summary>2018-07-09 03:31:01 - Zero-shot Domain Adaptation without Domain Semantic Descriptors</summary>

- *Atsutoshi Kumagai, Tomoharu Iwata*

- `1807.02927v1` - [abs](http://arxiv.org/abs/1807.02927v1) - [pdf](http://arxiv.org/pdf/1807.02927v1)

> We propose a method to infer domain-specific models such as classifiers for unseen domains, from which no data are given in the training phase, without domain semantic descriptors. When training and test distributions are different, standard supervised learning methods perform poorly. Zero-shot domain adaptation attempts to alleviate this problem by inferring models that generalize well to unseen domains by using training data in multiple source domains. Existing methods use observed semantic descriptors characterizing domains such as time information to infer the domain-specific models for the unseen domains. However, it cannot always be assumed that such metadata can be used in real-world applications. The proposed method can infer appropriate domain-specific models without any semantic descriptors by introducing the concept of latent domain vectors, which are latent representations for the domains and are used for inferring the models. The latent domain vector for the unseen domain is inferred from the set of the feature vectors in the corresponding domain, which is given in the testing phase. The domain-specific models consist of two components: the first is for extracting a representation of a feature vector to be predicted, and the second is for inferring model parameters given the latent domain vector. The posterior distributions of the latent domain vectors and the domain-specific models are parametrized by neural networks, and are optimized by maximizing the variational lower bound using stochastic gradient descent. The effectiveness of the proposed method was demonstrated through experiments using one regression and two classification tasks.

</details>

<details>

<summary>2018-07-09 07:00:01 - QUICKAR: Automatic Query Reformulation for Concept Location using Crowdsourced Knowledge</summary>

- *Mohammad Masudur Rahman, Chanchal K. Roy*

- `1807.02964v1` - [abs](http://arxiv.org/abs/1807.02964v1) - [pdf](http://arxiv.org/pdf/1807.02964v1)

> During maintenance, software developers deal with numerous change requests made by the users of a software system. Studies show that the developers find it challenging to select appropriate search terms from a change request during concept location. In this paper, we propose a novel technique--QUICKAR--that automatically suggests helpful reformulations for a given query by leveraging the crowdsourced knowledge from Stack Overflow. It determines semantic similarity or relevance between any two terms by analyzing their adjacent word lists from the programming questions of Stack Overflow, and then suggests semantically relevant queries for concept location. Experiments using 510 queries from two software systems suggest that our technique can improve or preserve the quality of 76% of the initial queries on average which is promising. Comparison with one baseline technique validates our preliminary findings, and also demonstrates the potential of our technique.

</details>

<details>

<summary>2018-07-09 09:37:43 - A Sequence-to-Sequence Model for Semantic Role Labeling</summary>

- *Angel Daza, Anette Frank*

- `1807.03006v1` - [abs](http://arxiv.org/abs/1807.03006v1) - [pdf](http://arxiv.org/pdf/1807.03006v1)

> We explore a novel approach for Semantic Role Labeling (SRL) by casting it as a sequence-to-sequence process. We employ an attention-based model enriched with a copying mechanism to ensure faithful regeneration of the input sequence, while enabling interleaved generation of argument role labels. Here, we apply this model in a monolingual setting, performing PropBank SRL on English language data. The constrained sequence generation set-up enforced with the copying mechanism allows us to analyze the performance and special properties of the model on manually labeled data and benchmarking against state-of-the-art sequence labeling models. We show that our model is able to solve the SRL argument labeling task on English data, yet further structural decoding constraints will need to be added to make the model truly competitive. Our work represents a first step towards more advanced, generative SRL labeling setups.

</details>

<details>

<summary>2018-07-09 14:06:24 - Ultra-Large Repair Search Space with Automatically Mined Templates: the Cardumen Mode of Astor</summary>

- *Matias Martinez, Martin Monperrus*

- `1712.03854v2` - [abs](http://arxiv.org/abs/1712.03854v2) - [pdf](http://arxiv.org/pdf/1712.03854v2)

> Astor is a program repair library which has different modes. In this paper, we present the Cardumen mode of Astor, a repair approach based mined templates that has an ultra-large search space. We evaluate the capacity of Cardumen to discover test-suite adequate patches (aka plausible patches) over the 356 real bugs from Defects4J. Cardumen finds 8935 patches over 77 bugs of Defects4J. This is the largest number of automatically synthesized patches ever reported, all patches being available in an open-science repository. Moreover, Cardumen identifies 8 unique patches, that are patches for Defects4J bugs that were never repaired in the whole history of program repair.

</details>

<details>

<summary>2018-07-09 22:28:09 - Who is Killed by Police: Introducing Supervised Attention for Hierarchical LSTMs</summary>

- *Minh Nguyen, Thien Huu Nguyen*

- `1807.03409v1` - [abs](http://arxiv.org/abs/1807.03409v1) - [pdf](http://arxiv.org/pdf/1807.03409v1)

> Finding names of people killed by police has become increasingly important as police shootings get more and more public attention (police killing detection). Unfortunately, there has been not much work in the literature addressing this problem. The early work in this field \cite{keith2017identifying} proposed a distant supervision framework based on Expectation Maximization (EM) to deal with the multiple appearances of the names in documents. However, such EM-based framework cannot take full advantages of deep learning models, necessitating the use of hand-designed features to improve the detection performance. In this work, we present a novel deep learning method to solve the problem of police killing recognition. The proposed method relies on hierarchical LSTMs to model the multiple sentences that contain the person names of interests, and introduce supervised attention mechanisms based on semantical word lists and dependency trees to upweight the important contextual words. Our experiments demonstrate the benefits of the proposed model and yield the state-of-the-art performance for police killing detection.

</details>

<details>

<summary>2018-07-09 23:40:23 - Utility of General and Specific Word Embeddings for Classifying Translational Stages of Research</summary>

- *Vincent Major, Alisa Surkis, Yindalon Aphinyanaphongs*

- `1705.06262v2` - [abs](http://arxiv.org/abs/1705.06262v2) - [pdf](http://arxiv.org/pdf/1705.06262v2)

> Conventional text classification models make a bag-of-words assumption reducing text into word occurrence counts per document. Recent algorithms such as word2vec are capable of learning semantic meaning and similarity between words in an entirely unsupervised manner using a contextual window and doing so much faster than previous methods. Each word is projected into vector space such that similar meaning words such as "strong" and "powerful" are projected into the same general Euclidean space. Open questions about these embeddings include their utility across classification tasks and the optimal properties and source of documents to construct broadly functional embeddings. In this work, we demonstrate the usefulness of pre-trained embeddings for classification in our task and demonstrate that custom word embeddings, built in the domain and for the tasks, can improve performance over word embeddings learnt on more general data including news articles or Wikipedia.

</details>

<details>

<summary>2018-07-10 06:21:22 - Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks</summary>

- *Yu Shi, Qi Zhu, Fang Guo, Chao Zhang, Jiawei Han*

- `1807.03490v1` - [abs](http://arxiv.org/abs/1807.03490v1) - [pdf](http://arxiv.org/pdf/1807.03490v1)

> Heterogeneous information networks (HINs) are ubiquitous in real-world applications. In the meantime, network embedding has emerged as a convenient tool to mine and learn from networked data. As a result, it is of interest to develop HIN embedding methods. However, the heterogeneity in HINs introduces not only rich information but also potentially incompatible semantics, which poses special challenges to embedding learning in HINs. With the intention to preserve the rich yet potentially incompatible information in HIN embedding, we propose to study the problem of comprehensive transcription of heterogeneous information networks. The comprehensive transcription of HINs also provides an easy-to-use approach to unleash the power of HINs, since it requires no additional supervision, expertise, or feature engineering. To cope with the challenges in the comprehensive transcription of HINs, we propose the HEER algorithm, which embeds HINs via edge representations that are further coupled with properly-learned heterogeneous metrics. To corroborate the efficacy of HEER, we conducted experiments on two large-scale real-words datasets with an edge reconstruction task and multiple case studies. Experiment results demonstrate the effectiveness of the proposed HEER model and the utility of edge representations and heterogeneous metrics. The code and data are available at https://github.com/GentleZhu/HEER.

</details>

<details>

<summary>2018-07-10 07:57:41 - Practical Program Repair via Bytecode Mutation</summary>

- *Ali Ghanbari, Lingming Zhang*

- `1807.03512v1` - [abs](http://arxiv.org/abs/1807.03512v1) - [pdf](http://arxiv.org/pdf/1807.03512v1)

> Software debugging is tedious, time-consuming, and even error-prone by itself. So, various automated debugging techniques have been proposed in the literature to facilitate the debugging process. Automated Program Repair (APR) is one of the most recent advances in automated debugging, and can directly produce patches for buggy programs with minimal human intervention. Although various advanced APR techniques (including those that are either search-based or semantic-based) have been proposed, the simplistic mutation-based APR technique, which simply uses pre-defined mutation operators (e.g., changing a>=b into a>b) to mutate programs for finding patches, has not yet been thoroughly studied. In this paper, we implement the first practical bytecode-level APR technique, PraPR, and present the first extensive study on fixing real-world bugs (e.g., Defects4J bugs) using bytecode mutation. The experimental results show that surprisingly even PraPR with only the basic traditional mutators can produce genuine patches for 18 bugs. Furthermore, with our augmented mutators, PraPR is able to produce genuine patches for 43 bugs, significantly outperforming state-of-the-art APR. It is also an order of magnitude faster, indicating a promising future for bytecode-mutation-based APR.

</details>

<details>

<summary>2018-07-10 09:10:35 - Semi-Supervised Clustering with Neural Networks</summary>

- *Ankita Shukla, Gullal Singh Cheema, Saket Anand*

- `1806.01547v2` - [abs](http://arxiv.org/abs/1806.01547v2) - [pdf](http://arxiv.org/pdf/1806.01547v2)

> Clustering using neural networks has recently demonstrated promising performance in machine learning and computer vision applications. However, the performance of current approaches is limited either by unsupervised learning or their dependence on large set of labeled data samples. In this paper, we propose ClusterNet that uses pairwise semantic constraints from very few labeled data samples (<5% of total data) and exploits the abundant unlabeled data to drive the clustering approach. We define a new loss function that uses pairwise semantic similarity between objects combined with constrained k-means clustering to efficiently utilize both labeled and unlabeled data in the same framework. The proposed network uses convolution autoencoder to learn a latent representation that groups data into k specified clusters, while also learning the cluster centers simultaneously. We evaluate and compare the performance of ClusterNet on several datasets and state of the art deep clustering approaches.

</details>

<details>

<summary>2018-07-10 13:48:29 - Ontology-based multi-agent system to support business users and management</summary>

- *Dejan Lavbič, Olegas Vasilecas, Rok Rupnik*

- `1807.03646v1` - [abs](http://arxiv.org/abs/1807.03646v1) - [pdf](http://arxiv.org/pdf/1807.03646v1)

> For some decision processes a significant added value is achieved when enterprises' internal Data Warehouse (DW) can be integrated and combined with external data gained from web sites of competitors and other relevant Web sources. In this paper we discuss the agent-based integration approach using ontologies (DSS-MAS). In this approach data from internal DW and external sources are scanned by coordinated group of agents, while semantically integrated and relevant data is reported to business users according to business rules. After data from internal DW, Web sources and business rules are acquired, agents using these data and rules can infer new knowledge and therefore facilitate decision making process. Knowledge represented in enterprises' ontologies is acquired from business users without extensive technical knowledge using user friendly user interface based on constraints and predefined templates. The approach presented in the paper was verified using the case study from the domain of mobile communications with the emphasis on supply and demand of mobile phones.

</details>

<details>

<summary>2018-07-10 14:03:23 - Enriching Knowledge Bases with Counting Quantifiers</summary>

- *Paramita Mirza, Simon Razniewski, Fariz Darari, Gerhard Weikum*

- `1807.03656v1` - [abs](http://arxiv.org/abs/1807.03656v1) - [pdf](http://arxiv.org/pdf/1807.03656v1)

> Information extraction traditionally focuses on extracting relations between identifiable entities, such as <Monterey, locatedIn, California>. Yet, texts often also contain Counting information, stating that a subject is in a specific relation with a number of objects, without mentioning the objects themselves, for example, "California is divided into 58 counties". Such counting quantifiers can help in a variety of tasks such as query answering or knowledge base curation, but are neglected by prior work. This paper develops the first full-fledged system for extracting counting information from text, called CINEX. We employ distant supervision using fact counts from a knowledge base as training seeds, and develop novel techniques for dealing with several challenges: (i) non-maximal training seeds due to the incompleteness of knowledge bases, (ii) sparse and skewed observations in text sources, and (iii) high diversity of linguistic patterns. Experiments with five human-evaluated relations show that CINEX can achieve 60% average precision for extracting counting information. In a large-scale experiment, we demonstrate the potential for knowledge base enrichment by applying CINEX to 2,474 frequent relations in Wikidata. CINEX can assert the existence of 2.5M facts for 110 distinct relations, which is 28% more than the existing Wikidata facts for these relations.

</details>

<details>

<summary>2018-07-10 17:02:16 - Speculative Buffer Overflows: Attacks and Defenses</summary>

- *Vladimir Kiriansky, Carl Waldspurger*

- `1807.03757v1` - [abs](http://arxiv.org/abs/1807.03757v1) - [pdf](http://arxiv.org/pdf/1807.03757v1)

> Practical attacks that exploit speculative execution can leak confidential information via microarchitectural side channels. The recently-demonstrated Spectre attacks leverage speculative loads which circumvent access checks to read memory-resident secrets, transmitting them to an attacker using cache timing or other covert communication channels.   We introduce Spectre1.1, a new Spectre-v1 variant that leverages speculative stores to create speculative buffer overflows. Much like classic buffer overflows, speculative out-of-bounds stores can modify data and code pointers. Data-value attacks can bypass some Spectre-v1 mitigations, either directly or by redirecting control flow. Control-flow attacks enable arbitrary speculative code execution, which can bypass fence instructions and all other software mitigations for previous speculative-execution attacks. It is easy to construct return-oriented-programming (ROP) gadgets that can be used to build alternative attack payloads.   We also present Spectre1.2: on CPUs that do not enforce read/write protections, speculative stores can overwrite read-only data and code pointers to breach sandboxes.   We highlight new risks posed by these vulnerabilities, discuss possible software mitigations, and sketch microarchitectural mechanisms that could serve as hardware defenses. We have not yet evaluated the performance impact of our proposed software and hardware mitigations. We describe the salient vulnerability features and additional hypothetical attack scenarios only to the detail necessary to guide hardware and software vendors in threat analysis and mitigations. We advise users to refer to more user-friendly vendor recommendations for mitigations against speculative buffer overflows or available patches.

</details>

<details>

<summary>2018-07-10 21:45:44 - Deep Structured Generative Models</summary>

- *Kun Xu, Haoyu Liang, Jun Zhu, Hang Su, Bo Zhang*

- `1807.03877v1` - [abs](http://arxiv.org/abs/1807.03877v1) - [pdf](http://arxiv.org/pdf/1807.03877v1)

> Deep generative models have shown promising results in generating realistic images, but it is still non-trivial to generate images with complicated structures. The main reason is that most of the current generative models fail to explore the structures in the images including spatial layout and semantic relations between objects. To address this issue, we propose a novel deep structured generative model which boosts generative adversarial networks (GANs) with the aid of structure information. In particular, the layout or structure of the scene is encoded by a stochastic and-or graph (sAOG), in which the terminal nodes represent single objects and edges represent relations between objects. With the sAOG appropriately harnessed, our model can successfully capture the intrinsic structure in the scenes and generate images of complicated scenes accordingly. Furthermore, a detection network is introduced to infer scene structures from a image. Experimental results demonstrate the effectiveness of our proposed method on both modeling the intrinsic structures, and generating realistic images.

</details>

<details>

<summary>2018-07-11 04:45:59 - A Dialogue Annotation Scheme for Weight Management Chat using the Trans-Theoretical Model of Health Behavior Change</summary>

- *Ramesh Manuvinakurike, Sumanth Bharadwaj, Kallirroi Georgila*

- `1807.03948v1` - [abs](http://arxiv.org/abs/1807.03948v1) - [pdf](http://arxiv.org/pdf/1807.03948v1)

> In this study we collect and annotate human-human role-play dialogues in the domain of weight management. There are two roles in the conversation: the "seeker" who is looking for ways to lose weight and the "helper" who provides suggestions to help the "seeker" in their weight loss journey. The chat dialogues collected are then annotated with a novel annotation scheme inspired by a popular health behavior change theory called "trans-theoretical model of health behavior change". We also build classifiers to automatically predict the annotation labels used in our corpus. We find that classification accuracy improves when oracle segmentations of the interlocutors' sentences are provided compared to directly classifying unsegmented sentences.

</details>

<details>

<summary>2018-07-11 05:06:53 - Towards Understanding End-of-trip Instructions in a Taxi Ride Scenario</summary>

- *Deepthi Karkada, Ramesh Manuvinakurike, Kallirroi Georgila*

- `1807.03950v1` - [abs](http://arxiv.org/abs/1807.03950v1) - [pdf](http://arxiv.org/pdf/1807.03950v1)

> We introduce a dataset containing human-authored descriptions of target locations in an "end-of-trip in a taxi ride" scenario. We describe our data collection method and a novel annotation scheme that supports understanding of such descriptions of target locations. Our dataset contains target location descriptions for both synthetic and real-world images as well as visual annotations (ground truth labels, dimensions of vehicles and objects, coordinates of the target location,distance and direction of the target location from vehicles and objects) that can be used in various visual and language tasks. We also perform a pilot experiment on how the corpus could be applied to visual reference resolution in this domain.

</details>

<details>

<summary>2018-07-11 09:06:20 - Medusa: A Scalable Interconnect for Many-Port DNN Accelerators and Wide DRAM Controller Interfaces</summary>

- *Yongming Shen, Tianchu Ji, Michael Ferdman, Peter Milder*

- `1807.04013v1` - [abs](http://arxiv.org/abs/1807.04013v1) - [pdf](http://arxiv.org/pdf/1807.04013v1)

> To cope with the increasing demand and computational intensity of deep neural networks (DNNs), industry and academia have turned to accelerator technologies. In particular, FPGAs have been shown to provide a good balance between performance and energy efficiency for accelerating DNNs. While significant research has focused on how to build efficient layer processors, the computational building blocks of DNN accelerators, relatively little attention has been paid to the on-chip interconnects that sit between the layer processors and the FPGA's DRAM controller.   We observe a disparity between DNN accelerator interfaces, which tend to comprise many narrow ports, and FPGA DRAM controller interfaces, which tend to be wide buses. This mismatch causes traditional interconnects to consume significant FPGA resources. To address this problem, we designed Medusa: an optimized FPGA memory interconnect which transposes data in the interconnect fabric, tailoring the interconnect to the needs of DNN layer processors. Compared to a traditional FPGA interconnect, our design can reduce LUT and FF use by 4.7x and 6.0x, and improves frequency by 1.8x.

</details>

<details>

<summary>2018-07-11 14:48:02 - Linear Transformations for Cross-lingual Semantic Textual Similarity</summary>

- *Tomáš Brychcín*

- `1807.04172v1` - [abs](http://arxiv.org/abs/1807.04172v1) - [pdf](http://arxiv.org/pdf/1807.04172v1)

> Cross-lingual semantic textual similarity systems estimate the degree of the meaning similarity between two sentences, each in a different language. State-of-the-art algorithms usually employ machine translation and combine vast amount of features, making the approach strongly supervised, resource rich, and difficult to use for poorly-resourced languages.   In this paper, we study linear transformations, which project monolingual semantic spaces into a shared space using bilingual dictionaries. We propose a novel transformation, which builds on the best ideas from prior works. We experiment with unsupervised techniques for sentence similarity based only on semantic spaces and we show they can be significantly improved by the word weighting. Our transformation outperforms other methods and together with word weighting leads to very promising results on several datasets in different languages.

</details>

<details>

<summary>2018-07-11 14:51:35 - Cross-lingual Word Analogies using Linear Transformations between Semantic Spaces</summary>

- *Tomáš Brychcín, Stephen Eugene Taylor, Lukáš Svoboda*

- `1807.04175v1` - [abs](http://arxiv.org/abs/1807.04175v1) - [pdf](http://arxiv.org/pdf/1807.04175v1)

> We generalize the word analogy task across languages, to provide a new intrinsic evaluation method for cross-lingual semantic spaces. We experiment with six languages within different language families, including English, German, Spanish, Italian, Czech, and Croatian. State-of-the-art monolingual semantic spaces are transformed into a shared space using dictionaries of word translations. We compare several linear transformations and rank them for experiments with monolingual (no transformation), bilingual (one semantic space is transformed to another), and multilingual (all semantic spaces are transformed onto English space) versions of semantic spaces. We show that tested linear transformations preserve relationships between words (word analogies) and lead to impressive results. We achieve average accuracy of 51.1%, 43.1%, and 38.2% for monolingual, bilingual, and multilingual semantic spaces, respectively.

</details>

<details>

<summary>2018-07-12 15:42:18 - A segmentation-free isogeometric extended mortar contact method</summary>

- *Thang Xuan Duong, Laura De Lorenzis, Roger A. Sauer*

- `1712.01179v2` - [abs](http://arxiv.org/abs/1712.01179v2) - [pdf](http://arxiv.org/pdf/1712.01179v2)

> This paper presents a new isogeometric mortar contact formulation based on an extended finite element interpolation to capture physical pressure discontinuities at the contact boundary. The so called two-half-pass algorithm is employed, which leads to an unbiased formulation and, when applied to the mortar setting, has the additional advantage that the mortar coupling term is no longer present in the contact forces. As a result, the computationally expensive segmentation at overlapping master-slave element boundaries, usually required in mortar methods (although often simplified with loss of accuracy), is not needed from the outset. For the numerical integration of general contact problems, the so-called refined boundary quadrature is employed, which is based on adaptive partitioning of contact elements along the contact boundary. The contact patch test shows that the proposed formulation passes the test without using either segmentation or refined boundary quadrature. Several numerical examples are presented to demonstrate the robustness and accuracy of the proposed formulation.

</details>

<details>

<summary>2018-07-12 16:14:24 - Symbolic Verification of Cache Side-channel Freedom</summary>

- *Sudipta Chattopadhyay, Abhik Roychoudhury*

- `1807.04701v1` - [abs](http://arxiv.org/abs/1807.04701v1) - [pdf](http://arxiv.org/pdf/1807.04701v1)

> Cache timing attacks allow third-party observers to retrieve sensitive information from program executions. But, is it possible to automatically check the vulnerability of a program against cache timing attacks and then, automatically shield program executions against these attacks? For a given program, a cache configuration and an attack model, our CACHEFIX framework either verifies the cache side-channel freedom of the program or synthesizes a series of patches to ensure cache side-channel freedom during program execution. At the core of our framework is a novel symbolic verification technique based on automated abstraction refinement of cache semantics. The power of such a framework is to allow symbolic reasoning over counterexample traces and to combine it with runtime monitoring for eliminating cache side channels during program execution. Our evaluation with routines from OpenSSL, libfixedtimefixedpoint, GDK and FourQlib libraries reveals that our CACHEFIX approach (dis)proves cache sidechannel freedom within an average of 75 seconds. Besides, in all except one case, CACHEFIX synthesizes all patches within 20 minutes to ensure cache side-channel freedom of the respective routines during execution.

</details>

<details>

<summary>2018-07-12 20:42:04 - Measuring and Computing Database Inconsistency via Repairs</summary>

- *Leopoldo Bertossi*

- `1804.08834v3` - [abs](http://arxiv.org/abs/1804.08834v3) - [pdf](http://arxiv.org/pdf/1804.08834v3)

> We propose a generic numerical measure of inconsistency of a database with respect to a set of integrity constraints. It is based on an abstract repair semantics. A particular inconsistency measure associated to cardinality-repairs is investigated; and we show that it can be computed via answer-set programs.   Keywords: Integrity constraints in databases, inconsistent databases, database repairs, inconsistency measure.

</details>

<details>

<summary>2018-07-13 10:01:19 - A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification</summary>

- *Zeyang Lei, Yujiu Yang, Min Yang, Yi Liu*

- `1807.04990v1` - [abs](http://arxiv.org/abs/1807.04990v1) - [pdf](http://arxiv.org/pdf/1807.04990v1)

> Deep learning approaches for sentiment classification do not fully exploit sentiment linguistic knowledge. In this paper, we propose a Multi-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the problem by integrating three kinds of sentiment linguistic knowledge (e.g., sentiment lexicon, negation words, intensity words) into the deep neural network via attention mechanisms. By using various types of sentiment resources, MEAN utilizes sentiment-relevant information from different representation subspaces, which makes it more effective to capture the overall semantics of the sentiment, negation and intensity words for sentiment prediction. The experimental results demonstrate that MEAN has robust superiority over strong competitors.

</details>

<details>

<summary>2018-07-13 13:58:58 - Smart buildings as Cyber-Physical Systems: Data-driven predictive control strategies for energy efficiency</summary>

- *Mischa Schmidt, Christer Åhlund*

- `1807.06084v1` - [abs](http://arxiv.org/abs/1807.06084v1) - [pdf](http://arxiv.org/pdf/1807.06084v1)

> Due to its significant contribution to global energy usage and the associated greenhouse gas emissions, existing building stock's energy efficiency must improve. Predictive building control promises to contribute to that by increasing the efficiency of building operations. Predictive control complements other means to increase performance such as refurbishments as well as modernizations of systems. This survey reviews recent works and contextualizes these with the current state of the art of interrelated topics in data handling, building automation, distributed control, and semantics. The comprehensive overview leads to seven research questions guiding future research directions.

</details>

<details>

<summary>2018-07-13 23:56:14 - Abstract: Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients</summary>

- *Imon Banerjee, Michael Francis Gensheimer, Douglas J. Wood, Solomon Henry, Daniel Chang, Daniel L. Rubin*

- `1801.03058v2` - [abs](http://arxiv.org/abs/1801.03058v2) - [pdf](http://arxiv.org/pdf/1801.03058v2)

> We propose a deep learning model - Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met) for estimating short-term life expectancy (3 months) of the patients by analyzing free-text clinical notes in the electronic medical record, while maintaining the temporal visit sequence. In a single framework, we integrated semantic data mapping and neural embedding technique to produce a text processing method that extracts relevant information from heterogeneous types of clinical notes in an unsupervised manner, and we designed a recurrent neural network to model the temporal dependency of the patient visits. The model was trained on a large dataset (10,293 patients) and validated on a separated dataset (1818 patients). Our method achieved an area under the ROC curve (AUC) of 0.89. To provide explain-ability, we developed an interactive graphical tool that may improve physician understanding of the basis for the model's predictions. The high accuracy and explain-ability of the PPES-Met model may enable our model to be used as a decision support tool to personalize metastatic cancer treatment and provide valuable assistance to the physicians.

</details>

<details>

<summary>2018-07-14 03:24:31 - Generating Synthetic Data for Neural Keyword-to-Question Models</summary>

- *Heng Ding, Krisztian Balog*

- `1807.05324v1` - [abs](http://arxiv.org/abs/1807.05324v1) - [pdf](http://arxiv.org/pdf/1807.05324v1)

> Search typically relies on keyword queries, but these are often semantically ambiguous. We propose to overcome this by offering users natural language questions, based on their keyword queries, to disambiguate their intent. This keyword-to-question task may be addressed using neural machine translation techniques. Neural translation models, however, require massive amounts of training data (keyword-question pairs), which is unavailable for this task. The main idea of this paper is to generate large amounts of synthetic training data from a small seed set of hand-labeled keyword-question pairs. Since natural language questions are available in large quantities, we develop models to automatically generate the corresponding keyword queries. Further, we introduce various filtering mechanisms to ensure that synthetic training data is of high quality. We demonstrate the feasibility of our approach using both automatic and manual evaluation. This is an extended version of the article published with the same title in the Proceedings of ICTIR'18.

</details>

<details>

<summary>2018-07-14 08:07:31 - ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies</summary>

- *Gustavo Correa Publio, Diego Esteves, Agnieszka Ławrynowicz, Panče Panov, Larisa Soldatova, Tommaso Soru, Joaquin Vanschoren, Hamid Zafar*

- `1807.05351v1` - [abs](http://arxiv.org/abs/1807.05351v1) - [pdf](http://arxiv.org/pdf/1807.05351v1)

> The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.

</details>

<details>

<summary>2018-07-15 09:36:39 - Concept-Based Embeddings for Natural Language Processing</summary>

- *Yukun Ma, Erik Cambria*

- `1807.05519v1` - [abs](http://arxiv.org/abs/1807.05519v1) - [pdf](http://arxiv.org/pdf/1807.05519v1)

> In this work, we focus on effectively leveraging and integrating information from concept-level as well as word-level via projecting concepts and words into a lower dimensional space while retaining most critical semantics. In a broad context of opinion understanding system, we investigate the use of the fused embedding for several core NLP tasks: named entity detection and classification, automatic speech recognition reranking, and targeted sentiment analysis.

</details>

<details>

<summary>2018-07-15 16:49:06 - WordNet-Based Information Retrieval Using Common Hypernyms and Combined Features</summary>

- *Vuong M. Ngo, Tru H. Cao, Tuan M. V. Le*

- `1807.05574v1` - [abs](http://arxiv.org/abs/1807.05574v1) - [pdf](http://arxiv.org/pdf/1807.05574v1)

> Text search based on lexical matching of keywords is not satisfactory due to polysemous and synonymous words. Semantic search that exploits word meanings, in general, improves search performance. In this paper, we survey WordNet-based information retrieval systems, which employ a word sense disambiguation method to process queries and documents. The problem is that in many cases a word has more than one possible direct sense, and picking only one of them may give a wrong sense for the word. Moreover, the previous systems use only word forms to represent word senses and their hypernyms. We propose a novel approach that uses the most specific common hypernym of the remaining undisambiguated multi-senses of a word, as well as combined WordNet features to represent word meanings. Experiments on a benchmark dataset show that, in terms of the MAP measure, our search engine is 17.7% better than the lexical search, and at least 9.4% better than all surveyed search systems using WordNet.   Keywords Ontology, word sense disambiguation, semantic annotation, semantic search.

</details>

<details>

<summary>2018-07-15 17:20:54 - Ontology-Based Query Expansion with Latently Related Named Entities for Semantic Text Search</summary>

- *Vuong M. Ngo, Tru H. Cao*

- `1807.05579v1` - [abs](http://arxiv.org/abs/1807.05579v1) - [pdf](http://arxiv.org/pdf/1807.05579v1)

> Traditional information retrieval systems represent documents and queries by keyword sets. However, the content of a document or a query is mainly defined by both keywords and named entities occurring in it. Named entities have ontological features, namely, their aliases, classes, and identifiers, which are hidden from their textual appearance. Besides, the meaning of a query may imply latent named entities that are related to the apparent ones in the query. We propose an ontology-based generalized vector space model to semantic text search. It exploits ontological features of named entities and their latently related ones to reveal the semantics of documents and queries. We also propose a framework to combine different ontologies to take their complementary advantages for semantic annotation and searching. Experiments on a benchmark dataset show better search quality of our model to other ones.

</details>

<details>

<summary>2018-07-15 19:15:41 - Deep Learning for Semantic Segmentation on Minimal Hardware</summary>

- *Sander G. van Dijk, Marcus M. Scheunemann*

- `1807.05597v1` - [abs](http://arxiv.org/abs/1807.05597v1) - [pdf](http://arxiv.org/pdf/1807.05597v1)

> Deep learning has revolutionised many fields, but it is still challenging to transfer its success to small mobile robots with minimal hardware. Specifically, some work has been done to this effect in the RoboCup humanoid football domain, but results that are performant and efficient and still generally applicable outside of this domain are lacking. We propose an approach conceptually different from those taken previously. It is based on semantic segmentation and does achieve these desired properties. In detail, it is being able to process full VGA images in real-time on a low-power mobile processor. It can further handle multiple image dimensions without retraining, it does not require specific domain knowledge for achieving a high frame rate and it is applicable on a minimal mobile hardware.

</details>

<details>

<summary>2018-07-15 23:48:59 - Cross Pixel Optical Flow Similarity for Self-Supervised Learning</summary>

- *Aravindh Mahendran, James Thewlis, Andrea Vedaldi*

- `1807.05636v1` - [abs](http://arxiv.org/abs/1807.05636v1) - [pdf](http://arxiv.org/pdf/1807.05636v1)

> We propose a novel method for learning convolutional neural image representations without manual supervision. We use motion cues in the form of optical flow, to supervise representations of static images. The obvious approach of training a network to predict flow from a single image can be needlessly difficult due to intrinsic ambiguities in this prediction task. We instead propose a much simpler learning goal: embed pixels such that the similarity between their embeddings matches that between their optical flow vectors. At test time, the learned deep network can be used without access to video or flow information and transferred to tasks such as image classification, detection, and segmentation. Our method, which significantly simplifies previous attempts at using motion for self-supervision, achieves state-of-the-art results in self-supervision using motion cues, competitive results for self-supervision in general, and is overall state of the art in self-supervised pretraining for semantic image segmentation, as demonstrated on standard benchmarks.

</details>

<details>

<summary>2018-07-16 05:24:37 - Pair-Linking for Collective Entity Disambiguation: Two Could Be Better Than All</summary>

- *Minh C. Phan, Aixin Sun, Yi Tay, Jialong Han, Chenliang Li*

- `1802.01074v3` - [abs](http://arxiv.org/abs/1802.01074v3) - [pdf](http://arxiv.org/pdf/1802.01074v3)

> Collective entity disambiguation aims to jointly resolve multiple mentions by linking them to their associated entities in a knowledge base. Previous works are primarily based on the underlying assumption that entities within the same document are highly related. However, the extend to which these mentioned entities are actually connected in reality is rarely studied and therefore raises interesting research questions. For the first time, we show that the semantic relationships between the mentioned entities are in fact less dense than expected. This could be attributed to several reasons such as noise, data sparsity and knowledge base incompleteness. As a remedy, we introduce MINTREE, a new tree-based objective for the entity disambiguation problem. The key intuition behind MINTREE is the concept of coherence relaxation which utilizes the weight of a minimum spanning tree to measure the coherence between entities. Based on this new objective, we design a novel entity disambiguation algorithms which we call Pair-Linking. Instead of considering all the given mentions, Pair-Linking iteratively selects a pair with the highest confidence at each step for decision making. Via extensive experiments, we show that our approach is not only more accurate but also surprisingly faster than many state-of-the-art collective linking algorithms.

</details>

<details>

<summary>2018-07-16 08:36:06 - Datalog-based Scalable Semantic Diffing of Concurrent Programs</summary>

- *Chungha Sung, Shuvendu Lahiri, Constantin Enea, Chao Wang*

- `1807.03777v2` - [abs](http://arxiv.org/abs/1807.03777v2) - [pdf](http://arxiv.org/pdf/1807.03777v2)

> When an evolving program is modified to address issues related to thread synchronization, there is a need to confirm the change is correct, i.e., it does not introduce unexpected behavior. However, manually comparing two programs to identify the semantic difference is labor intensive and error prone, whereas techniques based on model checking are computationally expensive. To fill the gap, we develop a fast and approximate static analysis for computing synchronization differences of two programs. The method is fast because, instead of relying on heavy-weight model checking techniques, it leverages a polynomial-time Datalog-based program analysis framework to compute differentiating data-flow edges, i.e., edges allowed by one program but not the other. Although approximation is used our method is sufficiently accurate due to careful design of the Datalog inference rules and iterative increase of the required data-flow edges for representing a difference. We have implemented our method and evaluated it on a large number of multithreaded C programs to confirm its ability to produce, often within seconds, the same differences obtained by human; in contrast, prior techniques based on model checking take minutes or even hours and thus can be 10x to 1000x slower.

</details>

<details>

<summary>2018-07-16 14:58:30 - Incorporating Glosses into Neural Word Sense Disambiguation</summary>

- *Fuli Luo, Tianyu Liu, Qiaolin Xia, Baobao Chang, Zhifang Sui*

- `1805.08028v2` - [abs](http://arxiv.org/abs/1805.08028v2) - [pdf](http://arxiv.org/pdf/1805.08028v2)

> Word Sense Disambiguation (WSD) aims to identify the correct meaning of polysemous words in the particular context. Lexical resources like WordNet which are proved to be of great help for WSD in the knowledge-based methods. However, previous neural networks for WSD always rely on massive labeled data (context), ignoring lexical resources like glosses (sense definitions). In this paper, we integrate the context and glosses of the target word into a unified framework in order to make full use of both labeled data and lexical knowledge. Therefore, we propose GAS: a gloss-augmented WSD neural network which jointly encodes the context and glosses of the target word. GAS models the semantic relationship between the context and the gloss in an improved memory network framework, which breaks the barriers of the previous supervised methods and knowledge-based methods. We further extend the original gloss of word sense via its semantic relations in WordNet to enrich the gloss information. The experimental results show that our model outperforms the state-of-theart systems on several English all-words WSD datasets.

</details>

<details>

<summary>2018-07-16 15:01:01 - Uncertainty and Interpretability in Convolutional Neural Networks for Semantic Segmentation of Colorectal Polyps</summary>

- *Kristoffer Wickstrøm, Michael Kampffmeyer, Robert Jenssen*

- `1807.10584v1` - [abs](http://arxiv.org/abs/1807.10584v1) - [pdf](http://arxiv.org/pdf/1807.10584v1)

> Convolutional Neural Networks (CNNs) are propelling advances in a range of different computer vision tasks such as object detection and object segmentation. Their success has motivated research in applications of such models for medical image analysis. If CNN-based models are to be helpful in a medical context, they need to be precise, interpretable, and uncertainty in predictions must be well understood. In this paper, we develop and evaluate recent advances in uncertainty estimation and model interpretability in the context of semantic segmentation of polyps from colonoscopy images. We evaluate and enhance several architectures of Fully Convolutional Networks (FCNs) for semantic segmentation of colorectal polyps and provide a comparison between these models. Our highest performing model achieves a 76.06\% mean IOU accuracy on the EndoScene dataset, a considerable improvement over the previous state-of-the-art.

</details>

<details>

<summary>2018-07-16 18:04:08 - Pangloss: Fast Entity Linking in Noisy Text Environments</summary>

- *Michael Conover, Matthew Hayes, Scott Blackburn, Pete Skomoroch, Sam Shah*

- `1807.06036v1` - [abs](http://arxiv.org/abs/1807.06036v1) - [pdf](http://arxiv.org/pdf/1807.06036v1)

> Entity linking is the task of mapping potentially ambiguous terms in text to their constituent entities in a knowledge base like Wikipedia. This is useful for organizing content, extracting structured data from textual documents, and in machine learning relevance applications like semantic search, knowledge graph construction, and question answering. Traditionally, this work has focused on text that has been well-formed, like news articles, but in common real world datasets such as messaging, resumes, or short-form social media, non-grammatical, loosely-structured text adds a new dimension to this problem.   This paper presents Pangloss, a production system for entity disambiguation on noisy text. Pangloss combines a probabilistic linear-time key phrase identification algorithm with a semantic similarity engine based on context-dependent document embeddings to achieve better than state-of-the-art results (>5% in F1) compared to other research or commercially available systems. In addition, Pangloss leverages a local embedded database with a tiered architecture to house its statistics and metadata, which allows rapid disambiguation in streaming contexts and on-device disambiguation in low-memory environments such as mobile phones.

</details>

<details>

<summary>2018-07-17 08:13:19 - Bench-Marking Information Extraction in Semi-Structured Historical Handwritten Records</summary>

- *Animesh Prasad, Hervé Déjean, Jean-Luc Meunier, Max Weidemann, Johannes Michael, Gundram Leifert*

- `1807.06270v1` - [abs](http://arxiv.org/abs/1807.06270v1) - [pdf](http://arxiv.org/pdf/1807.06270v1)

> In this report, we present our findings from benchmarking experiments for information extraction on historical handwritten marriage records Esposalles from IEHHR - ICDAR 2017 robust reading competition. The information extraction is modeled as semantic labeling of the sequence across 2 set of labels. This can be achieved by sequentially or jointly applying handwritten text recognition (HTR) and named entity recognition (NER). We deploy a pipeline approach where first we use state-of-the-art HTR and use its output as input for NER. We show that given low resource setup and simple structure of the records, high performance of HTR ensures overall high performance. We explore the various configurations of conditional random fields and neural networks to benchmark NER on given certain noisy input. The best model on 10-fold cross-validation as well as blind test data uses n-gram features with bidirectional long short-term memory.

</details>

<details>

<summary>2018-07-17 10:57:26 - Machine Translation using Semantic Web Technologies: A Survey</summary>

- *Diego Moussallem, Matthias Wauer, Axel-Cyrille Ngonga Ngomo*

- `1711.09476v3` - [abs](http://arxiv.org/abs/1711.09476v3) - [pdf](http://arxiv.org/pdf/1711.09476v3)

> A large number of machine translation approaches have recently been developed to facilitate the fluid migration of content across languages. However, the literature suggests that many obstacles must still be dealt with to achieve better automatic translations. One of these obstacles is lexical and syntactic ambiguity. A promising way of overcoming this problem is using Semantic Web technologies. This article presents the results of a systematic review of machine translation approaches that rely on Semantic Web technologies for translating texts. Overall, our survey suggests that while Semantic Web technologies can enhance the quality of machine translation outputs for various problems, the combination of both is still in its infancy.

</details>

<details>

<summary>2018-07-17 16:00:35 - Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing</summary>

- *Osman Ramadan, Paweł Budzianowski, Milica Gašić*

- `1807.06517v1` - [abs](http://arxiv.org/abs/1807.06517v1) - [pdf](http://arxiv.org/pdf/1807.06517v1)

> Robust dialogue belief tracking is a key component in maintaining good quality dialogue systems. The tasks that dialogue systems are trying to solve are becoming increasingly complex, requiring scalability to multi domain, semantically rich dialogues. However, most current approaches have difficulty scaling up with domains because of the dependency of the model parameters on the dialogue ontology. In this paper, a novel approach is introduced that fully utilizes semantic similarity between dialogue utterances and the ontology terms, allowing the information to be shared across domains. The evaluation is performed on a recently collected multi-domain dialogues dataset, one order of magnitude larger than currently available corpora. Our model demonstrates great capability in handling multi-domain dialogues, simultaneously outperforming existing state-of-the-art models in single-domain dialogue tracking tasks.

</details>

<details>

<summary>2018-07-17 17:59:39 - Using semantic clustering to support situation awareness on Twitter: The case of World Views</summary>

- *Charlie Kingston, Jason R. C. Nurse, Ioannis Agrafiotis, Andrew Milich*

- `1807.06588v1` - [abs](http://arxiv.org/abs/1807.06588v1) - [pdf](http://arxiv.org/pdf/1807.06588v1)

> In recent years, situation awareness has been recognised as a critical part of effective decision making, in particular for crisis management. One way to extract value and allow for better situation awareness is to develop a system capable of analysing a dataset of multiple posts, and clustering consistent posts into different views or stories (or, world views). However, this can be challenging as it requires an understanding of the data, including determining what is consistent data, and what data corroborates other data. Attempting to address these problems, this article proposes Subject-Verb-Object Semantic Suffix Tree Clustering (SVOSSTC) and a system to support it, with a special focus on Twitter content. The novelty and value of SVOSSTC is its emphasis on utilising the Subject-Verb-Object (SVO) typology in order to construct semantically consistent world views, in which individuals---particularly those involved in crisis response---might achieve an enhanced picture of a situation from social media data. To evaluate our system and its ability to provide enhanced situation awareness, we tested it against existing approaches, including human data analysis, using a variety of real-world scenarios. The results indicated a noteworthy degree of evidence (e.g., in cluster granularity and meaningfulness) to affirm the suitability and rigour of our approach. Moreover, these results highlight this article's proposals as innovative and practical system contributions to the research field.

</details>

<details>

<summary>2018-07-18 04:08:21 - UNet++: A Nested U-Net Architecture for Medical Image Segmentation</summary>

- *Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, Jianming Liang*

- `1807.10165v1` - [abs](http://arxiv.org/abs/1807.10165v1) - [pdf](http://arxiv.org/pdf/1807.10165v1)

> In this paper, we present UNet++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose CT scans of chest, nuclei segmentation in the microscopy images, liver segmentation in abdominal CT scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.

</details>

<details>

<summary>2018-07-18 09:58:50 - The Contextual Loss for Image Transformation with Non-Aligned Data</summary>

- *Roey Mechrez, Itamar Talmi, Lihi Zelnik-Manor*

- `1803.02077v4` - [abs](http://arxiv.org/abs/1803.02077v4) - [pdf](http://arxiv.org/pdf/1803.02077v4)

> Feed-forward CNNs trained for image transformation problems rely on loss functions that measure the similarity between the generated image and a target image. Most of the common loss functions assume that these images are spatially aligned and compare pixels at corresponding locations. However, for many tasks, aligned training pairs of images will not be available. We present an alternative loss function that does not require alignment, thus providing an effective and simple solution for a new space of problems. Our loss is based on both context and semantics -- it compares regions with similar semantic meaning, while considering the context of the entire image. Hence, for example, when transferring the style of one face to another, it will translate eyes-to-eyes and mouth-to-mouth. Our code can be found at https://www.github.com/roimehrez/contextualLoss

</details>

<details>

<summary>2018-07-18 19:10:45 - Semantic Parsing: Syntactic assurance to target sentence using LSTM Encoder CFG-Decoder</summary>

- *Fabiano Ferreira Luz, Marcelo Finger*

- `1807.07108v1` - [abs](http://arxiv.org/abs/1807.07108v1) - [pdf](http://arxiv.org/pdf/1807.07108v1)

> Semantic parsing can be defined as the process of mapping natural language sentences into a machine interpretable, formal representation of its meaning. Semantic parsing using LSTM encoder-decoder neural networks have become promising approach. However, human automated translation of natural language does not provide grammaticality guarantees for the sentences generate such a guarantee is particularly important for practical cases where a data base query can cause critical errors if the sentence is ungrammatical. In this work, we propose an neural architecture called Encoder CFG-Decoder, whose output conforms to a given context-free grammar. Results are show for any implementation of such architecture display its correctness and providing benchmark accuracy levels better than the literature.

</details>

<details>

<summary>2018-07-19 10:07:54 - Deep Reinforcement Learning for Chinese Zero pronoun Resolution</summary>

- *Qingyu Yin, Yu Zhang, Weinan Zhang, Ting Liu, William Yang Wang*

- `1806.03711v2` - [abs](http://arxiv.org/abs/1806.03711v2) - [pdf](http://arxiv.org/pdf/1806.03711v2)

> Deep neural network models for Chinese zero pronoun resolution learn semantic information for zero pronoun and candidate antecedents, but tend to be short-sighted---they often make local decisions. They typically predict coreference chains between the zero pronoun and one single candidate antecedent one link at a time, while overlooking their long-term influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is critical when later predicting zero pronoun-candidate antecedent pairs. In this study, we show how to integrate local and global decision-making by exploiting deep reinforcement learning models. With the help of the reinforcement learning agent, our model learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 dataset show that our technique surpasses the state-of-the-art models.

</details>

<details>

<summary>2018-07-19 12:07:50 - EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand Ultrasound Imaging without External Trackers</summary>

- *Bishesh Khanal, Alberto Gomez, Nicolas Toussaint, Steven McDonagh, Veronika Zimmer, Emily Skelton, Jacqueline Matthew, Daniel Grzech, Robert Wright, Chandni Gupta, Benjamin Hou, Daniel Rueckert, Julia A. Schnabel, Bernhard Kainz*

- `1807.10583v1` - [abs](http://arxiv.org/abs/1807.10583v1) - [pdf](http://arxiv.org/pdf/1807.10583v1)

> Ultrasound (US) is the most widely used fetal imaging technique. However, US images have limited capture range, and suffer from view dependent artefacts such as acoustic shadows. Compounding of overlapping 3D US acquisitions into a high-resolution volume can extend the field of view and remove image artefacts, which is useful for retrospective analysis including population based studies. However, such volume reconstructions require information about relative transformations between probe positions from which the individual volumes were acquired. In prenatal US scans, the fetus can move independently from the mother, making external trackers such as electromagnetic or optical tracking unable to track the motion between probe position and the moving fetus. We provide a novel methodology for image-based tracking and volume reconstruction by combining recent advances in deep learning and simultaneous localisation and mapping (SLAM). Tracking semantics are established through the use of a Residual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of concept, experiments are conducted on US volumes taken from a whole body fetal phantom, and from the heads of real fetuses. For the fetal head segmentation, we also introduce a novel weak annotation approach to minimise the required manual effort for ground truth annotation. We evaluate our method qualitatively, and quantitatively with respect to tissue discrimination accuracy and tracking robustness.

</details>

<details>

<summary>2018-07-20 03:45:04 - R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering</summary>

- *Pan Lu, Lei Ji, Wei Zhang, Nan Duan, Ming Zhou, Jianyong Wang*

- `1805.09701v2` - [abs](http://arxiv.org/abs/1805.09701v2) - [pdf](http://arxiv.org/pdf/1805.09701v2)

> Recently, Visual Question Answering (VQA) has emerged as one of the most significant tasks in multimodal learning as it requires understanding both visual and textual modalities. Existing methods mainly rely on extracting image and question features to learn their joint feature embedding via multimodal fusion or attention mechanism. Some recent studies utilize external VQA-independent models to detect candidate entities or attributes in images, which serve as semantic knowledge complementary to the VQA task. However, these candidate entities or attributes might be unrelated to the VQA task and have limited semantic capacities. To better utilize semantic knowledge in images, we propose a novel framework to learn visual relation facts for VQA. Specifically, we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset via a semantic similarity module, in which each data consists of an image, a corresponding question, a correct answer and a supporting relation fact. A well-defined relation detector is then adopted to predict visual question-related relation facts. We further propose a multi-step attention model composed of visual attention and semantic attention sequentially to extract related visual knowledge and semantic knowledge. We conduct comprehensive experiments on the two benchmark datasets, demonstrating that our model achieves state-of-the-art performance and verifying the benefit of considering visual relation facts.

</details>

<details>

<summary>2018-07-20 07:35:43 - Question-Aware Sentence Gating Networks for Question and Answering</summary>

- *Minjeong Kim, David Keetae Park, Hyungjong Noh, Yeonsoo Lee, Jaegul Choo*

- `1807.07964v1` - [abs](http://arxiv.org/abs/1807.07964v1) - [pdf](http://arxiv.org/pdf/1807.07964v1)

> Machine comprehension question answering, which finds an answer to the question given a passage, involves high-level reasoning processes of understanding and tracking the relevant contents across various semantic units such as words, phrases, and sentences in a document. This paper proposes the novel question-aware sentence gating networks that directly incorporate the sentence-level information into word-level encoding processes. To this end, our model first learns question-aware sentence representations and then dynamically combines them with word-level representations, resulting in semantically meaningful word representations for QA tasks. Experimental results demonstrate that our approach consistently improves the accuracy over existing baseline approaches on various QA datasets and bears the wide applicability to other neural network-based QA models.

</details>

<details>

<summary>2018-07-20 12:06:06 - Competition vs. Concatenation in Skip Connections of Fully Convolutional Networks</summary>

- *Santiago Estrada, Sailesh Conjeti, Muneer Ahmad, Nassir Navab, Martin Reuter*

- `1807.07803v1` - [abs](http://arxiv.org/abs/1807.07803v1) - [pdf](http://arxiv.org/pdf/1807.07803v1)

> Increased information sharing through short and long-range skip connections between layers in fully convolutional networks have demonstrated significant improvement in performance for semantic segmentation. In this paper, we propose Competitive Dense Fully Convolutional Networks (CDFNet) by introducing competitive maxout activations in place of naive feature concatenation for inducing competition amongst layers. Within CDFNet, we propose two architectural contributions, namely competitive dense block (CDB) and competitive unpooling block (CUB) to induce competition at local and global scales for short and long-range skip connections respectively. This extension is demonstrated to boost learning of specialized sub-networks targeted at segmenting specific anatomies, which in turn eases the training of complex tasks. We present the proof-of-concept on the challenging task of whole body segmentation in the publicly available VISCERAL benchmark and demonstrate improved performance over multiple learning and registration based state-of-the-art methods.

</details>

<details>

<summary>2018-07-20 16:56:40 - Spectre Returns! Speculation Attacks using the Return Stack Buffer</summary>

- *Esmaeil Mohammadian Koruyeh, Khaled Khasawneh, Chengyu Song, Nael Abu-Ghazaleh*

- `1807.07940v1` - [abs](http://arxiv.org/abs/1807.07940v1) - [pdf](http://arxiv.org/pdf/1807.07940v1)

> The recent Spectre attacks exploit speculative execution, a pervasively used feature of modern microprocessors, to allow the exfiltration of sensitive data across protection boundaries. In this paper, we introduce a new Spectre-class attack that we call SpectreRSB. In particular, rather than exploiting the branch predictor unit, SpectreRSB exploits the return stack buffer (RSB), a common predictor structure in modern CPUs used to predict return addresses. We show that both local attacks (within the same process such as Spectre 1) and attacks on SGX are possible by constructing proof of concept attacks. We also analyze additional types of the attack on the kernel or across address spaces and show that under some practical and widely used conditions they are possible. Importantly, none of the known defenses including Retpoline and Intel's microcode patches stop all SpectreRSB attacks. We believe that future system developers should be aware of this vulnerability and consider it in developing defenses against speculation attacks. In particular, on Core-i7 Skylake and newer processors (but not on Intel's Xeon processor line), a patch called RSB refilling is used to address a vulnerability when the RSB underfills; this defense interferes with SpectreRSB's ability to launch attacks that switch into the kernel. We recommend that this patch should be used on all machines to protect against SpectreRSB.

</details>

<details>

<summary>2018-07-20 17:31:06 - Future Semantic Segmentation with Convolutional LSTM</summary>

- *Seyed shahabeddin Nabavi, Mrigank Rochan, Yang, Wang*

- `1807.07946v1` - [abs](http://arxiv.org/abs/1807.07946v1) - [pdf](http://arxiv.org/pdf/1807.07946v1)

> We consider the problem of predicting semantic segmentation of future frames in a video. Given several observed frames in a video, our goal is to predict the semantic segmentation map of future frames that are not yet observed. A reliable solution to this problem is useful in many applications that require real-time decision making, such as autonomous driving. We propose a novel model that uses convolutional LSTM (ConvLSTM) to encode the spatiotemporal information of observed frames for future prediction. We also extend our model to use bidirectional ConvLSTM to capture temporal information in both directions. Our proposed approach outperforms other state-of-the-art methods on the benchmark dataset.

</details>

<details>

<summary>2018-07-20 17:45:14 - On the Automatic Generation of Medical Imaging Reports</summary>

- *Baoyu Jing, Pengtao Xie, Eric Xing*

- `1711.08195v3` - [abs](http://arxiv.org/abs/1711.08195v3) - [pdf](http://arxiv.org/pdf/1711.08195v3)

> Medical imaging is widely used in clinical practice for diagnosis and treatment. Report-writing can be error-prone for unexperienced physicians, and time- consuming and tedious for experienced physicians. To address these issues, we study the automatic generation of medical imaging reports. This task presents several challenges. First, a complete report contains multiple heterogeneous forms of information, including findings and tags. Second, abnormal regions in medical images are difficult to identify. Third, the re- ports are typically long, containing multiple sentences. To cope with these challenges, we (1) build a multi-task learning framework which jointly performs the pre- diction of tags and the generation of para- graphs, (2) propose a co-attention mechanism to localize regions containing abnormalities and generate narrations for them, (3) develop a hierarchical LSTM model to generate long paragraphs. We demonstrate the effectiveness of the proposed methods on two publicly available datasets.

</details>

<details>

<summary>2018-07-20 18:26:29 - Knowledge Integration for Disease Characterization: A Breast Cancer Example</summary>

- *Oshani Seneviratne, Sabbir M. Rashid, Shruthi Chari, James P. McCusker, Kristin P. Bennett, James A. Hendler, Deborah L. McGuinness*

- `1807.07991v1` - [abs](http://arxiv.org/abs/1807.07991v1) - [pdf](http://arxiv.org/pdf/1807.07991v1)

> With the rapid advancements in cancer research, the information that is useful for characterizing disease, staging tumors, and creating treatment and survivorship plans has been changing at a pace that creates challenges when physicians try to remain current. One example involves increasing usage of biomarkers when characterizing the pathologic prognostic stage of a breast tumor. We present our semantic technology approach to support cancer characterization and demonstrate it in our end-to-end prototype system that collects the newest breast cancer staging criteria from authoritative oncology manuals to construct an ontology for breast cancer. Using a tool we developed that utilizes this ontology, physician-facing applications can be used to quickly stage a new patient to support identifying risks, treatment options, and monitoring plans based on authoritative and best practice guidelines. Physicians can also re-stage existing patients or patient populations, allowing them to find patients whose stage has changed in a given patient cohort. As new guidelines emerge, using our proposed mechanism, which is grounded by semantic technologies for ingesting new data from staging manuals, we have created an enriched cancer staging ontology that integrates relevant data from several sources with very little human intervention.

</details>

<details>

<summary>2018-07-22 22:50:34 - A Computational Theory for Life-Long Learning of Semantics</summary>

- *Peter Sutor Jr., Douglas Summers-Stay, Yiannis Aloimonos*

- `1806.10755v2` - [abs](http://arxiv.org/abs/1806.10755v2) - [pdf](http://arxiv.org/pdf/1806.10755v2)

> Semantic vectors are learned from data to express semantic relationships between elements of information, for the purpose of solving and informing downstream tasks. Other models exist that learn to map and classify supervised data. However, the two worlds of learning rarely interact to inform one another dynamically, whether across types of data or levels of semantics, in order to form a unified model. We explore the research problem of learning these vectors and propose a framework for learning the semantics of knowledge incrementally and online, across multiple mediums of data, via binary vectors. We discuss the aspects of this framework to spur future research on this approach and problem.

</details>

<details>

<summary>2018-07-23 04:41:57 - Stacked Cross Attention for Image-Text Matching</summary>

- *Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He*

- `1803.08024v2` - [abs](http://arxiv.org/abs/1803.08024v2) - [pdf](http://arxiv.org/pdf/1803.08024v2)

> In this paper, we study the problem of image-text matching. Inferring the latent semantic alignment between objects or other salient stuff (e.g. snow, sky, lawn) and the corresponding words in sentences allows to capture fine-grained interplay between vision and language, and makes image-text matching more interpretable. Prior work either simply aggregates the similarity of all possible pairs of regions and words without attending differentially to more and less important words or regions, or uses a multi-step attentional process to capture limited number of semantic alignments which is less interpretable. In this paper, we present Stacked Cross Attention to discover the full latent alignments using both image regions and words in a sentence as context and infer image-text similarity. Our approach achieves the state-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K, our approach outperforms the current best methods by 22.1% relatively in text retrieval from image query, and 18.2% relatively in image retrieval with text query (based on Recall@1). On MS-COCO, our approach improves sentence retrieval by 17.8% relatively and image retrieval by 16.6% relatively (based on Recall@1 using the 5K test set). Code has been made available at: https://github.com/kuanghuei/SCAN.

</details>

<details>

<summary>2018-07-23 05:11:23 - Actor-Action Semantic Segmentation with Region Masks</summary>

- *Kang Dang, Chunluan Zhou, Zhigang Tu, Michael Hoy, Justin Dauwels, Junsong Yuan*

- `1807.08430v1` - [abs](http://arxiv.org/abs/1807.08430v1) - [pdf](http://arxiv.org/pdf/1807.08430v1)

> In this paper, we study the actor-action semantic segmentation problem, which requires joint labeling of both actor and action categories in video frames. One major challenge for this task is that when an actor performs an action, different body parts of the actor provide different types of cues for the action category and may receive inconsistent action labeling when they are labeled independently. To address this issue, we propose an end-to-end region-based actor-action segmentation approach which relies on region masks from an instance segmentation algorithm. Our main novelty is to avoid labeling pixels in a region mask independently - instead we assign a single action label to these pixels to achieve consistent action labeling. When a pixel belongs to multiple region masks, max pooling is applied to resolve labeling conflicts. Our approach uses a two-stream network as the front-end (which learns features capturing both appearance and motion information), and uses two region-based segmentation networks as the back-end (which takes the fused features from the two-stream network as the input and predicts actor-action labeling). Experiments on the A2D dataset demonstrate that both the region-based segmentation strategy and the fused features from the two-stream network contribute to the performance improvements. The proposed approach outperforms the state-of-the-art results by more than 8% in mean class accuracy, and more than 5% in mean class IOU, which validates its effectiveness.

</details>

<details>

<summary>2018-07-23 06:55:23 - Learning to Play Pong using Policy Gradient Learning</summary>

- *Somnuk Phon-Amnuaisuk*

- `1807.08452v1` - [abs](http://arxiv.org/abs/1807.08452v1) - [pdf](http://arxiv.org/pdf/1807.08452v1)

> Activities in reinforcement learning (RL) revolve around learning the Markov decision process (MDP) model, in particular, the following parameters: state values, V; state-action values, Q; and policy, pi. These parameters are commonly implemented as an array. Scaling up the problem means scaling up the size of the array and this will quickly lead to a computational bottleneck. To get around this, the RL problem is commonly formulated to learn a specific task using hand-crafted input features to curb the size of the array. In this report, we discuss an alternative end-to-end Deep Reinforcement Learning (DRL) approach where the DRL attempts to learn general task representations which in our context refers to learning to play the Pong game from a sequence of screen snapshots without game-specific hand-crafted features. We apply artificial neural networks (ANN) to approximate a policy of the RL model. The policy network, via Policy Gradients (PG) method, learns to play the Pong game from a sequence of frames without any extra semantics apart from the pixel information and the score. In contrast to the traditional tabular RL approach where the contents in the array have clear interpretations such as V or Q, the interpretation of knowledge content from the weights of the policy network is more illusive. In this work, we experiment with various Deep ANN architectures i.e., Feed forward ANN (FFNN), Convolution ANN (CNN) and Asynchronous Advantage Actor-Critic (A3C). We also examine the activation of hidden nodes and the weights between the input and the hidden layers, before and after the DRL has successfully learnt to play the Pong game. Insights into the internal learning mechanisms and future research directions are then discussed.

</details>

<details>

<summary>2018-07-23 13:01:09 - Clafer: Lightweight Modeling of Structure, Behaviour, and Variability</summary>

- *Paulius Juodisius, Atrisha Sarkar, Raghava Rao Mukkamala, Michal Antkiewicz, Krzysztof Czarnecki, Andrzej Wasowski*

- `1807.08576v1` - [abs](http://arxiv.org/abs/1807.08576v1) - [pdf](http://arxiv.org/pdf/1807.08576v1)

> Embedded software is growing fast in size and complexity, leading to intimate mixture of complex architectures and complex control. Consequently, software specification requires modeling both structures and behaviour of systems. Unfortunately, existing languages do not integrate these aspects well, usually prioritizing one of them. It is common to develop a separate language for each of these facets. In this paper, we contribute Clafer: a small language that attempts to tackle this challenge. It combines rich structural modeling with state of the art behavioural formalisms. We are not aware of any other modeling language that seamlessly combines these facets common to system and software modeling. We show how Clafer, in a single unified syntax and semantics, allows capturing feature models (variability), component models, discrete control models (automata) and variability encompassing all these aspects. The language is built on top of first order logic with quantifiers over basic entities (for modeling structures) combined with linear temporal logic (for modeling behaviour). On top of this semantic foundation we build a simple but expressive syntax, enriched with carefully selected syntactic expansions that cover hierarchical modeling, associations, automata, scenarios, and Dwyer's property patterns. We evaluate Clafer using a power window case study, and comparing it against other notations that substantially overlap with its scope (SysML, AADL, Temporal OCL and Live Sequence Charts), discussing benefits and perils of using a single notation for the purpose.

</details>

<details>

<summary>2018-07-23 13:31:51 - 3D Convolutional Neural Networks for Tumor Segmentation using Long-range 2D Context</summary>

- *Pawel Mlynarski, Hervé Delingette, Antonio Criminisi, Nicholas Ayache*

- `1807.08599v1` - [abs](http://arxiv.org/abs/1807.08599v1) - [pdf](http://arxiv.org/pdf/1807.08599v1)

> We present an efficient deep learning approach for the challenging task of tumor segmentation in multisequence MR images. In recent years, Convolutional Neural Networks (CNN) have achieved state-of-the-art performances in a large variety of recognition tasks in medical imaging. Because of the considerable computational cost of CNNs, large volumes such as MRI are typically processed by subvolumes, for instance slices (axial, coronal, sagittal) or small 3D patches. In this paper we introduce a CNN-based model which efficiently combines the advantages of the short-range 3D context and the long-range 2D context. To overcome the limitations of specific choices of neural network architectures, we also propose to merge outputs of several cascaded 2D-3D models by a voxelwise voting strategy. Furthermore, we propose a network architecture in which the different MR sequences are processed by separate subnetworks in order to be more robust to the problem of missing MR sequences. Finally, a simple and efficient algorithm for training large CNN models is introduced. We evaluate our method on the public benchmark of the BRATS 2017 challenge on the task of multiclass segmentation of malignant brain tumors. Our method achieves good performances and produces accurate segmentations with median Dice scores of 0.918 (whole tumor), 0.883 (tumor core) and 0.854 (enhancing core). Our approach can be naturally applied to various tasks involving segmentation of lesions or organs.

</details>

<details>

<summary>2018-07-23 16:42:57 - Clearing noisy annotations for computed tomography imaging</summary>

- *Roman Khudorozhkov, Alexander Koryagin, Alexey Kozhevin*

- `1807.09151v1` - [abs](http://arxiv.org/abs/1807.09151v1) - [pdf](http://arxiv.org/pdf/1807.09151v1)

> One of the problems on the way to successful implementation of neural networks is the quality of annotation. For instance, different annotators can annotate images in a different way and very often their decisions do not match exactly and in extreme cases are even mutually exclusive which results in noisy annotations and, consequently, inaccurate predictions.   To avoid that problem in the task of computed tomography (CT) imaging segmentation we propose a clearing algorithm for annotations. It consists of 3 stages:   - annotators scoring, which assigns a higher confidence level to better annotators;   - nodules scoring, which assigns a higher confidence level to nodules confirmed by good annotators;   - nodules merging, which aggregates annotations according to nodules confidence.   In general, the algorithm can be applied to many different tasks (namely, binary and multi-class semantic segmentation, and also with trivial adjustments to classification and regression) where there are several annotators labeling each image.

</details>

<details>

<summary>2018-07-23 18:26:40 - Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer</summary>

- *David Berthelot, Colin Raffel, Aurko Roy, Ian Goodfellow*

- `1807.07543v2` - [abs](http://arxiv.org/abs/1807.07543v2) - [pdf](http://arxiv.org/pdf/1807.07543v2)

> Autoencoders provide a powerful framework for learning compressed representations by encoding all of the information needed to reconstruct a data point in a latent code. In some cases, autoencoders can "interpolate": By decoding the convex combination of the latent codes for two datapoints, the autoencoder can produce an output which semantically mixes characteristics from the datapoints. In this paper, we propose a regularization procedure which encourages interpolated outputs to appear more realistic by fooling a critic network which has been trained to recover the mixing coefficient from interpolated data. We then develop a simple benchmark task where we can quantitatively measure the extent to which various autoencoders can interpolate and show that our regularizer dramatically improves interpolation in this setting. We also demonstrate empirically that our regularizer produces latent codes which are more effective on downstream tasks, suggesting a possible link between interpolation abilities and learning useful representations.

</details>

<details>

<summary>2018-07-23 19:29:19 - Effective Reformulation of Query for Code Search using Crowdsourced Knowledge and Extra-Large Data Analytics</summary>

- *Mohammad Masudur Rahman, Chanchal K. Roy*

- `1807.08798v1` - [abs](http://arxiv.org/abs/1807.08798v1) - [pdf](http://arxiv.org/pdf/1807.08798v1)

> Software developers frequently issue generic natural language queries for code search while using code search engines (e.g., GitHub native search, Krugle). Such queries often do not lead to any relevant results due to vocabulary mismatch problems. In this paper, we propose a novel technique that automatically identifies relevant and specific API classes from Stack Overflow Q & A site for a programming task written as a natural language query, and then reformulates the query for improved code search. We first collect candidate API classes from Stack Overflow using pseudo-relevance feedback and two term weighting algorithms, and then rank the candidates using Borda count and semantic proximity between query keywords and the API classes. The semantic proximity has been determined by an analysis of 1.3 million questions and answers of Stack Overflow. Experiments using 310 code search queries report that our technique suggests relevant API classes with 48% precision and 58% recall which are 32% and 48% higher respectively than those of the state-of-the-art. Comparisons with two state-of-the-art studies and three popular search engines (e.g., Google, Stack Overflow, and GitHub native search) report that our reformulated queries (1) outperform the queries of the state-of-the-art, and (2) significantly improve the code search results provided by these contemporary search engines.

</details>

<details>

<summary>2018-07-23 20:22:15 - Object category learning and retrieval with weak supervision</summary>

- *Steven Hickson, Anelia Angelova, Irfan Essa, Rahul Sukthankar*

- `1801.08985v2` - [abs](http://arxiv.org/abs/1801.08985v2) - [pdf](http://arxiv.org/pdf/1801.08985v2)

> We consider the problem of retrieving objects from image data and learning to classify them into meaningful semantic categories with minimal supervision. To that end, we propose a fully differentiable unsupervised deep clustering approach to learn semantic classes in an end-to-end fashion without individual class labeling using only unlabeled object proposals. The key contributions of our work are 1) a kmeans clustering objective where the clusters are learned as parameters of the network and are represented as memory units, and 2) simultaneously building a feature representation, or embedding, while learning to cluster it. This approach shows promising results on two popular computer vision datasets: on CIFAR10 for clustering objects, and on the more complex and challenging Cityscapes dataset for semantically discovering classes which visually correspond to cars, people, and bicycles. Currently, the only supervision provided is segmentation objectness masks, but this method can be extended to use an unsupervised objectness-based object generation mechanism which will make the approach completely unsupervised.

</details>

<details>

<summary>2018-07-23 23:12:16 - Toward a language-theoretic foundation for planning and filtering</summary>

- *Fatemeh Zahra Saberifar, Shervin Ghasemlou, Dylan A. Shell, Jason M. O'Kane*

- `1807.08856v1` - [abs](http://arxiv.org/abs/1807.08856v1) - [pdf](http://arxiv.org/pdf/1807.08856v1)

> We address problems underlying the algorithmic question of automating the co-design of robot hardware in tandem with its apposite software. Specifically, we consider the impact that degradations of a robot's sensor and actuation suites may have on the ability of that robot to complete its tasks. We introduce a new formal structure that generalizes and consolidates a variety of well-known structures including many forms of plans, planning problems, and filters, into a single data structure called a procrustean graph, and give these graph structures semantics in terms of ideas based in formal language theory. We describe a collection of operations on procrustean graphs (both semantics-preserving and semantics-mutating), and show how a family of questions about the destructiveness of a change to the robot hardware can be answered by applying these operations. We also highlight the connections between this new approach and existing threads of research, including combinatorial filtering, Erdmann's strategy complexes, and hybrid automata.

</details>

<details>

<summary>2018-07-24 04:14:51 - Understanding and representing the semantics of large structured documents</summary>

- *Muhammad Mahbubur Rahman, Tim Finin*

- `1807.09842v1` - [abs](http://arxiv.org/abs/1807.09842v1) - [pdf](http://arxiv.org/pdf/1807.09842v1)

> Understanding large, structured documents like scholarly articles, requests for proposals or business reports is a complex and difficult task. It involves discovering a document's overall purpose and subject(s), understanding the function and meaning of its sections and subsections, and extracting low level entities and facts about them. In this research, we present a deep learning based document ontology to capture the general purpose semantic structure and domain specific semantic concepts from a large number of academic articles and business documents. The ontology is able to describe different functional parts of a document, which can be used to enhance semantic indexing for a better understanding by human beings and machines. We evaluate our models through extensive experiments on datasets of scholarly articles from arXiv and Request for Proposal documents.

</details>

<details>

<summary>2018-07-24 08:19:43 - Generalizable Data-free Objective for Crafting Universal Adversarial Perturbations</summary>

- *Konda Reddy Mopuri, Aditya Ganeshan, R. Venkatesh Babu*

- `1801.08092v3` - [abs](http://arxiv.org/abs/1801.08092v3) - [pdf](http://arxiv.org/pdf/1801.08092v3)

> Machine learning models are susceptible to adversarial perturbations: small changes to input that can cause large changes in output. It is also demonstrated that there exist input-agnostic perturbations, called universal adversarial perturbations, which can change the inference of target model on most of the data samples. However, existing methods to craft universal perturbations are (i) task specific, (ii) require samples from the training data distribution, and (iii) perform complex optimizations. Additionally, because of the data dependence, fooling ability of the crafted perturbations is proportional to the available training data. In this paper, we present a novel, generalizable and data-free approaches for crafting universal adversarial perturbations. Independent of the underlying task, our objective achieves fooling via corrupting the extracted features at multiple layers. Therefore, the proposed objective is generalizable to craft image-agnostic perturbations across multiple vision tasks such as object recognition, semantic segmentation, and depth estimation. In the practical setting of black-box attack scenario (when the attacker does not have access to the target model and it's training data), we show that our objective outperforms the data dependent objectives to fool the learned models. Further, via exploiting simple priors related to the data distribution, our objective remarkably boosts the fooling ability of the crafted perturbations. Significant fooling rates achieved by our objective emphasize that the current deep learning models are now at an increased risk, since our objective generalizes across multiple tasks without the requirement of training data for crafting the perturbations. To encourage reproducible research, we have released the codes for our proposed algorithm.

</details>

<details>

<summary>2018-07-24 23:06:49 - Domain Stylization: A Strong, Simple Baseline for Synthetic to Real Image Domain Adaptation</summary>

- *Aysegul Dundar, Ming-Yu Liu, Ting-Chun Wang, John Zedlewski, Jan Kautz*

- `1807.09384v1` - [abs](http://arxiv.org/abs/1807.09384v1) - [pdf](http://arxiv.org/pdf/1807.09384v1)

> Deep neural networks have largely failed to effectively utilize synthetic data when applied to real images due to the covariate shift problem. In this paper, we show that by applying a straightforward modification to an existing photorealistic style transfer algorithm, we achieve state-of-the-art synthetic-to-real domain adaptation results. We conduct extensive experimental validations on four synthetic-to-real tasks for semantic segmentation and object detection, and show that our approach exceeds the performance of any current state-of-the-art GAN-based image translation approach as measured by segmentation and object detection metrics. Furthermore we offer a distance based analysis of our method which shows a dramatic reduction in Frechet Inception distance between the source and target domains, offering a quantitative metric that demonstrates the effectiveness of our algorithm in bridging the synthetic-to-real gap.

</details>

<details>

<summary>2018-07-25 04:34:17 - Distinctive-attribute Extraction for Image Captioning</summary>

- *Boeun Kim, Young Han Lee, Hyedong Jung, Choongsang Cho*

- `1807.09434v1` - [abs](http://arxiv.org/abs/1807.09434v1) - [pdf](http://arxiv.org/pdf/1807.09434v1)

> Image captioning, an open research issue, has been evolved with the progress of deep neural networks. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are employed to compute image features and generate natural language descriptions in the research. In previous works, a caption involving semantic description can be generated by applying additional information into the RNNs. In this approach, we propose a distinctive-attribute extraction (DaE) which explicitly encourages significant meanings to generate an accurate caption describing the overall meaning of the image with their unique situation. Specifically, the captions of training images are analyzed by term frequency-inverse document frequency (TF-IDF), and the analyzed semantic information is trained to extract distinctive-attributes for inferring captions. The proposed scheme is evaluated on a challenge data, and it improves an objective performance while describing images in more detail.

</details>

<details>

<summary>2018-07-25 08:36:02 - Judging a Book by its Description : Analyzing Gender Stereotypes in the Man Bookers Prize Winning Fiction</summary>

- *Nishtha Madaan, Sameep Mehta, Shravika Mittal, Ashima Suvarna*

- `1807.10615v1` - [abs](http://arxiv.org/abs/1807.10615v1) - [pdf](http://arxiv.org/pdf/1807.10615v1)

> The presence of gender stereotypes in many aspects of society is a well-known phenomenon. In this paper, we focus on studying and quantifying such stereotypes and bias in the Man Bookers Prize winning fiction. We consider 275 books shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias is analyzed by semantic modeling of book descriptions on Goodreads. This reveals the pervasiveness of gender bias and stereotype in the books on different features like occupation, introductions and actions associated to the characters in the book.

</details>

<details>

<summary>2018-07-25 08:56:09 - Object-oriented Neural Programming (OONP) for Document Understanding</summary>

- *Zhengdong Lu, Xianggen Liu, Haotian Cui, Yukun Yan, Daqi Zheng*

- `1709.08853v6` - [abs](http://arxiv.org/abs/1709.08853v6) - [pdf](http://arxiv.org/pdf/1709.08853v6)

> We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure (referred to as ontology in this paper) that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and during the process it builds and updates an intermediate ontology to summarize its partial understanding of the text it covers. OONP supports a rich family of operations (both symbolic and differentiable) for composing the ontology, and a big variety of forms (both symbolic and differentiable) for representing the state and the document. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL) , reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes.

</details>

<details>

<summary>2018-07-25 10:06:35 - Learning Eligibility in Cancer Clinical Trials using Deep Neural Networks</summary>

- *Aurelia Bustos, Antonio Pertusa*

- `1803.08312v3` - [abs](http://arxiv.org/abs/1803.08312v3) - [pdf](http://arxiv.org/pdf/1803.08312v3)

> Interventional cancer clinical trials are generally too restrictive, and some patients are often excluded on the basis of comorbidity, past or concomitant treatments, or the fact that they are over a certain age. The efficacy and safety of new treatments for patients with these characteristics are, therefore, not defined. In this work, we built a model to automatically predict whether short clinical statements were considered inclusion or exclusion criteria. We used protocols from cancer clinical trials that were available in public registries from the last 18 years to train word-embeddings, and we constructed a~dataset of 6M short free-texts labeled as eligible or not eligible. A text classifier was trained using deep neural networks, with pre-trained word-embeddings as inputs, to predict whether or not short free-text statements describing clinical information were considered eligible. We additionally analyzed the semantic reasoning of the word-embedding representations obtained and were able to identify equivalent treatments for a type of tumor analogous with the drugs used to treat other tumors. We show that representation learning using {deep} neural networks can be successfully leveraged to extract the medical knowledge from clinical trial protocols for potentially assisting practitioners when prescribing treatments.

</details>

<details>

<summary>2018-07-25 13:42:47 - NegPSpan: efficient extraction of negative sequential patterns with embedding constraints</summary>

- *Thomas Guyet, René Quiniou*

- `1804.01256v2` - [abs](http://arxiv.org/abs/1804.01256v2) - [pdf](http://arxiv.org/pdf/1804.01256v2)

> Mining frequent sequential patterns consists in extracting recurrent behaviors, modeled as patterns, in a big sequence dataset. Such patterns inform about which events are frequently observed in sequences, i.e. what does really happen. Sometimes, knowing that some specific event does not happen is more informative than extracting a lot of observed events. Negative sequential patterns (NSP) formulate recurrent behaviors by patterns containing both observed events and absent events. Few approaches have been proposed to mine such NSPs. In addition, the syntax and semantics of NSPs differ in the different methods which makes it difficult to compare them. This article provides a unified framework for the formulation of the syntax and the semantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts NSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that other approaches do not take into account. The formal framework allows for highlighting the differences between the proposed approach wrt to the methods from the literature, especially wrt the state of the art approach eNSP. Intensive experiments on synthetic and real datasets show that NegPSpan can extract meaningful NSPs and that it can process bigger datasets than eNSP thanks to significantly lower memory requirements and better computation times.

</details>

<details>

<summary>2018-07-25 15:42:01 - A Novel ILP Framework for Summarizing Content with High Lexical Variety</summary>

- *Wencan Luo, Fei Liu, Zitao Liu, Diane Litman*

- `1807.09671v1` - [abs](http://arxiv.org/abs/1807.09671v1) - [pdf](http://arxiv.org/pdf/1807.09671v1)

> Summarizing content contributed by individuals can be challenging, because people make different lexical choices even when describing the same events. However, there remains a significant need to summarize such content. Examples include the student responses to post-class reflective questions, product reviews, and news articles published by different news agencies related to the same events. High lexical diversity of these documents hinders the system's ability to effectively identify salient content and reduce summary redundancy. In this paper, we overcome this issue by introducing an integer linear programming-based summarization framework. It incorporates a low-rank approximation to the sentence-word co-occurrence matrix to intrinsically group semantically-similar lexical items. We conduct extensive experiments on datasets of student responses, product reviews, and news documents. Our approach compares favorably to a number of extractive baselines as well as a neural abstractive summarization system. The paper finally sheds light on when and why the proposed framework is effective at summarizing content with high lexical variety.

</details>

<details>

<summary>2018-07-25 16:26:15 - Objects that Sound</summary>

- *Relja Arandjelović, Andrew Zisserman*

- `1712.06651v2` - [abs](http://arxiv.org/abs/1712.06651v2) - [pdf](http://arxiv.org/pdf/1712.06651v2)

> In this paper our objectives are, first, networks that can embed audio and visual inputs into a common space that is suitable for cross-modal retrieval; and second, a network that can localize the object that sounds in an image, given the audio signal. We achieve both these objectives by training from unlabelled video using only audio-visual correspondence (AVC) as the objective function. This is a form of cross-modal self-supervision from video.   To this end, we design new network architectures that can be trained for cross-modal retrieval and localizing the sound source in an image, by using the AVC task. We make the following contributions: (i) show that audio and visual embeddings can be learnt that enable both within-mode (e.g. audio-to-audio) and between-mode retrieval; (ii) explore various architectures for the AVC task, including those for the visual stream that ingest a single image, or multiple images, or a single image and multi-frame optical flow; (iii) show that the semantic object that sounds within an image can be localized (using only the sound, no motion or flow information); and (iv) give a cautionary tale on how to avoid undesirable shortcuts in the data preparation.

</details>

<details>

<summary>2018-07-25 19:30:43 - Towards Enhancing Lexical Resource and Using Sense-annotations of OntoSenseNet for Sentiment Analysis</summary>

- *Sreekavitha Parupalli, Vijjini Anvesh Rao, Radhika Mamidi*

- `1807.03004v2` - [abs](http://arxiv.org/abs/1807.03004v2) - [pdf](http://arxiv.org/pdf/1807.03004v2)

> This paper illustrates the interface of the tool we developed for crowd sourcing and we explain the annotation procedure in detail. Our tool is named as 'Parupalli Padajaalam' which means web of words by Parupalli. The aim of this tool is to populate the OntoSenseNet, sentiment polarity annotated Telugu resource. Recent works have shown the importance of word-level annotations on sentiment analysis. With this as basis, we aim to analyze the importance of sense-annotations obtained from OntoSenseNet in performing the task of sentiment analysis. We explain the fea- tures extracted from OntoSenseNet (Telugu). Furthermore we compute and explain the adverbial class distribution of verbs in OntoSenseNet. This task is known to aid in disambiguating word-senses which helps in enhancing the performance of word-sense disambiguation (WSD) task(s).

</details>

<details>

<summary>2018-07-26 13:11:51 - Term Set Expansion based on Multi-Context Term Embeddings: an End-to-end Workflow</summary>

- *Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Ido Dagan, Yoav Goldberg, Alon Eirew, Yael Green, Shira Guskin, Peter Izsak, Daniel Korat*

- `1807.10104v1` - [abs](http://arxiv.org/abs/1807.10104v1) - [pdf](http://arxiv.org/pdf/1807.10104v1)

> We present SetExpander, a corpus-based system for expanding a seed set of terms into a more complete set of terms that belong to the same semantic class. SetExpander implements an iterative end-to end workflow for term set expansion. It enables users to easily select a seed set of terms, expand it, view the expanded set, validate it, re-expand the validated set and store it, thus simplifying the extraction of domain-specific fine-grained semantic classes. SetExpander has been used for solving real-life use cases including integration in an automated recruitment system and an issues and defects resolution system. A video demo of SetExpander is available at https://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images were blurred for privacy reasons).

</details>

<details>

<summary>2018-07-26 18:17:19 - Semantically Meaningful View Selection</summary>

- *Joris Guérin, Olivier Gibaru, Eric Nyiri, Stéphane Thiery, Byron Boots*

- `1807.10303v1` - [abs](http://arxiv.org/abs/1807.10303v1) - [pdf](http://arxiv.org/pdf/1807.10303v1)

> An understanding of the nature of objects could help robots to solve both high-level abstract tasks and improve performance at lower-level concrete tasks. Although deep learning has facilitated progress in image understanding, a robot's performance in problems like object recognition often depends on the angle from which the object is observed. Traditionally, robot sorting tasks rely on a fixed top-down view of an object. By changing its viewing angle, a robot can select a more semantically informative view leading to better performance for object recognition. In this paper, we introduce the problem of semantic view selection, which seeks to find good camera poses to gain semantic knowledge about an observed object. We propose a conceptual formulation of the problem, together with a solvable relaxation based on clustering. We then present a new image dataset consisting of around 10k images representing various views of 144 objects under different poses. Finally we use this dataset to propose a first solution to the problem by training a neural network to predict a "semantic score" from a top view image and camera pose. The views predicted to have higher scores are then shown to provide better clustering results than fixed top-down views.

</details>

<details>

<summary>2018-07-27 03:08:32 - Identifying Patch Correctness in Test-Based Program Repair</summary>

- *Yingfei Xiong, Xinyuan Liu, Muhan Zeng, Lu Zhang, Gang Huang*

- `1706.09120v3` - [abs](http://arxiv.org/abs/1706.09120v3) - [pdf](http://arxiv.org/pdf/1706.09120v3)

> Test-based automatic program repair has attracted a lot of attention in recent years. However, the test suites in practice are often too weak to guarantee correctness and existing approaches often generate a large number of incorrect patches.   To reduce the number of incorrect patches generated, we propose a novel approach that heuristically determines the correctness of the generated patches. The core idea is to exploit the behavior similarity of test case executions. The passing tests on original and patched programs are likely to behave similarly while the failing tests on original and patched programs are likely to behave differently. Also, if two tests exhibit similar runtime behavior, the two tests are likely to have the same test results. Based on these observations, we generate new test inputs to enhance the test suites and use their behavior similarity to determine patch correctness.   Our approach is evaluated on a dataset consisting of 139 patches generated from existing program repair systems including jGenProg, Nopol, jKali, ACS and HDRepair. Our approach successfully prevented 56.3\% of the incorrect patches to be generated, without blocking any correct patches.

</details>

<details>

<summary>2018-07-27 03:29:41 - Understanding V2V Driving Scenarios through Traffic Primitives</summary>

- *Wenshuo Wang, Weiyang Zhang, Ding Zhao*

- `1807.10422v1` - [abs](http://arxiv.org/abs/1807.10422v1) - [pdf](http://arxiv.org/pdf/1807.10422v1)

> Semantically understanding complex drivers' encountering behavior, wherein two or multiple vehicles are spatially close to each other, does potentially benefit autonomous car's decision-making design. This paper presents a framework of analyzing various encountering behaviors through decomposing driving encounter data into small building blocks, called driving primitives, using nonparametric Bayesian learning (NPBL) approaches, which offers a flexible way to gain an insight into the complex driving encounters without any prerequisite knowledge. The effectiveness of our proposed primitive-based framework is validated based on 976 naturalistic driving encounters, from which more than 4000 driving primitives are learned using NPBL - a sticky HDP-HMM, combined a hidden Markov model (HMM) with a hierarchical Dirichlet process (HDP). After that, a dynamic time warping method integrated with k-means clustering is then developed to cluster all these extracted driving primitives into groups. Experimental results find that there exist 20 kinds of driving primitives capable of representing the basic components of driving encounters in our database. This primitive-based analysis methodology potentially reveals underlying information of vehicle-vehicle encounters for self-driving applications.

</details>

<details>

<summary>2018-07-27 09:45:04 - Global and local evaluation of link prediction tasks with neural embeddings</summary>

- *Asan Agibetov, Matthias Samwald*

- `1807.10511v1` - [abs](http://arxiv.org/abs/1807.10511v1) - [pdf](http://arxiv.org/pdf/1807.10511v1)

> We focus our attention on the link prediction problem for knowledge graphs, which is treated herein as a binary classification task on neural embeddings of the entities. By comparing, combining and extending different methodologies for link prediction on graph-based data coming from different domains, we formalize a unified methodology for the quality evaluation benchmark of neural embeddings for knowledge graphs. This benchmark is then used to empirically investigate the potential of training neural embeddings globally for the entire graph, as opposed to the usual way of training embeddings locally for a specific relation. This new way of testing the quality of the embeddings evaluates the performance of binary classifiers for scalable link prediction with limited data. Our evaluation pipeline is made open source, and with this we aim to draw more attention of the community towards an important issue of transparency and reproducibility of the neural embeddings evaluations.

</details>

<details>

<summary>2018-07-27 19:07:33 - Improving Neural Sequence Labelling using Additional Linguistic Information</summary>

- *Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer*

- `1807.10805v1` - [abs](http://arxiv.org/abs/1807.10805v1) - [pdf](http://arxiv.org/pdf/1807.10805v1)

> Sequence labelling is the task of assigning categorical labels to a data sequence. In Natural Language Processing, sequence labelling can be applied to various fundamental problems, such as Part of Speech (POS) tagging, Named Entity Recognition (NER), and Chunking. In this study, we propose a method to add various linguistic features to the neural sequence framework to improve sequence labelling. Besides word level knowledge, sense embeddings are added to provide semantic information. Additionally, selective readings of character embeddings are added to capture contextual as well as morphological features for each word in a sentence. Compared to previous methods, these added linguistic features allow us to design a more concise model and perform more efficient training. Our proposed architecture achieves state of the art results on the benchmark datasets of POS, NER, and chunking. Moreover, the convergence rate of our model is significantly better than the previous state of the art models.

</details>

<details>

<summary>2018-07-29 08:06:19 - Artificial Impostors for Location Privacy Preservation</summary>

- *Cheng Wang, Zhiyang Xie*

- `1801.06827v3` - [abs](http://arxiv.org/abs/1801.06827v3) - [pdf](http://arxiv.org/pdf/1801.06827v3)

> The progress of location-based services has led to serious concerns on location privacy leakage. For effective and efficient location privacy preservation (LPP), existing methods are still not fully competent. They are often vulnerable under the identification attack with side information, or hard to be implemented due to the high computational complexity. In this paper, we pursue the high protection efficacy and low computational complexity simultaneously. We propose a scalable LPP method based on the paradigm of counterfeiting locations. To make fake locations extremely plausible, we forge them through synthesizing artificial impostors (AIs). The AIs refer to the synthesized traces which have similar semantic features to the actual traces, and do not contain any target location. Two dedicated techniques are devised: the sampling-based synthesis method and population-level semantic model. They play significant roles in two critical steps of synthesizing AIs. We conduct experiments on real datasets in two cities (Shanghai, China and Asturias, Spain) to validate the high efficacy and scalability of the proposed method. In these two datasets, the experimental results show that our method achieves the preservation efficacy of $97.65\%$ and $96.12\%$, and its run time of building the generators is only $230.47$ and $215.92$ seconds, respectively. This study would give the research community new insights into improving the practicality of the state-of-the-art LPP paradigm via counterfeiting locations.

</details>

<details>

<summary>2018-07-29 08:42:30 - Discovering Latent Information By Spreading Activation Algorithm For Document Retrieval</summary>

- *Vuong M. Ngo*

- `1808.01968v1` - [abs](http://arxiv.org/abs/1808.01968v1) - [pdf](http://arxiv.org/pdf/1808.01968v1)

> Syntactic search relies on keywords contained in a query to find suitable documents. So, documents that do not contain the keywords but contain information related to the query are not retrieved. Spreading activation is an algorithm for finding latent information in a query by exploiting relations between nodes in an associative network or semantic network. However, the classical spreading activation algorithm uses all relations of a node in the network that will add unsuitable information into the query. In this paper, we propose a novel approach for semantic text search, called query-oriented-constrained spreading activation that only uses relations relating to the content of the query to find really related information. Experiments on a benchmark dataset show that, in terms of the MAP measure, our search engine is 18.9% and 43.8% respectively better than the syntactic search and the search using the classical constrained spreading activation.   KEYWORDS: Information Retrieval, Ontology, Semantic Search, Spreading Activation

</details>

<details>

<summary>2018-07-29 19:11:57 - VSE++: Improving Visual-Semantic Embeddings with Hard Negatives</summary>

- *Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler*

- `1707.05612v4` - [abs](http://arxiv.org/abs/1707.05612v4) - [pdf](http://arxiv.org/pdf/1707.05612v4)

> We present a new technique for learning visual-semantic embeddings for cross-modal retrieval. Inspired by hard negative mining, the use of hard negatives in structured prediction, and ranking loss functions, we introduce a simple change to common loss functions used for multi-modal embeddings. That, combined with fine-tuning and use of augmented data, yields significant gains in retrieval performance. We showcase our approach, VSE++, on MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8% in caption retrieval and 11.3% in image retrieval (at R@1).

</details>

<details>

<summary>2018-07-29 21:45:35 - Reinforced Auto-Zoom Net: Towards Accurate and Fast Breast Cancer Segmentation in Whole-slide Images</summary>

- *Nanqing Dong, Michael Kampffmeyer, Xiaodan Liang, Zeya Wang, Wei Dai, Eric P. Xing*

- `1807.11113v1` - [abs](http://arxiv.org/abs/1807.11113v1) - [pdf](http://arxiv.org/pdf/1807.11113v1)

> Convolutional neural networks have led to significant breakthroughs in the domain of medical image analysis. However, the task of breast cancer segmentation in whole-slide images (WSIs) is still underexplored. WSIs are large histopathological images with extremely high resolution. Constrained by the hardware and field of view, using high-magnification patches can slow down the inference process and using low-magnification patches can cause the loss of information. In this paper, we aim to achieve two seemingly conflicting goals for breast cancer segmentation: accurate and fast prediction. We propose a simple yet efficient framework Reinforced Auto-Zoom Net (RAZN) to tackle this task. Motivated by the zoom-in operation of a pathologist using a digital microscope, RAZN learns a policy network to decide whether zooming is required in a given region of interest. Because the zoom-in action is selective, RAZN is robust to unbalanced and noisy ground truth labels and can efficiently reduce overfitting. We evaluate our method on a public breast cancer dataset. RAZN outperforms both single-scale and multi-scale baseline approaches, achieving better accuracy at low inference cost.

</details>

<details>

<summary>2018-07-30 08:33:13 - Concurrent Learning of Semantic Relations</summary>

- *Georgios Balikas, Gaël Dias, Rumen Moraliyski, Massih-Reza Amini*

- `1807.10076v3` - [abs](http://arxiv.org/abs/1807.10076v3) - [pdf](http://arxiv.org/pdf/1807.10076v3)

> Discovering whether words are semantically related and identifying the specific semantic relation that holds between them is of crucial importance for NLP as it is essential for tasks like query expansion in IR. Within this context, different methodologies have been proposed that either exclusively focus on a single lexical relation (e.g. hypernymy vs. random) or learn specific classifiers capable of identifying multiple semantic relations (e.g. hypernymy vs. synonymy vs. random). In this paper, we propose another way to look at the problem that relies on the multi-task learning paradigm. In particular, we want to study whether the learning process of a given semantic relation (e.g. hypernymy) can be improved by the concurrent learning of another semantic relation (e.g. co-hyponymy). Within this context, we particularly examine the benefits of semi-supervised learning where the training of a prediction function is performed over few labeled data jointly with many unlabeled ones. Preliminary results based on simple learning strategies and state-of-the-art distributional feature representations show that concurrent learning can lead to improvements in a vast majority of tested situations.

</details>

<details>

<summary>2018-07-30 08:49:25 - Semantic Labeling in Very High Resolution Images via a Self-Cascaded Convolutional Neural Network</summary>

- *Yongcheng Liu, Bin Fan, Lingfeng Wang, Jun Bai, Shiming Xiang, Chunhong Pan*

- `1807.11236v1` - [abs](http://arxiv.org/abs/1807.11236v1) - [pdf](http://arxiv.org/pdf/1807.11236v1)

> Semantic labeling for very high resolution (VHR) images in urban areas, is of significant importance in a wide range of remote sensing applications. However, many confusing manmade objects and intricate fine-structured objects make it very difficult to obtain both coherent and accurate labeling results. For this challenging task, we propose a novel deep model with convolutional neural networks (CNNs), i.e., an end-to-end self-cascaded network (ScasNet). Specifically, for confusing manmade objects, ScasNet improves the labeling coherence with sequential global-to-local contexts aggregation. Technically, multi-scale contexts are captured on the output of a CNN encoder, and then they are successively aggregated in a self-cascaded manner. Meanwhile, for fine-structured objects, ScasNet boosts the labeling accuracy with a coarse-to-fine refinement strategy. It progressively refines the target objects using the low-level features learned by CNN's shallow layers. In addition, to correct the latent fitting residual caused by multi-feature fusion inside ScasNet, a dedicated residual correction scheme is proposed. It greatly improves the effectiveness of ScasNet. Extensive experimental results on three public datasets, including two challenging benchmarks, show that ScasNet achieves the state-of-the-art performance.

</details>

<details>

<summary>2018-07-30 10:31:52 - Graphene: Semantically-Linked Propositions in Open Information Extraction</summary>

- *Matthias Cetto, Christina Niklaus, André Freitas, Siegfried Handschuh*

- `1807.11276v1` - [abs](http://arxiv.org/abs/1807.11276v1) - [pdf](http://arxiv.org/pdf/1807.11276v1)

> We present an Open Information Extraction (IE) approach that uses a two-layered transformation stage consisting of a clausal disembedding layer and a phrasal disembedding layer, together with rhetorical relation identification. In that way, we convert sentences that present a complex linguistic structure into simplified, syntactically sound sentences, from which we can extract propositions that are represented in a two-layered hierarchy in the form of core relational tuples and accompanying contextual information which are semantically linked via rhetorical relations. In a comparative evaluation, we demonstrate that our reference implementation Graphene outperforms state-of-the-art Open IE systems in the construction of correct n-ary predicate-argument structures. Moreover, we show that existing Open IE approaches can benefit from the transformation process of our framework.

</details>

<details>

<summary>2018-07-30 11:06:31 - Towards an automated approach for bug fix pattern detection</summary>

- *Fernanda Madeiral, Thomas Durieux, Victor Sobreira, Marcelo Maia*

- `1807.11286v1` - [abs](http://arxiv.org/abs/1807.11286v1) - [pdf](http://arxiv.org/pdf/1807.11286v1)

> The characterization of bug datasets is essential to support the evaluation of automatic program repair tools. In a previous work, we manually studied almost 400 human-written patches (bug fixes) from the Defects4J dataset and annotated them with properties, such as repair patterns. However, manually finding these patterns in different datasets is tedious and time-consuming. To address this activity, we designed and implemented PPD, a detector of repair patterns in patches, which performs source code change analysis at abstract-syntax tree level. In this paper, we report on PPD and its evaluation on Defects4J, where we compare the results from the automated detection with the results from the previous manual analysis. We found that PPD has overall precision of 91% and overall recall of 92%, and we conclude that PPD has the potential to detect as many repair patterns as human manual analysis.

</details>

<details>

<summary>2018-07-30 13:18:15 - On Looking for Local Expansion Invariants in Argumentation Semantics: a Preliminary Report</summary>

- *Stefano Bistarelli, Francesco Santini, Carlo Taticchi*

- `1802.08328v2` - [abs](http://arxiv.org/abs/1802.08328v2) - [pdf](http://arxiv.org/pdf/1802.08328v2)

> We study invariant local expansion operators for conflict-free and admissible sets in Abstract Argumentation Frameworks (AFs). Such operators are directly applied on AFs, and are invariant with respect to a chosen "semantics" (that is w.r.t. each of the conflict free/admissible set of arguments). Accordingly, we derive a definition of robustness for AFs in terms of the number of times such operators can be applied without producing any change in the chosen semantics.

</details>

<details>

<summary>2018-07-30 16:52:04 - Leveraging Motion Priors in Videos for Improving Human Segmentation</summary>

- *Yu-Ting Chen, Wen-Yen Chang, Hai-Lun Lu, Tingfan Wu, Min Sun*

- `1807.11436v1` - [abs](http://arxiv.org/abs/1807.11436v1) - [pdf](http://arxiv.org/pdf/1807.11436v1)

> Despite many advances in deep-learning based semantic segmentation, performance drop due to distribution mismatch is often encountered in the real world. Recently, a few domain adaptation and active learning approaches have been proposed to mitigate the performance drop. However, very little attention has been made toward leveraging information in videos which are naturally captured in most camera systems. In this work, we propose to leverage "motion prior" in videos for improving human segmentation in a weakly-supervised active learning setting. By extracting motion information using optical flow in videos, we can extract candidate foreground motion segments (referred to as motion prior) potentially corresponding to human segments. We propose to learn a memory-network-based policy model to select strong candidate segments (referred to as strong motion prior) through reinforcement learning. The selected segments have high precision and are directly used to finetune the model. In a newly collected surveillance camera dataset and a publicly available UrbanStreet dataset, our proposed method improves the performance of human segmentation across multiple scenes and modalities (i.e., RGB to Infrared (IR)). Last but not least, our method is empirically complementary to existing domain adaptation approaches such that additional performance gain is achieved by combining our weakly-supervised active learning approach with domain adaptation approaches.

</details>

<details>

<summary>2018-07-30 21:14:25 - UH-PRHLT at SemEval-2016 Task 3: Combining Lexical and Semantic-based Features for Community Question Answering</summary>

- *Marc Franco-Salvador, Sudipta Kar, Thamar Solorio, Paolo Rosso*

- `1807.11584v1` - [abs](http://arxiv.org/abs/1807.11584v1) - [pdf](http://arxiv.org/pdf/1807.11584v1)

> In this work we describe the system built for the three English subtasks of the SemEval 2016 Task 3 by the Department of Computer Science of the University of Houston (UH) and the Pattern Recognition and Human Language Technology (PRHLT) research center - Universitat Polit`ecnica de Val`encia: UH-PRHLT. Our system represents instances by using both lexical and semantic-based similarity measures between text pairs. Our semantic features include the use of distributed representations of words, knowledge graphs generated with the BabelNet multilingual semantic network, and the FrameNet lexical database. Experimental results outperform the random and Google search engine baselines in the three English subtasks. Our approach obtained the highest results of subtask B compared to the other task participants.

</details>

<details>

<summary>2018-07-31 00:50:15 - An Enhanced Latent Semantic Analysis Approach for Arabic Document Summarization</summary>

- *Kamal Al-Sabahi, Zuping Zhang, Jun Long, Khaled Alwesabi*

- `1807.11618v1` - [abs](http://arxiv.org/abs/1807.11618v1) - [pdf](http://arxiv.org/pdf/1807.11618v1)

> The fast-growing amount of information on the Internet makes the research in automatic document summarization very urgent. It is an effective solution for information overload. Many approaches have been proposed based on different strategies, such as latent semantic analysis (LSA). However, LSA, when applied to document summarization, has some limitations which diminish its performance. In this work, we try to overcome these limitations by applying statistic and linear algebraic approaches combined with syntactic and semantic processing of text. First, the part of speech tagger is utilized to reduce the dimension of LSA. Then, the weight of the term in four adjacent sentences is added to the weighting schemes while calculating the input matrix to take into account the word order and the syntactic relations. In addition, a new LSA-based sentence selection algorithm is proposed, in which the term description is combined with sentence description for each topic which in turn makes the generated summary more informative and diverse. To ensure the effectiveness of the proposed LSA-based sentence selection algorithm, extensive experiment on Arabic and English are done. Four datasets are used to evaluate the new model, Linguistic Data Consortium (LDC) Arabic Newswire-a corpus, Essex Arabic Summaries Corpus (EASC), DUC2002, and Multilingual MSS 2015 dataset. Experimental results on the four datasets show the effectiveness of the proposed model on Arabic and English datasets. It performs comprehensively better compared to the state-of-the-art methods.

</details>

<details>

<summary>2018-07-31 01:08:37 - Ontology-Grounded Topic Modeling for Climate Science Research</summary>

- *Jennifer Sleeman, Tim Finin, Milton Halem*

- `1807.10965v2` - [abs](http://arxiv.org/abs/1807.10965v2) - [pdf](http://arxiv.org/pdf/1807.10965v2)

> In scientific disciplines where research findings have a strong impact on society, reducing the amount of time it takes to understand, synthesize and exploit the research is invaluable. Topic modeling is an effective technique for summarizing a collection of documents to find the main themes among them and to classify other documents that have a similar mixture of co-occurring words. We show how grounding a topic model with an ontology, extracted from a glossary of important domain phrases, improves the topics generated and makes them easier to understand. We apply and evaluate this method to the climate science domain. The result improves the topics generated and supports faster research understanding, discovery of social networks among researchers, and automatic ontology generation.

</details>

<details>

<summary>2018-07-31 06:42:30 - DOCK: Detecting Objects by transferring Common-sense Knowledge</summary>

- *Krishna Kumar Singh, Santosh Divvala, Ali Farhadi, Yong Jae Lee*

- `1804.01077v2` - [abs](http://arxiv.org/abs/1804.01077v2) - [pdf](http://arxiv.org/pdf/1804.01077v2)

> We present a scalable approach for Detecting Objects by transferring Common-sense Knowledge (DOCK) from source to target categories. In our setting, the training data for the source categories have bounding box annotations, while those for the target categories only have image-level annotations. Current state-of-the-art approaches focus on image-level visual or semantic similarity to adapt a detector trained on the source categories to the new target categories. In contrast, our key idea is to (i) use similarity not at the image-level, but rather at the region-level, and (ii) leverage richer common-sense (based on attribute, spatial, etc.) to guide the algorithm towards learning the correct detections. We acquire such common-sense cues automatically from readily-available knowledge bases without any extra human effort. On the challenging MS COCO dataset, we find that common-sense knowledge can substantially improve detection performance over existing transfer-learning baselines.

</details>

<details>

<summary>2018-07-31 09:21:22 - RiTUAL-UH at TRAC 2018 Shared Task: Aggression Identification</summary>

- *Niloofar Safi Samghabadi, Deepthi Mave, Sudipta Kar, Thamar Solorio*

- `1807.11712v1` - [abs](http://arxiv.org/abs/1807.11712v1) - [pdf](http://arxiv.org/pdf/1807.11712v1)

> This paper presents our system for "TRAC 2018 Shared Task on Aggression Identification". Our best systems for the English dataset use a combination of lexical and semantic features. However, for Hindi data using only lexical features gave us the best results. We obtained weighted F1- measures of 0.5921 for the English Facebook task (ranked 12th), 0.5663 for the English Social Media task (ranked 6th), 0.6292 for the Hindi Facebook task (ranked 1st), and 0.4853 for the Hindi Social Media task (ranked 2nd).

</details>

<details>

<summary>2018-07-31 11:18:18 - A First Experiment on Including Text Literals in KGloVe</summary>

- *Michael Cochez, Martina Garofalo, Jérôme Lenßen, Maria Angela Pellegrino*

- `1807.11761v1` - [abs](http://arxiv.org/abs/1807.11761v1) - [pdf](http://arxiv.org/pdf/1807.11761v1)

> Graph embedding models produce embedding vectors for entities and relations in Knowledge Graphs, often without taking literal properties into account. We show an initial idea based on the combination of global graph structure with additional information provided by textual information in properties. Our initial experiment shows that this approach might be useful, but does not clearly outperform earlier approaches when evaluated on machine learning tasks.

</details>


## 2018-08

<details>

<summary>2018-08-01 00:11:13 - Cognitive Techniques for Early Detection of Cybersecurity Events</summary>

- *Sandeep Narayanan, Ashwinkumar Ganesan, Karuna Joshi, Tim Oates, Anupam Joshi, Tim Finin*

- `1808.00116v1` - [abs](http://arxiv.org/abs/1808.00116v1) - [pdf](http://arxiv.org/pdf/1808.00116v1)

> The early detection of cybersecurity events such as attacks is challenging given the constantly evolving threat landscape. Even with advanced monitoring, sophisticated attackers can spend as many as 146 days in a system before being detected. This paper describes a novel, cognitive framework that assists a security analyst by exploiting the power of semantically rich knowledge representation and reasoning with machine learning techniques. Our Cognitive Cybersecurity system ingests information from textual sources, and various agents representing host and network-based sensors, and represents this information in a knowledge graph. This graph uses terms from an extended version of the Unified Cybersecurity Ontology. The system reasons over the knowledge graph to derive better actionable intelligence to security administrators, thus decreasing their cognitive load and increasing their confidence in the system. We have developed a proof of concept framework for our approach and demonstrate its capabilities using a custom-built ransomware instance that is similar to WannaCry.

</details>

<details>

<summary>2018-08-01 00:28:32 - Toward Multimodal Interaction in Scalable Visual Digital Evidence Visualization Using Computer Vision Techniques and ISS</summary>

- *Serguei A. Mokhov, Miao Song, Jashanjot Singh, Joey Paquet, Mourad Debbabi, Sudhir Mudur*

- `1808.00118v1` - [abs](http://arxiv.org/abs/1808.00118v1) - [pdf](http://arxiv.org/pdf/1808.00118v1)

> Visualization requirements in Forensic Lucid have to do with different levels of case knowledge abstraction, representation, aggregation, as well as the operational aspects as the final long-term goal of this proposal. It encompasses anything from the finer detailed representation of hierarchical contexts to Forensic Lucid programs, to the documented evidence and its management, its linkage to programs, to evaluation, and to the management of GIPSY software networks. This includes an ability to arbitrarily switch between those views combined with usable multimodal interaction. The purpose is to determine how the findings can be applied to Forensic Lucid and investigation case management. It is also natural to want a convenient and usable evidence visualization, its semantic linkage and the reasoning machinery for it. Thus, we propose a scalable management, visualization, and evaluation of digital evidence using the modified interactive 3D documentary system - Illimitable Space System - (ISS) to represent, semantically link, and provide a usable interface to digital investigators that is navigable via different multimodal interaction techniques using Computer Vision techniques including gestures, as well as eye-gaze and audio.

</details>

<details>

<summary>2018-08-01 12:39:43 - Learning Visual Question Answering by Bootstrapping Hard Attention</summary>

- *Mateusz Malinowski, Carl Doersch, Adam Santoro, Peter Battaglia*

- `1808.00300v1` - [abs](http://arxiv.org/abs/1808.00300v1) - [pdf](http://arxiv.org/pdf/1808.00300v1)

> Attention mechanisms in biological perception are thought to select subsets of perceptual information for more sophisticated processing which would be prohibitive to perform on all sensory inputs. In computer vision, however, there has been relatively little exploration of hard attention, where some information is selectively ignored, in spite of the success of soft attention, where information is re-weighted and aggregated, but never filtered out. Here, we introduce a new approach for hard attention and find it achieves very competitive performance on a recently-released visual question answering datasets, equalling and in some cases surpassing similar soft attention architectures while entirely ignoring some features. Even though the hard attention mechanism is thought to be non-differentiable, we found that the feature magnitudes correlate with semantic relevance, and provide a useful signal for our mechanism's attentional selection criterion. Because hard attention selects important features of the input information, it can also be more efficient than analogous soft attention mechanisms. This is especially important for recent approaches that use non-local pairwise operations, whereby computational and memory costs are quadratic in the size of the set of features.

</details>

<details>

<summary>2018-08-01 14:49:30 - A monolithic approach to fluid-structure interaction based on a hybrid Eulerian-ALE fluid domain decomposition involving cut elements</summary>

- *Benedikt Schott, Christoph Ager, Wolfgang A. Wall*

- `1808.00343v1` - [abs](http://arxiv.org/abs/1808.00343v1) - [pdf](http://arxiv.org/pdf/1808.00343v1)

> A novel method for complex fluid-structure interaction (FSI) involving large structural deformation and motion is proposed. The new approach is based on a hybrid fluid formulation that combines the advantages of purely Eulerian (fixed-grid) and Arbitrary-Lagrangian-Eulerian (ALE moving mesh) formulations in the context of FSI. The structure - as commonly given in Lagrangian description - is surrounded by a fine resolved layer of fluid elements based on an ALE-framework. This ALE-fluid patch, which is embedded in an Eulerian background fluid domain, follows the deformation and motion of the structural interface. This approximation technique is not limited to Finite Element Methods, but can can also be realized within other frameworks like Finite Volume or Discontinuous Galerkin Methods. In this work, the surface coupling between the two disjoint fluid subdomains is imposed weakly using a stabilized Nitsche's technique in a Cut Finite Element Method (CutFEM) framework. At the fluid-solid interface, standard weak coupling of node-matching or non-matching finite element approximations can be utilized. As the fluid subdomains can be meshed independently, a sufficient mesh quality in the vicinity of the common fluid-structure interface can be assured. To our knowledge the proposed method is the only method (despite some overlapping domain decomposition approaches that suffer from other issues) that allows for capturing boundary layers and flow detachment via appropriate grids around largely moving and deforming bodies and is able to do this e.g. without the necessity of costly remeshing procedures. In addition it might also help to safe computational costs as now background grids can be much coarser. Various FSI-cases of rising complexity conclude the work.

</details>

<details>

<summary>2018-08-01 15:07:08 - A Virtual Element Method for 2D linear elastic fracture analysis</summary>

- *Vien Minh Nguyen-Thanh, Xiaoying Zhuang, Hung Nguyen-Xuan, Timon Rabczuk, Peter Wriggers*

- `1808.00355v1` - [abs](http://arxiv.org/abs/1808.00355v1) - [pdf](http://arxiv.org/pdf/1808.00355v1)

> This paper presents the Virtual Element Method (VEM) for the modeling of crack propagation in 2D within the context of linear elastic fracture mechanics (LEFM). By exploiting the advantage of mesh flexibility in the VEM, we establish an adaptive mesh refinement strategy based on the superconvergent patch recovery for triangular, quadrilateral as well as for arbitrary polygonal meshes. For the local stiffness matrix in VEM, we adopt a stabilization term which is stable for both isotropic scaling and ratio. Stress intensity factors (SIFs) of a polygonal mesh are discussed and solved by using the interaction domain integral. The present VEM formulations are finally tested and validated by studying its convergence rate for both continuous and discontinuous problems, and are compared with the optimal convergence rate in the conventional Finite Element Method (FEM). Furthermore, the adaptive mesh refinement strategies used to effectively predict the crack growth with the existence of hanging nodes in nonconforming elements are examined.

</details>

<details>

<summary>2018-08-01 15:44:55 - Standards-Based Worldwide Semantic Interoperability for IoT</summary>

- *Erno Kovacs, Martin Bauer, Jaeho Kim, Jaeseok Yun, Franck Le Gall, Mengxuan Zhao*

- `1808.00386v1` - [abs](http://arxiv.org/abs/1808.00386v1) - [pdf](http://arxiv.org/pdf/1808.00386v1)

> Global IoT services (GIoTS) are combining locally available IoT resources with Cloud-based services. They are targeting world-wide services. GIoTS require interoperability between the locally installed heterogeneous IoT systems. Semantic processing is an important technology to enable data mediation as well as knowledge-based processing. This paper explains a system architecture for achieving world-wide semantic interoperability using international standards like oneM2M and the OMA NGSI-9/10 context interfaces (as used in the European Future Internet Platform FIWARE). Semantics also enables the use of Knowledge-based Semantic Processing Agents. Furthermore, we explain how semantic verification enables the testing of such complex systems.

</details>

<details>

<summary>2018-08-01 16:59:01 - Debugging Non-Ground ASP Programs: Technique and Graphical Tools</summary>

- *Carmine Dodaro, Philip Gasteiger, Kristian Reale, Francesco Ricca, Konstantin Schekotihin*

- `1808.00417v1` - [abs](http://arxiv.org/abs/1808.00417v1) - [pdf](http://arxiv.org/pdf/1808.00417v1)

> Answer Set Programming (ASP) is one of the major declarative programming paradigms in the area of logic programming and non-monotonic reasoning. Despite that ASP features a simple syntax and an intuitive semantics, errors are common during the development of ASP programs. In this paper we propose a novel debugging approach allowing for interactive localization of bugs in non-ground programs. The new approach points the user directly to a set of non-ground rules involved in the bug, which might be refined (up to the point in which the bug is easily identified) by asking the programmer a sequence of questions on an expected answer set. The approach has been implemented on top of the ASP solver WASP. The resulting debugger has been complemented by a user-friendly graphical interface, and integrated in ASPIDE, a rich IDE for answer set programs. In addition, an empirical analysis shows that the new debugger is not affected by the grounding blowup limiting the application of previous approaches based on meta-programming. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>

<details>

<summary>2018-08-02 03:23:04 - Semantic Segmentation with Scarce Data</summary>

- *Isay Katsman, Rohun Tripathi, Andreas Veit, Serge Belongie*

- `1807.00911v2` - [abs](http://arxiv.org/abs/1807.00911v2) - [pdf](http://arxiv.org/pdf/1807.00911v2)

> Semantic segmentation is a challenging vision problem that usually necessitates the collection of large amounts of finely annotated data, which is often quite expensive to obtain. Coarsely annotated data provides an interesting alternative as it is usually substantially more cheap. In this work, we present a method to leverage coarsely annotated data along with fine supervision to produce better segmentation results than would be obtained when training using only the fine data. We validate our approach by simulating a scarce data setting with less than 200 low resolution images from the Cityscapes dataset and show that our method substantially outperforms solely training on the fine annotation data by an average of 15.52% mIoU and outperforms the coarse mask by an average of 5.28% mIoU.

</details>

<details>

<summary>2018-08-02 07:18:55 - OntoSenseNet: A Verb-Centric Ontological Resource for Indian Languages</summary>

- *Jyoti Jha, Sreekavitha Parupalli, Navjyoti Singh*

- `1808.00694v1` - [abs](http://arxiv.org/abs/1808.00694v1) - [pdf](http://arxiv.org/pdf/1808.00694v1)

> Following approaches for understanding lexical meaning developed by Yaska, Patanjali and Bhartrihari from Indian linguistic traditions and extending approaches developed by Leibniz and Brentano in the modern times, a framework of formal ontology of language was developed. This framework proposes that meaning of words are in-formed by intrinsic and extrinsic ontological structures. The paper aims to capture such intrinsic and extrinsic meanings of words for two major Indian languages, namely, Hindi and Telugu. Parts-of-speech have been rendered into sense-types and sense-classes. Using them we have developed a gold- standard annotated lexical resource to support semantic understanding of a language. The resource has collection of Hindi and Telugu lexicons, which has been manually annotated by native speakers of the languages following our annotation guidelines. Further, the resource was utilised to derive adverbial sense-class distribution of verbs and karaka-verb sense- type distribution. Different corpora (news, novels) were compared using verb sense-types distribution. Word Embedding was used as an aid for the enrichment of the resource. This is a work in progress that aims at lexical coverage of language extensively.

</details>

<details>

<summary>2018-08-02 09:32:20 - Inlining External Sources in Answer Set Programs</summary>

- *Christoph Redl*

- `1808.00727v1` - [abs](http://arxiv.org/abs/1808.00727v1) - [pdf](http://arxiv.org/pdf/1808.00727v1)

> HEX-programs are an extension of answer set programs (ASP) with external sources. To this end, external atoms provide a bidirectional interface between the program and an external source. The traditional evaluation algorithm for HEX-programs is based on guessing truth values of external atoms and verifying them by explicit calls of the external source. The approach was optimized by techniques that reduce the number of necessary verification calls or speed them up, but the remaining external calls are still expensive. In this paper we present an alternative evaluation approach based on inlining of external atoms, motivated by existing but less general approaches for specialized formalisms such as DL-programs. External atoms are then compiled away such that no verification calls are necessary. The approach is implemented in the dlvhex reasoner. Experiments show a significant performance gain. Besides performance improvements, we further exploit inlining for extending previous (semantic) characterizations of program equivalence from ASP to HEX-programs, including those of strong equivalence, uniform equivalence and H, B -equivalence. Finally, based on these equivalence criteria, we characterize also inconsistency of programs wrt. extensions. Since well-known ASP extensions (such as constraint ASP) are special cases of HEX, the results are interesting beyond the particular formalism. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>

<details>

<summary>2018-08-02 10:07:57 - Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks</summary>

- *Matthias Plappert, Christian Mandery, Tamim Asfour*

- `1705.06400v2` - [abs](http://arxiv.org/abs/1705.06400v2) - [pdf](http://arxiv.org/pdf/1705.06400v2)

> Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learned end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2,846 human whole-body motions and 6,187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions.

</details>

<details>

<summary>2018-08-02 17:48:13 - Effective Parallel Corpus Mining using Bilingual Sentence Embeddings</summary>

- *Mandy Guo, Qinlan Shen, Yinfei Yang, Heming Ge, Daniel Cer, Gustavo Hernandez Abrego, Keith Stevens, Noah Constant, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil*

- `1807.11906v2` - [abs](http://arxiv.org/abs/1807.11906v2) - [pdf](http://arxiv.org/pdf/1807.11906v2)

> This paper presents an effective approach for parallel corpus mining using bilingual sentence embeddings. Our embedding models are trained to produce similar representations exclusively for bilingual sentence pairs that are translations of each other. This is achieved using a novel training method that introduces hard negatives consisting of sentences that are not translations but that have some degree of semantic similarity. The quality of the resulting embeddings are evaluated on parallel corpus reconstruction and by assessing machine translation systems trained on gold vs. mined sentence pairs. We find that the sentence embeddings can be used to reconstruct the United Nations Parallel Corpus at the sentence level with a precision of 48.9% for en-fr and 54.9% for en-es. When adapted to document level matching, we achieve a parallel document matching accuracy that is comparable to the significantly more computationally intensive approach of [Jakob 2010]. Using reconstructed parallel data, we are able to train NMT models that perform nearly as well as models trained on the original data (within 1-2 BLEU).

</details>

<details>

<summary>2018-08-02 20:28:44 - The Privacy Exposure Problem in Mobile Location-based Services</summary>

- *Fang-Jing Wu, Matthias R. Brust, Yan-Ann Chen, Tie Luo*

- `1808.01010v1` - [abs](http://arxiv.org/abs/1808.01010v1) - [pdf](http://arxiv.org/pdf/1808.01010v1)

> Mobile location-based services (LBSs) empowered by mobile crowdsourcing provide users with context-aware intelligent services based on user locations. As smartphones are capable of collecting and disseminating massive user location-embedded sensing information, privacy preservation for mobile users has become a crucial issue. This paper proposes a metric called privacy exposure to quantify the notion of privacy, which is subjective and qualitative in nature, in order to support mobile LBSs to evaluate the effectiveness of privacy-preserving solutions. This metric incorporates activity coverage and activity uniformity to address two primary privacy threats, namely activity hotspot disclosure and activity transition disclosure. In addition, we propose an algorithm to minimize privacy exposure for mobile LBSs. We evaluate the proposed metric and the privacy-preserving sensing algorithm via extensive simulations. Moreover, we have also implemented the algorithm in an Android-based mobile system and conducted real-world experiments. Both our simulations and experimental results demonstrate that (1) the proposed metric can properly quantify the privacy exposure level of human activities in the spatial domain and (2) the proposed algorithm can effectively cloak users' activity hotspots and transitions at both high and low user-mobility levels.

</details>

<details>

<summary>2018-08-02 21:05:30 - We Hear Your Activities through Wi-Fi Signals</summary>

- *Fang-Jing Wu, Gürkan Solmaz*

- `1808.01027v1` - [abs](http://arxiv.org/abs/1808.01027v1) - [pdf](http://arxiv.org/pdf/1808.01027v1)

> In this paper we focus on the problem of human activity recognition without identification of the individuals in a scene. We consider using Wi-Fi signals to detect certain human mobility behaviors such as stationary, walking, or running. The main objective is to successfully detect these behaviors for the individuals and based on that enable detection of the crowd's overall mobility behavior. We propose a method which infers mobility behaviors in two stages: from Wi-Fi signals to trajectories and from trajectories to the mobility behaviors. We evaluate the applicability of the proposed approach using the StudentLife dataset which contains Wi-Fi, GPS, and accelerometer measurements collected from smartphones of 49 students within a three-month period. The experimental results indicate that there is high correlation between stability of Wi-Fi signals and mobility activity. This unique characteristic provides sufficient evidences to extend the proposed idea to mobility analytics of groups of people in the future.

</details>

<details>

<summary>2018-08-03 08:07:32 - CAKE: Compact and Accurate K-dimensional representation of Emotion</summary>

- *Corentin Kervadec, Valentin Vielzeuf, Stéphane Pateux, Alexis Lechervy, Frédéric Jurie*

- `1807.11215v2` - [abs](http://arxiv.org/abs/1807.11215v2) - [pdf](http://arxiv.org/pdf/1807.11215v2)

> Numerous models describing the human emotional states have been built by the psychology community. Alongside, Deep Neural Networks (DNN) are reaching excellent performances and are becoming interesting features extraction tools in many computer vision tasks.Inspired by works from the psychology community, we first study the link between the compact two-dimensional representation of the emotion known as arousal-valence, and discrete emotion classes (e.g. anger, happiness, sadness, etc.) used in the computer vision community. It enables to assess the benefits -- in terms of discrete emotion inference -- of adding an extra dimension to arousal-valence (usually named dominance). Building on these observations, we propose CAKE, a 3-dimensional representation of emotion learned in a multi-domain fashion, achieving accurate emotion recognition on several public datasets. Moreover, we visualize how emotions boundaries are organized inside DNN representations and show that DNNs are implicitly learning arousal-valence-like descriptions of emotions. Finally, we use the CAKE representation to compare the quality of the annotations of different public datasets.

</details>

<details>

<summary>2018-08-04 05:03:43 - Abstractive Summarization Improved by WordNet-based Extractive Sentences</summary>

- *Niantao Xie, Sujian Li, Huiling Ren, Qibin Zhai*

- `1808.01426v1` - [abs](http://arxiv.org/abs/1808.01426v1) - [pdf](http://arxiv.org/pdf/1808.01426v1)

> Recently, the seq2seq abstractive summarization models have achieved good results on the CNN/Daily Mail dataset. Still, how to improve abstractive methods with extractive methods is a good research direction, since extractive methods have their potentials of exploiting various efficient features for extracting important sentences in one text. In this paper, in order to improve the semantic relevance of abstractive summaries, we adopt the WordNet based sentence ranking algorithm to extract the sentences which are most semantically to one text. Then, we design a dual attentional seq2seq framework to generate summaries with consideration of the extracted information. At the same time, we combine pointer-generator and coverage mechanisms to solve the problems of out-of-vocabulary (OOV) words and duplicate words which exist in the abstractive models. Experiments on the CNN/Daily Mail dataset show that our models achieve competitive performance with the state-of-the-art ROUGE scores. Human evaluations also show that the summaries generated by our models have high semantic relevance to the original text.

</details>

<details>

<summary>2018-08-04 09:34:16 - From Common to Special: When Multi-Attribute Learning Meets Personalized Opinions</summary>

- *Zhiyong Yang, Qianqian Xu, Xiaochun Cao, Qingming Huang*

- `1711.06867v2` - [abs](http://arxiv.org/abs/1711.06867v2) - [pdf](http://arxiv.org/pdf/1711.06867v2)

> Visual attributes, which refer to human-labeled semantic annotations, have gained increasing popularity in a wide range of real world applications. Generally, the existing attribute learning methods fall into two categories: one focuses on learning user-specific labels separately for different attributes, while the other one focuses on learning crowd-sourced global labels jointly for multiple attributes. However, both categories ignore the joint effect of the two mentioned factors: the personal diversity with respect to the global consensus; and the intrinsic correlation among multiple attributes. To overcome this challenge, we propose a novel model to learn user-specific predictors across multiple attributes. In our proposed model, the diversity of personalized opinions and the intrinsic relationship among multiple attributes are unified in a common-to-special manner. To this end, we adopt a three-component decomposition. Specifically, our model integrates a common cognition factor, an attribute-specific bias factor and a user-specific bias factor. Meanwhile Lasso and group Lasso penalties are adopted to leverage efficient feature selection. Furthermore, theoretical analysis is conducted to show that our proposed method could reach reasonable performance. Eventually, the empirical study carried out in this paper demonstrates the effectiveness of our proposed method.

</details>

<details>

<summary>2018-08-04 21:10:03 - Triplet Network with Attention for Speaker Diarization</summary>

- *Huan Song, Megan Willi, Jayaraman J. Thiagarajan, Visar Berisha, Andreas Spanias*

- `1808.01535v1` - [abs](http://arxiv.org/abs/1808.01535v1) - [pdf](http://arxiv.org/pdf/1808.01535v1)

> In automatic speech processing systems, speaker diarization is a crucial front-end component to separate segments from different speakers. Inspired by the recent success of deep neural networks (DNNs) in semantic inferencing, triplet loss-based architectures have been successfully used for this problem. However, existing work utilizes conventional i-vectors as the input representation and builds simple fully connected networks for metric learning, thus not fully leveraging the modeling power of DNN architectures. This paper investigates the importance of learning effective representations from the sequences directly in metric learning pipelines for speaker diarization. More specifically, we propose to employ attention models to learn embeddings and the metric jointly in an end-to-end fashion. Experiments are conducted on the CALLHOME conversational speech corpus. The diarization results demonstrate that, besides providing a unified model, the proposed approach achieves improved performance when compared against existing approaches.

</details>

<details>

<summary>2018-08-04 21:30:17 - Neural Article Pair Modeling for Wikipedia Sub-article Matching</summary>

- *Muhao Chen, Changping Meng, Gang Huang, Carlo Zaniolo*

- `1807.11689v2` - [abs](http://arxiv.org/abs/1807.11689v2) - [pdf](http://arxiv.org/pdf/1807.11689v2)

> Nowadays, editors tend to separate different subtopics of a long Wiki-pedia article into multiple sub-articles. This separation seeks to improve human readability. However, it also has a deleterious effect on many Wikipedia-based tasks that rely on the article-as-concept assumption, which requires each entity (or concept) to be described solely by one article. This underlying assumption significantly simplifies knowledge representation and extraction, and it is vital to many existing technologies such as automated knowledge base construction, cross-lingual knowledge alignment, semantic search and data lineage of Wikipedia entities. In this paper we provide an approach to match the scattered sub-articles back to their corresponding main-articles, with the intent of facilitating automated Wikipedia curation and processing. The proposed model adopts a hierarchical learning structure that combines multiple variants of neural document pair encoders with a comprehensive set of explicit features. A large crowdsourced dataset is created to support the evaluation and feature extraction for the task. Based on the large dataset, the proposed model achieves promising results of cross-validation and significantly outperforms previous approaches. Large-scale serving on the entire English Wikipedia also proves the practicability and scalability of the proposed model by effectively extracting a vast collection of newly paired main and sub-articles.

</details>

<details>

<summary>2018-08-05 09:50:47 - LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse Semantic Accumulation and Example to Pattern Transformation</summary>

- *Pankaj Gupta, Hinrich Schütze*

- `1808.01591v1` - [abs](http://arxiv.org/abs/1808.01591v1) - [pdf](http://arxiv.org/pdf/1808.01591v1)

> Recurrent neural networks (RNNs) are temporal networks and cumulative in nature that have shown promising results in various natural language processing tasks. Despite their success, it still remains a challenge to understand their hidden behavior. In this work, we analyze and interpret the cumulative nature of RNN via a proposed technique named as Layer-wIse-Semantic-Accumulation (LISA) for explaining decisions and detecting the most likely (i.e., saliency) patterns that the network relies on while decision making. We demonstrate (1) LISA: "How an RNN accumulates or builds semantics during its sequential processing for a given text example and expected response" (2) Example2pattern: "How the saliency patterns look like for each category in the data according to the network in decision making". We analyse the sensitiveness of RNNs about different inputs to check the increase or decrease in prediction scores and further extract the saliency patterns learned by the network. We employ two relation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to explain RNN predictions via the LISA and example2pattern.

</details>

<details>

<summary>2018-08-05 17:47:18 - Instantiation</summary>

- *Abhijeet Gupta, Gemma Boleda, Sebastian Pado*

- `1808.01662v1` - [abs](http://arxiv.org/abs/1808.01662v1) - [pdf](http://arxiv.org/pdf/1808.01662v1)

> In computational linguistics, a large body of work exists on distributed modeling of lexical relations, focussing largely on lexical relations such as hypernymy (scientist -- person) that hold between two categories, as expressed by common nouns. In contrast, computational linguistics has paid little attention to entities denoted by proper nouns (Marie Curie, Mumbai, ...). These have investigated in detail by the Knowledge Representation and Semantic Web communities, but generally not with regard to their linguistic properties.   Our paper closes this gap by investigating and modeling the lexical relation of instantiation, which holds between an entity-denoting and a category-denoting expression (Marie Curie -- scientist or Mumbai -- city). We present a new, principled dataset for the task of instantiation detection as well as experiments and analyses on this dataset. We obtain the following results: (a), entities belonging to one category form a region in distributional space, but the embedding for the category word is typically located outside this subspace; (b) it is easy to learn to distinguish entities from categories from distributional evidence, but due to (a), instantiation proper is much harder to learn when using common nouns as representations of categories; (c) this problem can be alleviated by using category representations based on entity rather than category word embeddings.

</details>

<details>

<summary>2018-08-06 02:53:01 - Intrusion Prediction with System-call Sequence-to-Sequence Model</summary>

- *ShaoHua Lv, Jian Wang, YinQi Yang, JiQiang Liu*

- `1808.01717v1` - [abs](http://arxiv.org/abs/1808.01717v1) - [pdf](http://arxiv.org/pdf/1808.01717v1)

> The advanced development of the Internet facilitates efficient information exchange while also been exploited by adversaries. Intrusion detection system (IDS) as an important defense component of network security has always been widely studied in security research. However, research on intrusion prediction, which is more critical for network security, is received less attention. We argue that the advanced anticipation and timely impede of invasion is more vital than simple alarms in security defenses. General research methods regarding prediction are analyzing short term of system-calls to predict forthcoming abnormal behaviors. In this paper we take advantages of the remarkable performance of recurrent neural networks (RNNs) in dealing with long sequential problem, introducing the sequence-to-sequence model into our intrusion prediction work. By semantic modeling system-calls we build a robust system-call sequence-to-sequence prediction model. With taking the system-call traces invoked during the program running as known prerequisite, our model predicts sequence of system-calls that is most likely to be executed in a near future period of time that enabled the ability of monitoring system status and prophesying the intrusion behaviors. Our experiments show that the predict method proposed in this paper achieved well prediction performance on ADFALD intrusion detection test data set. Moreover, the predicted sequence, combined with the known invoked traces of system, significantly improves the performance of intrusion detection verified on various classifiers.

</details>

<details>

<summary>2018-08-06 03:04:35 - Principles for Developing a Knowledge Graph of Interlinked Events from News Headlines on Twitter</summary>

- *Saeedeh Shekarpour, Ankita Saxena, Krishnaprasad Thirunarayan, Valerie L. Shalin, Amit Sheth*

- `1808.02022v1` - [abs](http://arxiv.org/abs/1808.02022v1) - [pdf](http://arxiv.org/pdf/1808.02022v1)

> The ever-growing datasets published on Linked Open Data mainly contain encyclopedic information. However, there is a lack of quality structured and semantically annotated datasets extracted from unstructured real-time sources. In this paper, we present principles for developing a knowledge graph of interlinked events using the case study of news headlines published on Twitter which is a real-time and eventful source of fresh information. We represent the essential pipeline containing the required tasks ranging from choosing background data model, event annotation (i.e., event recognition and classification), entity annotation and eventually interlinking events. The state-of-the-art is limited to domain-specific scenarios for recognizing and classifying events, whereas this paper plays the role of a domain-agnostic road-map for developing a knowledge graph of interlinked events.

</details>

<details>

<summary>2018-08-06 10:17:55 - A Hierarchical Approach to Neural Context-Aware Modeling</summary>

- *Patrick Huber, Jan Niehues, Alex Waibel*

- `1807.11582v2` - [abs](http://arxiv.org/abs/1807.11582v2) - [pdf](http://arxiv.org/pdf/1807.11582v2)

> We present a new recurrent neural network topology to enhance state-of-the-art machine learning systems by incorporating a broader context. Our approach overcomes recent limitations with extended narratives through a multi-layered computational approach to generate an abstract context representation. Therefore, the developed system captures the narrative on word-level, sentence-level, and context-level. Through the hierarchical set-up, our proposed model summarizes the most salient information on each level and creates an abstract representation of the extended context. We subsequently use this representation to enhance neural language processing systems on the task of semantic error detection. To show the potential of the newly introduced topology, we compare the approach against a context-agnostic set-up including a standard neural language model and a supervised binary classification network. The performance measures on the error detection task show the advantage of the hierarchical context-aware topologies, improving the baseline by 12.75% relative for unsupervised models and 20.37% relative for supervised models.

</details>

<details>

<summary>2018-08-06 12:24:19 - An Efficient Approach to Learning Chinese Judgment Document Similarity Based on Knowledge Summarization</summary>

- *Yinglong Ma, Peng Zhang, Jiangang Ma*

- `1808.01843v1` - [abs](http://arxiv.org/abs/1808.01843v1) - [pdf](http://arxiv.org/pdf/1808.01843v1)

> A previous similar case in common law systems can be used as a reference with respect to the current case such that identical situations can be treated similarly in every case. However, current approaches for judgment document similarity computation failed to capture the core semantics of judgment documents and therefore suffer from lower accuracy and higher computation complexity. In this paper, a knowledge block summarization based machine learning approach is proposed to compute the semantic similarity of Chinese judgment documents. By utilizing domain ontologies for judgment documents, the core semantics of Chinese judgment documents is summarized based on knowledge blocks. Then the WMD algorithm is used to calculate the similarity between knowledge blocks. At last, the related experiments were made to illustrate that our approach is very effective and efficient in achieving higher accuracy and faster computation speed in comparison with the traditional approaches.

</details>

<details>

<summary>2018-08-06 17:59:45 - Automated Extraction of Personal Knowledge from Smartphone Push Notifications</summary>

- *Yuanchun Li, Ziyue Yang, Yao Guo, Xiangqun Chen, Yuvraj Agarwal, Jason Hong*

- `1808.02013v1` - [abs](http://arxiv.org/abs/1808.02013v1) - [pdf](http://arxiv.org/pdf/1808.02013v1)

> Personalized services are in need of a rich and powerful personal knowledge base, i.e. a knowledge base containing information about the user. This paper proposes an approach to extracting personal knowledge from smartphone push notifications, which are used by mobile systems and apps to inform users of a rich range of information. Our solution is based on the insight that most notifications are formatted using templates, while knowledge entities can be usually found within the parameters to the templates. As defining all the notification templates and their semantic rules are impractical due to the huge number of notification templates used by potentially millions of apps, we propose an automated approach for personal knowledge extraction from push notifications. We first discover notification templates through pattern mining, then use machine learning to understand the template semantics. Based on the templates and their semantics, we are able to translate notification text into knowledge facts automatically. Users' privacy is preserved as we only need to upload the templates to the server for model training, which do not contain any personal information. According to our experiments with about 120 million push notifications from 100,000 smartphone users, our system is able to extract personal knowledge accurately and efficiently.

</details>

<details>

<summary>2018-08-07 01:25:05 - Twitter Sentiment Analysis via Bi-sense Emoji Embedding and Attention-based LSTM</summary>

- *Yuxiao Chen, Jianbo Yuan, Quanzeng You, Jiebo Luo*

- `1807.07961v2` - [abs](http://arxiv.org/abs/1807.07961v2) - [pdf](http://arxiv.org/pdf/1807.07961v2)

> Sentiment analysis on large-scale social media data is important to bridge the gaps between social media contents and real world activities including political election prediction, individual and public emotional status monitoring and analysis, and so on. Although textual sentiment analysis has been well studied based on platforms such as Twitter and Instagram, analysis of the role of extensive emoji uses in sentiment analysis remains light. In this paper, we propose a novel scheme for Twitter sentiment analysis with extra attention on emojis. We first learn bi-sense emoji embeddings under positive and negative sentimental tweets individually, and then train a sentiment classifier by attending on these bi-sense emoji embeddings with an attention-based long short-term memory network (LSTM). Our experiments show that the bi-sense embedding is effective for extracting sentiment-aware embeddings of emojis and outperforms the state-of-the-art models. We also visualize the attentions to show that the bi-sense emoji embedding provides better guidance on the attention mechanism to obtain a more robust understanding of the semantics and sentiments.

</details>

<details>

<summary>2018-08-07 04:08:39 - Survey of Automated Vulnerability Detection and Exploit Generation Techniques in Cyber Reasoning Systems</summary>

- *Teresa Nicole Brooks*

- `1702.06162v4` - [abs](http://arxiv.org/abs/1702.06162v4) - [pdf](http://arxiv.org/pdf/1702.06162v4)

> Software is everywhere, from mission critical systems such as industrial power stations, pacemakers and even household appliances. This growing dependence on technology and the increasing complexity software has serious security implications as it means we are potentially surrounded by software that contain exploitable vulnerabilities. These challenges have made binary analysis an important area of research in computer science and has emphasized the need for building automated analysis systems that can operate at scale, speed and efficacy; all while performing with the skill of a human expert. Though great progress has been made in this area of research, there remains limitations and open challenges to be addressed. Recognizing this need, DARPA sponsored the Cyber Grand Challenge (CGC), a competition to showcase the current state of the art in systems that perform; automated vulnerability detection, exploit generation and software patching. This paper is a survey of the vulnerability detection and exploit generation techniques, underlying technologies and related works of two of the winning systems Mayhem and Mechanical Phish.

</details>

<details>

<summary>2018-08-07 06:47:50 - Segmental Audio Word2Vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection</summary>

- *Yu-Hsuan Wang, Hung-yi Lee, Lin-shan Lee*

- `1808.02228v1` - [abs](http://arxiv.org/abs/1808.02228v1) - [pdf](http://arxiv.org/pdf/1808.02228v1)

> While Word2Vec represents words (in text) as vectors carrying semantic information, audio Word2Vec was shown to be able to represent signal segments of spoken words as vectors carrying phonetic structure information. Audio Word2Vec can be trained in an unsupervised way from an unlabeled corpus, except the word boundaries are needed. In this paper, we extend audio Word2Vec from word-level to utterance-level by proposing a new segmental audio Word2Vec, in which unsupervised spoken word boundary segmentation and audio Word2Vec are jointly learned and mutually enhanced, so an utterance can be directly represented as a sequence of vectors carrying phonetic structure information. This is achieved by a segmental sequence-to-sequence autoencoder (SSAE), in which a segmentation gate trained with reinforcement learning is inserted in the encoder. Experiments on English, Czech, French and German show very good performance in both unsupervised spoken word segmentation and spoken term detection applications (significantly better than frame-based DTW).

</details>

<details>

<summary>2018-08-07 17:47:55 - SketchyScene: Richly-Annotated Scene Sketches</summary>

- *Changqing Zou, Qian Yu, Ruofei Du, Haoran Mo, Yi-Zhe Song, Tao Xiang, Chengying Gao, Baoquan Chen, Hao Zhang*

- `1808.02473v1` - [abs](http://arxiv.org/abs/1808.02473v1) - [pdf](http://arxiv.org/pdf/1808.02473v1)

> We contribute the first large-scale dataset of scene sketches, SketchyScene, with the goal of advancing research on sketch understanding at both the object and scene level. The dataset is created through a novel and carefully designed crowdsourcing pipeline, enabling users to efficiently generate large quantities of realistic and diverse scene sketches. SketchyScene contains more than 29,000 scene-level sketches, 7,000+ pairs of scene templates and photos, and 11,000+ object sketches. All objects in the scene sketches have ground-truth semantic and instance masks. The dataset is also highly scalable and extensible, easily allowing augmenting and/or changing scene composition. We demonstrate the potential impact of SketchyScene by training new computational models for semantic segmentation of scene sketches and showing how the new dataset enables several applications including image retrieval, sketch colorization, editing, and captioning, etc. The dataset and code can be found at https://github.com/SketchyScene/SketchyScene.

</details>

<details>

<summary>2018-08-08 09:40:35 - On the Monitoring of Decentralized Specifications Semantics, Properties, Analysis, and Simulation</summary>

- *Antoine El-Hokayem, Yliès Falcone*

- `1808.02692v1` - [abs](http://arxiv.org/abs/1808.02692v1) - [pdf](http://arxiv.org/pdf/1808.02692v1)

> We define two complementary approaches to monitor decentralized systems. The first relies on those with a centralized specification, i.e, when the specification is written for the behavior of the entire system. To do so, our approach introduces a data-structure that i) keeps track of the execution of an automaton, ii) has predictable parameters and size, and iii) guarantees strong eventual consistency. The second approach defines decentralized specifications wherein multiple specifications are provided for separate parts of the system. We study two properties of decentralized specifications pertaining to monitorability and compatibility between specification and architecture. We also present a general algorithm for monitoring decentralized specifications. We map three existing algorithms to our approaches and provide a framework for analyzing their behavior. Furthermore, we introduce THEMIS, a framework for designing such decentralized algorithms and simulating their behavior. We show the usage of THEMIS to compare multiple algorithms and verify the trends predicted by the analysis by studying two scenarios: a synthetic benchmark and a real example.

</details>

<details>

<summary>2018-08-08 20:49:30 - Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text</summary>

- *Yue Liu, Tongtao Zhang, Zhicheng Liang, Heng Ji, Deborah L. McGuinness*

- `1807.01763v3` - [abs](http://arxiv.org/abs/1807.01763v3) - [pdf](http://arxiv.org/pdf/1807.01763v3)

> We present an end-to-end approach that takes unstructured textual input and generates structured output compliant with a given vocabulary. Inspired by recent successes in neural machine translation, we treat the triples within a given knowledge graph as an independent graph language and propose an encoder-decoder framework with an attention mechanism that leverages knowledge graph embeddings. Our model learns the mapping from natural language text to triple representation in the form of subject-predicate-object using the selected knowledge graph vocabulary. Experiments on three different data sets show that we achieve competitive F1-Measures over the baselines using our simple yet effective approach. A demo video is included.

</details>

<details>

<summary>2018-08-09 04:06:20 - Logical Semantics and Commonsense Knowledge: Where Did we Go Wrong, and How to Go Forward, Again</summary>

- *Walid S. Saba*

- `1808.01741v2` - [abs](http://arxiv.org/abs/1808.01741v2) - [pdf](http://arxiv.org/pdf/1808.01741v2)

> We argue that logical semantics might have faltered due to its failure in distinguishing between two fundamentally very different types of concepts: ontological concepts, that should be types in a strongly-typed ontology, and logical concepts, that are predicates corresponding to properties of and relations between objects of various ontological types. We will then show that accounting for these differences amounts to the integration of lexical and compositional semantics in one coherent framework, and to an embedding in our logical semantics of a strongly-typed ontology that reflects our commonsense view of the world and the way we talk about it in ordinary language. We will show that in such a framework a number of challenges in natural language semantics can be adequately and systematically treated.

</details>

<details>

<summary>2018-08-09 14:24:47 - The KIT Motion-Language Dataset</summary>

- *Matthias Plappert, Christian Mandery, Tamim Asfour*

- `1607.03827v2` - [abs](http://arxiv.org/abs/1607.03827v2) - [pdf](http://arxiv.org/pdf/1607.03827v2)

> Linking human motion and natural language is of great interest for the generation of semantic representations of human activities as well as for the generation of robot activities based on natural language input. However, while there have been years of research in this area, no standardized and openly available dataset exists to support the development and evaluation of such systems. We therefore propose the KIT Motion-Language Dataset, which is large, open, and extensible. We aggregate data from multiple motion capture databases and include them in our dataset using a unified representation that is independent of the capture system or marker set, making it easy to work with the data regardless of its origin. To obtain motion annotations in natural language, we apply a crowd-sourcing approach and a web-based tool that was specifically build for this purpose, the Motion Annotation Tool. We thoroughly document the annotation process itself and discuss gamification methods that we used to keep annotators motivated. We further propose a novel method, perplexity-based selection, which systematically selects motions for further annotation that are either under-represented in our dataset or that have erroneous annotations. We show that our method mitigates the two aforementioned problems and ensures a systematic annotation process. We provide an in-depth analysis of the structure and contents of our resulting dataset, which, as of October 10, 2016, contains 3911 motions with a total duration of 11.23 hours and 6278 annotations in natural language that contain 52,903 words. We believe this makes our dataset an excellent choice that enables more transparent and comparable research in this important area.

</details>

<details>

<summary>2018-08-09 20:25:43 - Is prioritized sweeping the better episodic control?</summary>

- *Johanni Brea*

- `1711.06677v2` - [abs](http://arxiv.org/abs/1711.06677v2) - [pdf](http://arxiv.org/pdf/1711.06677v2)

> Episodic control has been proposed as a third approach to reinforcement learning, besides model-free and model-based control, by analogy with the three types of human memory. i.e. episodic, procedural and semantic memory. But the theoretical properties of episodic control are not well investigated. Here I show that in deterministic tree Markov decision processes, episodic control is equivalent to a form of prioritized sweeping in terms of sample efficiency as well as memory and computation demands. For general deterministic and stochastic environments, prioritized sweeping performs better even when memory and computation demands are restricted to be equal to those of episodic control. These results suggest generalizations of prioritized sweeping to partially observable environments, its combined use with function approximation and the search for possible implementations of prioritized sweeping in brains.

</details>

<details>

<summary>2018-08-09 21:44:58 - Efficient human-like semantic representations via the Information Bottleneck principle</summary>

- *Noga Zaslavsky, Charles Kemp, Terry Regier, Naftali Tishby*

- `1808.03353v1` - [abs](http://arxiv.org/abs/1808.03353v1) - [pdf](http://arxiv.org/pdf/1808.03353v1)

> Maintaining efficient semantic representations of the environment is a major challenge both for humans and for machines. While human languages represent useful solutions to this problem, it is not yet clear what computational principle could give rise to similar solutions in machines. In this work we propose an answer to this open question. We suggest that languages compress percepts into words by optimizing the Information Bottleneck (IB) tradeoff between the complexity and accuracy of their lexicons. We present empirical evidence that this principle may give rise to human-like semantic representations, by exploring how human languages categorize colors. We show that color naming systems across languages are near-optimal in the IB sense, and that these natural systems are similar to artificial IB color naming systems with a single tradeoff parameter controlling the cross-language variability. In addition, the IB systems evolve through a sequence of structural phase transitions, demonstrating a possible adaptation process. This work thus identifies a computational principle that characterizes human semantic systems, and that could usefully inform semantic representations in machines.

</details>

<details>

<summary>2018-08-10 04:24:34 - A Hassle-Free Machine Learning Method for Cohort Selection of Clinical Trials</summary>

- *Liu Man*

- `1808.04694v1` - [abs](http://arxiv.org/abs/1808.04694v1) - [pdf](http://arxiv.org/pdf/1808.04694v1)

> Traditional text classification techniques in clinical domain have heavily relied on the manually extracted textual cues. This paper proposes a generally supervised machine learning method that is equally hassle-free and does not use clinical knowledge. The employed methods were simple to implement, fast to run and yet effective. This paper proposes a novel named entity recognition (NER) based an ensemble system capable of learning the keyword features in the document. Instead of merely considering the whole sentence/paragraph for analysis, the NER based keyword features can stress the important clinic relevant phases more. In addition, to capture the semantic information in the documents, the FastText features originating from the document level FastText classification results are exploited.

</details>

<details>

<summary>2018-08-10 09:30:52 - Out of the Black Box: Properties of deep neural networks and their applications</summary>

- *Nizar Ouarti, David Carmona*

- `1808.04433v1` - [abs](http://arxiv.org/abs/1808.04433v1) - [pdf](http://arxiv.org/pdf/1808.04433v1)

> Deep neural networks are powerful machine learning approaches that have exhibited excellent results on many classification tasks. However, they are considered as black boxes and some of their properties remain to be formalized. In the context of image recognition, it is still an arduous task to understand why an image is recognized or not. In this study, we formalize some properties shared by eight state-of-the-art deep neural networks in order to grasp the principles allowing a given deep neural network to classify an image. Our results, tested on these eight networks, show that an image can be sub-divided into several regions (patches) responding at different degrees of probability (local property). With the same patch, some locations in the image can answer two (or three) orders of magnitude higher than other locations (spatial property). Some locations are activators and others inhibitors (activation-inhibition property). The repetition of the same patch can increase (or decrease) the probability of recognition of an object (cumulative property). Furthermore, we propose a new approach called Deepception that exploits these properties to deceive a deep neural network. We obtain for the VGG-VDD-19 neural network a fooling ratio of 88\%. Thanks to our "Psychophysics" approach, no prior knowledge on the networks architectures is required.

</details>

<details>

<summary>2018-08-11 01:52:57 - An Implementation, Empirical Evaluation and Proposed Improvement for Bidirectional Splitting Method for Argumentation Frameworks under Stable Semantics</summary>

- *Renata Wong*

- `1808.03736v1` - [abs](http://arxiv.org/abs/1808.03736v1) - [pdf](http://arxiv.org/pdf/1808.03736v1)

> Abstract argumentation frameworks are formal systems that facilitate obtaining conclusions from non-monotonic knowledge systems. Within such a system, an argumentation semantics is defined as a set of arguments with some desired qualities, for example, that the elements are not in conflict with each other. Splitting an argumentation framework can efficiently speed up the computation of argumentation semantics. With respect to stable semantics, two methods have been proposed to split an argumentation framework either in a unidirectional or bidirectional fashion. The advantage of bidirectional splitting is that it is not structure-dependent and, unlike unidirectional splitting, it can be used for frameworks consisting of a single strongly connected component. Bidirectional splitting makes use of a minimum cut. In this paper, we implement and test the performance of the bidirectional splitting method, along with two types of graph cut algorithms. Experimental data suggest that using a minimum cut will not improve the performance of computing stable semantics in most cases. Hence, instead of a minimum cut, we propose to use a balanced cut, where the framework is split into two sub-frameworks of equal size. Experimental results conducted on bidirectional splitting using the balanced cut show a significant improvement in the performance of computing semantics.

</details>

<details>

<summary>2018-08-11 05:05:06 - Knowledge Graph Embedding with Entity Neighbors and Deep Memory Network</summary>

- *Kai Wang, Yu Liu, Xiujuan Xu, Dan Lin*

- `1808.03752v1` - [abs](http://arxiv.org/abs/1808.03752v1) - [pdf](http://arxiv.org/pdf/1808.03752v1)

> Knowledge Graph Embedding (KGE) aims to represent entities and relations of knowledge graph in a low-dimensional continuous vector space. Recent works focus on incorporating structural knowledge with additional information, such as entity descriptions, relation paths and so on. However, common used additional information usually contains plenty of noise, which makes it hard to learn valuable representation. In this paper, we propose a new kind of additional information, called entity neighbors, which contain both semantic and topological features about given entity. We then develop a deep memory network model to encode information from neighbors. Employing a gating mechanism, representations of structure and neighbors are integrated into a joint representation. The experimental results show that our model outperforms existing KGE methods utilizing entity descriptions and achieves state-of-the-art metrics on 4 datasets.

</details>

<details>

<summary>2018-08-11 08:54:40 - Towards Unsupervised Automatic Speech Recognition Trained by Unaligned Speech and Text only</summary>

- *Yi-Chen Chen, Chia-Hao Shen, Sung-Feng Huang, Hung-yi Lee*

- `1803.10952v3` - [abs](http://arxiv.org/abs/1803.10952v3) - [pdf](http://arxiv.org/pdf/1803.10952v3)

> Automatic speech recognition (ASR) has been widely researched with supervised approaches, while many low-resourced languages lack audio-text aligned data, and supervised methods cannot be applied on them.   In this work, we propose a framework to achieve unsupervised ASR on a read English speech dataset, where audio and text are unaligned. In the first stage, each word-level audio segment in the utterances is represented by a vector representation extracted by a sequence-of-sequence autoencoder, in which phonetic information and speaker information are disentangled.   Secondly, semantic embeddings of audio segments are trained from the vector representations using a skip-gram model. Last but not the least, an unsupervised method is utilized to transform semantic embeddings of audio segments to text embedding space, and finally the transformed embeddings are mapped to words.   With the above framework, we are towards unsupervised ASR trained by unaligned text and speech only.

</details>

<details>

<summary>2018-08-12 08:56:06 - Outer Product-based Neural Collaborative Filtering</summary>

- *Xiangnan He, Xiaoyu Du, Xiang Wang, Feng Tian, Jinhui Tang, Tat-Seng Chua*

- `1808.03912v1` - [abs](http://arxiv.org/abs/1808.03912v1) - [pdf](http://arxiv.org/pdf/1808.03912v1)

> In this work, we contribute a new multi-layer neural network architecture named ONCF to perform collaborative filtering. The idea is to use an outer product to explicitly model the pairwise correlations between the dimensions of the embedding space. In contrast to existing neural recommender models that combine user embedding and item embedding via a simple concatenation or element-wise product, our proposal of using outer product above the embedding layer results in a two-dimensional interaction map that is more expressive and semantically plausible. Above the interaction map obtained by outer product, we propose to employ a convolutional neural network to learn high-order correlations among embedding dimensions. Extensive experiments on two public implicit feedback data demonstrate the effectiveness of our proposed ONCF framework, in particular, the positive effect of using outer product to model the correlations between embedding dimensions in the low level of multi-layer neural recommender model. The experiment codes are available at: https://github.com/duxy-me/ConvNCF

</details>

<details>

<summary>2018-08-12 11:53:04 - Sequence Labeling: A Practical Approach</summary>

- *Adnan Akhundov, Dietrich Trautmann, Georg Groh*

- `1808.03926v1` - [abs](http://arxiv.org/abs/1808.03926v1) - [pdf](http://arxiv.org/pdf/1808.03926v1)

> We take a practical approach to solving sequence labeling problem assuming unavailability of domain expertise and scarcity of informational and computational resources. To this end, we utilize a universal end-to-end Bi-LSTM-based neural sequence labeling model applicable to a wide range of NLP tasks and languages. The model combines morphological, semantic, and structural cues extracted from data to arrive at informed predictions. The model's performance is evaluated on eight benchmark datasets (covering three tasks: POS-tagging, NER, and Chunking, and four languages: English, German, Dutch, and Spanish). We observe state-of-the-art results on four of them: CoNLL-2012 (English NER), CoNLL-2002 (Dutch NER), GermEval 2014 (German NER), Tiger Corpus (German POS-tagging), and competitive performance on the rest.

</details>

<details>

<summary>2018-08-12 12:02:45 - Learning an Executable Neural Semantic Parser</summary>

- *Jianpeng Cheng, Siva Reddy, Vijay Saraswat, Mirella Lapata*

- `1711.05066v2` - [abs](http://arxiv.org/abs/1711.05066v2) - [pdf](http://arxiv.org/pdf/1711.05066v2)

> This paper describes a neural semantic parser that maps natural language utterances onto logical forms which can be executed against a task-specific environment, such as a knowledge base or a database, to produce a response. The parser generates tree-structured logical forms with a transition-based approach which combines a generic tree-generation algorithm with domain-general operations defined by the logical language. The generation process is modeled by structured recurrent neural networks, which provide a rich encoding of the sentential context and generation history for making predictions. To tackle mismatches between natural language and logical form tokens, various attention mechanisms are explored. Finally, we consider different training settings for the neural semantic parser, including a fully supervised training where annotated logical forms are given, weakly-supervised training where denotations are provided, and distant supervision where only unlabeled sentences and a knowledge base are available. Experiments across a wide range of datasets demonstrate the effectiveness of our parser.

</details>

<details>

<summary>2018-08-13 04:02:25 - Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling</summary>

- *Luheng He, Kenton Lee, Omer Levy, Luke Zettlemoyer*

- `1805.04787v2` - [abs](http://arxiv.org/abs/1805.04787v2) - [pdf](http://arxiv.org/pdf/1805.04787v2)

> Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features. We propose an end-to-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.

</details>

<details>

<summary>2018-08-13 09:50:43 - Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering</summary>

- *Daniil Sorokin, Iryna Gurevych*

- `1808.04126v1` - [abs](http://arxiv.org/abs/1808.04126v1) - [pdf](http://arxiv.org/pdf/1808.04126v1)

> The most approaches to Knowledge Base Question Answering are based on semantic parsing. In this paper, we address the problem of learning vector representations for complex semantic parses that consist of multiple entities and relations. Previous work largely focused on selecting the correct semantic relations for a question and disregarded the structure of the semantic parse: the connections between entities and the directions of the relations. We propose to use Gated Graph Neural Networks to encode the graph structure of the semantic parse. We show on two data sets that the graph networks outperform all baseline models that do not explicitly model the structure. The error analysis confirms that our approach can successfully process complex semantic parses.

</details>

<details>

<summary>2018-08-13 11:15:23 - Multi-Task Learning for Sequence Tagging: An Empirical Study</summary>

- *Soravit Changpinyo, Hexiang Hu, Fei Sha*

- `1808.04151v1` - [abs](http://arxiv.org/abs/1808.04151v1) - [pdf](http://arxiv.org/pdf/1808.04151v1)

> We study three general multi-task learning (MTL) approaches on 11 sequence tagging tasks. Our extensive empirical results show that in about 50% of the cases, jointly learning all 11 tasks improves upon either independent or pairwise learning of the tasks. We also show that pairwise MTL can inform us what tasks can benefit others or what tasks can be benefited if they are learned jointly. In particular, we identify tasks that can always benefit others as well as tasks that can always be harmed by others. Interestingly, one of our MTL approaches yields embeddings of the tasks that reveal the natural clustering of semantic and syntactic tasks. Our inquiries have opened the doors to further utilization of MTL in NLP.

</details>

<details>

<summary>2018-08-13 11:47:51 - Relaxed Schedulers Can Efficiently Parallelize Iterative Algorithms</summary>

- *Dan Alistarh, Trevor Brown, Justin Kopinsky, Giorgi Nadiradze*

- `1808.04155v1` - [abs](http://arxiv.org/abs/1808.04155v1) - [pdf](http://arxiv.org/pdf/1808.04155v1)

> There has been significant progress in understanding the parallelism inherent to iterative sequential algorithms: for many classic algorithms, the depth of the dependence structure is now well understood, and scheduling techniques have been developed to exploit this shallow dependence structure for efficient parallel implementations. A related, applied research strand has studied methods by which certain iterative task-based algorithms can be efficiently parallelized via relaxed concurrent priority schedulers. These allow for high concurrency when inserting and removing tasks, at the cost of executing superfluous work due to the relaxed semantics of the scheduler.   In this work, we take a step towards unifying these two research directions, by showing that there exists a family of relaxed priority schedulers that can efficiently and deterministically execute classic iterative algorithms such as greedy maximal independent set (MIS) and matching. Our primary result shows that, given a randomized scheduler with an expected relaxation factor of $k$ in terms of the maximum allowed priority inversions on a task, and any graph on $n$ vertices, the scheduler is able to execute greedy MIS with only an additive factor of poly($k$) expected additional iterations compared to an exact (but not scalable) scheduler. This counter-intuitive result demonstrates that the overhead of relaxation when computing MIS is not dependent on the input size or structure of the input graph. Experimental results show that this overhead can be clearly offset by the gain in performance due to the highly scalable scheduler. In sum, we present an efficient method to deterministically parallelize iterative sequential algorithms, with provable runtime guarantees in terms of the number of executed tasks to completion.

</details>

<details>

<summary>2018-08-13 13:59:38 - Addressing Client Needs for Cloud Computing using Formal Foundations</summary>

- *Andreea Buga, Sorana Tania Nemes, Atif Mashkoor*

- `1808.04222v1` - [abs](http://arxiv.org/abs/1808.04222v1) - [pdf](http://arxiv.org/pdf/1808.04222v1)

> Cloud-enabled large-scale distributed systems orchestrate resources and services from various providers in order to deliver high-quality software solutions to the end users. The space and structure created by such technological advancements are immense sources of information and impose a high complexity and heterogeneity, which might lead to unexpected failures. In this chapter, we present a model that coordinates the multi-cloud interaction through the specification, validation, and verification of a middle-ware exploiting monitoring and adaptation processes. The monitoring processes handle collecting meaningful data and assessing the state of components, while the adaptation processes restore the system as dictated by the evolution needs and sudden changes in the operating environment conditions. We employ Abstract State Machines to specify the models and we further make use of the ASMETA framework to simulate and validate them. Desired properties of the system are defined and analysed with the aid of the Computation Tree Logic.

</details>

<details>

<summary>2018-08-13 15:37:29 - Fast, Better Training Trick -- Random Gradient</summary>

- *Jiakai Wei*

- `1808.04293v1` - [abs](http://arxiv.org/abs/1808.04293v1) - [pdf](http://arxiv.org/pdf/1808.04293v1)

> In this paper, we will show an unprecedented method to accelerate training and improve performance, which called random gradient (RG). This method can be easier to the training of any model without extra calculation cost, we use Image classification, Semantic segmentation, and GANs to confirm this method can improve speed which is training model in computer vision. The central idea is using the loss multiplied by a random number to random reduce the back-propagation gradient. We can use this method to produce a better result in Pascal VOC, Cifar, Cityscapes datasets.

</details>

<details>

<summary>2018-08-14 02:37:20 - A Full End-to-End Semantic Role Labeler, Syntax-agnostic Over Syntax-aware?</summary>

- *Jiaxun Cai, Shexia He, Zuchao Li, Hai Zhao*

- `1808.03815v2` - [abs](http://arxiv.org/abs/1808.03815v2) - [pdf](http://arxiv.org/pdf/1808.03815v2)

> Semantic role labeling (SRL) is to recognize the predicate-argument structure of a sentence, including subtasks of predicate disambiguation and argument labeling. Previous studies usually formulate the entire SRL problem into two or more subtasks. For the first time, this paper introduces an end-to-end neural model which unifiedly tackles the predicate disambiguation and the argument labeling in one shot. Using a biaffine scorer, our model directly predicts all semantic role labels for all given word pairs in the sentence without relying on any syntactic parse information. Specifically, we augment the BiLSTM encoder with a non-linear transformation to further distinguish the predicate and the argument in a given sentence, and model the semantic role labeling process as a word pair classification task by employing the biaffine attentional mechanism. Though the proposed model is syntax-agnostic with local decoder, it outperforms the state-of-the-art syntax-aware SRL systems on the CoNLL-2008, 2009 benchmarks for both English and Chinese. To our best knowledge, we report the first syntax-agnostic SRL model that surpasses all known syntax-aware models.

</details>

<details>

<summary>2018-08-14 06:26:12 - Familia: A Configurable Topic Modeling Framework for Industrial Text Engineering</summary>

- *Di Jiang, Yuanfeng Song, Rongzhong Lian, Siqi Bao, Jinhua Peng, Huang He, Hua Wu*

- `1808.03733v2` - [abs](http://arxiv.org/abs/1808.03733v2) - [pdf](http://arxiv.org/pdf/1808.03733v2)

> In the last decade, a variety of topic models have been proposed for text engineering. However, except Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (LDA), most of existing topic models are seldom applied or considered in industrial scenarios. This phenomenon is caused by the fact that there are very few convenient tools to support these topic models so far. Intimidated by the demanding expertise and labor of designing and implementing parameter inference algorithms, software engineers are prone to simply resort to PLSA/LDA, without considering whether it is proper for their problem at hand or not. In this paper, we propose a configurable topic modeling framework named Familia, in order to bridge the huge gap between academic research fruits and current industrial practice. Familia supports an important line of topic models that are widely applicable in text engineering scenarios. In order to relieve burdens of software engineers without knowledge of Bayesian networks, Familia is able to conduct automatic parameter inference for a variety of topic models. Simply through changing the data organization of Familia, software engineers are able to easily explore a broad spectrum of existing topic models or even design their own topic models, and find the one that best suits the problem at hand. With its superior extendability, Familia has a novel sampling mechanism that strikes balance between effectiveness and efficiency of parameter inference. Furthermore, Familia is essentially a big topic modeling framework that supports parallel parameter inference and distributed parameter storage. The utilities and necessity of Familia are demonstrated in real-life industrial applications. Familia would significantly enlarge software engineers' arsenal of topic models and pave the way for utilizing highly customized topic models in real-life problems.

</details>

<details>

<summary>2018-08-14 14:03:47 - Improving Generalization via Scalable Neighborhood Component Analysis</summary>

- *Zhirong Wu, Alexei A. Efros, Stella X. Yu*

- `1808.04699v1` - [abs](http://arxiv.org/abs/1808.04699v1) - [pdf](http://arxiv.org/pdf/1808.04699v1)

> Current major approaches to visual recognition follow an end-to-end formulation that classifies an input image into one of the pre-determined set of semantic categories. Parametric softmax classifiers are a common choice for such a closed world with fixed categories, especially when big labeled data is available during training. However, this becomes problematic for open-set scenarios where new categories are encountered with very few examples for learning a generalizable parametric classifier. We adopt a non-parametric approach for visual recognition by optimizing feature embeddings instead of parametric classifiers. We use a deep neural network to learn the visual feature that preserves the neighborhood structure in the semantic space, based on the Neighborhood Component Analysis (NCA) criterion. Limited by its computational bottlenecks, we devise a mechanism to use augmented memory to scale NCA for large datasets and very deep networks. Our experiments deliver not only remarkable performance on ImageNet classification for such a simple non-parametric method, but most importantly a more generalizable feature representation for sub-category discovery and few-shot recognition.

</details>

<details>

<summary>2018-08-14 20:52:43 - Embedding Grammars</summary>

- *David Wingate, William Myers, Nancy Fulda, Tyler Etchart*

- `1808.04891v1` - [abs](http://arxiv.org/abs/1808.04891v1) - [pdf](http://arxiv.org/pdf/1808.04891v1)

> Classic grammars and regular expressions can be used for a variety of purposes, including parsing, intent detection, and matching. However, the comparisons are performed at a structural level, with constituent elements (words or characters) matched exactly. Recent advances in word embeddings show that semantically related words share common features in a vector-space representation, suggesting the possibility of a hybrid grammar and word embedding. In this paper, we blend the structure of standard context-free grammars with the semantic generalization capabilities of word embeddings to create hybrid semantic grammars. These semantic grammars generalize the specific terminals used by the programmer to other words and phrases with related meanings, allowing the construction of compact grammars that match an entire region of the vector space rather than matching specific elements.

</details>

<details>

<summary>2018-08-15 00:20:35 - Holographic Visualisation of Radiology Data and Automated Machine Learning-based Medical Image Segmentation</summary>

- *Lucian Trestioreanu*

- `1808.04929v1` - [abs](http://arxiv.org/abs/1808.04929v1) - [pdf](http://arxiv.org/pdf/1808.04929v1)

> Within this thesis we propose a platform for combining Augmented Reality (AR) hardware with machine learning in a user-oriented pipeline, offering to the medical staff an intuitive 3D visualization of volumetric Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) medical image segmentations inside the AR headset, that does not need human intervention for loading, processing and segmentation of medical images. The AR visualization, based on Microsoft HoloLens, employs a modular and thus scalable frontend-backend architecture for real-time visualizations on multiple AR headsets. As Convolutional Neural Networks (CNNs) have lastly demonstrated superior performance for the machine learning task of image semantic segmentation, the pipeline also includes a fully automated CNN algorithm for the segmentation of the liver from CT scans. The model is based on the Deep Retinal Image Understanding (DRIU) model which is a Fully Convolutional Network with side outputs from feature maps with different resolution, extracted at different stages of the network. The algorithm is 2.5D which means that the input is a set of consecutive scan slices. The experiments have been performed on the Liver Tumor Segmentation Challenge (LiTS) dataset for liver segmentation and demonstrated good results and flexibility. While multiple approaches exist in the domain, only few of them have focused on overcoming the practical aspects which still largely hold this technology away from the operating rooms. In line with this, we also are next planning an evaluation from medical doctors and radiologists in a real-world environment.

</details>

<details>

<summary>2018-08-15 14:54:44 - Joint & Progressive Learning from High-Dimensional Data for Multi-Label Classification</summary>

- *Danfeng Hong, Naoto Yokoya, Jian Xu, Xiaoxiang Zhu*

- `1808.05110v1` - [abs](http://arxiv.org/abs/1808.05110v1) - [pdf](http://arxiv.org/pdf/1808.05110v1)

> Despite the fact that nonlinear subspace learning techniques (e.g. manifold learning) have successfully applied to data representation, there is still room for improvement in explainability (explicit mapping), generalization (out-of-samples), and cost-effectiveness (linearization). To this end, a novel linearized subspace learning technique is developed in a joint and progressive way, called \textbf{j}oint and \textbf{p}rogressive \textbf{l}earning str\textbf{a}teg\textbf{y} (J-Play), with its application to multi-label classification. The J-Play learns high-level and semantically meaningful feature representation from high-dimensional data by 1) jointly performing multiple subspace learning and classification to find a latent subspace where samples are expected to be better classified; 2) progressively learning multi-coupled projections to linearly approach the optimal mapping bridging the original space with the most discriminative subspace; 3) locally embedding manifold structure in each learnable latent subspace. Extensive experiments are performed to demonstrate the superiority and effectiveness of the proposed method in comparison with previous state-of-the-art methods.

</details>

<details>

<summary>2018-08-16 03:08:54 - A Graph Traversal Based Approach to Answer Non-Aggregation Questions Over DBpedia</summary>

- *Chenhao Zhu, Kan Ren, Xuan Liu, Haofen Wang, Yiding Tian, Yong Yu*

- `1510.04780v2` - [abs](http://arxiv.org/abs/1510.04780v2) - [pdf](http://arxiv.org/pdf/1510.04780v2)

> We present a question answering system over DBpedia, filling the gap between user information needs expressed in natural language and a structured query interface expressed in SPARQL over the underlying knowledge base (KB). Given the KB, our goal is to comprehend a natural language query and provide corresponding accurate answers. Focusing on solving the non-aggregation questions, in this paper, we construct a subgraph of the knowledge base from the detected entities and propose a graph traversal method to solve both the semantic item mapping problem and the disambiguation problem in a joint way. Compared with existing work, we simplify the process of query intention understanding and pay more attention to the answer path ranking. We evaluate our method on a non-aggregation question dataset and further on a complete dataset. Experimental results show that our method achieves best performance compared with several state-of-the-art systems.

</details>

<details>

<summary>2018-08-16 06:21:56 - EmbNum: Semantic labeling for numerical values with deep metric learning</summary>

- *Phuc Nguyen, Khai Nguyen, Ryutaro Ichise, Hideaki Takeda*

- `1807.01367v2` - [abs](http://arxiv.org/abs/1807.01367v2) - [pdf](http://arxiv.org/pdf/1807.01367v2)

> Semantic labeling for numerical values is a task of assigning semantic labels to unknown numerical attributes. The semantic labels could be numerical properties in ontologies, instances in knowledge bases, or labeled data that are manually annotated by domain experts. In this paper, we refer to semantic labeling as a retrieval setting where the label of an unknown attribute is assigned by the label of the most relevant attribute in labeled data. One of the greatest challenges is that an unknown attribute rarely has the same set of values with the similar one in the labeled data. To overcome the issue, statistical interpretation of value distribution is taken into account. However, the existing studies assume a specific form of distribution. It is not appropriate in particular to apply open data where there is no knowledge of data in advance. To address these problems, we propose a neural numerical embedding model (EmbNum) to learn useful representation vectors for numerical attributes without prior assumptions on the distribution of data. Then, the "semantic similarities" between the attributes are measured on these representation vectors by the Euclidean distance. Our empirical experiments on City Data and Open Data show that EmbNum significantly outperforms state-of-the-art methods for the task of numerical attribute semantic labeling regarding effectiveness and efficiency.

</details>

<details>

<summary>2018-08-16 08:11:24 - Computing Word Classes Using Spectral Clustering</summary>

- *Effi Levi, Saggy Herman, Ari Rappoport*

- `1808.05374v1` - [abs](http://arxiv.org/abs/1808.05374v1) - [pdf](http://arxiv.org/pdf/1808.05374v1)

> Clustering a lexicon of words is a well-studied problem in natural language processing (NLP). Word clusters are used to deal with sparse data in statistical language processing, as well as features for solving various NLP tasks (text categorization, question answering, named entity recognition and others).   Spectral clustering is a widely used technique in the field of image processing and speech recognition. However, it has scarcely been explored in the context of NLP; specifically, the method used in this (Meila and Shi, 2001) has never been used to cluster a general word lexicon.   We apply spectral clustering to a lexicon of words, evaluating the resulting clusters by using them as features for solving two classical NLP tasks: semantic role labeling and dependency parsing. We compare performance with Brown clustering, a widely-used technique for word clustering, as well as with other clustering methods. We show that spectral clusters produce similar results to Brown clusters, and outperform other clustering methods. In addition, we quantify the overlap between spectral and Brown clusters, showing that each model captures some information which is uncaptured by the other.

</details>

<details>

<summary>2018-08-16 08:22:59 - Towards Automated Data Integration in Software Analytics</summary>

- *Silverio Martínez-Fernández, Petar Jovanovic, Xavier Franch, Andreas Jedlitschka*

- `1808.05376v1` - [abs](http://arxiv.org/abs/1808.05376v1) - [pdf](http://arxiv.org/pdf/1808.05376v1)

> Software organizations want to be able to base their decisions on the latest set of available data and the real-time analytics derived from them. In order to support "real-time enterprise" for software organizations and provide information transparency for diverse stakeholders, we integrate heterogeneous data sources about software analytics, such as static code analysis, testing results, issue tracking systems, network monitoring systems, etc. To deal with the heterogeneity of the underlying data sources, we follow an ontology-based data integration approach in this paper and define an ontology that captures the semantics of relevant data for software analytics. Furthermore, we focus on the integration of such data sources by proposing two approaches: a static and a dynamic one. We first discuss the current static approach with a predefined set of analytic views representing software quality factors and further envision how this process could be automated in order to dynamically build custom user analysis using a semi-automatic platform for managing the lifecycle of analytics infrastructures.

</details>

<details>

<summary>2018-08-16 09:02:37 - Story Disambiguation: Tracking Evolving News Stories across News and Social Streams</summary>

- *Bichen Shi, Thanh-Binh Le, Neil Hurley, Georgiana Ifrim*

- `1808.05906v1` - [abs](http://arxiv.org/abs/1808.05906v1) - [pdf](http://arxiv.org/pdf/1808.05906v1)

> Following a particular news story online is an important but difficult task, as the relevant information is often scattered across different domains/sources (e.g., news articles, blogs, comments, tweets), presented in various formats and language styles, and may overlap with thousands of other stories. In this work we join the areas of topic tracking and entity disambiguation, and propose a framework named Story Disambiguation - a cross-domain story tracking approach that builds on real-time entity disambiguation and a learning-to-rank framework to represent and update the rich semantic structure of news stories. Given a target news story, specified by a seed set of documents, the goal is to effectively select new story-relevant documents from an incoming document stream. We represent stories as entity graphs and we model the story tracking problem as a learning-to-rank task. This enables us to track content with high accuracy, from multiple domains, in real-time. We study a range of text, entity and graph based features to understand which type of features are most effective for representing stories. We further propose new semi-supervised learning techniques to automatically update the story representation over time. Our empirical study shows that we outperform the accuracy of state-of-the-art methods for tracking mixed-domain document streams, while requiring fewer labeled data to seed the tracked stories. This is particularly the case for local news stories that are easily over shadowed by other trending stories, and for complex news stories with ambiguous content in noisy stream environments.

</details>

<details>

<summary>2018-08-16 12:13:16 - Sememe Prediction: Learning Semantic Knowledge from Unstructured Textual Wiki Descriptions</summary>

- *Wei Li, Xuancheng Ren, Damai Dai, Yunfang Wu, Houfeng Wang, Xu Sun*

- `1808.05437v1` - [abs](http://arxiv.org/abs/1808.05437v1) - [pdf](http://arxiv.org/pdf/1808.05437v1)

> Huge numbers of new words emerge every day, leading to a great need for representing them with semantic meaning that is understandable to NLP systems. Sememes are defined as the minimum semantic units of human languages, the combination of which can represent the meaning of a word. Manual construction of sememe based knowledge bases is time-consuming and labor-intensive. Fortunately, communities are devoted to composing the descriptions of words in the wiki websites. In this paper, we explore to automatically predict lexical sememes based on the descriptions of the words in the wiki websites. We view this problem as a weakly ordered multi-label task and propose a Label Distributed seq2seq model (LD-seq2seq) with a novel soft loss function to solve the problem. In the experiments, we take a real-world sememe knowledge base HowNet and the corresponding descriptions of the words in Baidu Wiki for training and evaluation. The results show that our LD-seq2seq model not only beats all the baselines significantly on the test set, but also outperforms amateur human annotators in a random subset of the test set.

</details>

<details>

<summary>2018-08-16 12:30:52 - DRLGENCERT: Deep Learning-based Automated Testing of Certificate Verification in SSL/TLS Implementations</summary>

- *Chao Chen, Wenrui Diao, Yingpei Zeng, Shanqing Guo, Chengyu Hu*

- `1808.05444v1` - [abs](http://arxiv.org/abs/1808.05444v1) - [pdf](http://arxiv.org/pdf/1808.05444v1)

> The Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols are the foundation of network security. The certificate verification in SSL/TLS implementations is vital and may become the weak link in the whole network ecosystem. In previous works, some research focused on the automated testing of certificate verification, and the main approaches rely on generating massive certificates through randomly combining parts of seed certificates for fuzzing. Although the generated certificates could meet the semantic constraints, the cost is quite heavy, and the performance is limited due to the randomness. To fill this gap, in this paper, we propose DRLGENCERT, the first framework of applying deep reinforcement learning to the automated testing of certificate verification in SSL/TLS implementations. DRLGENCERT accepts ordinary certificates as input and outputs newly generated certificates which could trigger discrepancies with high efficiency. Benefited by the deep reinforcement learning, when generating certificates, our framework could choose the best next action according to the result of a previous modification, instead of simple random combinations. At the same time, we developed a set of new techniques to support the overall design, like new feature extraction method for X.509 certificates, fine-grained differential testing, and so forth. Also, we implemented a prototype of DRLGENCERT and carried out a series of real-world experiments. The results show DRLGENCERT is quite efficient, and we obtained 84,661 discrepancy-triggering certificates from 181,900 certificate seeds, say around 46.5% effectiveness. Also, we evaluated six popular SSL/TLS implementations, including GnuTLS, MatrixSSL, MbedTLS, NSS, OpenSSL, and wolfSSL. DRLGENCERT successfully discovered 23 serious certificate verification flaws, and most of them were previously unknown.

</details>

<details>

<summary>2018-08-16 18:14:01 - Multi-task Learning for Universal Sentence Embeddings: A Thorough Evaluation using Transfer and Auxiliary Tasks</summary>

- *Wasi Uddin Ahmad, Xueying Bai, Zhechao Huang, Chao Jiang, Nanyun Peng, Kai-Wei Chang*

- `1804.07911v2` - [abs](http://arxiv.org/abs/1804.07911v2) - [pdf](http://arxiv.org/pdf/1804.07911v2)

> Learning distributed sentence representations is one of the key challenges in natural language processing. Previous work demonstrated that a recurrent neural network (RNNs) based sentence encoder trained on a large collection of annotated natural language inference data, is efficient in the transfer learning to facilitate other related tasks. In this paper, we show that joint learning of multiple tasks results in better generalizable sentence representations by conducting extensive experiments and analysis comparing the multi-task and single-task learned sentence encoders. The quantitative analysis using auxiliary tasks show that multi-task learning helps to embed better semantic information in the sentence representations compared to single-task learning. In addition, we compare multi-task sentence encoders with contextualized word representations and show that combining both of them can further boost the performance of transfer learning.

</details>

<details>

<summary>2018-08-18 10:23:09 - SeVeN: Augmenting Word Embeddings with Unsupervised Relation Vectors</summary>

- *Luis Espinosa-Anke, Steven Schockaert*

- `1808.06068v1` - [abs](http://arxiv.org/abs/1808.06068v1) - [pdf](http://arxiv.org/pdf/1808.06068v1)

> We present SeVeN (Semantic Vector Networks), a hybrid resource that encodes relationships between words in the form of a graph. Different from traditional semantic networks, these relations are represented as vectors in a continuous vector space. We propose a simple pipeline for learning such relation vectors, which is based on word vector averaging in combination with an ad hoc autoencoder. We show that by explicitly encoding relational information in a dedicated vector space we can capture aspects of word meaning that are complementary to what is captured by word embeddings. For example, by examining clusters of relation vectors, we observe that relational similarities can be identified at a more abstract level than with traditional word vector differences. Finally, we test the effectiveness of semantic vector networks in two tasks: measuring word similarity and neural text categorization. SeVeN is available at bitbucket.org/luisespinosa/seven.

</details>

<details>

<summary>2018-08-18 13:44:56 - Neural Vector Spaces for Unsupervised Information Retrieval</summary>

- *Christophe Van Gysel, Maarten de Rijke, Evangelos Kanoulas*

- `1708.02702v4` - [abs](http://arxiv.org/abs/1708.02702v4) - [pdf](http://arxiv.org/pdf/1708.02702v4)

> We propose the Neural Vector Space Model (NVSM), a method that learns representations of documents in an unsupervised manner for news article retrieval. In the NVSM paradigm, we learn low-dimensional representations of words and documents from scratch using gradient descent and rank documents according to their similarity with query representations that are composed from word representations. We show that NVSM performs better at document ranking than existing latent semantic vector space methods. The addition of NVSM to a mixture of lexical language models and a state-of-the-art baseline vector space model yields a statistically significant increase in retrieval effectiveness. Consequently, NVSM adds a complementary relevance signal. Next to semantic matching, we find that NVSM performs well in cases where lexical matching is needed.   NVSM learns a notion of term specificity directly from the document collection without feature engineering. We also show that NVSM learns regularities related to Luhn significance. Finally, we give advice on how to deploy NVSM in situations where model selection (e.g., cross-validation) is infeasible. We find that an unsupervised ensemble of multiple models trained with different hyperparameter values performs better than a single cross-validated model. Therefore, NVSM can safely be used for ranking documents without supervised relevance judgments.

</details>

<details>

<summary>2018-08-19 14:35:57 - BinMatch: A Semantics-based Hybrid Approach on Binary Code Clone Analysis</summary>

- *Yikun Hu, Yuanyuan Zhang, Juanru Li, Hui Wang, Bodong Li, Dawu Gu*

- `1808.06216v1` - [abs](http://arxiv.org/abs/1808.06216v1) - [pdf](http://arxiv.org/pdf/1808.06216v1)

> Binary code clone analysis is an important technique which has a wide range of applications in software engineering (e.g., plagiarism detection, bug detection). The main challenge of the topic lies in the semantics-equivalent code transformation (e.g., optimization, obfuscation) which would alter representations of binary code tremendously. Another chal- lenge is the trade-off between detection accuracy and coverage. Unfortunately, existing techniques still rely on semantics-less code features which are susceptible to the code transformation. Besides, they adopt merely either a static or a dynamic approach to detect binary code clones, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid approach to detect binary clone functions. We execute a template binary function with its test cases, and emulate the execution of every target function for clone comparison with the runtime information migrated from that template function. The semantic signatures are extracted during the execution of the template function and emulation of the target function. Lastly, a similarity score is calculated from their signatures to measure their likeness. We implement the approach in a prototype system designated as BinMatch which analyzes IA-32 binary code on the Linux platform. We evaluate BinMatch with eight real-world projects compiled with different compilation configurations and commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BinMatch is robust to the semantics-equivalent code transformation. Besides, it not only covers all target functions for clone analysis, but also improves the detection accuracy comparing to the state-of-the-art solutions.

</details>

<details>

<summary>2018-08-20 04:28:05 - Self-Attentive Sequential Recommendation</summary>

- *Wang-Cheng Kang, Julian McAuley*

- `1808.09781v1` - [abs](http://arxiv.org/abs/1808.09781v1) - [pdf](http://arxiv.org/pdf/1808.09781v1)

> Sequential dynamics are a key feature of many modern recommender systems, which seek to capture the `context' of users' activities on the basis of actions they have performed recently. To capture such patterns, two approaches have proliferated: Markov Chains (MCs) and Recurrent Neural Networks (RNNs). Markov Chains assume that a user's next action can be predicted on the basis of just their last (or last few) actions, while RNNs in principle allow for longer-term semantics to be uncovered. Generally speaking, MC-based methods perform best in extremely sparse datasets, where model parsimony is critical, while RNNs perform better in denser datasets where higher model complexity is affordable. The goal of our work is to balance these two goals, by proposing a self-attention based sequential model (SASRec) that allows us to capture long-term semantics (like an RNN), but, using an attention mechanism, makes its predictions based on relatively few actions (like an MC). At each time step, SASRec seeks to identify which items are `relevant' from a user's action history, and use them to predict the next item. Extensive empirical studies show that our method outperforms various state-of-the-art sequential models (including MC/CNN/RNN-based approaches) on both sparse and dense datasets. Moreover, the model is an order of magnitude more efficient than comparable CNN/RNN-based models. Visualizations on attention weights also show how our model adaptively handles datasets with various density, and uncovers meaningful patterns in activity sequences.

</details>

<details>

<summary>2018-08-20 09:38:04 - Leveraging Historical Associations between Requirements and Source Code to Identify Impacted Classes</summary>

- *Davide Falessi, Justin Roll, Jin Guo, Jane Cleland-Huang*

- `1808.06359v1` - [abs](http://arxiv.org/abs/1808.06359v1) - [pdf](http://arxiv.org/pdf/1808.06359v1)

> As new requirements are introduced and implemented in a software system, developers must identify the set of source code classes which need to be changed. Therefore, past effort has focused on predicting the set of classes impacted by a requirement. In this paper, we introduce and evaluate a new type of information based on the intuition that the set of requirements which are associated with historical changes to a specific class are likely to exhibit semantic similarity to new requirements which impact that class. This new Requirements to Requirements Set (R2RS) family of metrics captures the semantic similarity between a new requirement and the set of existing requirements previously associated with a class. The aim of this paper is to present and evaluate the usefulness of R2RS metrics in predicting the set of classes impacted by a requirement. We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores). We evaluate if R2RS is useful for predicting impacted classes in combination and against four other families of metrics that are based upon temporal locality of changes, direct similarity to code, complexity metrics, and code smells. Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes. Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60% across the various classifiers and projects.

</details>

<details>

<summary>2018-08-20 15:15:32 - Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies</summary>

- *Alessandro Achille, Tom Eccles, Loic Matthey, Christopher P. Burgess, Nick Watters, Alexander Lerchner, Irina Higgins*

- `1808.06508v1` - [abs](http://arxiv.org/abs/1808.06508v1) - [pdf](http://arxiv.org/pdf/1808.06508v1)

> Intelligent behaviour in the real-world requires the ability to acquire new knowledge from an ongoing sequence of experiences while preserving and reusing past knowledge. We propose a novel algorithm for unsupervised representation learning from piece-wise stationary visual data: Variational Autoencoder with Shared Embeddings (VASE). Based on the Minimum Description Length principle, VASE automatically detects shifts in the data distribution and allocates spare representational capacity to new knowledge, while simultaneously protecting previously learnt representations from catastrophic forgetting. Our approach encourages the learnt representations to be disentangled, which imparts a number of desirable properties: VASE can deal sensibly with ambiguous inputs, it can enhance its own representations through imagination-based exploration, and most importantly, it exhibits semantically meaningful sharing of latents between different datasets. Compared to baselines with entangled representations, our approach is able to reason beyond surface-level statistics and perform semantically meaningful cross-domain inference.

</details>

<details>

<summary>2018-08-20 16:03:10 - Code Vectors: Understanding Programs Through Embedded Abstracted Symbolic Traces</summary>

- *Jordan Henkel, Shuvendu K. Lahiri, Ben Liblit, Thomas Reps*

- `1803.06686v2` - [abs](http://arxiv.org/abs/1803.06686v2) - [pdf](http://arxiv.org/pdf/1803.06686v2)

> With the rise of machine learning, there is a great deal of interest in treating programs as data to be fed to learning algorithms. However, programs do not start off in a form that is immediately amenable to most off-the-shelf learning techniques. Instead, it is necessary to transform the program to a suitable representation before a learning technique can be applied.   In this paper, we use abstractions of traces obtained from symbolic execution of a program as a representation for learning word embeddings. We trained a variety of word embeddings under hundreds of parameterizations, and evaluated each learned embedding on a suite of different tasks. In our evaluation, we obtain 93% top-1 accuracy on a benchmark consisting of over 19,000 API-usage analogies extracted from the Linux kernel. In addition, we show that embeddings learned from (mainly) semantic abstractions provide nearly triple the accuracy of those learned from (mainly) syntactic abstractions.

</details>

<details>

<summary>2018-08-20 17:55:56 - High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</summary>

- *Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, Bryan Catanzaro*

- `1711.11585v2` - [abs](http://arxiv.org/abs/1711.11585v2) - [pdf](http://arxiv.org/pdf/1711.11585v2)

> We present a new method for synthesizing high-resolution photo-realistic images from semantic label maps using conditional generative adversarial networks (conditional GANs). Conditional GANs have enabled a variety of applications, but the results are often limited to low-resolution and still far from realistic. In this work, we generate 2048x1024 visually appealing results with a novel adversarial loss, as well as new multi-scale generator and discriminator architectures. Furthermore, we extend our framework to interactive visual manipulation with two additional features. First, we incorporate object instance segmentation information, which enables object manipulations such as removing/adding objects and changing the object category. Second, we propose a method to generate diverse results given the same input, allowing users to edit the object appearance interactively. Human opinion studies demonstrate that our method significantly outperforms existing methods, advancing both the quality and the resolution of deep image synthesis and editing.

</details>

<details>

<summary>2018-08-21 01:57:49 - Learning to Compose over Tree Structures via POS Tags</summary>

- *Gehui Shen, Zhi-Hong Deng, Ting Huang, Xi Chen*

- `1808.06075v2` - [abs](http://arxiv.org/abs/1808.06075v2) - [pdf](http://arxiv.org/pdf/1808.06075v2)

> Recursive Neural Network (RecNN), a type of models which compose words or phrases recursively over syntactic tree structures, has been proven to have superior ability to obtain sentence representation for a variety of NLP tasks. However, RecNN is born with a thorny problem that a shared compositional function for each node of trees can't capture the complex semantic compositionality so that the expressive power of model is limited. In this paper, in order to address this problem, we propose Tag-Guided HyperRecNN/TreeLSTM (TG-HRecNN/TreeLSTM), which introduces hypernetwork into RecNNs to take as inputs Part-of-Speech (POS) tags of word/phrase and generate the semantic composition parameters dynamically. Experimental results on five datasets for two typical NLP tasks show proposed models both obtain significant improvement compared with RecNN and TreeLSTM consistently. Our TG-HTreeLSTM outperforms all existing RecNN-based models and achieves or is competitive with state-of-the-art on four sentence classification benchmarks. The effectiveness of our models is also demonstrated by qualitative analysis.

</details>

<details>

<summary>2018-08-21 04:16:03 - Vicious Circle Principle and Logic Programs with Aggregates</summary>

- *Michael Gelfond, Yuanlin Zhang*

- `1808.07050v1` - [abs](http://arxiv.org/abs/1808.07050v1) - [pdf](http://arxiv.org/pdf/1808.07050v1)

> The paper presents a knowledge representation language $\mathcal{A}log$ which extends ASP with aggregates. The goal is to have a language based on simple syntax and clear intuitive and mathematical semantics. We give some properties of $\mathcal{A}log$, an algorithm for computing its answer sets, and comparison with other approaches.

</details>

<details>

<summary>2018-08-21 08:57:43 - Dynamic Integration of Background Knowledge in Neural NLU Systems</summary>

- *Dirk Weissenborn, Tomáš Kočiský, Chris Dyer*

- `1706.02596v3` - [abs](http://arxiv.org/abs/1706.02596v3) - [pdf](http://arxiv.org/pdf/1706.02596v3)

> Common-sense and background knowledge is required to understand natural language, but in most neural natural language understanding (NLU) systems, this knowledge must be acquired from training corpora during learning, and then it is static at test time. We introduce a new architecture for the dynamic integration of explicit background knowledge in NLU models. A general-purpose reading module reads background knowledge in the form of free-text statements (together with task-specific text inputs) and yields refined word representations to a task-specific NLU architecture that reprocesses the task inputs with these representations. Experiments on document question answering (DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness and flexibility of the approach. Analysis shows that our model learns to exploit knowledge in a semantically appropriate way.

</details>

<details>

<summary>2018-08-21 11:28:14 - Acoustic-to-Word Recognition with Sequence-to-Sequence Models</summary>

- *Shruti Palaskar, Florian Metze*

- `1807.09597v2` - [abs](http://arxiv.org/abs/1807.09597v2) - [pdf](http://arxiv.org/pdf/1807.09597v2)

> Acoustic-to-Word recognition provides a straightforward solution to end-to-end speech recognition without needing external decoding, language model re-scoring or lexicon. While character-based models offer a natural solution to the out-of-vocabulary problem, word models can be simpler to decode and may also be able to directly recognize semantically meaningful units. We present effective methods to train Sequence-to-Sequence models for direct word-level recognition (and character-level recognition) and show an absolute improvement of 4.4-5.0\% in Word Error Rate on the Switchboard corpus compared to prior work. In addition to these promising results, word-based models are more interpretable than character models, which have to be composed into words using a separate decoding step. We analyze the encoder hidden states and the attention behavior, and show that location-aware attention naturally represents words as a single speech-word-vector, despite spanning multiple frames in the input. We finally show that the Acoustic-to-Word model also learns to segment speech into words with a mean standard deviation of 3 frames as compared with human annotated forced-alignments for the Switchboard corpus.

</details>

<details>

<summary>2018-08-21 11:37:57 - Demonstrating PAR4SEM - A Semantic Writing Aid with Adaptive Paraphrasing</summary>

- *Seid Muhie Yimam, Chris Biemann*

- `1808.06853v1` - [abs](http://arxiv.org/abs/1808.06853v1) - [pdf](http://arxiv.org/pdf/1808.06853v1)

> In this paper, we present Par4Sem, a semantic writing aid tool based on adaptive paraphrasing. Unlike many annotation tools that are primarily used to collect training examples, Par4Sem is integrated into a real word application, in this case a writing aid tool, in order to collect training examples from usage data. Par4Sem is a tool, which supports an adaptive, iterative, and interactive process where the underlying machine learning models are updated for each iteration using new training examples from usage data. After motivating the use of ever-learning tools in NLP applications, we evaluate Par4Sem by adopting it to a text simplification task through mere usage.

</details>

<details>

<summary>2018-08-22 02:03:27 - Probabilistic Semantic Retrieval for Surveillance Videos with Activity Graphs</summary>

- *Yuting Chen, Joseph Wang, Yannan Bai, Gregory Castañón, Venkatesh Saligrama*

- `1712.06204v2` - [abs](http://arxiv.org/abs/1712.06204v2) - [pdf](http://arxiv.org/pdf/1712.06204v2)

> We present a novel framework for finding complex activities matching user-described queries in cluttered surveillance videos. The wide diversity of queries coupled with unavailability of annotated activity data limits our ability to train activity models. To bridge the semantic gap we propose to let users describe an activity as a semantic graph with object attributes and inter-object relationships associated with nodes and edges, respectively. We learn node/edge-level visual predictors during training and, at test-time, propose to retrieve activity by identifying likely locations that match the semantic graph. We formulate a novel CRF based probabilistic activity localization objective that accounts for mis-detections, mis-classifications and track-losses, and outputs a likelihood score for a candidate grounded location of the query in the video. We seek groundings that maximize overall precision and recall. To handle the combinatorial search over all high-probability groundings, we propose a highest precision subgraph matching algorithm. Our method outperforms existing retrieval methods on benchmarked datasets.

</details>

<details>

<summary>2018-08-22 03:55:33 - Coarse-to-Fine Annotation Enrichment for Semantic Segmentation Learning</summary>

- *Yadan Luo, Ziwei Wang, Zi Huang, Yang Yang, Cong Zhao*

- `1808.07209v1` - [abs](http://arxiv.org/abs/1808.07209v1) - [pdf](http://arxiv.org/pdf/1808.07209v1)

> Rich high-quality annotated data is critical for semantic segmentation learning, yet acquiring dense and pixel-wise ground-truth is both labor- and time-consuming. Coarse annotations (e.g., scribbles, coarse polygons) offer an economical alternative, with which training phase could hardly generate satisfactory performance unfortunately. In order to generate high-quality annotated data with a low time cost for accurate segmentation, in this paper, we propose a novel annotation enrichment strategy, which expands existing coarse annotations of training data to a finer scale. Extensive experiments on the Cityscapes and PASCAL VOC 2012 benchmarks have shown that the neural networks trained with the enriched annotations from our framework yield a significant improvement over that trained with the original coarse labels. It is highly competitive to the performance obtained by using human annotated dense annotations. The proposed method also outperforms among other state-of-the-art weakly-supervised segmentation methods.

</details>

<details>

<summary>2018-08-22 04:40:36 - Maximising Throughput in a Complex Coal Export System</summary>

- *Mateus Rocha de Paula, Natashia Boland, Andreas Ernst, Alexandre Mendes, Martin Savelsbergh*

- `1808.06044v2` - [abs](http://arxiv.org/abs/1808.06044v2) - [pdf](http://arxiv.org/pdf/1808.06044v2)

> The Port of Newcastle features three coal export terminals, operating primarily in cargo assembly mode, that share a rail network on their inbound side, and a channel on their outbound side. Maximising throughput at a single coal terminal, taking into account its layout, its equipment, and its operating policies, is already challenging, but maximising throughput of the Hunter Valley coal export system as a whole requires that terminals and inbound and outbound shared resources be considered simultaneously. Existing approaches to do so either lack realism or are too computationally demanding to be useful as an everyday planning tool. We present a parallel genetic algorithm to optimise the integrated system. The algorithm models activities in continuous time, can handle practical planning horizons efficiently, and generates solutions that match or improve solutions obtained with the state-of-the-art solvers, whilst vastly outperforming them both in memory usage and running time.

</details>

<details>

<summary>2018-08-22 05:57:13 - Hierarchical Neural Network for Extracting Knowledgeable Snippets and Documents</summary>

- *Ganbin Zhou, Rongyu Cao, Xiang Ao, Ping Luo, Fen Lin, Leyu Lin, Qing He*

- `1808.07228v1` - [abs](http://arxiv.org/abs/1808.07228v1) - [pdf](http://arxiv.org/pdf/1808.07228v1)

> In this study, we focus on extracting knowledgeable snippets and annotating knowledgeable documents from Web corpus, consisting of the documents from social media and We-media. Informally, knowledgeable snippets refer to the text describing concepts, properties of entities, or relations among entities, while knowledgeable documents are the ones with enough knowledgeable snippets. These knowledgeable snippets and documents could be helpful in multiple applications, such as knowledge base construction and knowledge-oriented service. Previous studies extracted the knowledgeable snippets using the pattern-based method. Here, we propose the semantic-based method for this task. Specifically, a CNN based model is developed to extract knowledgeable snippets and annotate knowledgeable documents simultaneously. Additionally, a "low-level sharing, high-level splitting" structure of CNN is designed to handle the documents from different content domains. Compared with building multiple domain-specific CNNs, this joint model not only critically saves the training time, but also improves the prediction accuracy visibly. The superiority of the proposed method is demonstrated in a real dataset from Wechat public platform.

</details>

<details>

<summary>2018-08-22 15:16:26 - Source-Critical Reinforcement Learning for Transferring Spoken Language Understanding to a New Language</summary>

- *He Bai, Yu Zhou, Jiajun Zhang, Liang Zhao, Mei-Yuh Hwang, Chengqing Zong*

- `1808.06167v2` - [abs](http://arxiv.org/abs/1808.06167v2) - [pdf](http://arxiv.org/pdf/1808.06167v2)

> To deploy a spoken language understanding (SLU) model to a new language, language transferring is desired to avoid the trouble of acquiring and labeling a new big SLU corpus. Translating the original SLU corpus into the target language is an attractive strategy. However, SLU corpora consist of plenty of semantic labels (slots), which general-purpose translators cannot handle well, not to mention additional culture differences. This paper focuses on the language transferring task given a tiny in-domain parallel SLU corpus. The in-domain parallel corpus can be used as the first adaptation on the general translator. But more importantly, we show how to use reinforcement learning (RL) to further finetune the adapted translator, where translated sentences with more proper slot tags receive higher rewards. We evaluate our approach on Chinese to English language transferring for SLU systems. The experimental results show that the generated English SLU corpus via adaptation and reinforcement learning gives us over 97% in the slot F1 score and over 84% accuracy in domain classification. It demonstrates the effectiveness of the proposed language transferring method. Compared with naive translation, our proposed method improves domain classification accuracy by relatively 22%, and the slot filling F1 score by relatively more than 71%.

</details>

<details>

<summary>2018-08-23 03:52:02 - Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering</summary>

- *Wuwei Lan, Wei Xu*

- `1806.04330v2` - [abs](http://arxiv.org/abs/1806.04330v2) - [pdf](http://arxiv.org/pdf/1806.04330v2)

> In this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available. We release our implementations as an open-source toolkit.

</details>

<details>

<summary>2018-08-23 03:58:21 - Exploiting Rich Syntactic Information for Semantic Parsing with Graph-to-Sequence Model</summary>

- *Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin*

- `1808.07624v1` - [abs](http://arxiv.org/abs/1808.07624v1) - [pdf](http://arxiv.org/pdf/1808.07624v1)

> Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a sequential LSTM, to extract word order features while neglecting other valuable syntactic information such as dependency graph or constituent trees. In this paper, we first propose to use the \textit{syntactic graph} to represent three types of syntactic information, i.e., word order, dependency and constituency features. We further employ a graph-to-sequence model to encode the syntactic graph and decode a logical form. Experimental results on benchmark datasets show that our model is comparable to the state-of-the-art on Jobs640, ATIS and Geo880. Experimental results on adversarial examples demonstrate the robustness of the model is also improved by encoding more syntactic information.

</details>

<details>

<summary>2018-08-23 04:03:58 - Weakly-supervised Neural Semantic Parsing with a Generative Ranker</summary>

- *Jianpeng Cheng, Mirella Lapata*

- `1808.07625v1` - [abs](http://arxiv.org/abs/1808.07625v1) - [pdf](http://arxiv.org/pdf/1808.07625v1)

> Weakly-supervised semantic parsers are trained on utterance-denotation pairs, treating logical forms as latent. The task is challenging due to the large search space and spuriousness of logical forms. In this paper we introduce a neural parser-ranker system for weakly-supervised semantic parsing. The parser generates candidate tree-structured logical forms from utterances using clues of denotations. These candidates are then ranked based on two criterion: their likelihood of executing to the correct denotation, and their agreement with the utterance semantics. We present a scheduled training procedure to balance the contribution of the two objectives. Furthermore, we propose to use a neurally encoded lexicon to inject prior domain knowledge to the model. Experiments on three Freebase datasets demonstrate the effectiveness of our semantic parser, achieving results within the state-of-the-art range.

</details>

<details>

<summary>2018-08-23 12:47:01 - Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs</summary>

- *Dimitri Kartsaklis, Mohammad Taher Pilehvar, Nigel Collier*

- `1808.07724v1` - [abs](http://arxiv.org/abs/1808.07724v1) - [pdf](http://arxiv.org/pdf/1808.07724v1)

> This paper addresses the problem of mapping natural language text to knowledge base entities. The mapping process is approached as a composition of a phrase or a sentence into a point in a multi-dimensional entity space obtained from a knowledge graph. The compositional model is an LSTM equipped with a dynamic disambiguation mechanism on the input word embeddings (a Multi-Sense LSTM), addressing polysemy issues. Further, the knowledge base space is prepared by collecting random walks from a graph enhanced with textual features, which act as a set of semantic bridges between text and knowledge base entities. The ideas of this work are demonstrated on large-scale text-to-entity mapping and entity classification tasks, with state of the art results.

</details>

<details>

<summary>2018-08-23 20:23:36 - Financial Aspect-Based Sentiment Analysis using Deep Representations</summary>

- *Steve Yang, Jason Rosenfeld, Jacques Makutonin*

- `1808.07931v1` - [abs](http://arxiv.org/abs/1808.07931v1) - [pdf](http://arxiv.org/pdf/1808.07931v1)

> The topic of aspect-based sentiment analysis (ABSA) has been explored for a variety of industries, but it still remains much unexplored in finance. The recent release of data for an open challenge (FiQA) from the companion proceedings of WWW '18 has provided valuable finance-specific annotations. FiQA contains high quality labels, but it still lacks data quantity to apply traditional ABSA deep learning architecture. In this paper, we employ high-level semantic representations and methods of inductive transfer learning for NLP. We experiment with extensions of recently developed domain adaptation methods and target task fine-tuning that significantly improve performance on a small dataset. Our results show an 8.7% improvement in the F1 score for classification and an 11% improvement over the MSE for regression on current state-of-the-art results.

</details>

<details>

<summary>2018-08-24 03:46:45 - Features of word similarity</summary>

- *Arthur M. Jacobs, Annette Kinder*

- `1808.07999v1` - [abs](http://arxiv.org/abs/1808.07999v1) - [pdf](http://arxiv.org/pdf/1808.07999v1)

> In this theoretical note we compare different types of computational models of word similarity and association in their ability to predict a set of about 900 rating data. Using regression and predictive modeling tools (neural net, decision tree) the performance of a total of 28 models using different combinations of both surface and semantic word features is evaluated. The results present evidence for the hypothesis that word similarity ratings are based on more than only semantic relatedness. The limited cross-validated performance of the models asks for the development of psychological process models of the word similarity rating task.

</details>

<details>

<summary>2018-08-24 03:55:24 - Fake Sentence Detection as a Training Task for Sentence Encoding</summary>

- *Viresh Ranjan, Heeyoung Kwon, Niranjan Balasubramanian, Minh Hoai*

- `1808.03840v4` - [abs](http://arxiv.org/abs/1808.03840v4) - [pdf](http://arxiv.org/pdf/1808.03840v4)

> Sentence encoders are typically trained on language modeling tasks with large unlabeled datasets. While these encoders achieve state-of-the-art results on many sentence-level tasks, they are difficult to train with long training cycles. We introduce fake sentence detection as a new training task for learning sentence encoders. We automatically generate fake sentences by corrupting original sentences from a source collection and train the encoders to produce representations that are effective at detecting fake sentences. This binary classification task turns to be quite efficient for training sentence encoders. We compare a basic BiLSTM encoder trained on this task with a strong sentence encoding models (Skipthought and FastSent) trained on a language modeling task. We find that the BiLSTM trains much faster on fake sentence detection (20 hours instead of weeks) using smaller amounts of data (1M instead of 64M sentences). Further analysis shows the learned representations capture many syntactic and semantic properties expected from good sentence representations.

</details>

<details>

<summary>2018-08-24 08:32:38 - Role Semantics for Better Models of Implicit Discourse Relations</summary>

- *Michael Roth*

- `1808.08047v1` - [abs](http://arxiv.org/abs/1808.08047v1) - [pdf](http://arxiv.org/pdf/1808.08047v1)

> Predicting the structure of a discourse is challenging because relations between discourse segments are often implicit and thus hard to distinguish computationally. I extend previous work to classify implicit discourse relations by introducing a novel set of features on the level of semantic roles. My results demonstrate that such features are helpful, yielding results competitive with other feature-rich approaches on the PDTB. My main contribution is an analysis of improvements that can be traced back to role-based features, providing insights into why and when role semantics is helpful.

</details>

<details>

<summary>2018-08-24 13:40:40 - Securify: Practical Security Analysis of Smart Contracts</summary>

- *Petar Tsankov, Andrei Dan, Dana Drachsler Cohen, Arthur Gervais, Florian Buenzli, Martin Vechev*

- `1806.01143v2` - [abs](http://arxiv.org/abs/1806.01143v2) - [pdf](http://arxiv.org/pdf/1806.01143v2)

> Permissionless blockchains allow the execution of arbitrary programs (called smart contracts), enabling mutually untrusted entities to interact without relying on trusted third parties. Despite their potential, repeated security concerns have shaken the trust in handling billions of USD by smart contracts.   To address this problem, we present Securify, a security analyzer for Ethereum smart contracts that is scalable, fully automated, and able to prove contract behaviors as safe/unsafe with respect to a given property. Securify's analysis consists of two steps. First, it symbolically analyzes the contract's dependency graph to extract precise semantic information from the code. Then, it checks compliance and violation patterns that capture sufficient conditions for proving if a property holds or not. To enable extensibility, all patterns are specified in a designated domain-specific language.   Securify is publicly released, it has analyzed >18K contracts submitted by its users, and is regularly used to conduct security audits by experts. We present an extensive evaluation of Securify over real-world Ethereum smart contracts and demonstrate that it can effectively prove the correctness of smart contracts and discover critical violations.

</details>

<details>

<summary>2018-08-25 15:30:17 - Inductive Learning of Answer Set Programs from Noisy Examples</summary>

- *Mark Law, Alessandra Russo, Krysia Broda*

- `1808.08441v1` - [abs](http://arxiv.org/abs/1808.08441v1) - [pdf](http://arxiv.org/pdf/1808.08441v1)

> In recent years, non-monotonic Inductive Logic Programming has received growing interest. Specifically, several new learning frameworks and algorithms have been introduced for learning under the answer set semantics, allowing the learning of common-sense knowledge involving defaults and exceptions, which are essential aspects of human reasoning. In this paper, we present a noise-tolerant generalisation of the learning from answer sets framework. We evaluate our ILASP3 system, both on synthetic and on real datasets, represented in the new framework. In particular, we show that on many of the datasets ILASP3 achieves a higher accuracy than other ILP systems that have previously been applied to the datasets, including a recently proposed differentiable learning framework.

</details>

<details>

<summary>2018-08-25 23:50:10 - Training Classifiers with Natural Language Explanations</summary>

- *Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, Christopher Ré*

- `1805.03818v4` - [abs](http://arxiv.org/abs/1805.03818v4) - [pdf](http://arxiv.org/pdf/1805.03818v4)

> Training accurate classifiers requires many labels, but each label provides only limited information (one bit for binary classification). In this work, we propose BabbleLabble, a framework for training classifiers in which an annotator provides a natural language explanation for each labeling decision. A semantic parser converts these explanations into programmatic labeling functions that generate noisy labels for an arbitrary amount of unlabeled data, which is used to train a classifier. On three relation extraction tasks, we find that users are able to train classifiers with comparable F1 scores from 5-100$\times$ faster by providing explanations instead of just labels. Furthermore, given the inherent imperfection of labeling functions, we find that a simple rule-based semantic parser suffices.

</details>

<details>

<summary>2018-08-26 18:36:20 - Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge</summary>

- *Pasquale Minervini, Sebastian Riedel*

- `1808.08609v1` - [abs](http://arxiv.org/abs/1808.08609v1) - [pdf](http://arxiv.org/pdf/1808.08609v1)

> Adversarial examples are inputs to machine learning models designed to cause the model to make a mistake. They are useful for understanding the shortcomings of machine learning models, interpreting their results, and for regularisation. In NLP, however, most example generation strategies produce input text by using known, pre-specified semantic transformations, requiring significant manual effort and in-depth understanding of the problem and domain. In this paper, we investigate the problem of automatically generating adversarial examples that violate a set of given First-Order Logic constraints in Natural Language Inference (NLI). We reduce the problem of identifying such adversarial examples to a combinatorial optimisation problem, by maximising a quantity measuring the degree of violation of such constraints and by using a language model for generating linguistically-plausible examples. Furthermore, we propose a method for adversarially regularising neural NLI models for incorporating background knowledge. Our results show that, while the proposed method does not always improve results on the SNLI and MultiNLI datasets, it significantly and consistently increases the predictive accuracy on adversarially-crafted datasets -- up to a 79.6% relative improvement -- while drastically reducing the number of background knowledge violations. Furthermore, we show that adversarial examples transfer among model architectures, and that the proposed adversarial training procedure improves the robustness of NLI models to adversarial examples.

</details>

<details>

<summary>2018-08-26 21:33:32 - Identifying Domain Adjacent Instances for Semantic Parsers</summary>

- *James Ferguson, Janara Christensen, Edward Li, Edgar Gonzàlez*

- `1808.08626v1` - [abs](http://arxiv.org/abs/1808.08626v1) - [pdf](http://arxiv.org/pdf/1808.08626v1)

> When the semantics of a sentence are not representable in a semantic parser's output schema, parsing will inevitably fail. Detection of these instances is commonly treated as an out-of-domain classification problem. However, there is also a more subtle scenario in which the test data is drawn from the same domain. In addition to formalizing this problem of domain-adjacency, we present a comparison of various baselines that could be used to solve it. We also propose a new simple sentence representation that emphasizes words which are unexpected. This approach improves the performance of a downstream semantic parser run on in-domain and domain-adjacent instances.

</details>

<details>

<summary>2018-08-26 23:09:03 - Twin-GAN -- Unpaired Cross-Domain Image Translation with Weight-Sharing GANs</summary>

- *Jerry Li*

- `1809.00946v1` - [abs](http://arxiv.org/abs/1809.00946v1) - [pdf](http://arxiv.org/pdf/1809.00946v1)

> We present a framework for translating unlabeled images from one domain into analog images in another domain. We employ a progressively growing skip-connected encoder-generator structure and train it with a GAN loss for realistic output, a cycle consistency loss for maintaining same-domain translation identity, and a semantic consistency loss that encourages the network to keep the input semantic features in the output. We apply our framework on the task of translating face images, and show that it is capable of learning semantic mappings for face images with no supervised one-to-one image mapping.

</details>

<details>

<summary>2018-08-26 23:31:02 - Scientific Relation Extraction with Selectively Incorporated Concept Embeddings</summary>

- *Yi Luan, Mari Ostendorf, Hannaneh Hajishirzi*

- `1808.08643v1` - [abs](http://arxiv.org/abs/1808.08643v1) - [pdf](http://arxiv.org/pdf/1808.08643v1)

> This paper describes our submission for the SemEval 2018 Task 7 shared task on semantic relation extraction and classification in scientific papers. We extend the end-to-end relation extraction model of (Miwa and Bansal) with enhancements such as a character-level encoding attention mechanism on selecting pretrained concept candidate embeddings. Our official submission ranked the second in relation classification task (Subtask 1.1 and Subtask 2 Senerio 2), and the first in the relation extraction task (Subtask 2 Scenario 1).

</details>

<details>

<summary>2018-08-27 00:01:11 - Predicting Semantic Relations using Global Graph Properties</summary>

- *Yuval Pinter, Jacob Eisenstein*

- `1808.08644v1` - [abs](http://arxiv.org/abs/1808.08644v1) - [pdf](http://arxiv.org/pdf/1808.08644v1)

> Semantic graphs, such as WordNet, are resources which curate natural language on two distinguishable layers. On the local level, individual relations between synsets (semantic building blocks) such as hypernymy and meronymy enhance our understanding of the words used to express their meanings. Globally, analysis of graph-theoretic properties of the entire net sheds light on the structure of human language as a whole. In this paper, we combine global and local properties of semantic graphs through the framework of Max-Margin Markov Graph Models (M3GM), a novel extension of Exponential Random Graph Model (ERGM) that scales to large multi-relational graphs. We demonstrate how such global modeling improves performance on the local task of predicting semantic relations between synsets, yielding new state-of-the-art results on the WN18RR dataset, a challenging version of WordNet link prediction in which "easy" reciprocal cases are removed. In addition, the M3GM model identifies multirelational motifs that are characteristic of well-formed lexical semantic ontologies.

</details>

<details>

<summary>2018-08-27 01:19:25 - A Classification of BPMN Collaborations based on Safeness and Soundness Notions</summary>

- *Flavio Corradini, Chiara Muzi, Barbara Re, Francesco Tiezzi*

- `1809.06178v1` - [abs](http://arxiv.org/abs/1809.06178v1) - [pdf](http://arxiv.org/pdf/1809.06178v1)

> BPMN 2.0 standard has a huge uptake in modelling business processes within the same organisation or collaborations involving multiple interacting participants. It results that providing a solid foundation to enable BPMN designers to understand their models in a consistent way is becoming more and more important. In our investigation we define and exploit a formal characterisation of the collaborations' semantics, specifically and directly given for BPMN models, to provide a classification of BPMN collaborations. In particular, we refer to collaborations involving processes with arbitrary topology, thus overcoming the well-structuredness limitations. The proposed classification is based on some of the most important correctness properties in the business process domain, namely safeness and soundness. We prove, with a uniform formal framework, some conjectured and expected results and, most of all, we achieve novel results for BPMN collaborations concerning the relationships between safeness and soundness, and their compositionality, that represent major advances in the state-of-the-art.

</details>

<details>

<summary>2018-08-27 01:19:44 - Persistent Stochastic Non-Interference</summary>

- *Jane Hillston, Carla Piazza, Sabina Rossi*

- `1808.08650v1` - [abs](http://arxiv.org/abs/1808.08650v1) - [pdf](http://arxiv.org/pdf/1808.08650v1)

> In this paper we present an information flow security property for stochastic, cooperating, processes expressed as terms of the Performance Evaluation Process Algebra (PEPA). We introduce the notion of Persistent Stochastic Non-Interference (PSNI) based on the idea that every state reachable by a process satisfies a basic Stochastic Non-Interference (SNI) property. The structural operational semantics of PEPA allows us to give two characterizations of PSNI: the first involves a single bisimulation-like equivalence check, while the second is formulated in terms of unwinding conditions. The observation equivalence at the base of our definition relies on the notion of lumpability and ensures that, for a secure process P, the steady state probability of observing the system being in a specific state P' is independent from its possible high level interactions.

</details>

<details>

<summary>2018-08-27 08:16:21 - A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation</summary>

- *Jingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xiaoyan Cai, Xu Sun*

- `1808.06945v2` - [abs](http://arxiv.org/abs/1808.06945v2) - [pdf](http://arxiv.org/pdf/1808.06945v2)

> Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections, which has not been well studied by most existing generative models. To address this problem, we propose a skeleton-based model to promote the coherence of generated stories. Different from traditional models that generate a complete sentence at a stroke, the proposed model first generates the most critical phrases, called skeleton, and then expands the skeleton to a complete and fluent sentence. The skeleton is not manually defined, but learned by a reinforcement learning method. Compared to the state-of-the-art models, our skeleton-based model can generate significantly more coherent text according to human evaluation and automatic evaluation. The G-score is improved by 20.1% in the human evaluation. The code is available at https://github.com/lancopku/Skeleton-Based-Generation-Model

</details>

<details>

<summary>2018-08-27 08:37:42 - simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions</summary>

- *Fenglin Liu, Xuancheng Ren, Yuanxin Liu, Houfeng Wang, Xu Sun*

- `1808.08732v1` - [abs](http://arxiv.org/abs/1808.08732v1) - [pdf](http://arxiv.org/pdf/1808.08732v1)

> The encode-decoder framework has shown recent success in image captioning. Visual attention, which is good at detailedness, and semantic attention, which is good at comprehensiveness, have been separately proposed to ground the caption on the image. In this paper, we propose the Stepwise Image-Topic Merging Network (simNet) that makes use of the two kinds of attention at the same time. At each time step when generating the caption, the decoder adaptively merges the attentive information in the extracted topics and the image according to the generated context, so that the visual information and the semantic information can be effectively combined. The proposed approach is evaluated on two benchmark datasets and reaches the state-of-the-art performances.(The code is available at https://github.com/lancopku/simNet)

</details>

<details>

<summary>2018-08-27 11:46:13 - An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation</summary>

- *Liangchen Luo, Jingjing Xu, Junyang Lin, Qi Zeng, Xu Sun*

- `1808.08795v1` - [abs](http://arxiv.org/abs/1808.08795v1) - [pdf](http://arxiv.org/pdf/1808.08795v1)

> Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The model contains two auto-encoders and one mapping module. The auto-encoders learn the semantic representations of inputs and responses, and the mapping module learns to connect the utterance-level representations. Experimental results from automatic and human evaluations demonstrate that our model is capable of generating responses of high coherence and fluency compared to baseline models. The code is available at https://github.com/lancopku/AMM

</details>

<details>

<summary>2018-08-27 11:49:48 - Character-level Chinese-English Translation through ASCII Encoding</summary>

- *Nikola I. Nikolov, Yuhuang Hu, Mi Xue Tan, Richard H. R. Hahnloser*

- `1805.03330v2` - [abs](http://arxiv.org/abs/1805.03330v2) - [pdf](http://arxiv.org/pdf/1805.03330v2)

> Character-level Neural Machine Translation (NMT) models have recently achieved impressive results on many language pairs. They mainly do well for Indo-European language pairs, where the languages share the same writing system. However, for translating between Chinese and English, the gap between the two different writing systems poses a major challenge because of a lack of systematic correspondence between the individual linguistic units. In this paper, we enable character-level NMT for Chinese, by breaking down Chinese characters into linguistic units similar to that of Indo-European languages. We use the Wubi encoding scheme, which preserves the original shape and semantic information of the characters, while also being reversible. We show promising results from training Wubi-based models on the character- and subword-level with recurrent as well as convolutional models.

</details>

<details>

<summary>2018-08-27 13:00:13 - Question Generation from SQL Queries Improves Neural Semantic Parsing</summary>

- *Daya Guo, Yibo Sun, Duyu Tang, Nan Duan, Jian Yin, Hong Chi, James Cao, Peng Chen, Ming Zhou*

- `1808.06304v2` - [abs](http://arxiv.org/abs/1808.06304v2) - [pdf](http://arxiv.org/pdf/1808.06304v2)

> We study how to learn a semantic parser of state-of-the-art accuracy with less supervised training data. We conduct our study on WikiSQL, the largest hand-annotated semantic parsing dataset to date. First, we demonstrate that question generation is an effective method that empowers us to learn a state-of-the-art neural network based semantic parser with thirty percent of the supervised training data. Second, we show that applying question generation to the full supervised training data further improves the state-of-the-art model. In addition, we observe that there is a logarithmic relationship between the accuracy of a semantic parser and the amount of training data.

</details>

<details>

<summary>2018-08-27 16:12:36 - Zero-shot Transfer Learning for Semantic Parsing</summary>

- *Javid Dadashkarimi, Alexander Fabbri, Sekhar Tatikonda, Dragomir R. Radev*

- `1808.09889v1` - [abs](http://arxiv.org/abs/1808.09889v1) - [pdf](http://arxiv.org/pdf/1808.09889v1)

> While neural networks have shown impressive performance on large datasets, applying these models to tasks where little data is available remains a challenging problem.   In this paper we propose to use feature transfer in a zero-shot experimental setting on the task of semantic parsing.   We first introduce a new method for learning the shared space between multiple domains based on the prediction of the domain label for each example.   Our experiments support the superiority of this method in a zero-shot experimental setting in terms of accuracy metrics compared to state-of-the-art techniques.   In the second part of this paper we study the impact of individual domains and examples on semantic parsing performance.   We use influence functions to this aim and investigate the sensitivity of domain-label classification loss on each example.   Our findings reveal that cross-domain adversarial attacks identify useful examples for training even from the domains the least similar to the target domain. Augmenting our training data with these influential examples further boosts our accuracy at both the token and the sequence level.

</details>

<details>

<summary>2018-08-27 17:39:56 - Improving Information Extraction from Images with Learned Semantic Models</summary>

- *Stephan Baier, Yunpu Ma, Volker Tresp*

- `1808.08941v1` - [abs](http://arxiv.org/abs/1808.08941v1) - [pdf](http://arxiv.org/pdf/1808.08941v1)

> Many applications require an understanding of an image that goes beyond the simple detection and classification of its objects. In particular, a great deal of semantic information is carried in the relationships between objects. We have previously shown that the combination of a visual model and a statistical semantic prior model can improve on the task of mapping images to their associated scene description. In this paper, we review the model and compare it to a novel conditional multi-way model for visual relationship detection, which does not include an explicitly trained visual prior model. We also discuss potential relationships between the proposed methods and memory models of the human brain.

</details>

<details>

<summary>2018-08-27 20:44:03 - A Graph-to-Sequence Model for AMR-to-Text Generation</summary>

- *Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea*

- `1805.02473v3` - [abs](http://arxiv.org/abs/1805.02473v3) - [pdf](http://arxiv.org/pdf/1805.02473v3)

> The problem of AMR-to-text generation is to recover a text representing the same meaning as an input AMR graph. The current state-of-the-art method uses a sequence-to-sequence model, leveraging LSTM for encoding a linearized AMR structure. Although being able to model non-local semantic information, a sequence LSTM can lose information from the AMR graph structure, and thus faces challenges with large graphs, which result in long sequences. We introduce a neural graph-to-sequence model, using a novel LSTM structure for directly encoding graph-level semantics. On a standard benchmark, our model shows superior results to existing methods in the literature.

</details>

<details>

<summary>2018-08-28 06:23:02 - A Visual Attention Grounding Neural Model for Multimodal Machine Translation</summary>

- *Mingyang Zhou, Runxiang Cheng, Yong Jae Lee, Zhou Yu*

- `1808.08266v2` - [abs](http://arxiv.org/abs/1808.08266v2) - [pdf](http://arxiv.org/pdf/1808.08266v2)

> We introduce a novel multimodal machine translation model that utilizes parallel visual and textual information. Our model jointly optimizes the learning of a shared visual-language embedding and a translator. The model leverages a visual attention grounding mechanism that links the visual semantics with the corresponding textual semantics. Our approach achieves competitive state-of-the-art results on the Multi30K and the Ambiguous COCO datasets. We also collected a new multilingual multimodal product description dataset to simulate a real-world international online shopping scenario. On this dataset, our visual attention grounding model outperforms other methods by a large margin.

</details>

<details>

<summary>2018-08-28 07:05:22 - Cross-Lingual Cross-Platform Rumor Verification Pivoting on Multimedia Content</summary>

- *Weiming Wen, Songwen Su, Zhou Yu*

- `1808.04911v2` - [abs](http://arxiv.org/abs/1808.04911v2) - [pdf](http://arxiv.org/pdf/1808.04911v2)

> With the increasing popularity of smart devices, rumors with multimedia content become more and more common on social networks. The multimedia information usually makes rumors look more convincing. Therefore, finding an automatic approach to verify rumors with multimedia content is a pressing task. Previous rumor verification research only utilizes multimedia as input features. We propose not to use the multimedia content but to find external information in other news platforms pivoting on it. We introduce a new features set, cross-lingual cross-platform features that leverage the semantic similarity between the rumors and the external information. When implemented, machine learning methods utilizing such features achieved the state-of-the-art rumor verification results.

</details>

<details>

<summary>2018-08-28 08:04:21 - Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation</summary>

- *Hardy, Andreas Vlachos*

- `1808.09160v1` - [abs](http://arxiv.org/abs/1808.09160v1) - [pdf](http://arxiv.org/pdf/1808.09160v1)

> Recent work on abstractive summarization has made progress with neural encoder-decoder architectures. However, such models are often challenged due to their lack of explicit semantic modeling of the source document and its summary. In this paper, we extend previous work on abstractive summarization using Abstract Meaning Representation (AMR) with a neural language generation stage which we guide using the source document. We demonstrate that this guidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using gold standard AMR parses and parses obtained from an off-the-shelf parser respectively. We also find that the summarization performance using the latter is 2 ROUGE-2 points higher than that of a well-established neural encoder-decoder approach trained on a larger dataset. Code is available at \url{https://github.com/sheffieldnlp/AMR2Text-summ}

</details>

<details>

<summary>2018-08-28 11:34:10 - CFAAR: Control Flow Alteration to Assist Repair</summary>

- *Chadi Trad, Rawad Abou Assi, Wes Masri, Fadi Zaraket*

- `1808.09229v1` - [abs](http://arxiv.org/abs/1808.09229v1) - [pdf](http://arxiv.org/pdf/1808.09229v1)

> We present CFAAR, a program repair assistance technique that operates by selectively altering the outcome of suspicious predicates in order to yield expected behavior. CFAAR is applicable to defects that are repairable by negating predicates under specific conditions. CFAAR proceeds as follows: 1) it identifies predicates such that negating them at given instances would make the failing tests exhibit correct behavior; 2) for each candidate predicate, it uses the program state information to build a classifier that dictates when the predicate should be negated; 3) for each classifier, it leverages a Decision Tree to synthesize a patch to be presented to the developer. We evaluated our toolset using 149 defects from the IntroClass and Siemens benchmarks. CFAAR identified 91 potential candidate defects and generated plausible patches for 41 of them. Twelve of the patches are believed to be correct, whereas the rest provide repair assistance to the developer.

</details>

<details>

<summary>2018-08-28 14:01:07 - Card-660: Cambridge Rare Word Dataset - a Reliable Benchmark for Infrequent Word Representation Models</summary>

- *Mohammad Taher Pilehvar, Dimitri Kartsaklis, Victor Prokhorov, Nigel Collier*

- `1808.09308v1` - [abs](http://arxiv.org/abs/1808.09308v1) - [pdf](http://arxiv.org/pdf/1808.09308v1)

> Rare word representation has recently enjoyed a surge of interest, owing to the crucial role that effective handling of infrequent words can play in accurate semantic understanding. However, there is a paucity of reliable benchmarks for evaluation and comparison of these techniques. We show in this paper that the only existing benchmark (the Stanford Rare Word dataset) suffers from low-confidence annotations and limited vocabulary; hence, it does not constitute a solid comparison framework. In order to fill this evaluation gap, we propose CAmbridge Rare word Dataset (Card-660), an expert-annotated word similarity dataset which provides a highly reliable, yet challenging, benchmark for rare word representation techniques. Through a set of experiments we show that even the best mainstream word embeddings, with millions of words in their vocabularies, are unable to achieve performances higher than 0.43 (Pearson correlation) on the dataset, compared to a human-level upperbound of 0.90. We release the dataset and the annotation materials at https://pilehvar.github.io/card-660/.

</details>

<details>

<summary>2018-08-28 14:49:19 - Exploiting the Shape of CAN Data for In-Vehicle Intrusion Detection</summary>

- *Zachariah Tyree, Robert A. Bridges, Frank L. Combs, Michael R. Moore*

- `1808.10840v1` - [abs](http://arxiv.org/abs/1808.10840v1) - [pdf](http://arxiv.org/pdf/1808.10840v1)

> Modern vehicles rely on scores of electronic control units (ECUs) broadcasting messages over a few controller area networks (CANs). Bereft of security features, in-vehicle CANs are exposed to cyber manipulation and multiple researches have proved viable, life-threatening cyber attacks. Complicating the issue, CAN messages lack a common mapping of functions to commands, so packets are observable but not easily decipherable. We present a transformational approach to CAN IDS that exploits the geometric properties of CAN data to inform two novel detectors--one based on distance from a learned, lower dimensional manifold and the other on discontinuities of the manifold over time. Proof-of-concept tests are presented by implementing a potential attack approach on a driving vehicle. The initial results suggest that (1) the first detector requires additional refinement but does hold promise; (2) the second detector gives a clear, strong indicator of the attack; and (3) the algorithms keep pace with high-speed CAN messages. As our approach is data-driven it provides a vehicle-agnostic IDS that eliminates the need to reverse engineer CAN messages and can be ported to an after-market plugin.

</details>

<details>

<summary>2018-08-28 15:19:33 - Universal Dependency Parsing with a General Transition-Based DAG Parser</summary>

- *Daniel Hershcovich, Omri Abend, Ari Rappoport*

- `1808.09354v1` - [abs](http://arxiv.org/abs/1808.09354v1) - [pdf](http://arxiv.org/pdf/1808.09354v1)

> This paper presents our experiments with applying TUPA to the CoNLL 2018 UD shared task. TUPA is a general neural transition-based DAG parser, which we use to present the first experiments on recovering enhanced dependencies as part of the general parsing task. TUPA was designed for parsing UCCA, a cross-linguistic semantic annotation scheme, exhibiting reentrancy, discontinuity and non-terminal nodes. By converting UD trees and graphs to a UCCA-like DAG format, we train TUPA almost without modification on the UD parsing task. The generic nature of our approach lends itself naturally to multitask learning. Our code is available at https://github.com/CoNLL-UD-2018/HUJI

</details>

<details>

<summary>2018-08-28 17:25:27 - WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse</summary>

- *Manaal Faruqui, Ellie Pavlick, Ian Tenney, Dipanjan Das*

- `1808.09422v1` - [abs](http://arxiv.org/abs/1808.09422v1) - [pdf](http://arxiv.org/pdf/1808.09422v1)

> We release a corpus of 43 million atomic edits across 8 languages. These edits are mined from Wikipedia edit history and consist of instances in which a human editor has inserted a single contiguous phrase into, or deleted a single contiguous phrase from, an existing sentence. We use the collected data to show that the language generated during editing differs from the language that we observe in standard corpora, and that models trained on edits encode different aspects of semantics and discourse than models trained on raw, unstructured text. We release the full corpus as a resource to aid ongoing research in semantics, discourse, and representation learning.

</details>

<details>

<summary>2018-08-28 18:00:44 - Graphene: A Context-Preserving Open Information Extraction System</summary>

- *Matthias Cetto, Christina Niklaus, André Freitas, Siegfried Handschuh*

- `1808.09463v1` - [abs](http://arxiv.org/abs/1808.09463v1) - [pdf](http://arxiv.org/pdf/1808.09463v1)

> We introduce Graphene, an Open IE system whose goal is to generate accurate, meaningful and complete propositions that may facilitate a variety of downstream semantic applications. For this purpose, we transform syntactically complex input sentences into clean, compact structures in the form of core facts and accompanying contexts, while identifying the rhetorical relations that hold between them in order to maintain their semantic relationship. In that way, we preserve the context of the relational tuples extracted from a source sentence, generating a novel lightweight semantic representation for Open IE that enhances the expressiveness of the extracted propositions.

</details>

<details>

<summary>2018-08-28 19:15:57 - Semantic Matching Against a Corpus: New Applications and Methods</summary>

- *Lucy H. Lin, Scott Miles, Noah A. Smith*

- `1808.09502v1` - [abs](http://arxiv.org/abs/1808.09502v1) - [pdf](http://arxiv.org/pdf/1808.09502v1)

> We consider the case of a domain expert who wishes to explore the extent to which a particular idea is expressed in a text collection. We propose the task of semantically matching the idea, expressed as a natural language proposition, against a corpus. We create two preliminary tasks derived from existing datasets, and then introduce a more realistic one on disaster recovery designed for emergency managers, whom we engaged in a user study. On the latter, we find that a new model built from natural language entailment data produces higher-quality matches than simple word-vector averaging, both on expert-crafted queries and on ones produced by the subjects themselves. This work provides a proof-of-concept for such applications of semantic matching and illustrates key challenges.

</details>

<details>

<summary>2018-08-28 20:55:41 - Towards Semi-Supervised Learning for Deep Semantic Role Labeling</summary>

- *Sanket Vaibhav Mehta, Jay Yoon Lee, Jaime Carbonell*

- `1808.09543v1` - [abs](http://arxiv.org/abs/1808.09543v1) - [pdf](http://arxiv.org/pdf/1808.09543v1)

> Neural models have shown several state-of-the-art performances on Semantic Role Labeling (SRL). However, the neural models require an immense amount of semantic-role corpora and are thus not well suited for low-resource languages or domains. The paper proposes a semi-supervised semantic role labeling method that outperforms the state-of-the-art in limited SRL training corpora. The method is based on explicitly enforcing syntactic constraints by augmenting the training objective with a syntactic-inconsistency loss component and uses SRL-unlabeled instances to train a joint-objective LSTM. On CoNLL-2012 English section, the proposed semi-supervised training with 1%, 10% SRL-labeled data and varying amounts of SRL-unlabeled data achieves +1.58, +0.78 F1, respectively, over the pre-trained models that were trained on SOTA architecture with ELMo on the same SRL-labeled data. Additionally, by using the syntactic-inconsistency loss on inference time, the proposed model achieves +3.67, +2.1 F1 over pre-trained model on 1%, 10% SRL-labeled data, respectively.

</details>

<details>

<summary>2018-08-29 04:23:02 - Improved Semantic-Aware Network Embedding with Fine-Grained Word Alignment</summary>

- *Dinghan Shen, Xinyuan Zhang, Ricardo Henao, Lawrence Carin*

- `1808.09633v1` - [abs](http://arxiv.org/abs/1808.09633v1) - [pdf](http://arxiv.org/pdf/1808.09633v1)

> Network embeddings, which learn low-dimensional representations for each vertex in a large-scale network, have received considerable attention in recent years. For a wide range of applications, vertices in a network are typically accompanied by rich textual information such as user profiles, paper abstracts, etc. We propose to incorporate semantic features into network embeddings by matching important words between text sequences for all pairs of vertices. We introduce a word-by-word alignment framework that measures the compatibility of embeddings between word pairs, and then adaptively accumulates these alignment features with a simple yet effective aggregation function. In experiments, we evaluate the proposed framework on three real-world benchmarks for downstream tasks, including link prediction and multi-label vertex classification. Results demonstrate that our model outperforms state-of-the-art network embedding methods by a large margin.

</details>

<details>

<summary>2018-08-29 06:06:58 - Precise Condition Synthesis for Program Repair</summary>

- *Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang Huang, Lu Zhang*

- `1608.07754v5` - [abs](http://arxiv.org/abs/1608.07754v5) - [pdf](http://arxiv.org/pdf/1608.07754v5)

> Due to the difficulty of repairing defect, many research efforts have been devoted into automatic defect repair. Given a buggy program that fails some test cases, a typical automatic repair technique tries to modify the program to make all tests pass. However, since the test suites in real world projects are usually insufficient, aiming at passing the test suites often leads to incorrect patches.   In this paper we aim to produce precise patches, that is, any patch we produce has a relatively high probability to be correct. More concretely, we focus on condition synthesis, which was shown to be able to repair more than half of the defects in existing approaches. Our key insight is threefold. First, it is important to know what variables in a local context should be used in an "if" condition, and we propose a sorting method based on the dependency relations between variables. Second, we observe that the API document can be used to guide the repair process, and propose document analysis technique to further filter the variables. Third, it is important to know what predicates should be performed on the set of variables, and we propose to mine a set of frequently used predicates in similar contexts from existing projects.   We develop a novel program repair system, ACS, that could generate precise conditions at faulty locations. Furthermore, given the generated conditions are very precise, we can perform a repair operation that is previously deemed to be too overfitting: directly returning the test oracle to repair the defect. Using our approach, we successfully repaired 17 defects on four projects of Defects4J, which is the largest number of fully automatically repaired defects reported on the dataset so far. More importantly, the precision of our approach in the evaluation is 73.9%, which is significantly higher than previous approaches, which are usually less than 40%.

</details>

<details>

<summary>2018-08-29 09:21:22 - Chest X-ray Inpainting with Deep Generative Models</summary>

- *Ecem Sogancioglu, Shi Hu, Davide Belli, Bram van Ginneken*

- `1809.01471v1` - [abs](http://arxiv.org/abs/1809.01471v1) - [pdf](http://arxiv.org/pdf/1809.01471v1)

> Generative adversarial networks have been successfully applied to inpainting in natural images. However, the current state-of-the-art models have not yet been widely adopted in the medical imaging domain. In this paper, we investigate the performance of three recently published deep learning based inpainting models: context encoders, semantic image inpainting, and the contextual attention model, applied to chest x-rays, as the chest exam is the most commonly performed radiological procedure. We train these generative models on 1.2M 128 $\times$ 128 patches from 60K healthy x-rays, and learn to predict the center 64 $\times$ 64 region in each patch. We test the models on both the healthy and abnormal radiographs. We evaluate the results by visual inspection and comparing the PSNR scores. The outputs of the models are in most cases highly realistic. We show that the methods have potential to enhance and detect abnormalities. In addition, we perform a 2AFC observer study and show that an experienced human observer performs poorly in detecting inpainted regions, particularly those generated by the contextual attention model.

</details>

<details>

<summary>2018-08-29 10:30:03 - What can we learn from Semantic Tagging?</summary>

- *Mostafa Abdou, Artur Kulmizev, Vinit Ravishankar, Lasha Abzianidze, Johan Bos*

- `1808.09716v1` - [abs](http://arxiv.org/abs/1808.09716v1) - [pdf](http://arxiv.org/pdf/1808.09716v1)

> We investigate the effects of multi-task learning using the recently introduced task of semantic tagging. We employ semantic tagging as an auxiliary task for three different NLP tasks: part-of-speech tagging, Universal Dependency parsing, and Natural Language Inference. We compare full neural network sharing, partial neural network sharing, and what we term the learning what to share setting where negative transfer between tasks is less likely. Our findings show considerable improvements for all tasks, particularly in the learning what to share setting, which shows consistent gains across all tasks.

</details>

<details>

<summary>2018-08-29 11:04:07 - Understanding Latent Factors Using a GWAP</summary>

- *Johannes Kunkel, Benedikt Loepp, Jürgen Ziegler*

- `1808.10260v1` - [abs](http://arxiv.org/abs/1808.10260v1) - [pdf](http://arxiv.org/pdf/1808.10260v1)

> Recommender systems relying on latent factor models often appear as black boxes to their users. Semantic descriptions for the factors might help to mitigate this problem. Achieving this automatically is, however, a non-straightforward task due to the models' statistical nature. We present an output-agreement game that represents factors by means of sample items and motivates players to create such descriptions. A user study shows that the collected output actually reflects real-world characteristics of the factors.

</details>

<details>

<summary>2018-08-29 12:22:07 - Vulnerable Open Source Dependencies: Counting Those That Matter</summary>

- *Ivan Pashchenko, Henrik Plate, Serena Elisa Ponta, Antonino Sabetta, Fabio Massacci*

- `1808.09753v1` - [abs](http://arxiv.org/abs/1808.09753v1) - [pdf](http://arxiv.org/pdf/1808.09753v1)

> BACKGROUND: Vulnerable dependencies are a known problem in today's open-source software ecosystems because OSS libraries are highly interconnected and developers do not always update their dependencies. AIMS: In this paper we aim to present a precise methodology, that combines the code-based analysis of patches with information on build, test, update dates, and group extracted from the very code repository, and therefore, caters to the needs of industrial practice for correct allocation of development and audit resources. METHOD: To understand the industrial impact of the proposed methodology, we considered the 200 most popular OSS Java libraries used by SAP in its own software. Our analysis included 10905 distinct GAVs (group, artifact, version) when considering all the library versions. RESULTS: We found that about 20% of the dependencies affected by a known vulnerability are not deployed, and therefore, they do not represent a danger to the analyzed library because they cannot be exploited in practice. Developers of the analyzed libraries are able to fix (and actually responsible for) 82% of the deployed vulnerable dependencies. The vast majority (81%) of vulnerable dependencies may be fixed by simply updating to a new version, while 1% of the vulnerable dependencies in our sample are halted, and therefore, potentially require a costly mitigation strategy. CONCLUSIONS: Our case study shows that the correct counting allows software development companies to receive actionable information about their library dependencies, and therefore, correctly allocate costly development and audit resources, which is spent inefficiently in case of distorted measurements.

</details>

<details>

<summary>2018-08-29 15:40:37 - Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation</summary>

- *Adam Poliak, Aparajita Haldar, Rachel Rudinger, J. Edward Hu, Ellie Pavlick, Aaron Steven White, Benjamin Van Durme*

- `1804.08207v2` - [abs](http://arxiv.org/abs/1804.08207v2) - [pdf](http://arxiv.org/pdf/1804.08207v2)

> We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our collection as the DNC: Diverse Natural Language Inference Collection. The DNC is available online at https://www.decomp.net, and will grow over time as additional resources are recast and added from novel sources.

</details>

<details>

<summary>2018-08-29 16:51:51 - Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data</summary>

- *Zi Lin, Yuguang Duan, Yuanyuan Zhao, Weiwei Sun, Xiaojun Wan*

- `1808.09409v2` - [abs](http://arxiv.org/abs/1808.09409v2) - [pdf](http://arxiv.org/pdf/1808.09409v2)

> This paper studies semantic parsing for interlanguage (L2), taking semantic role labeling (SRL) as a case task and learner Chinese as a case language. We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL. Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parser-based and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chinese can be. We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages. Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data. We then show such information is very effective to enhance SRL for learner texts. Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.

</details>

<details>

<summary>2018-08-29 17:43:11 - Neural Compositional Denotational Semantics for Question Answering</summary>

- *Nitish Gupta, Mike Lewis*

- `1808.09942v1` - [abs](http://arxiv.org/abs/1808.09942v1) - [pdf](http://arxiv.org/pdf/1808.09942v1)

> Answering compositional questions requiring multi-step reasoning is challenging. We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph (KG), which is inspired by formal approaches to semantics. Each span of text is represented by a denotation in a KG and a vector that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituent spans, culminating in a grounding for the complete sentence which answers the question. For example, to interpret "not green", the model represents "green" as a set of KG entities and "not" as a trainable ungrounded vector---and then uses this vector to parameterize a composition function that performs a complement operation. For each sentence, we build a parse chart subsuming all possible parses, allowing the model to jointly learn both the composition operators and output structure by gradient descent from end-task supervision. The model learns a variety of challenging semantic operators, such as quantifiers, disjunctions and composed relations, and infers latent syntactic structure. It also generalizes well to longer questions than seen in its training data, in contrast to RNN, its tree-based variants, and semantic parsing baselines.

</details>

<details>

<summary>2018-08-29 17:44:38 - End-to-End Neural Entity Linking</summary>

- *Nikolaos Kolitsas, Octavian-Eugen Ganea, Thomas Hofmann*

- `1808.07699v2` - [abs](http://arxiv.org/abs/1808.07699v2) - [pdf](http://arxiv.org/pdf/1808.07699v2)

> Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.

</details>

<details>

<summary>2018-08-29 21:18:23 - Petri Nets and Machines of Things That Flow</summary>

- *Sabah Al-Fedaghi, Dana Shbeeb*

- `1810.09652v1` - [abs](http://arxiv.org/abs/1810.09652v1) - [pdf](http://arxiv.org/pdf/1810.09652v1)

> Petri nets are an established graphical formalism for modeling and analyzing the behavior of systems. An important consideration of the value of Petri nets is their use in describing both the syntax and semantics of modeling formalisms. Describing a modeling notation in terms of a formal technique such as Petri nets provides a way to minimize ambiguity. Accordingly, it is imperative to develop a deep and diverse understanding of Petri nets. This paper is directed toward a new, but preliminary, exploration of the semantics of such an important tool. Specifically, the concern in this paper is with the semantics of Petri nets interpreted in a modeling language based on the notion of machines of things that flow. The semantics of several Petri net diagrams are analyzed in terms of flow of things. The results point to the viability of the approach for exploring the underlying assumptions of Petri nets.

</details>

<details>

<summary>2018-08-30 03:55:11 - Modeling OWL with Rules: The ROWL Protege Plugin</summary>

- *Md. Kamruzzaman Sarker, David Carral, Adila A. Krisnadhi, Pascal Hitzler*

- `1808.10104v1` - [abs](http://arxiv.org/abs/1808.10104v1) - [pdf](http://arxiv.org/pdf/1808.10104v1)

> In our experience, some ontology users find it much easier to convey logical statements using rules rather than OWL (or description logic) axioms. Based on recent theoretical developments on transformations between rules and description logics, we develop ROWL, a Protege plugin that allows users to enter OWL axioms by way of rules; the plugin then automatically converts these rules into OWL DL axioms if possible, and prompts the user in case such a conversion is not possible without weakening the semantics of the rule.

</details>

<details>

<summary>2018-08-30 03:57:58 - OWLAx: A Protege Plugin to Support Ontology Axiomatization through Diagramming</summary>

- *Md. Kamruzzaman Sarker, Adila A. Krisnadhi, Pascal Hitzler*

- `1808.10105v1` - [abs](http://arxiv.org/abs/1808.10105v1) - [pdf](http://arxiv.org/pdf/1808.10105v1)

> Once the conceptual overview, in terms of a somewhat informal class diagram, has been designed in the course of engineering an ontology, the process of adding many of the appropriate logical axioms is mostly a routine task. We provide a Protege plugin which supports this task, together with a visual user interface, based on established methods for ontology design pattern modeling.

</details>

<details>

<summary>2018-08-30 04:05:35 - Rule-based OWL Modeling with ROWLTab Protege Plugin</summary>

- *Md. Kamruzzaman Sarker, Adila Krisnadhi, David Carral, Pascal Hitzler*

- `1808.10108v1` - [abs](http://arxiv.org/abs/1808.10108v1) - [pdf](http://arxiv.org/pdf/1808.10108v1)

> It has been argued that it is much easier to convey logical statements using rules rather than OWL (or description logic (DL)) axioms. Based on recent theoretical developments on transformations between rules and DLs, we have developed ROWLTab, a Protege plugin that allows users to enter OWL axioms by way of rules; the plugin then automatically converts these rules into OWL 2 DL axioms if possible, and prompts the user in case such a conversion is not possible without weakening the semantics of the rule. In this paper, we present ROWLTab, together with a user evaluation of its effectiveness compared to entering axioms using the standard Protege interface. Our evaluation shows that modeling with ROWLTab is much quicker than the standard interface, while at the same time, also less prone to errors for hard modeling tasks.

</details>

<details>

<summary>2018-08-30 17:29:02 - The Bounded Laplace Mechanism in Differential Privacy</summary>

- *Naoise Holohan, Spiros Antonatos, Stefano Braghin, Pól Mac Aonghusa*

- `1808.10410v1` - [abs](http://arxiv.org/abs/1808.10410v1) - [pdf](http://arxiv.org/pdf/1808.10410v1)

> The Laplace mechanism is the workhorse of differential privacy, applied to many instances where numerical data is processed. However, the Laplace mechanism can return semantically impossible values, such as negative counts, due to its infinite support. There are two popular solutions to this: (i) bounding/capping the output values and (ii) bounding the mechanism support. In this paper, we show that bounding the mechanism support, while using the parameters of the pure Laplace mechanism, does not typically preserve differential privacy. We also present a robust method to compute the optimal mechanism parameters to achieve differential privacy in such a setting.

</details>

<details>

<summary>2018-08-30 19:01:20 - Syntactic Scaffolds for Semantic Structures</summary>

- *Swabha Swayamdipta, Sam Thomson, Kenton Lee, Luke Zettlemoyer, Chris Dyer, Noah A. Smith*

- `1808.10485v1` - [abs](http://arxiv.org/abs/1808.10485v1) - [pdf](http://arxiv.org/pdf/1808.10485v1)

> We introduce the syntactic scaffold, an approach to incorporating syntactic information into semantic tasks. Syntactic scaffolds avoid expensive syntactic processing at runtime, only making use of a treebank during training, through a multitask objective. We improve over strong baselines on PropBank semantics, frame semantics, and coreference resolution, achieving competitive performance on all three tasks.

</details>

<details>

<summary>2018-08-30 21:54:56 - Beyond Word Embeddings: Learning Entity and Concept Representations from Large Scale Knowledge Bases</summary>

- *Walid Shalaby, Wlodek Zadrozny, Hongxia Jin*

- `1801.00388v2` - [abs](http://arxiv.org/abs/1801.00388v2) - [pdf](http://arxiv.org/pdf/1801.00388v2)

> Text representations using neural word embeddings have proven effective in many NLP applications. Recent researches adapt the traditional word embedding models to learn vectors of multiword expressions (concepts/entities). However, these methods are limited to textual knowledge bases (e.g., Wikipedia). In this paper, we propose a novel and simple technique for integrating the knowledge about concepts from two large scale knowledge bases of different structure (Wikipedia and Probase) in order to learn concept representations. We adapt the efficient skip-gram model to seamlessly learn from the knowledge in Wikipedia text and Probase concept graph. We evaluate our concept embedding models on two tasks: (1) analogical reasoning, where we achieve a state-of-the-art performance of 91% on semantic analogies, (2) concept categorization, where we achieve a state-of-the-art performance on two benchmark datasets achieving categorization accuracy of 100% on one and 98% on the other. Additionally, we present a case study to evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised method and its ability to better generalize to out of vocabulary entity mentions compared to the tedious and error prone methods which depend on gazetteers and regular expressions.

</details>

<details>

<summary>2018-08-31 09:56:43 - Gibson Env: Real-World Perception for Embodied Agents</summary>

- *Fei Xia, Amir Zamir, Zhi-Yang He, Alexander Sax, Jitendra Malik, Silvio Savarese*

- `1808.10654v1` - [abs](http://arxiv.org/abs/1808.10654v1) - [pdf](http://arxiv.org/pdf/1808.10654v1)

> Developing visual perception models for active agents and sensorimotor control are cumbersome to be done in the physical world, as existing algorithms are too slow to efficiently learn in real-time and robots are fragile and costly. This has given rise to learning-in-simulation which consequently casts a question on whether the results transfer to real-world. In this paper, we are concerned with the problem of developing real-world perception for active agents, propose Gibson Virtual Environment for this purpose, and showcase sample perceptual tasks learned therein. Gibson is based on virtualizing real spaces, rather than using artificially designed ones, and currently includes over 1400 floor spaces from 572 full buildings. The main characteristics of Gibson are: I. being from the real-world and reflecting its semantic complexity, II. having an internal synthesis mechanism, "Goggles", enabling deploying the trained models in real-world without needing further domain adaptation, III. embodiment of agents and making them subject to constraints of physics and space.

</details>

<details>

<summary>2018-08-31 11:14:36 - Beyond Weight Tying: Learning Joint Input-Output Embeddings for Neural Machine Translation</summary>

- *Nikolaos Pappas, Lesly Miculicich Werlen, James Henderson*

- `1808.10681v1` - [abs](http://arxiv.org/abs/1808.10681v1) - [pdf](http://arxiv.org/pdf/1808.10681v1)

> Tying the weights of the target word embeddings with the target word classifiers of neural machine translation models leads to faster training and often to better translation quality. Given the success of this parameter sharing, we investigate other forms of sharing in between no sharing and hard equality of parameters. In particular, we propose a structure-aware output layer which captures the semantic structure of the output space of words within a joint input-output embedding. The model is a generalized form of weight tying which shares parameters but allows learning a more flexible relationship with input word embeddings and allows the effective capacity of the output layer to be controlled. In addition, the model shares weights across output classifiers and translation contexts which allows it to better leverage prior knowledge about them. Our evaluation on English-to-Finnish and English-to-German datasets shows the effectiveness of the method against strong encoder-decoder baselines trained with or without weight tying.

</details>

<details>

<summary>2018-08-31 14:54:49 - Cognate-aware morphological segmentation for multilingual neural translation</summary>

- *Stig-Arne Grönroos, Sami Virpioja, Mikko Kurimo*

- `1808.10791v1` - [abs](http://arxiv.org/abs/1808.10791v1) - [pdf](http://arxiv.org/pdf/1808.10791v1)

> This article describes the Aalto University entry to the WMT18 News Translation Shared Task. We participate in the multilingual subtrack with a system trained under the constrained condition to translate from English to both Finnish and Estonian. The system is based on the Transformer model. We focus on improving the consistency of morphological segmentation for words that are similar orthographically, semantically, and distributionally; such words include etymological cognates, loan words, and proper names. For this, we introduce Cognate Morfessor, a multilingual variant of the Morfessor method. We show that our approach improves the translation quality particularly for Estonian, which has less resources for training the translation model.

</details>

<details>

<summary>2018-08-31 17:07:31 - Automated segmentation on the entire cardiac cycle using a deep learning work-flow</summary>

- *Nicoló Savioli, Miguel Silva Vieira, Pablo Lamata, Giovanni Montana*

- `1809.01015v1` - [abs](http://arxiv.org/abs/1809.01015v1) - [pdf](http://arxiv.org/pdf/1809.01015v1)

> The segmentation of the left ventricle (LV) from CINE MRI images is essential to infer important clinical parameters. Typically, machine learning algorithms for automated LV segmentation use annotated contours from only two cardiac phases, diastole, and systole. In this work, we present an analysis work-flow for fully-automated LV segmentation that learns from images acquired through the cardiac cycle. The workflow consists of three components: first, for each image in the sequence, we perform an automated localization and subsequent cropping of the bounding box containing the cardiac silhouette. Second, we identify the LV contours using a Temporal Fully Convolutional Neural Network (T-FCNN), which extends Fully Convolutional Neural Networks (FCNN) through a recurrent mechanism enforcing temporal coherence across consecutive frames. Finally, we further defined the boundaries using either one of two components: fully-connected Conditional Random Fields (CRFs) with Gaussian edge potentials and Semantic Flow. Our initial experiments suggest that significant improvement in performance can potentially be achieved by using a recurrent neural network component that explicitly learns cardiac motion patterns whilst performing LV segmentation.

</details>


## 2018-09

<details>

<summary>2018-09-01 03:07:17 - Dependency-based Hybrid Trees for Semantic Parsing</summary>

- *Zhanming Jie, Wei Lu*

- `1809.00107v1` - [abs](http://arxiv.org/abs/1809.00107v1) - [pdf](http://arxiv.org/pdf/1809.00107v1)

> We propose a novel dependency-based hybrid tree model for semantic parsing, which converts natural language utterance into machine interpretable meaning representations. Unlike previous state-of-the-art models, the semantic information is interpreted as the latent dependency between the natural language words in our joint representation. Such dependency information can capture the interactions between the semantics and natural language words. We integrate a neural component into our model and propose an efficient dynamic-programming algorithm to perform tractable inference. Through extensive experiments on the standard multilingual GeoQuery dataset with eight languages, we demonstrate that our proposed approach is able to achieve state-of-the-art performance across several languages. Analysis also justifies the effectiveness of using our new dependency-based representation.

</details>

<details>

<summary>2018-09-01 12:20:26 - Gaussian Word Embedding with a Wasserstein Distance Loss</summary>

- *Chi Sun, Hang Yan, Xipeng Qiu, Xuanjing Huang*

- `1808.07016v7` - [abs](http://arxiv.org/abs/1808.07016v7) - [pdf](http://arxiv.org/pdf/1808.07016v7)

> Compared with word embedding based on point representation, distribution-based word embedding shows more flexibility in expressing uncertainty and therefore embeds richer semantic information when representing words. The Wasserstein distance provides a natural notion of dissimilarity with probability measures and has a closed-form solution when measuring the distance between two Gaussian distributions. Therefore, with the aim of representing words in a highly efficient way, we propose to operate a Gaussian word embedding model with a loss function based on the Wasserstein distance. Also, external information from ConceptNet will be used to semi-supervise the results of the Gaussian word embedding. Thirteen datasets from the word similarity task, together with one from the word entailment task, and six datasets from the downstream document classification task will be evaluated in this paper to test our hypothesis.

</details>

<details>

<summary>2018-09-01 12:33:13 - Multi-Modal Coreference Resolution with the Correlation between Space Structures</summary>

- *Qibin Zheng, Xingchun Diao, Jianjun Cao, Xiaolei Zhou, Yi Liu, Hongmei Li*

- `1804.08010v2` - [abs](http://arxiv.org/abs/1804.08010v2) - [pdf](http://arxiv.org/pdf/1804.08010v2)

> Multi-modal data is becoming more common in big data background. Finding the semantically similar objects from different modality is one of the heart problems of multi-modal learning. Most of the current methods try to learn the inter-modal correlation with extrinsic supervised information, while intrinsic structural information of each modality is neglected. The performance of these methods heavily depends on the richness of training samples. However, obtaining the multi-modal training samples is still a labor and cost intensive work. In this paper, we bring a extrinsic correlation between the space structures of each modalities in coreference resolution. With this correlation, a semi-supervised learning model for multi-modal coreference resolution is proposed. We firstly extract high-level features of images and text, then compute the distances of each object from some reference points to build the space structure of each modality. With a shared reference point set, the space structures of each modality are correlated. We employ the correlation to build a commonly shared space that the semantic distance between multi-modal objects can be computed directly. The experiments on two multi-modal datasets show that our model performs better than the existing methods with insufficient training data.

</details>

<details>

<summary>2018-09-01 15:11:12 - Improving Visual Relationship Detection using Semantic Modeling of Scene Descriptions</summary>

- *Stephan Baier, Yunpu Ma, Volker Tresp*

- `1809.00204v1` - [abs](http://arxiv.org/abs/1809.00204v1) - [pdf](http://arxiv.org/pdf/1809.00204v1)

> Structured scene descriptions of images are useful for the automatic processing and querying of large image databases. We show how the combination of a semantic and a visual statistical model can improve on the task of mapping images to their associated scene description. In this paper we consider scene descriptions which are represented as a set of triples (subject, predicate, object), where each triple consists of a pair of visual objects, which appear in the image, and the relationship between them (e.g. man-riding-elephant, man-wearing-hat). We combine a standard visual model for object detection, based on convolutional neural networks, with a latent variable model for link prediction. We apply multiple state-of-the-art link prediction methods and compare their capability for visual relationship detection. One of the main advantages of link prediction methods is that they can also generalize to triples, which have never been observed in the training data. Our experimental results on the recently published Stanford Visual Relationship dataset, a challenging real world dataset, show that the integration of a semantic model using link prediction methods can significantly improve the results for visual relationship detection. Our combined approach achieves superior performance compared to the state-of-the-art method from the Stanford computer vision group.

</details>

<details>

<summary>2018-09-02 06:22:39 - Towards Automated Customer Support</summary>

- *Momchil Hardalov, Ivan Koychev, Preslav Nakov*

- `1809.00303v1` - [abs](http://arxiv.org/abs/1809.00303v1) - [pdf](http://arxiv.org/pdf/1809.00303v1)

> Recent years have seen growing interest in conversational agents, such as chatbots, which are a very good fit for automated customer support because the domain in which they need to operate is narrow. This interest was in part inspired by recent advances in neural machine translation, esp. the rise of sequence-to-sequence (seq2seq) and attention-based models such as the Transformer, which have been applied to various other tasks and have opened new research directions in question answering, chatbots, and conversational systems. Still, in many cases, it might be feasible and even preferable to use simple information retrieval techniques. Thus, here we compare three different models:(i) a retrieval model, (ii) a sequence-to-sequence model with attention, and (iii) Transformer. Our experiments with the Twitter Customer Support Dataset, which contains over two million posts from customer support services of twenty major brands, show that the seq2seq model outperforms the other two in terms of semantics and word overlap.

</details>

<details>

<summary>2018-09-02 20:22:48 - Zero-shot User Intent Detection via Capsule Neural Networks</summary>

- *Congying Xia, Chenwei Zhang, Xiaohui Yan, Yi Chang, Philip S. Yu*

- `1809.00385v1` - [abs](http://arxiv.org/abs/1809.00385v1) - [pdf](http://arxiv.org/pdf/1809.00385v1)

> User intent detection plays a critical role in question-answering and dialog systems. Most previous works treat intent detection as a classification problem where utterances are labeled with predefined intents. However, it is labor-intensive and time-consuming to label users' utterances as intents are diversely expressed and novel intents will continually be involved. Instead, we study the zero-shot intent detection problem, which aims to detect emerging user intents where no labeled utterances are currently available. We propose two capsule-based architectures: INTENT-CAPSNET that extracts semantic features from utterances and aggregates them to discriminate existing intents, and INTENTCAPSNET-ZSL which gives INTENTCAPSNET the zero-shot learning ability to discriminate emerging intents via knowledge transfer from existing intents. Experiments on two real-world datasets show that our model not only can better discriminate diversely expressed existing intents, but is also able to discriminate emerging intents when no labeled utterances are available.

</details>

<details>

<summary>2018-09-03 00:04:49 - Hypernyms Through Intra-Article Organization in Wikipedia</summary>

- *Disha Shrivastava, Sreyash Kenkre, Santosh Penubothula*

- `1809.00414v1` - [abs](http://arxiv.org/abs/1809.00414v1) - [pdf](http://arxiv.org/pdf/1809.00414v1)

> We introduce a new measure for unsupervised hypernym detection and directionality. The motivation is to keep the measure computationally light and portatable across languages. We show that the relative physical location of words in explanatory articles captures the directionality property. Further, the phrases in section titles of articles about the word, capture the semantic similarity needed for hypernym detection task. We experimentally show that the combination of features coming from these two simple measures suffices to produce results comparable with the best unsupervised measures in terms of the average precision.

</details>

<details>

<summary>2018-09-03 10:29:09 - Crowdsourcing Semantic Label Propagation in Relation Classification</summary>

- *Anca Dumitrache, Lora Aroyo, Chris Welty*

- `1809.00537v1` - [abs](http://arxiv.org/abs/1809.00537v1) - [pdf](http://arxiv.org/pdf/1809.00537v1)

> Distant supervision is a popular method for performing relation extraction from text that is known to produce noisy labels. Most progress in relation extraction and classification has been made with crowdsourced corrections to distant-supervised labels, and there is evidence that indicates still more would be better. In this paper, we explore the problem of propagating human annotation signals gathered for open-domain relation classification through the CrowdTruth methodology for crowdsourcing, that captures ambiguity in annotations by measuring inter-annotator disagreement. Our approach propagates annotations to sentences that are similar in a low dimensional embedding space, expanding the number of labels by two orders of magnitude. Our experiments show significant improvement in a sentence-level multi-class relation classifier.

</details>

<details>

<summary>2018-09-03 11:51:13 - ViewpointS: towards a Collective Brain</summary>

- *Philippe Lemoisson, Stefano A. Cerri*

- `1809.00564v1` - [abs](http://arxiv.org/abs/1809.00564v1) - [pdf](http://arxiv.org/pdf/1809.00564v1)

> Tracing knowledge acquisition and linking learning events to interaction between peers is a major challenge of our times. We have conceived, designed and evaluated a new paradigm for constructing and using collective knowledge by Web interactions that we called ViewpointS. By exploiting the similarity with Edelman's Theory of Neuronal Group Selection (TNGS), we conjecture that it may be metaphorically considered a Collective Brain, especially effective in the case of trans-disciplinary representations. Far from being without doubts, in the paper we present the reasons (and the limits) of our proposal that aims to become a useful integrating tool for future quantitative explorations of individual as well as collective learning at different degrees of granu-larity. We are therefore challenging each of the current approaches: the logical one in the semantic Web, the statistical one in mining and deep learning, the social one in recommender systems based on authority and trust; not in each of their own preferred field of operation, rather in their integration weaknesses far from the holistic and dynamic behavior of the human brain.

</details>

<details>

<summary>2018-09-03 13:11:07 - Affordance Extraction and Inference based on Semantic Role Labeling</summary>

- *Daniel Loureiro, Alípio Mário Jorge*

- `1809.00589v1` - [abs](http://arxiv.org/abs/1809.00589v1) - [pdf](http://arxiv.org/pdf/1809.00589v1)

> Common-sense reasoning is becoming increasingly important for the advancement of Natural Language Processing. While word embeddings have been very successful, they cannot explain which aspects of 'coffee' and 'tea' make them similar, or how they could be related to 'shop'. In this paper, we propose an explicit word representation that builds upon the Distributional Hypothesis to represent meaning from semantic roles, and allow inference of relations from their meshing, as supported by the affordance-based Indexical Hypothesis. We find that our model improves the state-of-the-art on unsupervised word similarity tasks while allowing for direct inference of new relations from the same vector space.

</details>

<details>

<summary>2018-09-03 13:21:28 - IoU is not submodular</summary>

- *Tanguy Kerdoncuff, Rémi Emonet*

- `1809.00593v1` - [abs](http://arxiv.org/abs/1809.00593v1) - [pdf](http://arxiv.org/pdf/1809.00593v1)

> This short article aims at demonstrate that the Intersection over Union (or Jaccard index) is not a submodular function. This mistake has been made in an article which is cited and used as a foundation in another article. The Intersection of Union is widely used in machine learning as a cost function especially for imbalance data and semantic segmentation.

</details>

<details>

<summary>2018-09-03 14:24:22 - Changing Observations in Epistemic Temporal Logic</summary>

- *Aurèle Barrière, Bastien Maubert, Aniello Murano, Sasha Rubin*

- `1805.06881v2` - [abs](http://arxiv.org/abs/1805.06881v2) - [pdf](http://arxiv.org/pdf/1805.06881v2)

> We study dynamic changes of agents' observational power in logics of knowledge and time. We consider CTL*K, the extension of CTL* with knowledge operators, and enrich it with a new operator that models a change in an agent's way of observing the system. We extend the classic semantics of knowledge for perfect-recall agents to account for changes of observation, and we show that this new operator strictly increases the expressivity of CTL*K. We reduce the model-checking problem for our logic to that for CTL*K, which is known to be decidable. This provides a solution to the model-checking problem for our logic, but its complexity is not optimal. Indeed we provide a direct decision procedure with better complexity.

</details>

<details>

<summary>2018-09-03 18:33:06 - DeepTag: inferring all-cause diagnoses from clinical notes in under-resourced medical domain</summary>

- *Allen Nie, Ashley Zehnder, Rodney L. Page, Arturo L. Pineda, Manuel A. Rivas, Carlos D. Bustamante, James Zou*

- `1806.10722v2` - [abs](http://arxiv.org/abs/1806.10722v2) - [pdf](http://arxiv.org/pdf/1806.10722v2)

> Large scale veterinary clinical records can become a powerful resource for patient care and research. However, clinicians lack the time and resource to annotate patient records with standard medical diagnostic codes and most veterinary visits are captured in free text notes. The lack of standard coding makes it challenging to use the clinical data to improve patient care. It is also a major impediment to cross-species translational research, which relies on the ability to accurately identify patient cohorts with specific diagnostic criteria in humans and animals. In order to reduce the coding burden for veterinary clinical practice and aid translational research, we have developed a deep learning algorithm, DeepTag, which automatically infers diagnostic codes from veterinary free text notes. DeepTag is trained on a newly curated dataset of 112,558 veterinary notes manually annotated by experts. DeepTag extends multi-task LSTM with an improved hierarchical objective that captures the semantic structures between diseases. To foster human-machine collaboration, DeepTag also learns to abstain in examples when it is uncertain and defers them to human experts, resulting in improved performance. DeepTag accurately infers disease codes from free text even in challenging cross-hospital settings where the text comes from different clinical settings than the ones used for training. It enables automated disease annotation across a broad range of clinical diagnoses with minimal pre-processing. The technical framework in this work can be applied in other medical domains that currently lack medical coding resources.

</details>

<details>

<summary>2018-09-04 02:30:57 - Sequence-to-Action: End-to-End Semantic Graph Generation for Semantic Parsing</summary>

- *Bo Chen, Le Sun, Xianpei Han*

- `1809.00773v1` - [abs](http://arxiv.org/abs/1809.00773v1) - [pdf](http://arxiv.org/pdf/1809.00773v1)

> This paper proposes a neural semantic parsing approach -- Sequence-to-Action, which models semantic parsing as an end-to-end semantic graph generation process. Our method simultaneously leverages the advantages from two recent promising directions of semantic parsing. Firstly, our model uses a semantic graph to represent the meaning of a sentence, which has a tight-coupling with knowledge bases. Secondly, by leveraging the powerful representation learning and prediction ability of neural network models, we propose a RNN model which can effectively map sentences to action sequences for semantic graph generation. Experiments show that our method achieves state-of-the-art performance on OVERNIGHT dataset and gets competitive performance on GEO and ATIS datasets.

</details>

<details>

<summary>2018-09-04 19:29:03 - Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints</summary>

- *Ashutosh Baheti, Alan Ritter, Jiwei Li, Bill Dolan*

- `1809.01215v1` - [abs](http://arxiv.org/abs/1809.01215v1) - [pdf](http://arxiv.org/pdf/1809.01215v1)

> Neural conversation models tend to generate safe, generic responses for most inputs. This is due to the limitations of likelihood-based decoding objectives in generation tasks with diverse outputs, such as conversation. To address this challenge, we propose a simple yet effective approach for incorporating side information in the form of distributional constraints over the generated responses. We propose two constraints that help generate more content rich responses that are based on a model of syntax and topics (Griffiths et al., 2005) and semantic similarity (Arora et al., 2016). We evaluate our approach against a variety of competitive baselines, using both automatic metrics and human judgments, showing that our proposed approach generates responses that are much less generic without sacrificing plausibility. A working demo of our code can be found at https://github.com/abaheti95/DC-NeuralConversation.

</details>

<details>

<summary>2018-09-05 02:15:02 - Policy Shaping and Generalized Update Equations for Semantic Parsing from Denotations</summary>

- *Dipendra Misra, Ming-Wei Chang, Xiaodong He, Wen-tau Yih*

- `1809.01299v1` - [abs](http://arxiv.org/abs/1809.01299v1) - [pdf](http://arxiv.org/pdf/1809.01299v1)

> Semantic parsing from denotations faces two key challenges in model training: (1) given only the denotations (e.g., answers), search for good candidate semantic parses, and (2) choose the best model update algorithm. We propose effective and general solutions to each of them. Using policy shaping, we bias the search procedure towards semantic parses that are more compatible to the text, which provide better supervision signals for training. In addition, we propose an update equation that generalizes three different families of learning algorithms, which enables fast model exploration. When experimented on a recently proposed sequential question answering dataset, our framework leads to a new state-of-the-art model that outperforms previous work by 5.0% absolute on exact match accuracy.

</details>

<details>

<summary>2018-09-05 05:24:00 - Neural MultiVoice Models for Expressing Novel Personalities in Dialog</summary>

- *Shereen Oraby, Lena Reed, Sharath TS, Shubhangi Tandon, Marilyn Walker*

- `1809.01331v1` - [abs](http://arxiv.org/abs/1809.01331v1) - [pdf](http://arxiv.org/pdf/1809.01331v1)

> Natural language generators for task-oriented dialog should be able to vary the style of the output utterance while still effectively realizing the system dialog actions and their associated semantics. While the use of neural generation for training the response generation component of conversational agents promises to simplify the process of producing high quality responses in new domains, to our knowledge, there has been very little investigation of neural generators for task-oriented dialog that can vary their response style, and we know of no experiments on models that can generate responses that are different in style from those seen during training, while still maintain- ing semantic fidelity to the input meaning representation. Here, we show that a model that is trained to achieve a single stylis- tic personality target can produce outputs that combine stylistic targets. We carefully evaluate the multivoice outputs for both semantic fidelity and for similarities to and differences from the linguistic features that characterize the original training style. We show that contrary to our predictions, the learned models do not always simply interpolate model parameters, but rather produce styles that are distinct, and novel from the personalities they were trained on.

</details>

<details>

<summary>2018-09-05 08:14:16 - Firearms and Tigers are Dangerous, Kitchen Knives and Zebras are Not: Testing whether Word Embeddings Can Tell</summary>

- *Pia Sommerauer, Antske Fokkens*

- `1809.01375v1` - [abs](http://arxiv.org/abs/1809.01375v1) - [pdf](http://arxiv.org/pdf/1809.01375v1)

> This paper presents an approach for investigating the nature of semantic information captured by word embeddings. We propose a method that extends an existing human-elicited semantic property dataset with gold negative examples using crowd judgments. Our experimental approach tests the ability of supervised classifiers to identify semantic features in word embedding vectors and com- pares this to a feature-identification method based on full vector cosine similarity. The idea behind this method is that properties identified by classifiers, but not through full vector comparison are captured by embeddings. Properties that cannot be identified by either method are not. Our results provide an initial indication that semantic properties relevant for the way entities interact (e.g. dangerous) are captured, while perceptual information (e.g. colors) is not represented. We conclude that, though preliminary, these results show that our method is suitable for identifying which properties are captured by embeddings.

</details>

<details>

<summary>2018-09-05 09:08:43 - Deep learning bank distress from news and numerical financial data</summary>

- *Paola Cerchiello, Giancarlo Nicola, Samuel Ronnqvist, Peter Sarlin*

- `1706.09627v3` - [abs](http://arxiv.org/abs/1706.09627v3) - [pdf](http://arxiv.org/pdf/1706.09627v3)

> In this paper we focus our attention on the exploitation of the information contained in financial news to enhance the performance of a classifier of bank distress. Such information should be analyzed and inserted into the predictive model in the most efficient way and this task deals with all the issues related to text analysis and specifically analysis of news media. Among the different models proposed for such purpose, we investigate one of the possible deep learning approaches, based on a doc2vec representation of the textual data, a kind of neural network able to map the sequential and symbolic text input onto a reduced latent semantic space. Afterwards, a second supervised neural network is trained combining news data with standard financial figures to classify banks whether in distressed or tranquil states, based on a small set of known distress events. Then the final aim is not only the improvement of the predictive performance of the classifier but also to assess the importance of news data in the classification process. Does news data really bring more useful information not contained in standard financial variables? Our results seem to confirm such hypothesis.

</details>

<details>

<summary>2018-09-05 21:46:35 - Simple Unsupervised Keyphrase Extraction using Sentence Embeddings</summary>

- *Kamil Bennani-Smires, Claudiu Musat, Andreea Hossmann, Michael Baeriswyl, Martin Jaggi*

- `1801.04470v3` - [abs](http://arxiv.org/abs/1801.04470v3) - [pdf](http://arxiv.org/pdf/1801.04470v3)

> Keyphrase extraction is the task of automatically selecting a small set of phrases that best describe a given free text document. Supervised keyphrase extraction requires large amounts of labeled training data and generalizes very poorly outside the domain of the training data. At the same time, unsupervised systems have poor accuracy, and often do not generalize well, as they require the input document to belong to a larger corpus also given as input. Addressing these drawbacks, in this paper, we tackle keyphrase extraction from single documents with EmbedRank: a novel unsupervised method, that leverages sentence embeddings. EmbedRank achieves higher F-scores than graph-based state of the art systems on standard datasets and is suitable for real-time processing of large amounts of Web data. With EmbedRank, we also explicitly increase coverage and diversity among the selected keyphrases by introducing an embedding-based maximal marginal relevance (MMR) for new phrases. A user study including over 200 votes showed that, although reducing the phrases' semantic overlap leads to no gains in F-score, our high diversity selection is preferred by humans.

</details>

<details>

<summary>2018-09-06 16:27:32 - Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models</summary>

- *Tong Niu, Mohit Bansal*

- `1809.02079v1` - [abs](http://arxiv.org/abs/1809.02079v1) - [pdf](http://arxiv.org/pdf/1809.02079v1)

> We present two categories of model-agnostic adversarial strategies that reveal the weaknesses of several generative, task-oriented dialogue models: Should-Not-Change strategies that evaluate over-sensitivity to small and semantics-preserving edits, as well as Should-Change strategies that test if a model is over-stable against subtle yet semantics-changing modifications. We next perform adversarial training with each strategy, employing a max-margin approach for negative generative examples. This not only makes the target dialogue model more robust to the adversarial inputs, but also helps it perform significantly better on the original inputs. Moreover, training on all strategies combined achieves further improvements, achieving a new state-of-the-art performance on the original task (also verified via human evaluation). In addition to adversarial training, we also address the robustness task at the model-level, by feeding it subword units as both inputs and outputs, and show that the resulting model is equally competitive, requires only 1/4 of the original vocabulary size, and is robust to one of the adversarial strategies (to which the original model is vulnerable) even without adversarial training.

</details>

<details>

<summary>2018-09-06 17:08:21 - Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation</summary>

- *Mikel Artetxe, Gorka Labaka, Iñigo Lopez-Gazpio, Eneko Agirre*

- `1809.02094v1` - [abs](http://arxiv.org/abs/1809.02094v1) - [pdf](http://arxiv.org/pdf/1809.02094v1)

> Following the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones.

</details>

<details>

<summary>2018-09-07 04:57:15 - Generating Sentences by Editing Prototypes</summary>

- *Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, Percy Liang*

- `1709.08878v2` - [abs](http://arxiv.org/abs/1709.08878v2) - [pdf](http://arxiv.org/pdf/1709.08878v2)

> We propose a new generative model of sentences that first samples a prototype sentence from the training corpus and then edits it into a new sentence. Compared to traditional models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.

</details>

<details>

<summary>2018-09-07 08:01:55 - Weighted Abstract Dialectical Frameworks: Extended and Revised Report</summary>

- *Gerhard Brewka, Jörg Pührer, Hannes Strass, Johannes P. Wallner, Stefan Woltran*

- `1806.07717v2` - [abs](http://arxiv.org/abs/1806.07717v2) - [pdf](http://arxiv.org/pdf/1806.07717v2)

> Abstract Dialectical Frameworks (ADFs) generalize Dung's argumentation frameworks allowing various relationships among arguments to be expressed in a systematic way. We further generalize ADFs so as to accommodate arbitrary acceptance degrees for the arguments. This makes ADFs applicable in domains where both the initial status of arguments and their relationship are only insufficiently specified by Boolean functions. We define all standard ADF semantics for the weighted case, including grounded, preferred and stable semantics. We illustrate our approach using acceptance degrees from the unit interval and show how other valuation structures can be integrated. In each case it is sufficient to specify how the generalized acceptance conditions are represented by formulas, and to specify the information ordering underlying the characteristic ADF operator. We also present complexity results for problems related to weighted ADFs.

</details>

<details>

<summary>2018-09-07 09:31:52 - Feature Learning for Meta-Paths in Knowledge Graphs</summary>

- *Sebastian Bischoff*

- `1809.03267v1` - [abs](http://arxiv.org/abs/1809.03267v1) - [pdf](http://arxiv.org/pdf/1809.03267v1)

> In this thesis, we study the problem of feature learning on heterogeneous knowledge graphs. These features can be used to perform tasks such as link prediction, classification and clustering on graphs. Knowledge graphs provide rich semantics encoded in the edge and node types. Meta-paths consist of these types and abstract paths in the graph. Until now, meta-paths can only be used as categorical features with high redundancy and are therefore unsuitable for machine learning models. We propose meta-path embeddings to solve this problem by learning semantical and compact vector representations of them. Current graph embedding methods only embed nodes and edge types and therefore miss semantics encoded in the combination of them. Our method embeds meta-paths using the skipgram model with an extension to deal with the redundancy and high amount of meta-paths in big knowledge graphs. We critically evaluate our embedding approach by predicting links on Wikidata. The experiments indicate that we learn a sensible embedding of the meta-paths but can improve it further.

</details>

<details>

<summary>2018-09-07 10:00:53 - On2Vec: Embedding-based Relation Prediction for Ontology Population</summary>

- *Muhao Chen, Yingtao Tian, Xuelu Chen, Zijun Xue, Carlo Zaniolo*

- `1809.02382v1` - [abs](http://arxiv.org/abs/1809.02382v1) - [pdf](http://arxiv.org/pdf/1809.02382v1)

> Populating ontology graphs represents a long-standing problem for the Semantic Web community. Recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. However, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. These comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. Hence, we propose On2Vec, a novel translation-based graph embedding method for ontology population. On2Vec integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. The first is the Component-specific Model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the Hierarchy Model that performs focused learning of hierarchical relation facts. Experiments on several well-known ontology graphs demonstrate the promising capabilities of On2Vec in predicting and verifying new relation facts. These promising results also make possible significant improvements in related methods.

</details>

<details>

<summary>2018-09-07 14:41:56 - Lung Cancer Screening Using Adaptive Memory-Augmented Recurrent Networks</summary>

- *Aryan Mobiny, Supratik Moulik, Hien Van Nguyen*

- `1710.05719v2` - [abs](http://arxiv.org/abs/1710.05719v2) - [pdf](http://arxiv.org/pdf/1710.05719v2)

> In this paper, we investigate the effectiveness of deep learning techniques for lung nodule classification in computed tomography scans. Using less than 10,000 training examples, our deep networks perform two times better than a standard radiology software. Visualization of the networks' neurons reveals semantically meaningful features that are consistent with the clinical knowledge and radiologists' perception. Our paper also proposes a novel framework for rapidly adapting deep networks to the radiologists' feedback, or change in the data due to the shift in sensor's resolution or patient population. The classification accuracy of our approach remains above 80% while popular deep networks' accuracy is around chance. Finally, we provide in-depth analysis of our framework by asking a radiologist to examine important networks' features and perform blind re-labeling of networks' mistakes.

</details>

<details>

<summary>2018-09-07 19:41:23 - Kernel Graph Convolutional Neural Networks</summary>

- *Giannis Nikolentzos, Polykarpos Meladianos, Antoine Jean-Pierre Tixier, Konstantinos Skianis, Michalis Vazirgiannis*

- `1710.10689v2` - [abs](http://arxiv.org/abs/1710.10689v2) - [pdf](http://arxiv.org/pdf/1710.10689v2)

> Graph kernels have been successfully applied to many graph classification problems. Typically, a kernel is first designed, and then an SVM classifier is trained based on the features defined implicitly by this kernel. This two-stage approach decouples data representation from learning, which is suboptimal. On the other hand, Convolutional Neural Networks (CNNs) have the capability to learn their own features directly from the raw data during training. Unfortunately, they cannot handle irregular data such as graphs. We address this challenge by using graph kernels to embed meaningful local neighborhoods of the graphs in a continuous vector space. A set of filters is then convolved with these patches, pooled, and the output is then passed to a feedforward network. With limited parameter tuning, our approach outperforms strong baselines on 7 out of 10 benchmark datasets.

</details>

<details>

<summary>2018-09-07 21:43:30 - Coherence-Aware Neural Topic Modeling</summary>

- *Ran Ding, Ramesh Nallapati, Bing Xiang*

- `1809.02687v1` - [abs](http://arxiv.org/abs/1809.02687v1) - [pdf](http://arxiv.org/pdf/1809.02687v1)

> Topic models are evaluated based on their ability to describe documents well (i.e. low perplexity) and to produce topics that carry coherent semantic meaning. In topic modeling so far, perplexity is a direct optimization target. However, topic coherence, owing to its challenging computation, is not optimized for and is only evaluated after training. In this work, under a neural variational inference framework, we propose methods to incorporate a topic coherence objective into the training process. We demonstrate that such a coherence-aware topic model exhibits a similar level of perplexity as baseline models but achieves substantially higher topic coherence.

</details>

<details>

<summary>2018-09-07 22:39:49 - Empirical Vulnerability Analysis of Automated Smart Contracts Security Testing on Blockchains</summary>

- *Reza M. Parizi, Ali Dehghantanha, Kim-Kwang Raymond Choo, Amritraj Singh*

- `1809.02702v1` - [abs](http://arxiv.org/abs/1809.02702v1) - [pdf](http://arxiv.org/pdf/1809.02702v1)

> The emerging blockchain technology supports decentralized computing paradigm shift and is a rapidly approaching phenomenon. While blockchain is thought primarily as the basis of Bitcoin, its application has grown far beyond cryptocurrencies due to the introduction of smart contracts. Smart contracts are self-enforcing pieces of software, which reside and run over a hosting blockchain. Using blockchain-based smart contracts for secure and transparent management to govern interactions (authentication, connection, and transaction) in Internet-enabled environments, mostly IoT, is a niche area of research and practice. However, writing trustworthy and safe smart contracts can be tremendously challenging because of the complicated semantics of underlying domain-specific languages and its testability. There have been high-profile incidents that indicate blockchain smart contracts could contain various code-security vulnerabilities, instigating financial harms. When it involves security of smart contracts, developers embracing the ability to write the contracts should be capable of testing their code, for diagnosing security vulnerabilities, before deploying them to the immutable environments on blockchains. However, there are only a handful of security testing tools for smart contracts. This implies that the existing research on automatic smart contracts security testing is not adequate and remains in a very stage of infancy. With a specific goal to more readily realize the application of blockchain smart contracts in security and privacy, we should first understand their vulnerabilities before widespread implementation. Accordingly, the goal of this paper is to carry out a far-reaching experimental assessment of current static smart contracts security testing tools, for the most widely used blockchain, the Ethereum and its domain-specific programming language, Solidity to provide the first...

</details>

<details>

<summary>2018-09-08 06:43:01 - Exploration on Grounded Word Embedding: Matching Words and Images with Image-Enhanced Skip-Gram Model</summary>

- *Ruixuan Luo*

- `1809.02765v1` - [abs](http://arxiv.org/abs/1809.02765v1) - [pdf](http://arxiv.org/pdf/1809.02765v1)

> Word embedding is designed to represent the semantic meaning of a word with low dimensional vectors. The state-of-the-art methods of learning word embeddings (word2vec and GloVe) only use the word co-occurrence information. The learned embeddings are real number vectors, which are obscure to human. In this paper, we propose an Image-Enhanced Skip-Gram Model to learn grounded word embeddings by representing the word vectors in the same hyper-plane with image vectors. Experiments show that the image vectors and word embeddings learned by our model are highly correlated, which indicates that our model is able to provide a vivid image-based explanation to the word embeddings.

</details>

<details>

<summary>2018-09-08 12:49:18 - Attentive Semantic Role Labeling with Boundary Indicator</summary>

- *Zhuosheng Zhang, Shexia He, Zuchao Li, Hai Zhao*

- `1809.02796v1` - [abs](http://arxiv.org/abs/1809.02796v1) - [pdf](http://arxiv.org/pdf/1809.02796v1)

> The goal of semantic role labeling (SRL) is to discover the predicate-argument structure of a sentence, which plays a critical role in deep processing of natural language. This paper introduces simple yet effective auxiliary tags for dependency-based SRL to enhance a syntax-agnostic model with multi-hop self-attention. Our syntax-agnostic model achieves competitive performance with state-of-the-art models on the CoNLL-2009 benchmarks both for English and Chinese.

</details>

<details>

<summary>2018-09-08 15:29:47 - Extracting and Analyzing Semantic Relatedness between Cities Using News Articles</summary>

- *Yingjie Hu, Xinyue Ye, Shih-Lung Shaw*

- `1809.02823v1` - [abs](http://arxiv.org/abs/1809.02823v1) - [pdf](http://arxiv.org/pdf/1809.02823v1)

> News articles capture a variety of topics about our society. They reflect not only the socioeconomic activities that happened in our physical world, but also some of the cultures, human interests, and public concerns that exist only in the perceptions of people. Cities are frequently mentioned in news articles, and two or more cities may co-occur in the same article. Such co-occurrence often suggests certain relatedness between the mentioned cities, and the relatedness may be under different topics depending on the contents of the news articles. We consider the relatedness under different topics as semantic relatedness. By reading news articles, one can grasp the general semantic relatedness between cities, yet, given hundreds of thousands of news articles, it is very difficult, if not impossible, for anyone to manually read them. This paper proposes a computational framework which can "read" a large number of news articles and extract the semantic relatedness between cities. This framework is based on a natural language processing model and employs a machine learning process to identify the main topics of news articles. We describe the overall structure of this framework and its individual modules, and then apply it to an experimental dataset with more than 500,000 news articles covering the top 100 U.S. cities spanning a 10-year period. We perform exploratory visualization of the extracted semantic relatedness under different topics and over multiple years. We also analyze the impact of geographic distance on semantic relatedness and find varied distance decay effects. The proposed framework can be used to support large-scale content analysis in city network research.

</details>

<details>

<summary>2018-09-10 00:34:34 - A case for deep learning in semantics</summary>

- *Christopher Potts*

- `1809.03068v1` - [abs](http://arxiv.org/abs/1809.03068v1) - [pdf](http://arxiv.org/pdf/1809.03068v1)

> Pater's target article builds a persuasive case for establishing stronger ties between theoretical linguistics and connectionism (deep learning). This commentary extends his arguments to semantics, focusing in particular on issues of learning, compositionality, and lexical meaning.

</details>

<details>

<summary>2018-09-10 09:35:27 - Adaptive Behavior Generation for Autonomous Driving using Deep Reinforcement Learning with Compact Semantic States</summary>

- *Peter Wolf, Karl Kurzer, Tobias Wingert, Florian Kuhnt, J. Marius Zöllner*

- `1809.03214v1` - [abs](http://arxiv.org/abs/1809.03214v1) - [pdf](http://arxiv.org/pdf/1809.03214v1)

> Making the right decision in traffic is a challenging task that is highly dependent on individual preferences as well as the surrounding environment. Therefore it is hard to model solely based on expert knowledge. In this work we use Deep Reinforcement Learning to learn maneuver decisions based on a compact semantic state representation. This ensures a consistent model of the environment across scenarios as well as a behavior adaptation function, enabling on-line changes of desired behaviors without re-training. The input for the neural network is a simulated object list similar to that of Radar or Lidar sensors, superimposed by a relational semantic scene description. The state as well as the reward are extended by a behavior adaptation function and a parameterization respectively. With little expert knowledge and a set of mid-level actions, it can be seen that the agent is capable to adhere to traffic rules and learns to drive safely in a variety of situations.

</details>

<details>

<summary>2018-09-10 14:27:08 - xSense: Learning Sense-Separated Sparse Representations and Textual Definitions for Explainable Word Sense Networks</summary>

- *Ting-Yun Chang, Ta-Chung Chi, Shang-Chi Tsai, Yun-Nung Chen*

- `1809.03348v1` - [abs](http://arxiv.org/abs/1809.03348v1) - [pdf](http://arxiv.org/pdf/1809.03348v1)

> Despite the success achieved on various natural language processing tasks, word embeddings are difficult to interpret due to the dense vector representations. This paper focuses on interpreting the embeddings for various aspects, including sense separation in the vector dimensions and definition generation. Specifically, given a context together with a target word, our algorithm first projects the target word embedding to a high-dimensional sparse vector and picks the specific dimensions that can best explain the semantic meaning of the target word by the encoded contextual information, where the sense of the target word can be indirectly inferred. Finally, our algorithm applies an RNN to generate the textual definition of the target word in the human readable form, which enables direct interpretation of the corresponding word embedding. This paper also introduces a large and high-quality context-definition dataset that consists of sense definitions together with multiple example sentences per polysemous word, which is a valuable resource for definition modeling and word sense disambiguation. The conducted experiments show the superior performance in BLEU score and the human evaluation test.

</details>

<details>

<summary>2018-09-10 15:37:30 - Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space</summary>

- *Koki Washio, Tsuneaki Kato*

- `1809.03401v1` - [abs](http://arxiv.org/abs/1809.03401v1) - [pdf](http://arxiv.org/pdf/1809.03401v1)

> Capturing the semantic relations of words in a vector space contributes to many natural language processing tasks. One promising approach exploits lexico-syntactic patterns as features of word pairs. In this paper, we propose a novel model of this pattern-based approach, neural latent relational analysis (NLRA). NLRA can generalize co-occurrences of word pairs and lexico-syntactic patterns, and obtain embeddings of the word pairs that do not co-occur. This overcomes the critical data sparseness problem encountered in previous pattern-based models. Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous pattern-based models. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-the-art model that exploits additional semantic relational data.

</details>

<details>

<summary>2018-09-10 15:47:37 - Filling Missing Paths: Modeling Co-occurrences of Word Pairs and Dependency Paths for Recognizing Lexical Semantic Relations</summary>

- *Koki Washio, Tsuneaki Kato*

- `1809.03411v1` - [abs](http://arxiv.org/abs/1809.03411v1) - [pdf](http://arxiv.org/pdf/1809.03411v1)

> Recognizing lexical semantic relations between word pairs is an important task for many applications of natural language processing. One of the mainstream approaches to this task is to exploit the lexico-syntactic paths connecting two target words, which reflect the semantic relations of word pairs. However, this method requires that the considered words co-occur in a sentence. This requirement is hardly satisfied because of Zipf's law, which states that most content words occur very rarely. In this paper, we propose novel methods with a neural model of $P(path|w_1, w_2)$ to solve this problem. Our proposed model of $P(path|w_1, w_2)$ can be learned in an unsupervised manner and can generalize the co-occurrences of word pairs and dependency paths. This model can be used to augment the path data of word pairs that do not co-occur in the corpus, and extract features capturing relational information from word pairs. Our experimental results demonstrate that our methods improve on previous neural approaches based on dependency paths and successfully solve the focused problem.

</details>

<details>

<summary>2018-09-10 22:12:53 - REGMAPR - Text Matching Made Easy</summary>

- *Siddhartha Brahma*

- `1808.04343v3` - [abs](http://arxiv.org/abs/1808.04343v3) - [pdf](http://arxiv.org/pdf/1808.04343v3)

> Text matching is a fundamental problem in natural language processing. Neural models using bidirectional LSTMs for sentence encoding and inter-sentence attention mechanisms perform remarkably well on several benchmark datasets. We propose REGMAPR - a simple and general architecture for text matching that does not use inter-sentence attention. Starting from a Siamese architecture, we augment the embeddings of the words with two features based on exact and para- phrase match between words in the two sentences. We train the model using three types of regularization on datasets for textual entailment, paraphrase detection and semantic related- ness. REGMAPR performs comparably or better than more complex neural models or models using a large number of handcrafted features. REGMAPR achieves state-of-the-art results for paraphrase detection on the SICK dataset and for textual entailment on the SNLI dataset among models that do not use inter-sentence attention.

</details>

<details>

<summary>2018-09-10 23:20:00 - Detecting Gang-Involved Escalation on Social Media Using Context</summary>

- *Serina Chang, Ruiqi Zhong, Ethan Adams, Fei-Tzin Lee, Siddharth Varia, Desmond Patton, William Frey, Chris Kedzie, Kathleen McKeown*

- `1809.03632v1` - [abs](http://arxiv.org/abs/1809.03632v1) - [pdf](http://arxiv.org/pdf/1809.03632v1)

> Gang-involved youth in cities such as Chicago have increasingly turned to social media to post about their experiences and intents online. In some situations, when they experience the loss of a loved one, their online expression of emotion may evolve into aggression towards rival gangs and ultimately into real-world violence. In this paper, we present a novel system for detecting Aggression and Loss in social media. Our system features the use of domain-specific resources automatically derived from a large unlabeled corpus, and contextual representations of the emotional and semantic content of the user's recent tweets as well as their interactions with other users. Incorporating context in our Convolutional Neural Network (CNN) leads to a significant improvement.

</details>

<details>

<summary>2018-09-10 23:22:43 - Unsupervised Cross-lingual Transfer of Word Embedding Spaces</summary>

- *Ruochen Xu, Yiming Yang, Naoki Otani, Yuexin Wu*

- `1809.03633v1` - [abs](http://arxiv.org/abs/1809.03633v1) - [pdf](http://arxiv.org/pdf/1809.03633v1)

> Cross-lingual transfer of word embeddings aims to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces. Successfully solving this problem would benefit many downstream tasks such as to translate text classification models from resource-rich languages (e.g. English) to low-resource languages. Supervised methods for this problem rely on the availability of cross-lingual supervision, either using parallel corpora or bilingual lexicons as the labeled data for training, which may not be available for many low resource languages. This paper proposes an unsupervised learning approach that does not require any cross-lingual labeled data. Given two monolingual word embedding spaces for any language pair, our algorithm optimizes the transformation functions in both directions simultaneously based on distributional matching as well as minimizing the back-translation losses. We use a neural network implementation to calculate the Sinkhorn distance, a well-defined distributional similarity measure, and optimize our objective through back-propagation. Our evaluation on benchmark datasets for bilingual lexicon induction and cross-lingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other state-of-the-art supervised and unsupervised baseline methods over many language pairs.

</details>

<details>

<summary>2018-09-11 02:13:45 - Context-Dependent Diffusion Network for Visual Relationship Detection</summary>

- *Zhen Cui, Chunyan Xu, Wenming Zheng, Jian Yang*

- `1809.06213v1` - [abs](http://arxiv.org/abs/1809.06213v1) - [pdf](http://arxiv.org/pdf/1809.06213v1)

> Visual relationship detection can bridge the gap between computer vision and natural language for scene understanding of images. Different from pure object recognition tasks, the relation triplets of subject-predicate-object lie on an extreme diversity space, such as \textit{person-behind-person} and \textit{car-behind-building}, while suffering from the problem of combinatorial explosion. In this paper, we propose a context-dependent diffusion network (CDDN) framework to deal with visual relationship detection. To capture the interactions of different object instances, two types of graphs, word semantic graph and visual scene graph, are constructed to encode global context interdependency. The semantic graph is built through language priors to model semantic correlations across objects, whilst the visual scene graph defines the connections of scene objects so as to utilize the surrounding scene information. For the graph-structured data, we design a diffusion network to adaptively aggregate information from contexts, which can effectively learn latent representations of visual relationships and well cater to visual relationship detection in view of its isomorphic invariance to graphs. Experiments on two widely-used datasets demonstrate that our proposed method is more effective and achieves the state-of-the-art performance.

</details>

<details>

<summary>2018-09-11 06:40:36 - Evaluating Multimodal Representations on Sentence Similarity: vSTS, Visual Semantic Textual Similarity Dataset</summary>

- *Oier Lopez de Lacalle, Aitor Soroa, Eneko Agirre*

- `1809.03695v1` - [abs](http://arxiv.org/abs/1809.03695v1) - [pdf](http://arxiv.org/pdf/1809.03695v1)

> In this paper we introduce vSTS, a new dataset for measuring textual similarity of sentences using multimodal information. The dataset is comprised by images along with its respectively textual captions. We describe the dataset both quantitatively and qualitatively, and claim that it is a valid gold standard for measuring automatic multimodal textual similarity systems. We also describe the initial experiments combining the multimodal information.

</details>

<details>

<summary>2018-09-11 15:56:46 - Assessing Composition in Sentence Vector Representations</summary>

- *Allyson Ettinger, Ahmed Elgohary, Colin Phillips, Philip Resnik*

- `1809.03992v1` - [abs](http://arxiv.org/abs/1809.03992v1) - [pdf](http://arxiv.org/pdf/1809.03992v1)

> An important component of achieving language understanding is mastering the composition of sentence meaning, but an immediate challenge to solving this problem is the opacity of sentence vector representations produced by current neural sentence composition models. We present a method to address this challenge, developing tasks that directly target compositional meaning information in sentence vector representations with a high degree of precision and control. To enable the creation of these controlled tasks, we introduce a specialized sentence generation system that produces large, annotated sentence sets meeting specified syntactic, semantic and lexical constraints. We describe the details of the method and generation system, and then present results of experiments applying our method to probe for compositional information in embeddings from a number of existing sentence composition models. We find that the method is able to extract useful information about the differing capacities of these models, and we discuss the implications of our results with respect to these systems' capturing of sentence information. We make available for public use the datasets used for these experiments, as well as the generation system.

</details>

<details>

<summary>2018-09-11 16:09:53 - Evaluating Semantic Rationality of a Sentence: A Sememe-Word-Matching Neural Network based on HowNet</summary>

- *Shu Liu, Jingjing Xu, Xuancheng Ren, Xu Sun*

- `1809.03999v1` - [abs](http://arxiv.org/abs/1809.03999v1) - [pdf](http://arxiv.org/pdf/1809.03999v1)

> Automatic evaluation of semantic rationality is an important yet challenging task, and current automatic techniques cannot well identify whether a sentence is semantically rational. The methods based on the language model do not measure the sentence by rationality but by commonness. The methods based on the similarity with human written sentences will fail if human-written references are not available. In this paper, we propose a novel model called Sememe-Word-Matching Neural Network (SWM-NN) to tackle semantic rationality evaluation by taking advantage of sememe knowledge base HowNet. The advantage is that our model can utilize a proper combination of sememes to represent the fine-grained semantic meanings of a word within the specific contexts. We use the fine-grained semantic representation to help the model learn the semantic dependency among words. To evaluate the effectiveness of the proposed model, we build a large-scale rationality evaluation dataset. Experimental results on this dataset show that the proposed model outperforms the competitive baselines with a 5.4\% improvement in accuracy.

</details>

<details>

<summary>2018-09-11 20:56:02 - Heated-Up Softmax Embedding</summary>

- *Xu Zhang, Felix Xinnan Yu, Svebor Karaman, Wei Zhang, Shih-Fu Chang*

- `1809.04157v1` - [abs](http://arxiv.org/abs/1809.04157v1) - [pdf](http://arxiv.org/pdf/1809.04157v1)

> Metric learning aims at learning a distance which is consistent with the semantic meaning of the samples. The problem is generally solved by learning an embedding for each sample such that the embeddings of samples of the same category are compact while the embeddings of samples of different categories are spread-out in the feature space. We study the features extracted from the second last layer of a deep neural network based classifier trained with the cross entropy loss on top of the softmax layer. We show that training classifiers with different temperature values of softmax function leads to features with different levels of compactness. Leveraging these insights, we propose a "heating-up" strategy to train a classifier with increasing temperatures, leading the corresponding embeddings to achieve state-of-the-art performance on a variety of metric learning benchmarks.

</details>

<details>

<summary>2018-09-11 21:08:00 - Adversarial Propagation and Zero-Shot Cross-Lingual Transfer of Word Vector Specialization</summary>

- *Edoardo Maria Ponti, Ivan Vulić, Goran Glavaš, Nikola Mrkšić, Anna Korhonen*

- `1809.04163v1` - [abs](http://arxiv.org/abs/1809.04163v1) - [pdf](http://arxiv.org/pdf/1809.04163v1)

> Semantic specialization is the process of fine-tuning pre-trained distributional word vectors using external lexical knowledge (e.g., WordNet) to accentuate a particular semantic relation in the specialized vector space. While post-processing specialization methods are applicable to arbitrary distributional vectors, they are limited to updating only the vectors of words occurring in external lexicons (i.e., seen words), leaving the vectors of all other words unchanged. We propose a novel approach to specializing the full distributional vocabulary. Our adversarial post-specialization method propagates the external lexical knowledge to the full distributional space. We exploit words seen in the resources as training examples for learning a global specialization function. This function is learned by combining a standard L2-distance loss with an adversarial loss: the adversarial component produces more realistic output vectors. We show the effectiveness and robustness of the proposed method across three languages and on three tasks: word similarity, dialog state tracking, and lexical simplification. We report consistent improvements over distributional word vectors and vectors specialized by other state-of-the-art specialization frameworks. Finally, we also propose a cross-lingual transfer method for zero-shot specialization which successfully specializes a full target distributional space without any lexical knowledge in the target language and without any bilingual data.

</details>

<details>

<summary>2018-09-11 22:36:01 - Searching for Efficient Multi-Scale Architectures for Dense Image Prediction</summary>

- *Liang-Chieh Chen, Maxwell D. Collins, Yukun Zhu, George Papandreou, Barret Zoph, Florian Schroff, Hartwig Adam, Jonathon Shlens*

- `1809.04184v1` - [abs](http://arxiv.org/abs/1809.04184v1) - [pdf](http://arxiv.org/pdf/1809.04184v1)

> The design of neural network architectures is an important component for achieving state-of-the-art performance with machine learning systems across a broad array of tasks. Much work has endeavored to design and build architectures automatically through clever construction of a search space paired with simple learning algorithms. Recent progress has demonstrated that such meta-learning methods may exceed scalable human-invented architectures on image classification tasks. An open question is the degree to which such methods may generalize to new domains. In this work we explore the construction of meta-learning techniques for dense image prediction focused on the tasks of scene parsing, person-part segmentation, and semantic image segmentation. Constructing viable search spaces in this domain is challenging because of the multi-scale representation of visual information and the necessity to operate on high resolution imagery. Based on a survey of techniques in dense image prediction, we construct a recursive search space and demonstrate that even with efficient random search, we can identify architectures that outperform human-invented architectures and achieve state-of-the-art performance on three dense prediction tasks including 82.7\% on Cityscapes (street scene parsing), 71.3\% on PASCAL-Person-Part (person-part segmentation), and 87.9\% on PASCAL VOC 2012 (semantic image segmentation). Additionally, the resulting architecture is more computationally efficient, requiring half the parameters and half the computational cost as previous state of the art systems.

</details>

<details>

<summary>2018-09-11 23:46:33 - Zoom: SSD-based Vector Search for Optimizing Accuracy, Latency and Memory</summary>

- *Minjia Zhang, Yuxiong He*

- `1809.04067v1` - [abs](http://arxiv.org/abs/1809.04067v1) - [pdf](http://arxiv.org/pdf/1809.04067v1)

> With the advancement of machine learning and deep learning, vector search becomes instrumental to many information retrieval systems, to search and find best matches to user queries based on their semantic similarities.These online services require the search architecture to be both effective with high accuracy and efficient with low latency and memory footprint, which existing work fails to offer. We develop, Zoom, a new vector search solution that collaboratively optimizes accuracy, latency and memory based on a multiview approach. (1) A "preview" step generates a small set of good candidates, leveraging compressed vectors in memory for reduced footprint and fast lookup. (2) A "fullview" step on SSDs reranks those candidates with their full-length vector, striking high accuracy. Our evaluation shows that, Zoom achieves an order of magnitude improvements on efficiency while attaining equal or higher accuracy, comparing with the state-of-the-art.

</details>

<details>

<summary>2018-09-12 05:44:23 - Extracting Fairness Policies from Legal Documents</summary>

- *Rashmi Nagpal, Chetna Wadhwa, Mallika Gupta, Samiulla Shaikh, Sameep Mehta, Vikram Goyal*

- `1809.04262v1` - [abs](http://arxiv.org/abs/1809.04262v1) - [pdf](http://arxiv.org/pdf/1809.04262v1)

> Machine Learning community is recently exploring the implications of bias and fairness with respect to the AI applications. The definition of fairness for such applications varies based on their domain of application. The policies governing the use of such machine learning system in a given context are defined by the constitutional laws of nations and regulatory policies enforced by the organizations that are involved in the usage. Fairness related laws and policies are often spread across the large documents like constitution, agreements, and organizational regulations. These legal documents have long complex sentences in order to achieve rigorousness and robustness. Automatic extraction of fairness policies, or in general, any specific kind of policies from large legal corpus can be very useful for the study of bias and fairness in the context of AI applications.   We attempted to automatically extract fairness policies from publicly available law documents using two approaches based on semantic relatedness. The experiments reveal how classical Wordnet-based similarity and vector-based similarity differ in addressing this task. We have shown that similarity based on word vectors beats the classical approach with a large margin, whereas other vector representations of senses and sentences fail to even match the classical baseline. Further, we have presented thorough error analysis and reasoning to explain the results with appropriate examples from the dataset for deeper insights.

</details>

<details>

<summary>2018-09-12 06:37:51 - Knowledge-Aware Conversational Semantic Parsing Over Web Tables</summary>

- *Yibo Sun, Duyu Tang, Nan Duan, Jingjing Xu, Xiaocheng Feng, Bing Qin*

- `1809.04271v1` - [abs](http://arxiv.org/abs/1809.04271v1) - [pdf](http://arxiv.org/pdf/1809.04271v1)

> Conversational semantic parsing over tables requires knowledge acquiring and reasoning abilities, which have not been well explored by current state-of-the-art approaches. Motivated by this fact, we propose a knowledge-aware semantic parser to improve parsing performance by integrating various types of knowledge. In this paper, we consider three types of knowledge, including grammar knowledge, expert knowledge, and external resource knowledge. First, grammar knowledge empowers the model to effectively replicate previously generated logical form, which effectively handles the co-reference and ellipsis phenomena in conversation Second, based on expert knowledge, we propose a decomposable model, which is more controllable compared with traditional end-to-end models that put all the burdens of learning on trial-and-error in an end-to-end way. Third, external resource knowledge, i.e., provided by a pre-trained language model or an entity typing model, is used to improve the representation of question and table for a better semantic understanding. We conduct experiments on the SequentialQA dataset. Results show that our knowledge-aware model outperforms the state-of-the-art approaches. Incremental experimental results also prove the usefulness of various knowledge. Further analysis shows that our approach has the ability to derive the meaning representation of a context-dependent utterance by leveraging previously generated outcomes.

</details>

<details>

<summary>2018-09-12 07:09:08 - Safe Navigation with Human Instructions in Complex Scenes</summary>

- *Zhe Hu, Jia Pan, Tingxiang Fan, Ruigang Yang, Dinesh Manocha*

- `1809.04280v1` - [abs](http://arxiv.org/abs/1809.04280v1) - [pdf](http://arxiv.org/pdf/1809.04280v1)

> In this paper, we present a robotic navigation algorithm with natural language interfaces, which enables a robot to safely walk through a changing environment with moving persons by following human instructions such as "go to the restaurant and keep away from people". We first classify human instructions into three types: the goal, the constraints, and uninformative phrases. Next, we provide grounding for the extracted goal and constraint items in a dynamic manner along with the navigation process, to deal with the target objects that are too far away for sensor observation and the appearance of moving obstacles like humans. In particular, for a goal phrase (e.g., "go to the restaurant"), we ground it to a location in a predefined semantic map and treat it as a goal for a global motion planner, which plans a collision-free path in the workspace for the robot to follow. For a constraint phrase (e.g., "keep away from people"), we dynamically add the corresponding constraint into a local planner by adjusting the values of a local costmap according to the results returned by the object detection module. The updated costmap is then used to compute a local collision avoidance control for the safe navigation of the robot. By combining natural language processing, motion planning, and computer vision, our developed system is demonstrated to be able to successfully follow natural language navigation instructions to achieve navigation tasks in both simulated and real-world scenarios. Videos are available at https://sites.google.com/view/snhi

</details>

<details>

<summary>2018-09-12 10:11:39 - The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA</summary>

- *Shailza Jolly, Sandro Pezzelle, Tassilo Klein, Andreas Dengel, Moin Nabi*

- `1809.04344v1` - [abs](http://arxiv.org/abs/1809.04344v1) - [pdf](http://arxiv.org/pdf/1809.04344v1)

> We introduce MASSES, a simple evaluation metric for the task of Visual Question Answering (VQA). In its standard form, the VQA task is operationalized as follows: Given an image and an open-ended question in natural language, systems are required to provide a suitable answer. Currently, model performance is evaluated by means of a somehow simplistic metric: If the predicted answer is chosen by at least 3 human annotators out of 10, then it is 100% correct. Though intuitively valuable, this metric has some important limitations. First, it ignores whether the predicted answer is the one selected by the Majority (MA) of annotators. Second, it does not account for the quantitative Subjectivity (S) of the answers in the sample (and dataset). Third, information about the Semantic Similarity (SES) of the responses is completely neglected. Based on such limitations, we propose a multi-component metric that accounts for all these issues. We show that our metric is effective in providing a more fine-grained evaluation both on the quantitative and qualitative level.

</details>

<details>

<summary>2018-09-12 15:08:00 - Emo2Vec: Learning Generalized Emotion Representation by Multi-task Training</summary>

- *Peng Xu, Andrea Madotto, Chien-Sheng Wu, Ji Ho Park, Pascale Fung*

- `1809.04505v1` - [abs](http://arxiv.org/abs/1809.04505v1) - [pdf](http://arxiv.org/pdf/1809.04505v1)

> In this paper, we propose Emo2Vec which encodes emotional semantics into vectors. We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion/sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. Our evaluation of Emo2Vec shows that it outperforms existing affect-related representations, such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora. When concatenated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier.

</details>

<details>

<summary>2018-09-12 17:40:58 - Monocular Depth Estimation by Learning from Heterogeneous Datasets</summary>

- *Akhil Gurram, Onay Urfalioglu, Ibrahim Halfaoui, Fahd Bouzaraa, Antonio M. Lopez*

- `1803.08018v2` - [abs](http://arxiv.org/abs/1803.08018v2) - [pdf](http://arxiv.org/pdf/1803.08018v2)

> Depth estimation provides essential information to perform autonomous driving and driver assistance. Especially, Monocular Depth Estimation is interesting from a practical point of view, since using a single camera is cheaper than many other options and avoids the need for continuous calibration strategies as required by stereo-vision approaches. State-of-the-art methods for Monocular Depth Estimation are based on Convolutional Neural Networks (CNNs). A promising line of work consists of introducing additional semantic information about the traffic scene when training CNNs for depth estimation. In practice, this means that the depth data used for CNN training is complemented with images having pixel-wise semantic labels, which usually are difficult to annotate (e.g. crowded urban images). Moreover, so far it is common practice to assume that the same raw training data is associated with both types of ground truth, i.e., depth and semantic labels. The main contribution of this paper is to show that this hard constraint can be circumvented, i.e., that we can train CNNs for depth estimation by leveraging the depth and semantic information coming from heterogeneous datasets. In order to illustrate the benefits of our approach, we combine KITTI depth and Cityscapes semantic segmentation datasets, outperforming state-of-the-art results on Monocular Depth Estimation.

</details>

<details>

<summary>2018-09-12 19:53:56 - Semantic WordRank: Generating Finer Single-Document Summarizations</summary>

- *Hao Zhang, Jie Wang*

- `1809.04649v1` - [abs](http://arxiv.org/abs/1809.04649v1) - [pdf](http://arxiv.org/pdf/1809.04649v1)

> We present Semantic WordRank (SWR), an unsupervised method for generating an extractive summary of a single document. Built on a weighted word graph with semantic and co-occurrence edges, SWR scores sentences using an article-structure-biased PageRank algorithm with a Softplus function adjustment, and promotes topic diversity using spectral subtopic clustering under the Word-Movers-Distance metric. We evaluate SWR on the DUC-02 and SummBank datasets and show that SWR produces better summaries than the state-of-the-art algorithms over DUC-02 under common ROUGE measures. We then show that, under the same measures over SummBank, SWR outperforms each of the three human annotators (aka. judges) and compares favorably with the combined performance of all judges.

</details>

<details>

<summary>2018-09-13 00:29:17 - Robust Text-to-SQL Generation with Execution-Guided Decoding</summary>

- *Chenglong Wang, Kedar Tatwawadi, Marc Brockschmidt, Po-Sen Huang, Yi Mao, Oleksandr Polozov, Rishabh Singh*

- `1807.03100v3` - [abs](http://arxiv.org/abs/1807.03100v3) - [pdf](http://arxiv.org/pdf/1807.03100v3)

> We consider the problem of neural semantic parsing, which translates natural language questions into executable SQL queries. We introduce a new mechanism, execution guidance, to leverage the semantics of SQL. It detects and excludes faulty programs during the decoding procedure by conditioning on the execution of partially generated program. The mechanism can be used with any autoregressive generative model, which we demonstrate on four state-of-the-art recurrent or template-based semantic parsing models. We demonstrate that execution guidance universally improves model performance on various text-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS, and GeoQuery. As a result, we achieve new state-of-the-art execution accuracy of 83.8% on WikiSQL.

</details>

<details>

<summary>2018-09-13 02:16:40 - Toward Controlled Generation of Text</summary>

- *Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P. Xing*

- `1703.00955v4` - [abs](http://arxiv.org/abs/1703.00955v4) - [pdf](http://arxiv.org/pdf/1703.00955v4)

> Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.

</details>

<details>

<summary>2018-09-13 02:37:53 - Geodesic Clustering in Deep Generative Models</summary>

- *Tao Yang, Georgios Arvanitidis, Dongmei Fu, Xiaogang Li, Søren Hauberg*

- `1809.04747v1` - [abs](http://arxiv.org/abs/1809.04747v1) - [pdf](http://arxiv.org/pdf/1809.04747v1)

> Deep generative models are tremendously successful in learning low-dimensional latent representations that well-describe the data. These representations, however, tend to much distort relationships between points, i.e. pairwise distances tend to not reflect semantic similarities well. This renders unsupervised tasks, such as clustering, difficult when working with the latent representations. We demonstrate that taking the geometry of the generative model into account is sufficient to make simple clustering algorithms work well over latent representations. Leaning on the recent finding that deep generative models constitute stochastically immersed Riemannian manifolds, we propose an efficient algorithm for computing geodesics (shortest paths) and computing distances in the latent space, while taking its distortion into account. We further propose a new architecture for modeling uncertainty in variational autoencoders, which is essential for understanding the geometry of deep generative models. Experiments show that the geodesic distance is very likely to reflect the internal structure of the data.

</details>

<details>

<summary>2018-09-13 14:11:46 - How agents see things: On visual representations in an emergent language game</summary>

- *Diane Bouchacourt, Marco Baroni*

- `1808.10696v2` - [abs](http://arxiv.org/abs/1808.10696v2) - [pdf](http://arxiv.org/pdf/1808.10696v2)

> There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents' symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017) and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we are interested in developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.

</details>

<details>

<summary>2018-09-13 16:31:43 - Learning to Group and Label Fine-Grained Shape Components</summary>

- *Xiaogang Wang, Bin Zhou, Haiyue Fang, Xiaowu Chen, Qinping Zhao, Kai Xu*

- `1809.05050v1` - [abs](http://arxiv.org/abs/1809.05050v1) - [pdf](http://arxiv.org/pdf/1809.05050v1)

> A majority of stock 3D models in modern shape repositories are assembled with many fine-grained components. The main cause of such data form is the component-wise modeling process widely practiced by human modelers. These modeling components thus inherently reflect some function-based shape decomposition the artist had in mind during modeling. On the other hand, modeling components represent an over-segmentation since a functional part is usually modeled as a multi-component assembly. Based on these observations, we advocate that labeled segmentation of stock 3D models should not overlook the modeling components and propose a learning solution to grouping and labeling of the fine-grained components. However, directly characterizing the shape of individual components for the purpose of labeling is unreliable, since they can be arbitrarily tiny and semantically meaningless. We propose to generate part hypotheses from the components based on a hierarchical grouping strategy, and perform labeling on those part groups instead of directly on the components. Part hypotheses are mid-level elements which are more probable to carry semantic information. A multiscale 3D convolutional neural network is trained to extract context-aware features for the hypotheses. To accomplish a labeled segmentation of the whole shape, we formulate higher-order conditional random fields (CRFs) to infer an optimal label assignment for all components. Extensive experiments demonstrate that our method achieves significantly robust labeling results on raw 3D models from public shape repositories. Our work also contributes the first benchmark for component-wise labeling.

</details>

<details>

<summary>2018-09-13 20:09:12 - Visual Text Correction</summary>

- *Amir Mazaheri, Mubarak Shah*

- `1801.01967v3` - [abs](http://arxiv.org/abs/1801.01967v3) - [pdf](http://arxiv.org/pdf/1801.01967v3)

> Videos, images, and sentences are mediums that can express the same semantics. One can imagine a picture by reading a sentence or can describe a scene with some words. However, even small changes in a sentence can cause a significant semantic inconsistency with the corresponding video/image. For example, by changing the verb of a sentence, the meaning may drastically change. There have been many efforts to encode a video/sentence and decode it as a sentence/video. In this research, we study a new scenario in which both the sentence and the video are given, but the sentence is inaccurate. A semantic inconsistency between the sentence and the video or between the words of a sentence can result in an inaccurate description. This paper introduces a new problem, called Visual Text Correction (VTC), i.e., finding and replacing an inaccurate word in the textual description of a video. We propose a deep network that can simultaneously detect an inaccuracy in a sentence, and fix it by replacing the inaccurate word(s). Our method leverages the semantic interdependence of videos and words, as well as the short-term and long-term relations of the words in a sentence. In our formulation, part of a visual feature vector for every single word is dynamically selected through a gating process. Furthermore, to train and evaluate our model, we propose an approach to automatically construct a large dataset for VTC problem. Our experiments and performance analysis demonstrates that the proposed method provides very good results and also highlights the general challenges in solving the VTC problem. To the best of our knowledge, this work is the first of its kind for the Visual Text Correction task.

</details>

<details>

<summary>2018-09-14 07:51:19 - Characterizing Variation in Crowd-Sourced Data for Training Neural Language Generators to Produce Stylistically Varied Outputs</summary>

- *Juraj Juraska, Marilyn Walker*

- `1809.05288v1` - [abs](http://arxiv.org/abs/1809.05288v1) - [pdf](http://arxiv.org/pdf/1809.05288v1)

> One of the biggest challenges of end-to-end language generation from meaning representations in dialogue systems is making the outputs more natural and varied. Here we take a large corpus of 50K crowd-sourced utterances in the restaurant domain and develop text analysis methods that systematically characterize types of sentences in the training data. We then automatically label the training data to allow us to conduct two kinds of experiments with a neural generator. First, we test the effect of training the system with different stylistic partitions and quantify the effect of smaller, but more stylistically controlled training data. Second, we propose a method of labeling the style variants during training, and show that we can modify the style of the generated utterances using our stylistic labels. We contrast and compare these methods that can be used with any existing large corpus, showing how they vary in terms of semantic quality and stylistic control.

</details>

<details>

<summary>2018-09-14 08:58:49 - On Plans With Loops and Noise</summary>

- *Vaishak Belle*

- `1809.05309v1` - [abs](http://arxiv.org/abs/1809.05309v1) - [pdf](http://arxiv.org/pdf/1809.05309v1)

> In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.   Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about degrees of belief and noise, we revisit the execution semantics of generalised plans. The specification is then used to analyse the correctness of example plans.

</details>

<details>

<summary>2018-09-14 17:59:34 - Semantic Analysis of (Reflectional) Visual Symmetry: A Human-Centred Computational Model for Declarative Explainability</summary>

- *Jakob Suchan, Mehul Bhatt, Srikrishna Vardarajan, Seyed Ali Amirshahi, Stella Yu*

- `1806.07376v2` - [abs](http://arxiv.org/abs/1806.07376v2) - [pdf](http://arxiv.org/pdf/1806.07376v2)

> We present a computational model for the semantic interpretation of symmetry in naturalistic scenes. Key features include a human-centred representation, and a declarative, explainable interpretation model supporting deep semantic question-answering founded on an integration of methods in knowledge representation and deep learning based computer vision. In the backdrop of the visual arts, we showcase the framework's capability to generate human-centred, queryable, relational structures, also evaluating the framework with an empirical study on the human perception of visual symmetry. Our framework represents and is driven by the application of foundational, integrated Vision and Knowledge Representation and Reasoning methods for applications in the arts, and the psychological and social sciences.

</details>

<details>

<summary>2018-09-14 22:34:40 - Semantic DMN: Formalizing and Reasoning About Decisions in the Presence of Background Knowledge</summary>

- *Diego Calvanese, Marlon Dumas, Fabrizio Maria Maggi, Marco Montali*

- `1807.11615v3` - [abs](http://arxiv.org/abs/1807.11615v3) - [pdf](http://arxiv.org/pdf/1807.11615v3)

> The Decision Model and Notation (DMN) is a recent OMG standard for the elicitation and representation of decision models, and for managing their interconnection with business processes. DMN builds on the notion of decision tables, and their combination into more complex decision requirements graphs (DRGs), which bridge between business process models and decision logic models. DRGs may rely on additional, external business knowledge models, whose functioning is not part of the standard. In this work, we consider one of the most important types of business knowledge, namely background knowledge that conceptually accounts for the structural aspects of the domain of interest, and propose decision knowledge bases (DKBs), which semantically combine DRGs modeled in DMN, and domain knowledge captured by means of first-order logic with datatypes. We provide a logic-based semantics for such an integration, and formalize different DMN reasoning tasks for DKBs. We then consider background knowledge formulated as a description logic ontology with datatypes, and show how the main verification tasks for DMN in this enriched setting can be formalized as standard DL reasoning services, and actually carried out in ExpTime. We discuss the effectiveness of our framework on a case study in maritime security.

</details>

<details>

<summary>2018-09-15 02:54:34 - Geo-Text Data and Data-Driven Geospatial Semantics</summary>

- *Yingjie Hu*

- `1809.05636v1` - [abs](http://arxiv.org/abs/1809.05636v1) - [pdf](http://arxiv.org/pdf/1809.05636v1)

> Many datasets nowadays contain links between geographic locations and natural language texts. These links can be geotags, such as geotagged tweets or geotagged Wikipedia pages, in which location coordinates are explicitly attached to texts. These links can also be place mentions, such as those in news articles, travel blogs, or historical archives, in which texts are implicitly connected to the mentioned places. This kind of data is referred to as geo-text data. The availability of large amounts of geo-text data brings both challenges and opportunities. On the one hand, it is challenging to automatically process this kind of data due to the unstructured texts and the complex spatial footprints of some places. On the other hand, geo-text data offers unique research opportunities through the rich information contained in texts and the special links between texts and geography. As a result, geo-text data facilitates various studies especially those in data-driven geospatial semantics. This paper discusses geo-text data and related concepts. With a focus on data-driven research, this paper systematically reviews a large number of studies that have discovered multiple types of knowledge from geo-text data. Based on the literature review, a generalized workflow is extracted and key challenges for future work are discussed.

</details>

<details>

<summary>2018-09-15 10:37:06 - apk2vec: Semi-supervised multi-view representation learning for profiling Android applications</summary>

- *Annamalai Narayanan, Charlie Soh, Lihui Chen, Yang Liu, Lipo Wang*

- `1809.05693v1` - [abs](http://arxiv.org/abs/1809.05693v1) - [pdf](http://arxiv.org/pdf/1809.05693v1)

> Building behavior profiles of Android applications (apps) with holistic, rich and multi-view information (e.g., incorporating several semantic views of an app such as API sequences, system calls, etc.) would help catering downstream analytics tasks such as app categorization, recommendation and malware analysis significantly better. Towards this goal, we design a semi-supervised Representation Learning (RL) framework named apk2vec to automatically generate a compact representation (aka profile/embedding) for a given app. More specifically, apk2vec has the three following unique characteristics which make it an excellent choice for largescale app profiling: (1) it encompasses information from multiple semantic views such as API sequences, permissions, etc., (2) being a semi-supervised embedding technique, it can make use of labels associated with apps (e.g., malware family or app category labels) to build high quality app profiles, and (3) it combines RL and feature hashing which allows it to efficiently build profiles of apps that stream over time (i.e., online learning). The resulting semi-supervised multi-view hash embeddings of apps could then be used for a wide variety of downstream tasks such as the ones mentioned above. Our extensive evaluations with more than 42,000 apps demonstrate that apk2vec's app profiles could significantly outperform state-of-the-art techniques in four app analytics tasks namely, malware detection, familial clustering, app clone detection and app recommendation.

</details>

<details>

<summary>2018-09-15 11:04:30 - Inferring Political Alignments of Twitter Users: A case study on 2017 Turkish constitutional referendum</summary>

- *Kutlu Emre Yilmaz, Osman Abul*

- `1809.05699v1` - [abs](http://arxiv.org/abs/1809.05699v1) - [pdf](http://arxiv.org/pdf/1809.05699v1)

> Increasing popularity of Twitter in politics is subject to commercial and academic interest. To fully exploit the merits of this platform, reaching the target audience with desired political leanings is critical. This paper extends the research on inferring political orientations of Twitter users to the case of 2017 Turkish constitutional referendum. After constructing a targeted dataset of tweets, we explore several types of potential features to build accurate machine learning based predictive models. In our experiments, a three-class support vector machine (SVM) classifier trained on semantic features achieves the best accuracy score of 89.9%. Moreover, an SVM classifier trained on full-text features performs better than an SVM classifier trained on hashtags, with respective accuracy scores of 89.05% and 85.9%. Relatively high accuracy scores obtained by full-text features may point to differences in language use, which deserves further research.

</details>

<details>

<summary>2018-09-15 22:11:03 - AUEB at BioASQ 6: Document and Snippet Retrieval</summary>

- *Georgios-Ioannis Brokos, Polyvios Liosis, Ryan McDonald, Dimitris Pappas, Ion Androutsopoulos*

- `1809.06366v1` - [abs](http://arxiv.org/abs/1809.06366v1) - [pdf](http://arxiv.org/pdf/1809.06366v1)

> We present AUEB's submissions to the BioASQ 6 document and snippet retrieval tasks (parts of Task 6b, Phase A). Our models use novel extensions to deep learning architectures that operate solely over the text of the query and candidate document/snippets. Our systems scored at the top or near the top for all batches of the challenge, highlighting the effectiveness of deep learning for these tasks.

</details>

<details>

<summary>2018-09-16 06:02:37 - Cross-Domain Labeled LDA for Cross-Domain Text Classification</summary>

- *Baoyu Jing, Chenwei Lu, Deqing Wang, Fuzhen Zhuang, Cheng Niu*

- `1809.05820v1` - [abs](http://arxiv.org/abs/1809.05820v1) - [pdf](http://arxiv.org/pdf/1809.05820v1)

> Cross-domain text classification aims at building a classifier for a target domain which leverages data from both source and target domain. One promising idea is to minimize the feature distribution differences of the two domains. Most existing studies explicitly minimize such differences by an exact alignment mechanism (aligning features by one-to-one feature alignment, projection matrix etc.). Such exact alignment, however, will restrict models' learning ability and will further impair models' performance on classification tasks when the semantic distributions of different domains are very different. To address this problem, we propose a novel group alignment which aligns the semantics at group level. In addition, to help the model learn better semantic groups and semantics within these groups, we also propose a partial supervision for model's learning in source domain. To this end, we embed the group alignment and a partial supervision into a cross-domain topic model, and propose a Cross-Domain Labeled LDA (CDL-LDA). On the standard 20Newsgroup and Reuters dataset, extensive quantitative (classification, perplexity etc.) and qualitative (topic detection) experiments are conducted to show the effectiveness of the proposed group alignment and partial supervision.

</details>

<details>

<summary>2018-09-16 14:48:45 - Semantic Interoperability Middleware Architecture for Heterogeneous Environmental Data Sources</summary>

- *A. K. Akanbi, M. Masinde*

- `1809.05890v1` - [abs](http://arxiv.org/abs/1809.05890v1) - [pdf](http://arxiv.org/pdf/1809.05890v1)

> Data heterogeneity hampers the effort to integrate and infer knowledge from vast heterogeneous data sources. An application case study is described, in which the objective was to semantically represent and integrate structured data from sensor devices with unstructured data in the form of local indigenous knowledge. However, the semantic representation of these heterogeneous data sources for environmental monitoring systems is not well supported yet. To combat the incompatibility issues, a dedicated semantic middleware solution is required. In this paper, we describe and evaluate a cross-domain middleware architecture that semantically integrates and generate inference from heterogeneous data sources. These use of semantic technology for predicting and forecasting complex environmental phenomenon will increase the degree of accuracy of environmental monitoring systems.

</details>

<details>

<summary>2018-09-17 15:47:06 - Style Transfer Through Multilingual and Feedback-Based Back-Translation</summary>

- *Shrimai Prabhumoye, Yulia Tsvetkov, Alan W Black, Ruslan Salakhutdinov*

- `1809.06284v1` - [abs](http://arxiv.org/abs/1809.06284v1) - [pdf](http://arxiv.org/pdf/1809.06284v1)

> Style transfer is the task of transferring an attribute of a sentence (e.g., formality) while maintaining its semantic content. The key challenge in style transfer is to strike a balance between the competing goals, one to preserve meaning and the other to improve the style transfer accuracy. Prior research has identified that the task of meaning preservation is generally harder to attain and evaluate. This paper proposes two extensions of the state-of-the-art style transfer models aiming at improving the meaning preservation in style transfer. Our evaluation shows that these extensions help to ground meaning better while improving the transfer accuracy.

</details>

<details>

<summary>2018-09-17 16:27:13 - Guess who? Multilingual approach for the automated generation of author-stylized poetry</summary>

- *Alexey Tikhonov, Ivan P. Yamshchikov*

- `1807.07147v3` - [abs](http://arxiv.org/abs/1807.07147v3) - [pdf](http://arxiv.org/pdf/1807.07147v3)

> This paper addresses the problem of stylized text generation in a multilingual setup. A version of a language model based on a long short-term memory (LSTM) artificial neural network with extended phonetic and semantic embeddings is used for stylized poetry generation. The quality of the resulting poems generated by the network is estimated through bilingual evaluation understudy (BLEU), a survey and a new cross-entropy based metric that is suggested for the problems of such type. The experiments show that the proposed model consistently outperforms random sample and vanilla-LSTM baselines, humans also tend to associate machine generated texts with the target author.

</details>

<details>

<summary>2018-09-17 23:11:50 - Towards Deep and Representation Learning for Talent Search at LinkedIn</summary>

- *Rohan Ramanath, Hakan Inan, Gungor Polatkan, Bo Hu, Qi Guo, Cagri Ozcaglar, Xianren Wu, Krishnaram Kenthapadi, Sahin Cem Geyik*

- `1809.06473v1` - [abs](http://arxiv.org/abs/1809.06473v1) - [pdf](http://arxiv.org/pdf/1809.06473v1)

> Talent search and recommendation systems at LinkedIn strive to match the potential candidates to the hiring needs of a recruiter or a hiring manager expressed in terms of a search query or a job posting. Recent work in this domain has mainly focused on linear models, which do not take complex relationships between features into account, as well as ensemble tree models, which introduce non-linearity but are still insufficient for exploring all the potential feature interactions, and strictly separate feature generation from modeling. In this paper, we present the results of our application of deep and representation learning models on LinkedIn Recruiter. Our key contributions include: (i) Learning semantic representations of sparse entities within the talent search domain, such as recruiter ids, candidate ids, and skill entity ids, for which we utilize neural network models that take advantage of LinkedIn Economic Graph, and (ii) Deep models for learning recruiter engagement and candidate response in talent search applications. We also explore learning to rank approaches applied to deep models, and show the benefits for the talent search use case. Finally, we present offline and online evaluation results for LinkedIn talent search and recommendation systems, and discuss potential challenges along the path to a fully deep model architecture. The challenges and approaches discussed generalize to any multi-faceted search engine.

</details>

<details>

<summary>2018-09-18 05:26:40 - Automatic Judgment Prediction via Legal Reading Comprehension</summary>

- *Shangbang Long, Cunchao Tu, Zhiyuan Liu, Maosong Sun*

- `1809.06537v1` - [abs](http://arxiv.org/abs/1809.06537v1) - [pdf](http://arxiv.org/pdf/1809.06537v1)

> Automatic judgment prediction aims to predict the judicial results based on case materials. It has been studied for several decades mainly by lawyers and judges, considered as a novel and prospective application of artificial intelligence techniques in the legal field. Most existing methods follow the text classification framework, which fails to model the complex interactions among complementary case materials. To address this issue, we formalize the task as Legal Reading Comprehension according to the legal scenario. Following the working protocol of human judges, LRC predicts the final judgment results based on three types of information, including fact description, plaintiffs' pleas, and law articles. Moreover, we propose a novel LRC model, AutoJudge, which captures the complex semantic interactions among facts, pleas, and laws. In experiments, we construct a real-world civil case dataset for LRC. Experimental results on this dataset demonstrate that our model achieves significant improvement over state-of-the-art models. We will publish all source codes and datasets of this work on \urlgithub.com for further research.

</details>

<details>

<summary>2018-09-18 07:08:59 - User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks</summary>

- *Yilin Shen, Xiangyu Zeng, Yu Wang, Hongxia Jin*

- `1809.06559v1` - [abs](http://arxiv.org/abs/1809.06559v1) - [pdf](http://arxiv.org/pdf/1809.06559v1)

> Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.

</details>

<details>

<summary>2018-09-18 10:55:03 - Lung Cancer Concept Annotation from Spanish Clinical Narratives</summary>

- *Marjan Najafabadipour, Juan Manuel Tuñas, Alejandro Rodríguez-González, Ernestina Menasalvas*

- `1809.06639v1` - [abs](http://arxiv.org/abs/1809.06639v1) - [pdf](http://arxiv.org/pdf/1809.06639v1)

> Recent rapid increase in the generation of clinical data and rapid development of computational science make us able to extract new insights from massive datasets in healthcare industry. Oncological clinical notes are creating rich databases for documenting patients history and they potentially contain lots of patterns that could help in better management of the disease. However, these patterns are locked within free text (unstructured) portions of clinical documents and consequence in limiting health professionals to extract useful information from them and to finally perform Query and Answering (QA) process in an accurate way. The Information Extraction (IE) process requires Natural Language Processing (NLP) techniques to assign semantics to these patterns. Therefore, in this paper, we analyze the design of annotators for specific lung cancer concepts that can be integrated over Apache Unstructured Information Management Architecture (UIMA) framework. In addition, we explain the details of generation and storage of annotation outcomes.

</details>

<details>

<summary>2018-09-18 12:36:31 - Semantic Human Matting</summary>

- *Quan Chen, Tiezheng Ge, Yanyu Xu, Zhiqiang Zhang, Xinxin Yang, Kun Gai*

- `1809.01354v2` - [abs](http://arxiv.org/abs/1809.01354v2) - [pdf](http://arxiv.org/pdf/1809.01354v2)

> Human matting, high quality extraction of humans from natural images, is crucial for a wide variety of applications. Since the matting problem is severely under-constrained, most previous methods require user interactions to take user designated trimaps or scribbles as constraints. This user-in-the-loop nature makes them difficult to be applied to large scale data or time-sensitive scenarios. In this paper, instead of using explicit user input constraints, we employ implicit semantic constraints learned from data and propose an automatic human matting algorithm (SHM). SHM is the first algorithm that learns to jointly fit both semantic information and high quality details with deep networks. In practice, simultaneously learning both coarse semantics and fine details is challenging. We propose a novel fusion strategy which naturally gives a probabilistic estimation of the alpha matte. We also construct a very large dataset with high quality annotations consisting of 35,513 unique foregrounds to facilitate the learning and evaluation of human matting. Extensive experiments on this dataset and plenty of real images show that SHM achieves comparable results with state-of-the-art interactive matting methods.

</details>

<details>

<summary>2018-09-18 14:01:22 - Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation</summary>

- *Murhaf Fares, Stephan Oepen, Erik Velldal*

- `1809.06748v1` - [abs](http://arxiv.org/abs/1809.06748v1) - [pdf](http://arxiv.org/pdf/1809.06748v1)

> In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of noun--noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.

</details>

<details>

<summary>2018-09-19 08:13:05 - Multi-Scale Fully Convolutional Network for Cardiac Left Ventricle Segmentation</summary>

- *Han Kang, Defeng Chen*

- `1809.10203v1` - [abs](http://arxiv.org/abs/1809.10203v1) - [pdf](http://arxiv.org/pdf/1809.10203v1)

> The morphological structure of left ventricle segmented from cardiac magnetic resonance images can be used to calculate key clinical parameters, and it is of great significance to the accurate and efficient diagnosis of cardiovascular diseases. Compared with traditional methods, the segmentation algorithms based on fully convolutional neural network greatly improve the accuracy of semantic segmentation. For the problem of left ventricular segmentation, a new fully convolutional neural network structure named MS-FCN is proposed in this paper. The MS-FCN network employs a multi-scale pooling module to ensure that the network maximises the feature extraction ability and uses a dense connectivity decoder to refine the boundaries of the object. Based on the Sunnybrook cine-MR dataset provided by the MICCAI 2009 challenge, numerical experiments demonstrate that our proposed model has obtained state-of-the-art segmentation results: the Dice score of our method reaches 0.93 on the endocardium, and 0.96 on the epicardium.

</details>

<details>

<summary>2018-09-19 15:50:18 - MTLE: A Multitask Learning Encoder of Visual Feature Representations for Video and Movie Description</summary>

- *Oliver Nina, Washington Garcia, Scott Clouse, Alper Yilmaz*

- `1809.07257v1` - [abs](http://arxiv.org/abs/1809.07257v1) - [pdf](http://arxiv.org/pdf/1809.07257v1)

> Learning visual feature representations for video analysis is a daunting task that requires a large amount of training samples and a proper generalization framework. Many of the current state of the art methods for video captioning and movie description rely on simple encoding mechanisms through recurrent neural networks to encode temporal visual information extracted from video data. In this paper, we introduce a novel multitask encoder-decoder framework for automatic semantic description and captioning of video sequences. In contrast to current approaches, our method relies on distinct decoders that train a visual encoder in a multitask fashion. Our system does not depend solely on multiple labels and allows for a lack of training data working even with datasets where only one single annotation is viable per video. Our method shows improved performance over current state of the art methods in several metrics on multi-caption and single-caption datasets. To the best of our knowledge, our method is the first method to use a multitask approach for encoding video features. Our method demonstrates its robustness on the Large Scale Movie Description Challenge (LSMDC) 2017 where our method won the movie description task and its results were ranked among other competitors as the most helpful for the visually impaired.

</details>

<details>

<summary>2018-09-19 21:21:01 - Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders</summary>

- *Tengfei Ma, Jie Chen, Cao Xiao*

- `1809.02630v2` - [abs](http://arxiv.org/abs/1809.02630v2) - [pdf](http://arxiv.org/pdf/1809.02630v2)

> Deep generative models have achieved remarkable success in various data domains, including images, time series, and natural languages. There remain, however, substantial challenges for combinatorial structures, including graphs. One of the key challenges lies in the difficulty of ensuring semantic validity in context. For examples, in molecular graphs, the number of bonding-electron pairs must not exceed the valence of an atom; whereas in protein interaction networks, two proteins may be connected only when they belong to the same or correlated gene ontology terms. These constraints are not easy to be incorporated into a generative model. In this work, we propose a regularization framework for variational autoencoders as a step toward semantic validity. We focus on the matrix representation of graphs and formulate penalty terms that regularize the output distribution of the decoder to encourage the satisfaction of validity constraints. Experimental results confirm a much higher likelihood of sampling valid graphs in our approach, compared with others reported in the literature.

</details>

<details>

<summary>2018-09-19 22:03:32 - Machine Translation Evaluation Resources and Methods: A Survey</summary>

- *Lifeng Han*

- `1605.04515v8` - [abs](http://arxiv.org/abs/1605.04515v8) - [pdf](http://arxiv.org/pdf/1605.04515v8)

> We introduce the Machine Translation (MT) evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. The advanced human assessments include task-oriented measures, post-editing, segment ranking, and extended criteriea, etc. We classify the automatic evaluation methods into two categories, including lexical similarity scenario and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, F-measure, and word order. The linguistic features can be divided into syntactic features and semantic features respectively. The syntactic features include part of speech tag, phrase types and sentence structures, and the semantic features include named entity, synonyms, textual entailment, paraphrase, semantic roles, and language models. The deep learning models for evaluation are very newly proposed. Subsequently, we also introduce the evaluation methods for MT evaluation including different correlation scores, and the recent quality estimation (QE) tasks for MT.   This paper differs from the existing works \cite{GALEprogram2009,EuroMatrixProject2007} from several aspects, by introducing some recent development of MT evaluation measures, the different classifications from manual to automatic evaluation measures, the introduction of recent QE tasks of MT, and the concise construction of the content.   We hope this work will be helpful for MT researchers to easily pick up some metrics that are best suitable for their specific MT model development, and help MT evaluation researchers to get a general clue of how MT evaluation research developed. Furthermore, hopefully, this work can also shine some light on other evaluation tasks, except for translation, of NLP fields.

</details>

<details>

<summary>2018-09-20 07:12:42 - Precise but Natural Specification for Robot Tasks</summary>

- *Ivan Gavran, Brendon Boldt, Eva Darulova, Rupak Majumdar*

- `1803.02238v2` - [abs](http://arxiv.org/abs/1803.02238v2) - [pdf](http://arxiv.org/pdf/1803.02238v2)

> We present Flipper, a natural language interface for describing high-level task specifications for robots that are compiled into robot actions. Flipper starts with a formal core language for task planning that allows expressing rich temporal specifications and uses a semantic parser to provide a natural language interface. Flipper provides immediate visual feedback by executing an automatically constructed plan of the task in a graphical user interface. This allows the user to resolve potentially ambiguous interpretations. Flipper extends itself via naturalization: its users can add definitions for utterances, from which Flipper induces new rules and adds them to the core language, gradually growing a more and more natural task specification language. Flipper improves the naturalization by generalizing the definition provided by users. Unlike other task-specification systems, Flipper enables natural language interactions while maintaining the expressive power and formal precision of a programming language. We show through an initial user study that natural language interactions and generalization can considerably ease the description of tasks. Moreover, over time, users employ more and more concepts outside of the initial core language. Such extensions are available to the Flipper community, and users can use concepts that others have defined.

</details>

<details>

<summary>2018-09-20 07:15:02 - Counting the uncountable: deep semantic density estimation from Space</summary>

- *Andres C. Rodriguez, Jan D. Wegner*

- `1809.07091v2` - [abs](http://arxiv.org/abs/1809.07091v2) - [pdf](http://arxiv.org/pdf/1809.07091v2)

> We propose a new method to count objects of specific categories that are significantly smaller than the ground sampling distance of a satellite image. This task is hard due to the cluttered nature of scenes where different object categories occur. Target objects can be partially occluded, vary in appearance within the same class and look alike to different categories. Since traditional object detection is infeasible due to the small size of objects with respect to the pixel size, we cast object counting as a density estimation problem. To distinguish objects of different classes, our approach combines density estimation with semantic segmentation in an end-to-end learnable convolutional neural network (CNN). Experiments show that deep semantic density estimation can robustly count objects of various classes in cluttered scenes. Experiments also suggest that we need specific CNN architectures in remote sensing instead of blindly applying existing ones from computer vision.

</details>

<details>

<summary>2018-09-20 13:39:10 - Lessons learned in multilingual grounded language learning</summary>

- *Ákos Kádár, Desmond Elliott, Marc-Alexandre Côté, Grzegorz Chrupała, Afra Alishahi*

- `1809.07615v1` - [abs](http://arxiv.org/abs/1809.07615v1) - [pdf](http://arxiv.org/pdf/1809.07615v1)

> Recent work has shown how to learn better visual-semantic embeddings by leveraging image descriptions in more than one language. Here, we investigate in detail which conditions affect the performance of this type of grounded language learning model. We show that multilingual training improves over bilingual training, and that low-resource languages benefit from training with higher-resource languages. We demonstrate that a multilingual model can be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language enables further improvements via an additional caption-caption ranking objective.

</details>

<details>

<summary>2018-09-20 16:21:29 - Symbolic Priors for RNN-based Semantic Parsing</summary>

- *Chunyang Xiao, Marc Dymetman, Claire Gardent*

- `1809.07721v1` - [abs](http://arxiv.org/abs/1809.07721v1) - [pdf](http://arxiv.org/pdf/1809.07721v1)

> Seq2seq models based on Recurrent Neural Networks (RNNs) have recently received a lot of attention in the domain of Semantic Parsing for Question Answering. While in principle they can be trained directly on pairs (natural language utterances, logical forms), their performance is limited by the amount of available data. To alleviate this problem, we propose to exploit various sources of prior knowledge: the well-formedness of the logical forms is modeled by a weighted context-free grammar; the likelihood that certain entities present in the input utterance are also present in the logical form is modeled by weighted finite-state automata. The grammar and automata are combined together through an efficient intersection algorithm to form a soft guide ("background") to the RNN. We test our method on an extension of the Overnight dataset and show that it not only strongly improves over an RNN baseline, but also outperforms non-RNN models based on rich sets of hand-crafted features.

</details>

<details>

<summary>2018-09-21 02:29:30 - Unsupervised Abstractive Sentence Summarization using Length Controlled Variational Autoencoder</summary>

- *Raphael Schumann*

- `1809.05233v2` - [abs](http://arxiv.org/abs/1809.05233v2) - [pdf](http://arxiv.org/pdf/1809.05233v2)

> In this work we present an unsupervised approach to summarize sentences in abstractive way using Variational Autoencoder (VAE). VAE are known to learn a semantically rich latent variable, representing high dimensional input. VAEs are trained by learning to reconstruct the input from the probabilistic latent variable. Explicitly providing the information about output length during training influences the VAE to not encode this information and thus can be manipulated during inference. Instructing the decoder to produce a shorter output sequence leads to expressing the input sentence with fewer words. We show on different summarization data sets, that these shorter sentences can not beat a simple baseline but yield higher ROUGE scores than trying to reconstruct the whole sentence.

</details>

<details>

<summary>2018-09-21 02:59:20 - S3BD: Secure Semantic Search over Encrypted Big Data in the Cloud</summary>

- *Jason Woodworth, Mohsen Amini Salehi*

- `1809.07927v1` - [abs](http://arxiv.org/abs/1809.07927v1) - [pdf](http://arxiv.org/pdf/1809.07927v1)

> Cloud storage is a widely utilized service for both personal and enterprise demands. However, despite its advantages, many potential users with enormous amounts of sensitive data (big data) refrain from fully utilizing the cloud storage service due to valid concerns about data privacy. An established solution to the cloud data privacy problem is to perform encryption on the client-end. This approach, however, restricts data processing capabilities (eg, searching over the data). Accordingly, the research problem we investigate is how to enable real-time searching over the encrypted big data in the cloud. In particular, semantic search is of interest to clients dealing with big data. To address this problem, in this research, we develop a system (termed S3BD) for searching big data using cloud services without exposing any data to cloud providers. To keep real-time response on big data, S3BD proactively prunes the search space to a subset of the whole dataset. For that purpose, we propose a method to cluster the encrypted data. An abstract of each cluster is maintained on the client-end to navigate the search operation to appropriate clusters at the search time. Results of experiments, carried out on real-world big datasets, demonstrate that the search operation can be achieved in real-time and is significantly more efficient than other counterparts. In addition, a fully functional prototype of S3BD is made publicly available.

</details>

<details>

<summary>2018-09-21 09:31:39 - Using JSON-LD to Compose Different IoT and Cloud Services</summary>

- *Darko Andročec*

- `1809.08233v1` - [abs](http://arxiv.org/abs/1809.08233v1) - [pdf](http://arxiv.org/pdf/1809.08233v1)

> Internet of things and cloud computing are in the widespread use today, and often work together to accomplish complex business task and use cases. This paper propose the framework and its practical implementation to compose different things as services and cloud services. The ontology based approach and JSON-LD was used to semantically annotate both types of services, and enable the mechanism to semi-automatically compose these services. The use case and proof-of-concept application that use the proposed theoretical approach is also described in this work.

</details>

<details>

<summary>2018-09-21 09:31:45 - Exemplar-based synthesis of geology using kernel discrepancies and generative neural networks</summary>

- *Shing Chan, Ahmed H. Elsheikh*

- `1809.07748v2` - [abs](http://arxiv.org/abs/1809.07748v2) - [pdf](http://arxiv.org/pdf/1809.07748v2)

> We propose a framework for synthesis of geological images based on an exemplar image. We synthesize new realizations such that the discrepancy in the patch distribution between the realizations and the exemplar image is minimized. Such discrepancy is quantified using a kernel method for two-sample test called maximum mean discrepancy. To enable fast synthesis, we train a generative neural network in an offline phase to sample realizations efficiently during deployment, while also providing a parametrization of the synthesis process. We assess the framework on a classical binary image representing channelized subsurface reservoirs, finding that the method reproduces the visual patterns and spatial statistics (image histogram and two-point probability functions) of the exemplar image.

</details>

<details>

<summary>2018-09-21 09:59:16 - Towards a Mini-App for Smoothed Particle Hydrodynamics at Exascale</summary>

- *Danilo Guerrera, Rubén M. Cabezón, Jean-Guillaume Piccinali, Aurélien Cavelan, Florina M. Ciorba, David Imbert, Lucio Mayer, Darren Reed*

- `1809.08013v1` - [abs](http://arxiv.org/abs/1809.08013v1) - [pdf](http://arxiv.org/pdf/1809.08013v1)

> The smoothed particle hydrodynamics (SPH) technique is a purely Lagrangian method, used in numerical simulations of fluids in astrophysics and computational fluid dynamics, among many other fields. SPH simulations with detailed physics represent computationally-demanding calculations. The parallelization of SPH codes is not trivial due to the absence of a structured grid. Additionally, the performance of the SPH codes can be, in general, adversely impacted by several factors, such as multiple time-stepping, long-range interactions, and/or boundary conditions. This work presents insights into the current performance and functionalities of three SPH codes: SPHYNX, ChaNGa, and SPH-flow. These codes are the starting point of an interdisciplinary co-design project, SPH-EXA, for the development of an Exascale-ready SPH mini-app. To gain such insights, a rotating square patch test was implemented as a common test simulation for the three SPH codes and analyzed on two modern HPC systems. Furthermore, to stress the differences with the codes stemming from the astrophysics community (SPHYNX and ChaNGa), an additional test case, the Evrard collapse, has also been carried out. This work extrapolates the common basic SPH features in the three codes for the purpose of consolidating them into a pure-SPH, Exascale-ready, optimized, mini-app. Moreover, the outcome of this serves as direct feedback to the parent codes, to improve their performance and overall scalability.

</details>

<details>

<summary>2018-09-21 18:52:49 - (k,p)-Planarity: A Relaxation of Hybrid Planarity</summary>

- *Emilio Di Giacomo, William J. Lenhart, Giuseppe Liotta, Timothy W. Randolph, Alessandra Tappini*

- `1806.11413v2` - [abs](http://arxiv.org/abs/1806.11413v2) - [pdf](http://arxiv.org/pdf/1806.11413v2)

> We present a new model for hybrid planarity that relaxes existing hybrid representations. A graph $G = (V,E)$ is $(k,p)$-planar if $V$ can be partitioned into clusters of size at most $k$ such that $G$ admits a drawing where: (i) each cluster is associated with a closed, bounded planar region, called a cluster region; (ii) cluster regions are pairwise disjoint, (iii) each vertex $v \in V$ is identified with at most $p$ distinct points, called \emph{ports}, on the boundary of its cluster region; (iv) each inter-cluster edge $(u,v) \in E$ is identified with a Jordan arc connecting a port of $u$ to a port of $v$; (v) inter-cluster edges do not cross or intersect cluster regions except at their endpoints. We first tightly bound the number of edges in a $(k,p)$-planar graph with $p<k$. We then prove that $(4,1)$-planarity testing and $(2,2)$-planarity testing are NP-complete problems. Finally, we prove that neither the class of $(2,2)$-planar graphs nor the class of $1$-planar graphs contains the other, indicating that the $(k,p)$-planar graphs are a large and novel class.

</details>

<details>

<summary>2018-09-22 06:35:07 - Constructing Financial Sentimental Factors in Chinese Market Using Natural Language Processing</summary>

- *Junfeng Jiang, Jiahao Li*

- `1809.08390v1` - [abs](http://arxiv.org/abs/1809.08390v1) - [pdf](http://arxiv.org/pdf/1809.08390v1)

> In this paper, we design an integrated algorithm to evaluate the sentiment of Chinese market. Firstly, with the help of the web browser automation, we crawl a lot of news and comments from several influential financial websites automatically. Secondly, we use techniques of Natural Language Processing(NLP) under Chinese context, including tokenization, Word2vec word embedding and semantic database WordNet, to compute Senti-scores of these news and comments, and then construct the sentimental factor. Here, we build a finance-specific sentimental lexicon so that the sentimental factor can reflect the sentiment of financial market but not the general sentiments as happiness, sadness, etc. Thirdly, we also implement an adjustment of the standard sentimental factor. Our experimental performance shows that there is a significant correlation between our standard sentimental factor and the Chinese market, and the adjusted factor is even more informative, having a stronger correlation with the Chinese market. Therefore, our sentimental factors can be important references when making investment decisions. Especially during the Chinese market crash in 2015, the Pearson correlation coefficient of adjusted sentimental factor with SSE is 0.5844, which suggests that our model can provide a solid guidance, especially in the special period when the market is influenced greatly by public sentiment.

</details>

<details>

<summary>2018-09-22 09:07:52 - Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing</summary>

- *Jonathan Herzig, Jonathan Berant*

- `1804.07918v2` - [abs](http://arxiv.org/abs/1804.07918v2) - [pdf](http://arxiv.org/pdf/1804.07918v2)

> Building a semantic parser quickly in a new domain is a fundamental challenge for conversational interfaces, as current semantic parsers require expensive supervision and lack the ability to generalize to new domains. In this paper, we introduce a zero-shot approach to semantic parsing that can parse utterances in unseen domains while only being trained on examples in other source domains. First, we map an utterance to an abstract, domain-independent, logical form that represents the structure of the logical form, but contains slots instead of KB constants. Then, we replace slots with KB constants via lexical alignment scores and global inference. Our model reaches an average accuracy of 53.4% on 7 domains in the Overnight dataset, substantially better than other zero-shot baselines, and performs as good as a parser trained on over 30% of the target domain examples.

</details>

<details>

<summary>2018-09-22 10:07:46 - Medical Knowledge Embedding Based on Recursive Neural Network for Multi-Disease Diagnosis</summary>

- *Jingchi Jiang, Huanzheng Wang, Jing Xie, Xitong Guo, Yi Guan, Qiubin Yu*

- `1809.08422v1` - [abs](http://arxiv.org/abs/1809.08422v1) - [pdf](http://arxiv.org/pdf/1809.08422v1)

> The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding (i.e., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge but also establish the quantifiable relationship among them. In this paper, we propose recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with recursive neural network for multi-disease diagnosis. After RNKN is efficiently trained from manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. Experimental results verify that the diagnostic accuracy of RNKN is superior to that of some classical machine learning models and Markov logic network (MLN). The results also demonstrate that the more explicit the evidence extracted from CEMRs is, the better is the performance achieved. RNKN gradually exhibits the interpretation of knowledge embeddings as the number of training epochs increases.

</details>

<details>

<summary>2018-09-23 18:19:46 - Mind Your Language: Abuse and Offense Detection for Code-Switched Languages</summary>

- *Raghav Kapoor, Yaman Kumar, Kshitij Rajput, Rajiv Ratn Shah, Ponnurangam Kumaraguru, Roger Zimmermann*

- `1809.08652v1` - [abs](http://arxiv.org/abs/1809.08652v1) - [pdf](http://arxiv.org/pdf/1809.08652v1)

> In multilingual societies like the Indian subcontinent, use of code-switched languages is much popular and convenient for the users. In this paper, we study offense and abuse detection in the code-switched pair of Hindi and English (i.e. Hinglish), the pair that is the most spoken. The task is made difficult due to non-fixed grammar, vocabulary, semantics and spellings of Hinglish language. We apply transfer learning and make a LSTM based model for hate speech classification. This model surpasses the performance shown by the current best models to establish itself as the state-of-the-art in the unexplored domain of Hinglish offensive text classification.We also release our model and the embeddings trained for research purposes

</details>

<details>

<summary>2018-09-24 07:31:08 - KDSL: a Knowledge-Driven Supervised Learning Framework for Word Sense Disambiguation</summary>

- *Shi Yin, Yi Zhou, Chenguang Li, Shangfei Wang, Jianmin Ji, Xiaoping Chen, Ruili Wang*

- `1808.09888v4` - [abs](http://arxiv.org/abs/1808.09888v4) - [pdf](http://arxiv.org/pdf/1808.09888v4)

> We propose KDSL, a new word sense disambiguation (WSD) framework that utilizes knowledge to automatically generate sense-labeled data for supervised learning. First, from WordNet, we automatically construct a semantic knowledge base called DisDict, which provides refined feature words that highlight the differences among word senses, i.e., synsets. Second, we automatically generate new sense-labeled data by DisDict from unlabeled corpora. Third, these generated data, together with manually labeled data and unlabeled data, are fed to a neural framework conducting supervised and unsupervised learning jointly to model the semantic relations among synsets, feature words and their contexts. The experimental results show that KDSL outperforms several representative state-of-the-art methods on various major benchmarks. Interestingly, it performs relatively well even when manually labeled data is unavailable, thus provides a potential solution for similar tasks in a lack of manual annotations.

</details>

<details>

<summary>2018-09-24 09:06:37 - Object segmentation in depth maps with one user click and a synthetically trained fully convolutional network</summary>

- *Matthieu Grard, Romain Brégier, Florian Sella, Emmanuel Dellandréa, Liming Chen*

- `1801.01281v2` - [abs](http://arxiv.org/abs/1801.01281v2) - [pdf](http://arxiv.org/pdf/1801.01281v2)

> With more and more household objects built on planned obsolescence and consumed by a fast-growing population, hazardous waste recycling has become a critical challenge. Given the large variability of household waste, current recycling platforms mostly rely on human operators to analyze the scene, typically composed of many object instances piled up in bulk. Helping them by robotizing the unitary extraction is a key challenge to speed up this tedious process. Whereas supervised deep learning has proven very efficient for such object-level scene understanding, e.g., generic object detection and segmentation in everyday scenes, it however requires large sets of per-pixel labeled images, that are hardly available for numerous application contexts, including industrial robotics. We thus propose a step towards a practical interactive application for generating an object-oriented robotic grasp, requiring as inputs only one depth map of the scene and one user click on the next object to extract. More precisely, we address in this paper the middle issue of object seg-mentation in top views of piles of bulk objects given a pixel location, namely seed, provided interactively by a human operator. We propose a twofold framework for generating edge-driven instance segments. First, we repurpose a state-of-the-art fully convolutional object contour detector for seed-based instance segmentation by introducing the notion of edge-mask duality with a novel patch-free and contour-oriented loss function. Second, we train one model using only synthetic scenes, instead of manually labeled training data. Our experimental results show that considering edge-mask duality for training an encoder-decoder network, as we suggest, outperforms a state-of-the-art patch-based network in the present application context.

</details>

<details>

<summary>2018-09-24 09:55:37 - Representing Sets as Summed Semantic Vectors</summary>

- *Douglas Summers-Stay, Peter Sutor, Dandan Li*

- `1809.08823v1` - [abs](http://arxiv.org/abs/1809.08823v1) - [pdf](http://arxiv.org/pdf/1809.08823v1)

> Representing meaning in the form of high dimensional vectors is a common and powerful tool in biologically inspired architectures. While the meaning of a set of concepts can be summarized by taking a (possibly weighted) sum of their associated vectors, this has generally been treated as a one-way operation. In this paper we show how a technique built to aid sparse vector decomposition allows in many cases the exact recovery of the inputs and weights to such a sum, allowing a single vector to represent an entire set of vectors from a dictionary. We characterize the number of vectors that can be recovered under various conditions, and explore several ways such a tool can be used for vector-based reasoning.

</details>

<details>

<summary>2018-09-24 10:54:52 - Text Similarity in Vector Space Models: A Comparative Study</summary>

- *Omid Shahmirzadi, Adam Lugowski, Kenneth Younge*

- `1810.00664v1` - [abs](http://arxiv.org/abs/1810.00664v1) - [pdf](http://arxiv.org/pdf/1810.00664v1)

> Automatic measurement of semantic text similarity is an important task in natural language processing. In this paper, we evaluate the performance of different vector space models to perform this task. We address the real-world problem of modeling patent-to-patent similarity and compare TFIDF (and related extensions), topic models (e.g., latent semantic indexing), and neural models (e.g., paragraph vectors). Contrary to expectations, the added computational cost of text embedding methods is justified only when: 1) the target text is condensed; and 2) the similarity comparison is trivial. Otherwise, TFIDF performs surprisingly well in other cases: in particular for longer and more technical texts or for making finer-grained distinctions between nearest neighbors. Unexpectedly, extensions to the TFIDF method, such as adding noun phrases or calculating term weights incrementally, were not helpful in our context.

</details>

<details>

<summary>2018-09-24 13:42:13 - A Preliminary Report on Probabilistic Attack Normal Form for Constellation Semantics</summary>

- *Theofrastos Mantadelis, Stefano Bistarelli*

- `1810.00771v1` - [abs](http://arxiv.org/abs/1810.00771v1) - [pdf](http://arxiv.org/pdf/1810.00771v1)

> After Dung's founding work in Abstract Argumentation Frameworks there has been a growing interest in extending the Dung's semantics in order to describe more complex or real life situations. Several of these approaches take the direction of weighted or probabilistic extensions. One of the most prominent probabilistic approaches is that of constellation Probabilistic Abstract Argumentation Frameworks from Li~et~al. In this paper, we present a normal form for constellation probabilistic abstract argumentation frameworks. Furthermore, we present a transformation from general constellation probabilistic abstract argumentation frameworks to the presented normal form. In this way we illustrate that the simpler normal form has equal representation power with the general one.

</details>

<details>

<summary>2018-09-24 16:30:20 - SPX: Preserving End-to-End Security for Edge Computing</summary>

- *Ketan Bhardwaj, Ming-Wei Shih, Ada Gavrilovska, Taesoo Kim, Chengyu Song*

- `1809.09038v1` - [abs](http://arxiv.org/abs/1809.09038v1) - [pdf](http://arxiv.org/pdf/1809.09038v1)

> Beyond point solutions, the vision of edge computing is to enable web services to deploy their edge functions in a multi-tenant infrastructure present at the edge of mobile networks. However, edge functions can be rendered useless because of one critical issue: Web services are delivered over end-to-end encrypted connections, so edge functions cannot operate on encrypted traffic without compromising security or degrading performance. Any solution to this problem must interoperate with existing protocols like TLS, as well as with new emerging security protocols for client and IoT devices. The edge functions must remain invisible to client-side endpoints but may require explicit control from their service-side web services. Finally, a solution must operate within overhead margins which do not obviate the benefits of the edge.   To address this problem, this paper presents SPX - a solution for edge-ready and end-to-end secure protocol extensions, which can efficiently maintain end-to-edge-to-end ($E^3$) security semantics. Using our SPX prototype, we allow edge functions to operate on encrypted traffic, while ensuring that security semantics of secure protocols still hold. SPX uses Intel SGX to bind the communication channel with remote attestation and to provide a solution that not only defends against potential attacks but also results in low performance overheads, and neither mandates any changes on the end-user side nor breaks interoperability with existing protocols.

</details>

<details>

<summary>2018-09-24 19:46:24 - From Audio to Semantics: Approaches to end-to-end spoken language understanding</summary>

- *Parisa Haghani, Arun Narayanan, Michiel Bacchiani, Galen Chuang, Neeraj Gaur, Pedro Moreno, Rohit Prabhavalkar, Zhongdi Qu, Austin Waters*

- `1809.09190v1` - [abs](http://arxiv.org/abs/1809.09190v1) - [pdf](http://arxiv.org/pdf/1809.09190v1)

> Conventional spoken language understanding systems consist of two main components: an automatic speech recognition module that converts audio to a transcript, and a natural language understanding module that transforms the resulting text (or top N hypotheses) into a set of domains, intents, and arguments. These modules are typically optimized independently. In this paper, we formulate audio to semantic understanding as a sequence-to-sequence problem [1]. We propose and compare various encoder-decoder based approaches that optimize both modules jointly, in an end-to-end manner. Evaluations on a real-world task show that 1) having an intermediate text representation is crucial for the quality of the predicted semantics, especially the intent arguments and 2) jointly optimizing the full system improves overall accuracy of prediction. Compared to independently trained models, our best jointly trained model achieves similar domain and intent prediction F1 scores, but improves argument word error rate by 18% relative.

</details>

<details>

<summary>2018-09-24 20:08:42 - Automatic Rule Learning for Autonomous Driving Using Semantic Memory</summary>

- *Dmitriy Korchev, Aruna Jammalamadaka, Rajan Bhattacharyya*

- `1809.07904v2` - [abs](http://arxiv.org/abs/1809.07904v2) - [pdf](http://arxiv.org/pdf/1809.07904v2)

> This paper presents a novel approach for automatic rule learning applicable to an autonomous driving system using real driving data.

</details>

<details>

<summary>2018-09-24 20:29:35 - Generating Natural Language Adversarial Examples</summary>

- *Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, Kai-Wei Chang*

- `1804.07998v2` - [abs](http://arxiv.org/abs/1804.07998v2) - [pdf](http://arxiv.org/pdf/1804.07998v2)

> Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations are often virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97% and 70%, respectively. We additionally demonstrate that 92.3% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.

</details>

<details>

<summary>2018-09-25 14:28:06 - RGB Video Based Tennis Action Recognition Using a Deep Historical Long Short-Term Memory</summary>

- *Jiaxin Cai, Xin Tang*

- `1808.00845v2` - [abs](http://arxiv.org/abs/1808.00845v2) - [pdf](http://arxiv.org/pdf/1808.00845v2)

> Action recognition has attracted increasing attention from RGB input in computer vision partially due to potential applications on somatic simulation and statistics of sport such as virtual tennis game and tennis techniques and tactics analysis by video. Recently, deep learning based methods have achieved promising performance for action recognition. In this paper, we propose weighted Long Short-Term Memory adopted with convolutional neural network representations for three dimensional tennis shots recognition. First, the local two-dimensional convolutional neural network spatial representations are extracted from each video frame individually using a pre-trained Inception network. Then, a weighted Long Short-Term Memory decoder is introduced to take the output state at time t and the historical embedding feature at time t-1 to generate feature vector using a score weighting scheme. Finally, we use the adopted CNN and weighted LSTM to map the original visual features into a vector space to generate the spatial-temporal semantical description of visual sequences and classify the action video content. Experiments on the benchmark demonstrate that our method using only simple raw RGB video can achieve better performance than the state-of-the-art baselines for tennis shot recognition.

</details>

<details>

<summary>2018-09-25 15:29:11 - Coordinating and Integrating Faceted Classification with Rich Semantic Modeling</summary>

- *Robert B. Allen, Jaihyun Park*

- `1809.09548v1` - [abs](http://arxiv.org/abs/1809.09548v1) - [pdf](http://arxiv.org/pdf/1809.09548v1)

> Faceted classifications define dimensions for the types of entities included. In effect, the facets provide an "ontological commitment". We compare a faceted thesaurus, the Art and Architecture Thesaurus (AAT), with ontologies derived from the Basic Formal Ontology (BFO2), which is an upper (or formal) ontology widely used to describe entities in biomedicine. We consider how the AAT and BFO2-based ontologies could be coordinated and integrated into a Human Activity and Infrastructure Foundry (HAIF). To extend the AAT to enable this coordination and integration, we describe how a wider range of relationships among its terms could be introduced. Using these extensions, we explore richer modeling of topics from AAT that deal with Technology. Finally, we consider how ontology-based frames and semantic role frames can be integrated to make rich semantic statements about changes in the world.

</details>

<details>

<summary>2018-09-26 07:55:02 - Verisimilar Image Synthesis for Accurate Detection and Recognition of Texts in Scenes</summary>

- *Fangneng Zhan, Shijian Lu, Chuhui Xue*

- `1807.03021v2` - [abs](http://arxiv.org/abs/1807.03021v2) - [pdf](http://arxiv.org/pdf/1807.03021v2)

> The requirement of large amounts of annotated images has become one grand challenge while training deep neural network models for various visual detection and recognition tasks. This paper presents a novel image synthesis technique that aims to generate a large amount of annotated scene text images for training accurate and robust scene text detection and recognition models. The proposed technique consists of three innovative designs. First, it realizes "semantic coherent" synthesis by embedding texts at semantically sensible regions within the background image, where the semantic coherence is achieved by leveraging the semantic annotations of objects and image regions that have been created in the prior semantic segmentation research. Second, it exploits visual saliency to determine the embedding locations within each semantic sensible region, which coincides with the fact that texts are often placed around homogeneous regions for better visibility in scenes. Third, it designs an adaptive text appearance model that determines the color and brightness of embedded texts by learning from the feature of real scene text images adaptively. The proposed technique has been evaluated over five public datasets and the experiments show its superior performance in training accurate and robust scene text detection and recognition models.

</details>

<details>

<summary>2018-09-26 17:04:42 - From Classical to Generalized Zero-Shot Learning: a Simple Adaptation Process</summary>

- *Yannick Le Cacheux, Hervé Le Borgne, Michel Crucianu*

- `1809.10120v1` - [abs](http://arxiv.org/abs/1809.10120v1) - [pdf](http://arxiv.org/pdf/1809.10120v1)

> Zero-shot learning (ZSL) is concerned with the recognition of previously unseen classes. It relies on additional semantic knowledge for which a mapping can be learned with training examples of seen classes. While classical ZSL considers the recognition performance on unseen classes only, generalized zero-shot learning (GZSL) aims at maximizing performance on both seen and unseen classes. In this paper, we propose a new process for training and evaluation in the GZSL setting; this process addresses the gap in performance between samples from unseen and seen classes by penalizing the latter, and enables to select hyper-parameters well-suited to the GZSL task. It can be applied to any existing ZSL approach and leads to a significant performance boost: the experimental evaluation shows that GZSL performance, averaged over eight state-of-the-art methods, is improved from 28.5 to 42.2 on CUB and from 28.2 to 57.1 on AwA2.

</details>

<details>

<summary>2018-09-26 18:58:24 - Content Based Image Retrieval from AWiFS Images Repository of IRS Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas</summary>

- *Suraj Kothawade, Kunjan Mhaske, Sahil Sharma, Furkhan Shaikh*

- `1809.10190v1` - [abs](http://arxiv.org/abs/1809.10190v1) - [pdf](http://arxiv.org/pdf/1809.10190v1)

> Satellite Remote Sensing Technology is becoming a major milestone in the prediction of weather anomalies, natural disasters as well as finding alternative resources in proximity using multiple multi-spectral sensors emitting electromagnetic waves at distinct wavelengths. Hence, it is imperative to extract water bodies and burnt areas from orthorectified tiles and correspondingly rank them using similarity measures. Different objects in all the spheres of the earth have the inherent capability of absorbing electromagnetic waves of distant wavelengths. This creates various unique masks in terms of reflectance on the receptor. We propose Dynamic Semantic Segmentation (DSS) algorithms that utilized the mentioned capability to extract and rank Advanced Wide Field Sensor (AWiFS) images according to various features. This system stores data intelligently in the form of a sparse feature vector which drastically mitigates the computational and spatial costs incurred for further analysis. The compressed source image is divided into chunks and stored in the database for quicker retrieval. This work is intended to utilize readily available and cost effective resources like AWiFS dataset instead of depending on advanced technologies like Moderate Resolution Imaging Spectroradiometer (MODIS) for data which is scarce.

</details>

<details>

<summary>2018-09-26 19:33:13 - Modular Semantics and Characteristics for Bipolar Weighted Argumentation Graphs</summary>

- *Till Mossakowski, Fabian Neuhaus*

- `1807.06685v2` - [abs](http://arxiv.org/abs/1807.06685v2) - [pdf](http://arxiv.org/pdf/1807.06685v2)

> This paper addresses the semantics of weighted argumentation graphs that are bipolar, i.e. contain both attacks and supports for arguments. It builds on previous work by Amgoud, Ben-Naim et. al. We study the various characteristics of acceptability semantics that have been introduced in these works, and introduce the notion of a modular acceptability semantics. A semantics is modular if it cleanly separates aggregation of attacking and supporting arguments (for a given argument $a$) from the computation of their influence on $a$'s initial weight.   We show that the various semantics for bipolar argumentation graphs from the literature may be analysed as a composition of an aggregation function with an influence function. Based on this modular framework, we prove general convergence and divergence theorems. We demonstrate that all well-behaved modular acceptability semantics converge for all acyclic graphs and that no sum-based semantics can converge for all graphs. In particular, we show divergence of Euler-based semantics (Amgoud et al.) for certain cyclic graphs. Further, we provide the first semantics for bipolar weighted graphs that converges for all graphs.

</details>

<details>

<summary>2018-09-26 23:38:19 - Semantic Sentence Embeddings for Paraphrasing and Text Summarization</summary>

- *Chi Zhang, Shagan Sah, Thang Nguyen, Dheeraj Peri, Alexander Loui, Carl Salvaggio, Raymond Ptucha*

- `1809.10267v1` - [abs](http://arxiv.org/abs/1809.10267v1) - [pdf](http://arxiv.org/pdf/1809.10267v1)

> This paper introduces a sentence to vector encoding framework suitable for advanced natural language processing. Our latent representation is shown to encode sentences with common semantic information with similar vector representations. The vector representation is extracted from an encoder-decoder model which is trained on sentence paraphrase pairs. We demonstrate the application of the sentence representations for two different tasks -- sentence paraphrasing and paragraph summarization, making it attractive for commonly used recurrent frameworks that process text. Experimental results help gain insight how vector representations are suitable for advanced language embedding.

</details>

<details>

<summary>2018-09-27 00:06:53 - Semantically Enhanced Models for Commonsense Knowledge Acquisition</summary>

- *Ikhlas Alhussien, Erik Cambria, Zhang NengSheng*

- `1809.04708v2` - [abs](http://arxiv.org/abs/1809.04708v2) - [pdf](http://arxiv.org/pdf/1809.04708v2)

> Commonsense knowledge is paramount to enable intelligent systems. Typically, it is characterized as being implicit and ambiguous, hindering thereby the automation of its acquisition. To address these challenges, this paper presents semantically enhanced models to enable reasoning through resolving part of commonsense ambiguity. The proposed models enhance in a knowledge graph embedding (KGE) framework for knowledge base completion. Experimental results show the effectiveness of the new semantic models in commonsense reasoning.

</details>

<details>

<summary>2018-09-27 00:11:25 - Semantically Invariant Text-to-Image Generation</summary>

- *Shagan Sah, Dheeraj Peri, Ameya Shringi, Chi Zhang, Miguel Dominguez, Andreas Savakis, Ray Ptucha*

- `1809.10274v1` - [abs](http://arxiv.org/abs/1809.10274v1) - [pdf](http://arxiv.org/pdf/1809.10274v1)

> Image captioning has demonstrated models that are capable of generating plausible text given input images or videos. Further, recent work in image generation has shown significant improvements in image quality when text is used as a prior. Our work ties these concepts together by creating an architecture that can enable bidirectional generation of images and text. We call this network Multi-Modal Vector Representation (MMVR). Along with MMVR, we propose two improvements to the text conditioned image generation. Firstly, a n-gram metric based cost function is introduced that generalizes the caption with respect to the image. Secondly, multiple semantically similar sentences are shown to help in generating better images. Qualitative and quantitative evaluations demonstrate that MMVR improves upon existing text conditioned image generation results by over 20%, while integrating visual and text modalities.

</details>

<details>

<summary>2018-09-27 02:08:06 - Vector Learning for Cross Domain Representations</summary>

- *Shagan Sah, Chi Zhang, Thang Nguyen, Dheeraj Kumar Peri, Ameya Shringi, Raymond Ptucha*

- `1809.10312v1` - [abs](http://arxiv.org/abs/1809.10312v1) - [pdf](http://arxiv.org/pdf/1809.10312v1)

> Recently, generative adversarial networks have gained a lot of popularity for image generation tasks. However, such models are associated with complex learning mechanisms and demand very large relevant datasets. This work borrows concepts from image and video captioning models to form an image generative framework. The model is trained in a similar fashion as recurrent captioning model and uses the learned weights for image generation. This is done in an inverse direction, where the input is a caption and the output is an image. The vector representation of the sentence and frames are extracted from an encoder-decoder model which is initially trained on similar sentence and image pairs. Our model conditions image generation on a natural language caption. We leverage a sequence-to-sequence model to generate synthetic captions that have the same meaning for having a robust image generation. One key advantage of our method is that the traditional image captioning datasets can be used for synthetic sentence paraphrases. Results indicate that images generated through multiple captions are better at capturing the semantic meaning of the family of captions.

</details>

<details>

<summary>2018-09-27 10:10:20 - Generating Ontologies from Templates: A Rule-Based Approach for Capturing Regularity</summary>

- *Henrik Forssell, Christian Kindermann, Daniel P. Lupp, Uli Sattler, Evgenij Thorstensen*

- `1809.10436v1` - [abs](http://arxiv.org/abs/1809.10436v1) - [pdf](http://arxiv.org/pdf/1809.10436v1)

> We present a second-order language that can be used to succinctly specify ontologies in a consistent and transparent manner. This language is based on ontology templates (OTTR), a framework for capturing recurring patterns of axioms in ontological modelling. The language and our results are independent of any specific DL. We define the language and its semantics, including the case of negation-as-failure, investigate reasoning over ontologies specified using our language, and show results about the decidability of useful reasoning tasks about the language itself. We also state and discuss some open problems that we believe to be of interest.

</details>

<details>

<summary>2018-09-27 16:28:18 - Enabling FAIR Research in Earth Science through Research Objects</summary>

- *Andres Garcia-Silva, Jose Manuel Gomez-Perez, Raul Palma, Marcin Krystek, Simone Mantovani, Federica Foglini, Valentina Grande, Francesco De Leo, Stefano Salvi, Elisa Trasati, Vito Romaniello, Mirko Albani, Cristiano Silvagni, Rosemarie Leone, Fulvio Marelli, Sergio Albani, Michele Lazzarini, Hazel J. Napier, Helen M. Glaves, Timothy Aldridge, Charles Meertens, Fran Boler, Henry W. Loescher, Christine Laney, Melissa A Genazzio, Daniel Crawl, Ilkay Altintas*

- `1809.10617v1` - [abs](http://arxiv.org/abs/1809.10617v1) - [pdf](http://arxiv.org/pdf/1809.10617v1)

> Data-intensive science communities are progressively adopting FAIR practices that enhance the visibility of scientific breakthroughs and enable reuse. At the core of this movement, research objects contain and describe scientific information and resources in a way compliant with the FAIR principles and sustain the development of key infrastructure and tools. This paper provides an account of the challenges, experiences and solutions involved in the adoption of FAIR around research objects over several Earth Science disciplines. During this journey, our work has been comprehensive, with outcomes including: an extended research object model adapted to the needs of earth scientists; the provisioning of digital object identifiers (DOI) to enable persistent identification and to give due credit to authors; the generation of content-based, semantically rich, research object metadata through natural language processing, enhancing visibility and reuse through recommendation systems and third-party search engines; and various types of checklists that provide a compact representation of research object quality as a key enabler of scientific reuse. All these results have been integrated in ROHub, a platform that provides research object management functionality to a wealth of applications and interfaces across different scientific communities. To monitor and quantify the community uptake of research objects, we have defined indicators and obtained measures via ROHub that are also discussed herein.

</details>

<details>

<summary>2018-09-27 17:44:47 - Brokering Policies and Execution Monitors for IoT Middleware</summary>

- *Juan Carlos Fuentes Carranza, Philip W. L. Fong*

- `1809.10134v2` - [abs](http://arxiv.org/abs/1809.10134v2) - [pdf](http://arxiv.org/pdf/1809.10134v2)

> Event-based systems lie at the heart of many cloud-based Internet-of-Things (IoT) platforms. This combination of the Broker architectural style and the Publisher-Subscriber design pattern provides a way for smart devices to communicate and coordinate with one another. The present design of these cloud-based IoT frameworks lacks measures to (i) protect devices against malicious cloud disconnections, (ii) impose information flow control among communicating parties, and (iii) enforce coordination protocols in the presence of compromised devices. In this work, we propose to extend the modular event-based system architecture of Fiege et al., to incorporate brokering policies and execution monitors, in order to address the three protection challenges mentioned above. We formalized the operational semantics of our protection scheme, explored how the scheme can be used to enforce BLP-style information flow control and RBAC-style protection domains, implemented the proposal in an open-source MQTT broker, and evaluated the performance impact of the protection mechanisms.

</details>

<details>

<summary>2018-09-27 23:36:12 - Dissecting Contextual Word Embeddings: Architecture and Representation</summary>

- *Matthew E. Peters, Mark Neumann, Luke Zettlemoyer, Wen-tau Yih*

- `1808.08949v2` - [abs](http://arxiv.org/abs/1808.08949v2) - [pdf](http://arxiv.org/pdf/1808.08949v2)

> Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.

</details>

<details>

<summary>2018-09-28 03:30:37 - Learning and Planning with a Semantic Model</summary>

- *Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, Yuandong Tian*

- `1809.10842v1` - [abs](http://arxiv.org/abs/1809.10842v1) - [pdf](http://arxiv.org/pdf/1809.10842v1)

> Building deep reinforcement learning agents that can generalize and adapt to unseen environments remains a fundamental challenge for AI. This paper describes progresses on this challenge in the context of man-made environments, which are visually diverse but contain intrinsic semantic regularities. We propose a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-policy to execute, and updates the semantic model based on new observations. We perform experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content.

</details>

<details>

<summary>2018-09-28 09:30:26 - Bayesian Prediction of Future Street Scenes through Importance Sampling based Optimization</summary>

- *Apratim Bhattacharyya, Mario Fritz, Bernt Schiele*

- `1806.06939v2` - [abs](http://arxiv.org/abs/1806.06939v2) - [pdf](http://arxiv.org/pdf/1806.06939v2)

> For autonomous agents to successfully operate in the real world, anticipation of future events and states of their environment is a key competence. This problem can be formalized as a sequence prediction problem, where a number of observations are used to predict the sequence into the future. However, real-world scenarios demand a model of uncertainty of such predictions, as future states become increasingly uncertain and multi-modal -- in particular on long time horizons. This makes modelling and learning challenging. We cast state of the art semantic segmentation and future prediction models based on deep learning into a Bayesian formulation that in turn allows for a full Bayesian treatment of the prediction problem. We present a new sampling scheme for this model that draws from the success of variational autoencoders by incorporating a recognition network. In the experiments we show that our model outperforms prior work in accuracy of the predicted segmentation and provides calibrated probabilities that also better capture the multi-modal aspects of possible future states of street scenes.

</details>

<details>

<summary>2018-09-28 14:05:05 - A Systematic Study on Static Control Flow Obfuscation Techniques in Java</summary>

- *Renuka Kumar, Anjana Mariam Kurian*

- `1809.11037v1` - [abs](http://arxiv.org/abs/1809.11037v1) - [pdf](http://arxiv.org/pdf/1809.11037v1)

> Control flow obfuscation (CFO) alters the control flow path of a program without altering its semantics. Existing literature has proposed several techniques; however, a quick survey reveals a lack of clarity in the types of techniques proposed, and how many are unique. What is also unclear is whether there is a disparity in the theory and practice of CFO. In this paper, we systematically study CFO techniques proposed for Java programs, both from papers and commercially available tools. We evaluate 13 obfuscators using a dataset of 16 programs with varying software characteristics, and different obfuscator parameters. Each program is carefully reverse engineered to study the effect of obfuscation. Our study reveals that there are 36 unique techniques proposed in the literature and 7 from tools. Three of the most popular commercial obfuscators implement only 13 of the 36 techniques in the literature. Thus there appears to be a gap between the theory and practice of CFO. We propose a novel classification of the obfuscation techniques based on the underlying component of a program that is transformed. We identify the techniques that are potent against reverse engineering attacks, both from the perspective of a human analyst and an automated program decompiler. Our analysis reveals that majority of the tools do not implement these techniques, thus defeating the protection obfuscation offers. We furnish examples of select techniques and discuss our findings. To the best of our knowledge, we are the first to assemble such a research. This study will be useful to software designers to decide upon the best techniques to use based upon their needs, for researchers to understand the state-of-the-art and for commercial obfuscator developers to develop new techniques.

</details>

<details>

<summary>2018-09-28 17:20:54 - Fast Geometrically-Perturbed Adversarial Faces</summary>

- *Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, Nasser M. Nasrabadi*

- `1809.08999v2` - [abs](http://arxiv.org/abs/1809.08999v2) - [pdf](http://arxiv.org/pdf/1809.08999v2)

> The state-of-the-art performance of deep learning algorithms has led to a considerable increase in the utilization of machine learning in security-sensitive and critical applications. However, it has recently been shown that a small and carefully crafted perturbation in the input space can completely fool a deep model. In this study, we explore the extent to which face recognition systems are vulnerable to geometrically-perturbed adversarial faces. We propose a fast landmark manipulation method for generating adversarial faces, which is approximately 200 times faster than the previous geometric attacks and obtains 99.86% success rate on the state-of-the-art face recognition models. To further force the generated samples to be natural, we introduce a second attack constrained on the semantic structure of the face which has the half speed of the first attack with the success rate of 99.96%. Both attacks are extremely robust against the state-of-the-art defense methods with the success rate of equal or greater than 53.59%. Code is available at https://github.com/alldbi/FLM

</details>

<details>

<summary>2018-09-28 21:52:56 - Predicting Destinations by Nearest Neighbor Search on Training Vessel Routes</summary>

- *Valentin Roşca, Emanuel Onica, Paul Diac, Ciprian Amariei*

- `1810.00096v1` - [abs](http://arxiv.org/abs/1810.00096v1) - [pdf](http://arxiv.org/pdf/1810.00096v1)

> The DEBS Grand Challenge 2018 is set in the context of maritime route prediction. Vessel routes are modeled as streams of Automatic Identification System (AIS) data points selected from real-world tracking data. The challenge requires to correctly estimate the destination ports and arrival times of vessel trips, as early as possible. Our proposed solution partitions the training vessel routes by reported destination port and uses a nearest neighbor search to find the training routes that are closer to the query AIS point. Particular improvements have been included as well, such as a way to avoid changing the predicted ports frequently within one query route and automating the parameters tuning by the use of a genetic algorithm. This leads to significant improvements on the final score.

</details>

<details>

<summary>2018-09-29 03:23:53 - Knowledge-guided Semantic Computing Network</summary>

- *Guangming Shi, Zhongqiang Zhang, Dahua Gao, Xuemei Xie, Yihao Feng, Xinrui Ma, Danhua Liu*

- `1810.00139v1` - [abs](http://arxiv.org/abs/1810.00139v1) - [pdf](http://arxiv.org/pdf/1810.00139v1)

> It is very useful to integrate human knowledge and experience into traditional neural networks for faster learning speed, fewer training samples and better interpretability. However, due to the obscured and indescribable black box model of neural networks, it is very difficult to design its architecture, interpret its features and predict its performance. Inspired by human visual cognition process, we propose a knowledge-guided semantic computing network which includes two modules: a knowledge-guided semantic tree and a data-driven neural network. The semantic tree is pre-defined to describe the spatial structural relations of different semantics, which just corresponds to the tree-like description of objects based on human knowledge. The object recognition process through the semantic tree only needs simple forward computing without training. Besides, to enhance the recognition ability of the semantic tree in aspects of the diversity, randomicity and variability, we use the traditional neural network to aid the semantic tree to learn some indescribable features. Only in this case, the training process is needed. The experimental results on MNIST and GTSRB datasets show that compared with the traditional data-driven network, our proposed semantic computing network can achieve better performance with fewer training samples and lower computational complexity. Especially, Our model also has better adversarial robustness than traditional neural network with the help of human knowledge.

</details>

<details>

<summary>2018-09-29 20:30:06 - Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference</summary>

- *Ruying Bao, Sihang Liang, Qingcan Wang*

- `1805.07862v2` - [abs](http://arxiv.org/abs/1805.07862v2) - [pdf](http://arxiv.org/pdf/1805.07862v2)

> Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between the high-dimensional data space and the low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.

</details>

<details>

<summary>2018-09-30 00:24:22 - Community-Based Security for the Internet of Things</summary>

- *Quanyan Zhu, Stefan Rass, Peter Schartner*

- `1810.00281v1` - [abs](http://arxiv.org/abs/1810.00281v1) - [pdf](http://arxiv.org/pdf/1810.00281v1)

> With more and more devices becoming connectable to the internet, the number of services but also a lot of threats increases dramatically. Security is often a secondary matter behind functionality and comfort, but the problem has already been recognized. Still, with many IoT devices being deployed already, security will come step-by-step and through updates, patches and new versions of apps and IoT software. While these updates can be safely retrieved from app stores, the problems kick in via jailbroken devices and with the variety of untrusted sources arising on the internet. Since hacking is typically a community effort? these days, security could be a community goal too. The challenges are manifold, and one reason for weak or absent security on IoT devices is their weak computational power. In this chapter, we discuss a community based security mechanism in which devices mutually aid each other in secure software management. We discuss game-theoretic methods of community formation and light-weight cryptographic means to accomplish authentic software deployment inside the IoT device community.

</details>

<details>

<summary>2018-09-30 18:14:18 - A Deeper Look at 3D Shape Classifiers</summary>

- *Jong-Chyi Su, Matheus Gadelha, Rui Wang, Subhransu Maji*

- `1809.02560v2` - [abs](http://arxiv.org/abs/1809.02560v2) - [pdf](http://arxiv.org/pdf/1809.02560v2)

> We investigate the role of representations and architectures for classifying 3D shapes in terms of their computational efficiency, generalization, and robustness to adversarial transformations. By varying the number of training examples and employing cross-modal transfer learning we study the role of initialization of existing deep architectures for 3D shape classification. Our analysis shows that multiview methods continue to offer the best generalization even without pretraining on large labeled image datasets, and even when trained on simplified inputs such as binary silhouettes. Furthermore, the performance of voxel-based 3D convolutional networks and point-based architectures can be improved via cross-modal transfer from image representations. Finally, we analyze the robustness of 3D shape classifiers to adversarial transformations and present a novel approach for generating adversarial perturbations of a 3D shape for multiview classifiers using a differentiable renderer. We find that point-based networks are more robust to point position perturbations while voxel-based and multiview networks are easily fooled with the addition of imperceptible noise to the input.

</details>


## 2018-10

<details>

<summary>2018-10-01 03:00:11 - Semantic Segmentation for Urban Planning Maps based on U-Net</summary>

- *Zhiling Guo, Hiroaki Shengoku, Guangming Wu, Qi Chen, Wei Yuan, Xiaodan Shi, Xiaowei Shao, Yongwei Xu, Ryosuke Shibasaki*

- `1809.10862v2` - [abs](http://arxiv.org/abs/1809.10862v2) - [pdf](http://arxiv.org/pdf/1809.10862v2)

> The automatic digitizing of paper maps is a significant and challenging task for both academia and industry. As an important procedure of map digitizing, the semantic segmentation section mainly relies on manual visual interpretation with low efficiency. In this study, we select urban planning maps as a representative sample and investigate the feasibility of utilizing U-shape fully convolutional based architecture to perform end-to-end map semantic segmentation. The experimental results obtained from the test area in Shibuya district, Tokyo, demonstrate that our proposed method could achieve a very high Jaccard similarity coefficient of 93.63% and an overall accuracy of 99.36%. For implementation on GPGPU and cuDNN, the required processing time for the whole Shibuya district can be less than three minutes. The results indicate the proposed method can serve as a viable tool for urban planning map semantic segmentation task with high accuracy and efficiency.

</details>

<details>

<summary>2018-10-01 14:01:46 - Modular Vehicle Control for Transferring Semantic Information Between Weather Conditions Using GANs</summary>

- *Patrick Wenzel, Qadeer Khan, Daniel Cremers, Laura Leal-Taixé*

- `1807.01001v2` - [abs](http://arxiv.org/abs/1807.01001v2) - [pdf](http://arxiv.org/pdf/1807.01001v2)

> Even though end-to-end supervised learning has shown promising results for sensorimotor control of self-driving cars, its performance is greatly affected by the weather conditions under which it was trained, showing poor generalization to unseen conditions. In this paper, we show how knowledge can be transferred using semantic maps to new weather conditions without the need to obtain new ground truth data. To this end, we propose to divide the task of vehicle control into two independent modules: a control module which is only trained on one weather condition for which labeled steering data is available, and a perception module which is used as an interface between new weather conditions and the fixed control module. To generate the semantic data needed to train the perception module, we propose to use a generative adversarial network (GAN)-based model to retrieve the semantic information for the new conditions in an unsupervised manner. We introduce a master-servant architecture, where the master model (semantic labels available) trains the servant model (semantic labels not available). We show that our proposed method trained with ground truth data for a single weather condition is capable of achieving similar results on the task of steering angle prediction as an end-to-end model trained with ground truth data of 15 different weather conditions.

</details>

<details>

<summary>2018-10-01 14:24:20 - A categorisation and implementation of digital pen features for behaviour characterisation</summary>

- *Alexander Prange, Michael Barz, Daniel Sonntag*

- `1810.03970v1` - [abs](http://arxiv.org/abs/1810.03970v1) - [pdf](http://arxiv.org/pdf/1810.03970v1)

> In this paper we provide a categorisation and implementation of digital ink features for behaviour characterisation. Based on four feature sets taken from literature, we provide a categorisation in different classes of syntactic and semantic features. We implemented a publicly available framework to calculate these features and show its deployment in the use case of analysing cognitive assessments performed using a digital pen.

</details>

<details>

<summary>2018-10-01 17:55:37 - IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles</summary>

- *Tianze Shi, Kedar Tatwawadi, Kaushik Chakrabarti, Yi Mao, Oleksandr Polozov, Weizhu Chen*

- `1809.05054v2` - [abs](http://arxiv.org/abs/1809.05054v2) - [pdf](http://arxiv.org/pdf/1809.05054v2)

> We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory. To account for the fact that typically there are multiple correct SQL queries with the same or very similar semantics, we draw inspiration from syntactic parsing techniques and propose to train our sequence-to-action models with non-deterministic oracles. We evaluate our models on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the test set, a 2.1% absolute improvement over the models trained with traditional static oracles assuming a single correct target SQL query. When further combined with the execution-guided decoding strategy, our model sets a new state-of-the-art performance at an execution accuracy of 87.1%.

</details>

<details>

<summary>2018-10-01 19:15:57 - Joint On-line Learning of a Zero-shot Spoken Semantic Parser and a Reinforcement Learning Dialogue Manager</summary>

- *Matthieu Riou, Bassam Jabaian, Stéphane Huet, Fabrice Lefèvre*

- `1810.00924v1` - [abs](http://arxiv.org/abs/1810.00924v1) - [pdf](http://arxiv.org/pdf/1810.00924v1)

> Despite many recent advances for the design of dialogue systems, a true bottleneck remains the acquisition of data required to train its components. Unlike many other language processing applications, dialogue systems require interactions with users, therefore it is complex to develop them with pre-recorded data. Building on previous works, on-line learning is pursued here as a most convenient way to address the issue. Data collection, annotation and use in learning algorithms are performed in a single process. The main difficulties are then: to bootstrap an initial basic system, and to control the level of additional cost on the user side. Considering that well-performing solutions can be used directly off the shelf for speech recognition and synthesis, the study is focused on learning the spoken language understanding and dialogue management modules only. Several variants of joint learning are investigated and tested with user trials to confirm that the overall on-line learning can be obtained after only a few hundred training dialogues and can overstep an expert-based system.

</details>

<details>

<summary>2018-10-02 14:34:32 - An Empirical Analysis of the Role of Amplifiers, Downtoners, and Negations in Emotion Classification in Microblogs</summary>

- *Florian Strohm, Roman Klinger*

- `1808.10653v2` - [abs](http://arxiv.org/abs/1808.10653v2) - [pdf](http://arxiv.org/pdf/1808.10653v2)

> The effect of amplifiers, downtoners, and negations has been studied in general and particularly in the context of sentiment analysis. However, there is only limited work which aims at transferring the results and methods to discrete classes of emotions, e. g., joy, anger, fear, sadness, surprise, and disgust. For instance, it is not straight-forward to interpret which emotion the phrase "not happy" expresses. With this paper, we aim at obtaining a better understanding of such modifiers in the context of emotion-bearing words and their impact on document-level emotion classification, namely, microposts on Twitter. We select an appropriate scope detection method for modifiers of emotion words, incorporate it in a document-level emotion classification model as additional bag of words and show that this approach improves the performance of emotion classification. In addition, we build a term weighting approach based on the different modifiers into a lexical model for the analysis of the semantics of modifiers and their impact on emotion meaning. We show that amplifiers separate emotions expressed with an emotion- bearing word more clearly from other secondary connotations. Downtoners have the opposite effect. In addition, we discuss the meaning of negations of emotion-bearing words. For instance we show empirically that "not happy" is closer to sadness than to anger and that fear-expressing words in the scope of downtoners often express surprise.

</details>

<details>

<summary>2018-10-04 08:53:42 - Multilingual sequence-to-sequence speech recognition: architecture, transfer learning, and language modeling</summary>

- *Jaejin Cho, Murali Karthick Baskar, Ruizhi Li, Matthew Wiesner, Sri Harish Mallidi, Nelson Yalta, Martin Karafiat, Shinji Watanabe, Takaaki Hori*

- `1810.03459v1` - [abs](http://arxiv.org/abs/1810.03459v1) - [pdf](http://arxiv.org/pdf/1810.03459v1)

> Sequence-to-sequence (seq2seq) approach for low-resource ASR is a relatively new direction in speech research. The approach benefits by performing model training without using lexicon and alignments. However, this poses a new problem of requiring more data compared to conventional DNN-HMM systems. In this work, we attempt to use data from 10 BABEL languages to build a multi-lingual seq2seq model as a prior model, and then port them towards 4 other BABEL languages using transfer learning approach. We also explore different architectures for improving the prior multilingual seq2seq model. The paper also discusses the effect of integrating a recurrent neural network language model (RNNLM) with a seq2seq model during decoding. Experimental results show that the transfer learning approach from the multilingual model shows substantial gains over monolingual models across all 4 BABEL languages. Incorporating an RNNLM also brings significant improvements in terms of %WER, and achieves recognition performance comparable to the models trained with twice more training data.

</details>

<details>

<summary>2018-10-04 09:18:42 - Improving the Segmentation of Anatomical Structures in Chest Radiographs using U-Net with an ImageNet Pre-trained Encoder</summary>

- *Maayan Frid-Adar, Avi Ben-Cohen, Rula Amer, Hayit Greenspan*

- `1810.02113v1` - [abs](http://arxiv.org/abs/1810.02113v1) - [pdf](http://arxiv.org/pdf/1810.02113v1)

> Accurate segmentation of anatomical structures in chest radiographs is essential for many computer-aided diagnosis tasks. In this paper we investigate the latest fully-convolutional architectures for the task of multi-class segmentation of the lungs field, heart and clavicles in a chest radiograph. In addition, we explore the influence of using different loss functions in the training process of a neural network for semantic segmentation. We evaluate all models on a common benchmark of 247 X-ray images from the JSRT database and ground-truth segmentation masks from the SCR dataset. Our best performing architecture, is a modified U-Net that benefits from pre-trained encoder weights. This model outperformed the current state-of-the-art methods tested on the same benchmark, with Jaccard overlap scores of 96.1% for lung fields, 90.6% for heart and 85.5% for clavicles.

</details>

<details>

<summary>2018-10-04 09:58:34 - Learning Finer-class Networks for Universal Representations</summary>

- *Julien Girard, Youssef Tamaazousti, Hervé Le Borgne, Céline Hudelot*

- `1810.02126v1` - [abs](http://arxiv.org/abs/1810.02126v1) - [pdf](http://arxiv.org/pdf/1810.02126v1)

> Many real-world visual recognition use-cases can not directly benefit from state-of-the-art CNN-based approaches because of the lack of many annotated data. The usual approach to deal with this is to transfer a representation pre-learned on a large annotated source-task onto a target-task of interest. This raises the question of how well the original representation is "universal", that is to say directly adapted to many different target-tasks. To improve such universality, the state-of-the-art consists in training networks on a diversified source problem, that is modified either by adding generic or specific categories to the initial set of categories. In this vein, we proposed a method that exploits finer-classes than the most specific ones existing, for which no annotation is available. We rely on unsupervised learning and a bottom-up split and merge strategy. We show that our method learns more universal representations than state-of-the-art, leading to significantly better results on 10 target-tasks from multiple domains, using several network architectures, either alone or combined with networks learned at a coarser semantic level.

</details>

<details>

<summary>2018-10-04 14:34:02 - A Span Selection Model for Semantic Role Labeling</summary>

- *Hiroki Ouchi, Hiroyuki Shindo, Yuji Matsumoto*

- `1810.02245v1` - [abs](http://arxiv.org/abs/1810.02245v1) - [pdf](http://arxiv.org/pdf/1810.02245v1)

> We present a simple and accurate span-based model for semantic role labeling (SRL). Our model directly takes into account all possible argument spans and scores them for each label. At decoding time, we greedily select higher scoring labeled spans. One advantage of our model is to allow us to design and use span-level features, that are difficult to use in token-based BIO tagging approaches. Experimental results demonstrate that our ensemble model achieves the state-of-the-art results, 87.4 F1 and 87.0 F1 on the CoNLL-2005 and 2012 datasets, respectively.

</details>

<details>

<summary>2018-10-05 00:34:36 - Realisability of Pomsets via Communicating Automata</summary>

- *Roberto Guanciale Dr, Emilio Tuosto Dr*

- `1810.02469v1` - [abs](http://arxiv.org/abs/1810.02469v1) - [pdf](http://arxiv.org/pdf/1810.02469v1)

> Pomsets are a model of concurrent computations introduced by Pratt. They can provide a syntax-oblivious description of semantics of coordination models based on asynchronous message-passing, such as Message Sequence Charts (MSCs). In this paper, we study conditions that ensure a specification expressed as a set of pomsets can be faithfully realised via communicating automata. Our main contributions are (i) the definition of a realisability condition accounting for termination soundness, (ii) conditions for global specifications with "multi-threaded" participants, and (iii) the definition of realisability conditions that can be decided directly over pomsets. A positive by-product of our approach is the efficiency gain in the verification of the realisability conditions obtained when restricting to specific classes of choreographies characterisable in term of behavioural types.

</details>

<details>

<summary>2018-10-05 02:53:26 - Current Trends and Future Research Directions for Interactive Music</summary>

- *Mauricio Toro*

- `1810.04276v1` - [abs](http://arxiv.org/abs/1810.04276v1) - [pdf](http://arxiv.org/pdf/1810.04276v1)

> In this review, it is explained and compared different software and formalisms used in music interaction: sequencers, computer-assisted improvisation, meta- instruments, score-following, asynchronous dataflow languages, synchronous dataflow languages, process calculi, temporal constraints and interactive scores. Formal approaches have the advantage of providing rigorous semantics of the behavior of the model and proving correctness during execution. The main disadvantage of formal approaches is lack of commercial tools.

</details>

<details>

<summary>2018-10-05 14:35:01 - TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation</summary>

- *Pengcheng Yin, Graham Neubig*

- `1810.02720v1` - [abs](http://arxiv.org/abs/1810.02720v1) - [pdf](http://arxiv.org/pdf/1810.02720v1)

> We present TRANX, a transition-based neural semantic parser that maps natural language (NL) utterances into formal meaning representations (MRs). TRANX uses a transition system based on the abstract syntax description language for the target MR, which gives it two major advantages: (1) it is highly accurate, using information from the syntax of the target MR to constrain the output space and model the information flow, and (2) it is highly generalizable, and can easily be applied to new types of MR by just writing a new abstract syntax description corresponding to the allowable structures in the MR. Experiments on four different semantic parsing and code generation tasks show that our system is generalizable, extensible, and effective, registering strong results compared to existing neural semantic parsers.

</details>

<details>

<summary>2018-10-05 17:37:37 - POIReviewQA: A Semantically Enriched POI Retrieval and Question Answering Dataset</summary>

- *Gengchen Mai, Krzysztof Janowicz, Cheng He, Sumang Liu, Ni Lao*

- `1810.02802v1` - [abs](http://arxiv.org/abs/1810.02802v1) - [pdf](http://arxiv.org/pdf/1810.02802v1)

> Many services that perform information retrieval for Points of Interest (POI) utilize a Lucene-based setup with spatial filtering. While this type of system is easy to implement it does not make use of semantics but relies on direct word matches between a query and reviews leading to a loss in both precision and recall. To study the challenging task of semantically enriching POIs from unstructured data in order to support open-domain search and question answering (QA), we introduce a new dataset POIReviewQA. It consists of 20k questions (e.g."is this restaurant dog friendly?") for 1022 Yelp business types. For each question we sampled 10 reviews, and annotated each sentence in the reviews whether it answers the question and what the corresponding answer is. To test a system's ability to understand the text we adopt an information retrieval evaluation by ranking all the review sentences for a question based on the likelihood that they answer this question. We build a Lucene-based baseline model, which achieves 77.0% AUC and 48.8% MAP. A sentence embedding-based model achieves 79.2% AUC and 41.8% MAP, indicating that the dataset presents a challenging problem for future research by the GIR community. The result technology can help exploit the thematic content of web documents and social media for characterisation of locations.

</details>

<details>

<summary>2018-10-05 20:03:00 - A New Method for the Semantic Integration of Multiple OWL Ontologies using Alignments</summary>

- *Inès Osman*

- `1810.02869v1` - [abs](http://arxiv.org/abs/1810.02869v1) - [pdf](http://arxiv.org/pdf/1810.02869v1)

> This work is done as part of a master's thesis project. The goal is to integrate two or more ontologies (of the same or close domains) in a new consistent and coherent OWL ontology to insure semantic interoperability between them. To do this, we have chosen to create a bridge ontology that includes all source ontologies and their bridging axioms in a customized way. In addition, we introduced a new criterion for obtaining an ontology of better quality (having the minimum of semantic/logical conflicts). We have also proposed new terminology and definitions that clarify the unclear and misplaced "integration" and "merging" notions that are randomly used in state-of-the-art works. Finally, we tested and evaluated our OIA2R tool using ontologies and reference alignments of the OAEI campaign. It turned out that it is generic, efficient and powerful enough.

</details>

<details>

<summary>2018-10-06 17:29:28 - OpenTag: Open Attribute Value Extraction from Product Profiles [Deep Learning, Active Learning, Named Entity Recognition]</summary>

- *Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li*

- `1806.01264v2` - [abs](http://arxiv.org/abs/1806.01264v2) - [pdf](http://arxiv.org/pdf/1806.01264v2)

> Extraction of missing attribute values is to find values describing an attribute of interest from a free text input. Most past related work on extraction of missing attribute values work with a closed world assumption with the possible set of values known beforehand, or use dictionaries of values and hand-crafted features. How can we discover new attribute values that we have never seen before? Can we do this with limited human annotation or supervision? We study this problem in the context of product catalogs that often have missing values for many attributes of interest.   In this work, we leverage product profile information such as titles and descriptions to discover missing values of product attributes. We develop a novel deep tagging model OpenTag for this extraction problem with the following contributions: (1) we formalize the problem as a sequence tagging task, and propose a joint model exploiting recurrent neural networks (specifically, bidirectional LSTM) to capture context and semantics, and Conditional Random Fields (CRF) to enforce tagging consistency, (2) we develop a novel attention mechanism to provide interpretable explanation for our model's decisions, (3) we propose a novel sampling strategy exploring active learning to reduce the burden of human annotation. OpenTag does not use any dictionary or hand-crafted features as in prior works. Extensive experiments in real-life datasets in different domains show that OpenTag with our active learning strategy discovers new attribute values from as few as 150 annotated samples (reduction in 3.3x amount of annotation effort) with a high F-score of 83%, outperforming state-of-the-art models.

</details>

<details>

<summary>2018-10-07 14:14:27 - Assessing Crosslingual Discourse Relations in Machine Translation</summary>

- *Karin Sim Smith, Lucia Specia*

- `1810.03148v1` - [abs](http://arxiv.org/abs/1810.03148v1) - [pdf](http://arxiv.org/pdf/1810.03148v1)

> In an attempt to improve overall translation quality, there has been an increasing focus on integrating more linguistic elements into Machine Translation (MT). While significant progress has been achieved, especially recently with neural models, automatically evaluating the output of such systems is still an open problem. Current practice in MT evaluation relies on a single reference translation, even though there are many ways of translating a particular text, and it tends to disregard higher level information such as discourse. We propose a novel approach that assesses the translated output based on the source text rather than the reference translation, and measures the extent to which the semantics of the discourse elements (discourse relations, in particular) in the source text are preserved in the MT output. The challenge is to detect the discourse relations in the source text and determine whether these relations are correctly transferred crosslingually to the target language -- without a reference translation. This methodology could be used independently for discourse-level evaluation, or as a component in other metrics, at a time where substantial amounts of MT are online and would benefit from evaluation where the source text serves as a benchmark.

</details>

<details>

<summary>2018-10-08 09:57:44 - Multi-Task Learning for Domain-General Spoken Disfluency Detection in Dialogue Systems</summary>

- *Igor Shalyminov, Arash Eshghi, Oliver Lemon*

- `1810.03352v1` - [abs](http://arxiv.org/abs/1810.03352v1) - [pdf](http://arxiv.org/pdf/1810.03352v1)

> Spontaneous spoken dialogue is often disfluent, containing pauses, hesitations, self-corrections and false starts. Processing such phenomena is essential in understanding a speaker's intended meaning and controlling the flow of the conversation. Furthermore, this processing needs to be word-by-word incremental to allow further downstream processing to begin as early as possible in order to handle real spontaneous human conversational behaviour.   In addition, from a developer's point of view, it is highly desirable to be able to develop systems which can be trained from `clean' examples while also able to generalise to the very diverse disfluent variations on the same data -- thereby enhancing both data-efficiency and robustness. In this paper, we present a multi-task LSTM-based model for incremental detection of disfluency structure, which can be hooked up to any component for incremental interpretation (e.g. an incremental semantic parser), or else simply used to `clean up' the current utterance as it is being produced.   We train the system on the Switchboard Dialogue Acts (SWDA) corpus and present its accuracy on this dataset. Our model outperforms prior neural network-based incremental approaches by about 10 percentage points on SWDA while employing a simpler architecture. To test the model's generalisation potential, we evaluate the same model on the bAbI+ dataset, without any additional training. bAbI+ is a dataset of synthesised goal-oriented dialogues where we control the distribution of disfluencies and their types. This shows that our approach has good generalisation potential, and sheds more light on which types of disfluency might be amenable to domain-general processing.

</details>

<details>

<summary>2018-10-08 10:42:57 - Avoiding Echo-Responses in a Retrieval-Based Conversation System</summary>

- *Denis Fedorenko, Nikita Smetanin, Artem Rodichev*

- `1712.05626v2` - [abs](http://arxiv.org/abs/1712.05626v2) - [pdf](http://arxiv.org/pdf/1712.05626v2)

> Retrieval-based conversation systems generally tend to highly rank responses that are semantically similar or even identical to the given conversation context. While the system's goal is to find the most appropriate response, rather than the most semantically similar one, this tendency results in low-quality responses. We refer to this challenge as the echoing problem. To mitigate this problem, we utilize a hard negative mining approach at the training stage. The evaluation shows that the resulting model reduces echoing and achieves better results in terms of Average Precision and Recall@N metrics, compared to the models trained without the proposed approach.

</details>

<details>

<summary>2018-10-08 10:49:15 - Deep Feature Factorization For Concept Discovery</summary>

- *Edo Collins, Radhakrishna Achanta, Sabine Süsstrunk*

- `1806.10206v5` - [abs](http://arxiv.org/abs/1806.10206v5) - [pdf](http://arxiv.org/pdf/1806.10206v5)

> We propose Deep Feature Factorization (DFF), a method capable of localizing similar semantic concepts within an image or a set of images. We use DFF to gain insight into a deep convolutional neural network's learned features, where we detect hierarchical cluster structures in feature space. This is visualized as heat maps, which highlight semantically matching regions across a set of images, revealing what the network `perceives' as similar. DFF can also be used to perform co-segmentation and co-localization, and we report state-of-the-art results on these tasks.

</details>

<details>

<summary>2018-10-08 11:33:13 - Identification of promoted eclipse unstable interfaces using clone detection technique</summary>

- *Simon Kawuma, Evarist Nabaasa*

- `1810.03381v1` - [abs](http://arxiv.org/abs/1810.03381v1) - [pdf](http://arxiv.org/pdf/1810.03381v1)

> The Eclipse framework is a popular and widely used framework that has been evolving for over a decade. The framework provides both stable interfaces (APIs) and unstable interfaces (non-APIs). Despite being discouraged by Eclipse, client developers often use non-APIs which may cause their systems to fail when ported to new framework releases. To overcome this problem, Eclipse interface producers may promote unstable interfaces to APIs. However, client developers have no assistance to aid them to identify the promoted unstable interfaces in the Eclipse framework. We aim to help API users identify promoted unstable interfaces. We used the clone detection technique to identify promoted unstable interfaces as the framework evolves. Our empirical investigation on 16 Eclipse major releases presents the following observations. First, we have discovered that there exists over 60% non-API methods of the total interfaces in each of the analyzed 16 Eclipse releases. Second, we have discovered that the percentage of promoted non-APIs identified through clone detection ranges from 0.20% to 10.38%.

</details>

<details>

<summary>2018-10-08 21:51:44 - Comparing Models of Associative Meaning: An Empirical Investigation of Reference in Simple Language Games</summary>

- *Judy Hanwen Shen, Matthias Hofer, Bjarke Felbo, Roger Levy*

- `1810.03717v1` - [abs](http://arxiv.org/abs/1810.03717v1) - [pdf](http://arxiv.org/pdf/1810.03717v1)

> Simple reference games are of central theoretical and empirical importance in the study of situated language use. Although language provides rich, compositional truth-conditional semantics to facilitate reference, speakers and listeners may sometimes lack the overall lexical and cognitive resources to guarantee successful reference through these means alone. However, language also has rich associational structures that can serve as a further resource for achieving successful reference. Here we investigate this use of associational information in a setting where only associational information is available: a simplified version of the popular game Codenames. Using optimal experiment design techniques, we compare a range of models varying in the type of associative information deployed and in level of pragmatic sophistication against human behavior. In this setting, we find that listeners' behavior reflects direct bigram collocational associations more strongly than word-embedding or semantic knowledge graph-based associations and that there is little evidence for pragmatically sophisticated behavior by either speakers or listeners of the type that might be predicted by recursive-reasoning models such as the Rational Speech Acts theory. These results shed light on the nature of the lexical resources that speakers and listeners can bring to bear in achieving reference through associative meaning alone.

</details>

<details>

<summary>2018-10-09 03:34:18 - Weight Learning in a Probabilistic Extension of Answer Set Programs</summary>

- *Joohyung Lee, Yi Wang*

- `1808.04527v2` - [abs](http://arxiv.org/abs/1808.04527v2) - [pdf](http://arxiv.org/pdf/1808.04527v2)

> LPMLN is a probabilistic extension of answer set programs with the weight scheme derived from that of Markov Logic. Previous work has shown how inference in LPMLN can be achieved. In this paper, we present the concept of weight learning in LPMLN and learning algorithms for LPMLN derived from those for Markov Logic. We also present a prototype implementation that uses answer set solvers for learning as well as some example domains that illustrate distinct features of LPMLN learning. Learning in LPMLN is in accordance with the stable model semantics, thereby it learns parameters for probabilistic extensions of knowledge-rich domains where answer set programming has shown to be useful but limited to the deterministic case, such as reachability analysis and reasoning about actions in dynamic domains. We also apply the method to learn the parameters for probabilistic abductive reasoning about actions.

</details>

<details>

<summary>2018-10-09 08:30:44 - Interpreting Winograd Schemas Via the SP Theory of Intelligence and Its Realisation in the SP Computer Model</summary>

- *J Gerard Wolff*

- `1810.04554v1` - [abs](http://arxiv.org/abs/1810.04554v1) - [pdf](http://arxiv.org/pdf/1810.04554v1)

> In 'Winograd Schema' (WS) sentences like "The city councilmen refused the demonstrators a permit because they feared violence" and "The city councilmen refused the demonstrators a permit because they advocated revolution", it is easy for adults to understand what "they" refers to but can be difficult for AI systems. This paper describes how the SP System -- outlined in an appendix -- may solve this kind of problem of interpretation. The central idea is that a knowledge of discontinuous associations amongst linguistic features, and an ability to recognise such patterns of associations, provides a robust means of determining what a pronoun like "they" refers to. For any AI system to solve this kind of problem, it needs appropriate knowledge of relevant syntax and semantics which, ideally, it should learn for itself. Although the SP System has some strengths in unsupervised learning, its capabilities in this area are not yet good enough to learn the kind of knowledge needed to interpret WS examples, so it must be supplied with such knowledge at the outset. However, its existing strengths in unsupervised learning suggest that it has potential to learn the kind of knowledge needed for the interpretation of WS examples. In particular, it has potential to learn the kind of discontinuous association of linguistic features mentioned earlier.

</details>

<details>

<summary>2018-10-09 08:50:39 - BabelView: Evaluating the Impact of Code Injection Attacks in Mobile Webviews</summary>

- *Claudio Rizzo, Lorenzo Cavallaro, Johannes Kinder*

- `1709.05690v2` - [abs](http://arxiv.org/abs/1709.05690v2) - [pdf](http://arxiv.org/pdf/1709.05690v2)

> A Webview embeds a full-fledged browser in a mobile application and allows the application to expose a custom interface to JavaScript code. This is a popular technique to build so-called hybrid applications, but it circumvents the usual security model of the browser: any malicious JavaScript code injected into the Webview gains access to the interface and can use it to manipulate the device or exfiltrate sensitive data. In this paper, we present an approach to systematically evaluate the possible impact of code injection attacks against Webviews using static information flow analysis. Our key idea is that we can make reasoning about JavaScript semantics unnecessary by instrumenting the application with a model of possible attacker behavior -- the BabelView. We evaluate our approach on 11,648 apps from various Android marketplaces, finding 2,677 vulnerabilities in 1,663 apps. Taken together, the apps reported as vulnerable have over 835 million installations worldwide. We manually validated a random sample of 66 apps and estimate that our fully automated analysis achieves a precision of 90% at a recall of 66%.

</details>

<details>

<summary>2018-10-09 09:28:27 - Towards Verifying Semantic Roles Co-occurrence</summary>

- *Aliaksandr Huminski, Hao Zhang, Gangeshwar Krishnamurthy*

- `1810.03875v1` - [abs](http://arxiv.org/abs/1810.03875v1) - [pdf](http://arxiv.org/pdf/1810.03875v1)

> Semantic role theory considers roles as a small universal set of unanalyzed entities. It means that formally there are no restrictions on role combinations. We argue that the semantic roles co-occur in verb representations. It means that there are hidden restrictions on role combinations. To demonstrate that a practical and evidence-based approach has been built on in-depth analysis of the largest verb database VerbNet. The consequences of this approach are considered.

</details>

<details>

<summary>2018-10-09 09:37:31 - Event Representation through Semantic Roles: Evaluation of Coverage</summary>

- *Aliaksandr Huminski, Hao Zhang*

- `1810.03879v1` - [abs](http://arxiv.org/abs/1810.03879v1) - [pdf](http://arxiv.org/pdf/1810.03879v1)

> Semantic role theory is a widely used approach for event representation. Yet, there are multiple indications that semantic role paradigm is necessary but not sufficient to cover all elements of event structure. We conducted an analysis of semantic role representation for events to provide an empirical evidence of insufficiency. The consequence of that is a hybrid role-scalar approach. The results are considered as preliminary in investigation of semantic roles coverage for event representation.

</details>

<details>

<summary>2018-10-09 10:49:35 - Sentence Entailment in Compositional Distributional Semantics</summary>

- *Esma Balkir, Dimitri Kartsaklis, Mehrnoosh Sadrzadeh*

- `1512.04419v2` - [abs](http://arxiv.org/abs/1512.04419v2) - [pdf](http://arxiv.org/pdf/1512.04419v2)

> Distributional semantic models provide vector representations for words by gathering co-occurrence frequencies from corpora of text. Compositional distributional models extend these from words to phrases and sentences. In categorical compositional distributional semantics, phrase and sentence representations are functions of their grammatical structure and representations of the words therein. In this setting, grammatical structures are formalised by morphisms of a compact closed category and meanings of words are formalised by objects of the same category. These can be instantiated in the form of vectors or density matrices. This paper concerns the applications of this model to phrase and sentence level entailment. We argue that entropy-based distances of vectors and density matrices provide a good candidate to measure word-level entailment, show the advantage of density matrices over vectors for word level entailments, and prove that these distances extend compositionally from words to phrases and sentences. We exemplify our theoretical constructions on real data and a toy entailment dataset and provide preliminary experimental evidence.

</details>

<details>

<summary>2018-10-09 19:00:52 - Event Coreference Resolution Using Neural Network Classifiers</summary>

- *Arun Pandian, Lamana Mulaffer, Kemal Oflazer, Amna AlZeyara*

- `1810.04216v1` - [abs](http://arxiv.org/abs/1810.04216v1) - [pdf](http://arxiv.org/pdf/1810.04216v1)

> This paper presents a neural network classifier approach to detecting both within- and cross- document event coreference effectively using only event mention based features. Our approach does not (yet) rely on any event argument features such as semantic roles or spatiotemporal arguments. Experimental results on the ECB+ dataset show that our approach produces F1 scores that significantly outperform the state-of-the-art methods for both within-document and cross-document event coreference resolution when we use B3 and CEAFe evaluation measures, but gets worse F1 score with the MUC measure. However, when we use the CoNLL measure, which is the average of these three scores, our approach has slightly better F1 for within- document event coreference resolution but is significantly better for cross-document event coreference resolution.

</details>

<details>

<summary>2018-10-10 12:14:04 - End-to-End Text Classification via Image-based Embedding using Character-level Networks</summary>

- *Shunsuke Kitada, Ryunosuke Kotani, Hitoshi Iyatomi*

- `1810.03595v2` - [abs](http://arxiv.org/abs/1810.03595v2) - [pdf](http://arxiv.org/pdf/1810.03595v2)

> For analysing and/or understanding languages having no word boundaries based on morphological analysis such as Japanese, Chinese, and Thai, it is desirable to perform appropriate word segmentation before word embeddings. But it is inherently difficult in these languages. In recent years, various language models based on deep learning have made remarkable progress, and some of these methodologies utilizing character-level features have successfully avoided such a difficult problem. However, when a model is fed character-level features of the above languages, it often causes overfitting due to a large number of character types. In this paper, we propose a CE-CLCNN, character-level convolutional neural networks using a character encoder to tackle these problems. The proposed CE-CLCNN is an end-to-end learning model and has an image-based character encoder, i.e. the CE-CLCNN handles each character in the target document as an image. Through various experiments, we found and confirmed that our CE-CLCNN captured closely embedded features for visually and semantically similar characters and achieves state-of-the-art results on several open document classification tasks. In this paper we report the performance of our CE-CLCNN with the Wikipedia title estimation task and analyse the internal behaviour.

</details>

<details>

<summary>2018-10-10 21:42:29 - Leveraging Textual Specifications for Grammar-based Fuzzing of Network Protocols</summary>

- *Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser, Cristina Nita-Rotaru*

- `1810.04755v1` - [abs](http://arxiv.org/abs/1810.04755v1) - [pdf](http://arxiv.org/pdf/1810.04755v1)

> Grammar-based fuzzing is a technique used to find software vulnerabilities by injecting well-formed inputs generated following rules that encode application semantics. Most grammar-based fuzzers for network protocols rely on human experts to manually specify these rules. In this work we study automated learning of protocol rules from textual specifications (i.e. RFCs). We evaluate the automatically extracted protocol rules by applying them to a state-of-the-art fuzzer for transport protocols and show that it leads to a smaller number of test cases while finding the same attacks as the system that uses manually specified rules.

</details>

<details>

<summary>2018-10-10 23:12:01 - The IFF Foundation for Ontological Knowledge Organization</summary>

- *Robert E. Kent*

- `1810.04773v1` - [abs](http://arxiv.org/abs/1810.04773v1) - [pdf](http://arxiv.org/pdf/1810.04773v1)

> This paper discusses an axiomatic approach for the integration of ontologies, an approach that extends to first order logic a previous approach (Kent 2000) based on information flow. This axiomatic approach is represented in the Information Flow Framework (IFF), a metalevel framework for organizing the information that appears in digital libraries, distributed databases and ontologies (Kent 2001). The paper argues that the integration of ontologies is the two-step process of alignment and unification. Ontological alignment consists of the sharing of common terminology and semantics through a mediating ontology. Ontological unification, concentrated in a virtual ontology of community connections, is fusion of the alignment diagram of participant community ontologies - the quotient of the sum of the participant portals modulo the ontological alignment structure.

</details>

<details>

<summary>2018-10-11 13:54:50 - Semantic Structural Evaluation for Text Simplification</summary>

- *Elior Sulem, Omri Abend, Ari Rappoport*

- `1810.05022v1` - [abs](http://arxiv.org/abs/1810.05022v1) - [pdf](http://arxiv.org/pdf/1810.05022v1)

> Current measures for evaluating text simplification systems focus on evaluating lexical text aspects, neglecting its structural aspects. In this paper we propose the first measure to address structural aspects of text simplification, called SAMSA. It leverages recent advances in semantic parsing to assess simplification quality by decomposing the input based on its semantic structure and comparing it to the output. SAMSA provides a reference-less automatic evaluation procedure, avoiding the problems that reference-based methods face due to the vast space of valid simplifications for a given sentence. Our human evaluation experiments show both SAMSA's substantial correlation with human judgments, as well as the deficiency of existing reference-based measures in evaluating structural simplification.

</details>

<details>

<summary>2018-10-11 16:14:24 - Simple and Effective Text Simplification Using Semantic and Neural Methods</summary>

- *Elior Sulem, Omri Abend, Ari Rappoport*

- `1810.05104v1` - [abs](http://arxiv.org/abs/1810.05104v1) - [pdf](http://arxiv.org/pdf/1810.05104v1)

> Sentence splitting is a major simplification operator. Here we present a simple and efficient splitting algorithm based on an automatic semantic parser. After splitting, the text is amenable for further fine-tuned simplification operations. In particular, we show that neural Machine Translation can be effectively used in this situation. Previous application of Machine Translation for simplification suffers from a considerable disadvantage in that they are over-conservative, often failing to modify the source in any way. Splitting based on semantic parsing, as proposed here, alleviates this issue. Extensive automatic and human evaluation shows that the proposed method compares favorably to the state-of-the-art in combined lexical and structural simplification.

</details>

<details>

<summary>2018-10-11 17:03:44 - Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation</summary>

- *Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, Mingyan Liu, Dawn Song*

- `1810.05162v1` - [abs](http://arxiv.org/abs/1810.05162v1) - [pdf](http://arxiv.org/pdf/1810.05162v1)

> Deep Neural Networks (DNNs) have been widely applied in various recognition tasks. However, recently DNNs have been shown to be vulnerable against adversarial examples, which can mislead DNNs to make arbitrary incorrect predictions. While adversarial examples are well studied in classification tasks, other learning problems may have different properties. For instance, semantic segmentation requires additional components such as dilated convolutions and multiscale processing. In this paper, we aim to characterize adversarial examples based on spatial context information in semantic segmentation. We observe that spatial consistency information can be potentially leveraged to detect adversarial examples robustly even when a strong adaptive attacker has access to the model and detection strategies. We also show that adversarial examples based on attacks considered within the paper barely transfer among models, even though transferability is common in classification. Our observations shed new light on developing adversarial attacks and defenses to better understand the vulnerabilities of DNNs.

</details>

<details>

<summary>2018-10-12 02:19:42 - Important Attribute Identification in Knowledge Graph</summary>

- *Shengjie Sun, Dong Yang, Hongchun Zhang, Yanxu Chen, Chao Wei, Xiaonan Meng, Yi Hu*

- `1810.05320v1` - [abs](http://arxiv.org/abs/1810.05320v1) - [pdf](http://arxiv.org/pdf/1810.05320v1)

> The knowledge graph(KG) composed of entities with their descriptions and attributes, and relationship between entities, is finding more and more application scenarios in various natural language processing tasks. In a typical knowledge graph like Wikidata, entities usually have a large number of attributes, but it is difficult to know which ones are important. The importance of attributes can be a valuable piece of information in various applications spanning from information retrieval to natural language generation. In this paper, we propose a general method of using external user generated text data to evaluate the relative importance of an entity's attributes. To be more specific, we use the word/sub-word embedding techniques to match the external textual data back to entities' attribute name and values and rank the attributes by their matching cohesiveness. To our best knowledge, this is the first work of applying vector based semantic matching to important attribute identification, and our method outperforms the previous traditional methods. We also apply the outcome of the detected important attributes to a language generation task; compared with previous generated text, the new method generates much more customized and informative messages.

</details>

<details>

<summary>2018-10-12 09:33:18 - Axiomatizing Category Theory in Free Logic</summary>

- *Christoph Benzmüller, Dana S. Scott*

- `1609.01493v5` - [abs](http://arxiv.org/abs/1609.01493v5) - [pdf](http://arxiv.org/pdf/1609.01493v5)

> Starting from a generalization of the standard axioms for a monoid we present a stepwise development of various, mutually equivalent foundational axiom systems for category theory. Our axiom sets have been formalized in the Isabelle/HOL interactive proof assistant, and this formalization utilizes a semantically correct embedding of free logic in classical higher-order logic. The modeling and formal analysis of our axiom sets has been significantly supported by series of experiments with automated reasoning tools integrated with Isabelle/HOL. We also address the relation of our axiom systems to alternative proposals from the literature, including an axiom set proposed by Freyd and Scedrov for which we reveal a technical issue (when encoded in free logic where free variables range over defined and undefined objects): either all operations, e.g. morphism composition, are total or their axiom system is inconsistent. The repair for this problem is quite straightforward, however.

</details>

<details>

<summary>2018-10-12 15:14:00 - Grand Challenge: Real-time Destination and ETA Prediction for Maritime Traffic</summary>

- *Oleh Bodunov, Florian Schmidt, André Martin, Andrey Brito, Christof Fetzer*

- `1810.05567v1` - [abs](http://arxiv.org/abs/1810.05567v1) - [pdf](http://arxiv.org/pdf/1810.05567v1)

> In this paper, we present our approach for solving the DEBS Grand Challenge 2018. The challenge asks to provide a prediction for (i) a destination and the (ii) arrival time of ships in a streaming-fashion using Geo-spatial data in the maritime context. Novel aspects of our approach include the use of ensemble learning based on Random Forest, Gradient Boosting Decision Trees (GBDT), XGBoost Trees and Extremely Randomized Trees (ERT) in order to provide a prediction for a destination while for the arrival time, we propose the use of Feed-forward Neural Networks. In our evaluation, we were able to achieve an accuracy of 97% for the port destination classification problem and 90% (in mins) for the ETA prediction.

</details>

<details>

<summary>2018-10-12 19:54:11 - Formal Concept Analysis with Many-sorted Attributes</summary>

- *Robert E. Kent, John Brady*

- `1810.05703v1` - [abs](http://arxiv.org/abs/1810.05703v1) - [pdf](http://arxiv.org/pdf/1810.05703v1)

> This paper unites two problem-solving traditions in computer science: (1) constraint-based reasoning, and (2) formal concept analysis. For basic definitions and properties of networks of constraints, we follow the foundational approach of Montanari and Rossi. This paper advocates distributed relations as a more semantic version of networks of constraints. The theory developed here uses the theory of formal concept analysis, pioneered by Rudolf Wille and his colleagues, as a key for unlocking the hidden semantic structure within distributed relations. Conversely, this paper offers distributed relations as a seamless many-sorted extension to the formal contexts of formal concept analysis. Some of the intuitions underlying our approach were discussed in a preliminary fashion by Freuder and Wallace.

</details>

<details>

<summary>2018-10-13 06:35:18 - Human-competitive Patches in Automatic Program Repair with Repairnator</summary>

- *Martin Monperrus, Simon Urli, Thomas Durieux, Matias Martinez, Benoit Baudry, Lionel Seinturier*

- `1810.05806v1` - [abs](http://arxiv.org/abs/1810.05806v1) - [pdf](http://arxiv.org/pdf/1810.05806v1)

> Repairnator is a bot. It constantly monitors software bugs discovered during continuous integration of open-source software and tries to fix them automatically. If it succeeds to synthesize a valid patch, Repairnator proposes the patch to the human developers, disguised under a fake human identity. To date, Repairnator has been able to produce 5 patches that were accepted by the human developers and permanently merged in the code base. This is a milestone for human-competitiveness in software engineering research on automatic program repair.

</details>

<details>

<summary>2018-10-13 13:52:11 - On the security of the hierarchical attribute based encryption scheme proposed by Wang et al</summary>

- *Mohammad Ali, Javad Mohajeri, Mohammad-Reza Sadeghi*

- `1810.05864v1` - [abs](http://arxiv.org/abs/1810.05864v1) - [pdf](http://arxiv.org/pdf/1810.05864v1)

> Ciphertext-policy hierarchical attribute-based encryption (CP-HABE) is a promising cryptographic primitive for enforcing the fine-grained access control with scalable key delegation and user revocation mechanisms on the outsourced encrypted data in a cloud. Wang et al. (2011) proposed the first CP-HABE scheme and showed that the scheme is semantically secure in the random oracle model [4, 5]. Due to some weakness in its key delegation mechanism, by presenting two attacks, we demonstrate the scheme does not offer any confidentiality and fine-grained access control. In this way, anyone who has just one attribute can recover any outsourced encrypted data in the cloud.

</details>

<details>

<summary>2018-10-14 04:55:06 - A Comprehensive Survey of Deep Learning for Image Captioning</summary>

- *Md. Zakir Hossain, Ferdous Sohel, Mohd Fairuz Shiratuddin, Hamid Laga*

- `1810.04020v2` - [abs](http://arxiv.org/abs/1810.04020v2) - [pdf](http://arxiv.org/pdf/1810.04020v2)

> Generating a description of an image is called image captioning. Image captioning requires to recognize the important objects, their attributes and their relationships in an image. It also needs to generate syntactically and semantically correct sentences. Deep learning-based techniques are capable of handling the complexities and challenges of image captioning. In this survey paper, we aim to present a comprehensive review of existing deep learning-based image captioning techniques. We discuss the foundation of the techniques to analyze their performances, strengths and limitations. We also discuss the datasets and the evaluation metrics popularly used in deep learning based automatic image captioning.

</details>

<details>

<summary>2018-10-14 17:08:54 - Robust Neural Abstractive Summarization Systems and Evaluation against Adversarial Information</summary>

- *Lisa Fan, Dong Yu, Lu Wang*

- `1810.06065v1` - [abs](http://arxiv.org/abs/1810.06065v1) - [pdf](http://arxiv.org/pdf/1810.06065v1)

> Sequence-to-sequence (seq2seq) neural models have been actively investigated for abstractive summarization. Nevertheless, existing neural abstractive systems frequently generate factually incorrect summaries and are vulnerable to adversarial information, suggesting a crucial lack of semantic understanding. In this paper, we propose a novel semantic-aware neural abstractive summarization model that learns to generate high quality summaries through semantic interpretation over salient content. A novel evaluation scheme with adversarial samples is introduced to measure how well a model identifies off-topic information, where our model yields significantly better performance than the popular pointer-generator summarizer. Human evaluation also confirms that our system summaries are uniformly more informative and faithful as well as less redundant than the seq2seq model.

</details>

<details>

<summary>2018-10-14 19:11:19 - Conceptual Collectives</summary>

- *Robert E. Kent*

- `1810.07632v1` - [abs](http://arxiv.org/abs/1810.07632v1) - [pdf](http://arxiv.org/pdf/1810.07632v1)

> The notions of formal contexts and concept lattices, although introduced by Wille only ten years ago, already have proven to be of great utility in various applications such as data analysis and knowledge representation. In this paper we give arguments that Wille's original notion of formal context, although quite appealing in its simplicity, now should be replaced by a more semantic notion. This new notion of formal context entails a modified approach to concept construction. We base our arguments for these new versions of formal context and concept construction upon Wille's philosophical attitude with reference to the intensional aspect of concepts. We give a brief development of the relational theory of formal contexts and concept construction, demonstrating the equivalence of "concept-lattice construction" of Wille with the well-known "completion by cuts" of MacNeille. Generalization and abstraction of these formal contexts offers a powerful approach to knowledge representation.

</details>

<details>

<summary>2018-10-15 01:21:26 - Paraphrase Thought: Sentence Embedding Module Imitating Human Language Recognition</summary>

- *Myeongjun Jang, Pilsung Kang*

- `1808.05505v3` - [abs](http://arxiv.org/abs/1808.05505v3) - [pdf](http://arxiv.org/pdf/1808.05505v3)

> Sentence embedding is an important research topic in natural language processing. It is essential to generate a good embedding vector that fully reflects the semantic meaning of a sentence in order to achieve an enhanced performance for various natural language processing tasks, such as machine translation and document classification. Thus far, various sentence embedding models have been proposed, and their feasibility has been demonstrated through good performances on tasks following embedding, such as sentiment analysis and sentence classification. However, because the performances of sentence classification and sentiment analysis can be enhanced by using a simple sentence representation method, it is not sufficient to claim that these models fully reflect the meanings of sentences based on good performances for such tasks. In this paper, inspired by human language recognition, we propose the following concept of semantic coherence, which should be satisfied for a good sentence embedding method: similar sentences should be located close to each other in the embedding space. Then, we propose the Paraphrase-Thought (P-thought) model to pursue semantic coherence as much as possible. Experimental results on two paraphrase identification datasets (MS COCO and STS benchmark) show that the P-thought models outperform the benchmarked sentence embedding methods.

</details>

<details>

<summary>2018-10-15 10:55:24 - Term Set Expansion based NLP Architect by Intel AI Lab</summary>

- *Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Alon Eirew, Yael Green, Shira Guskin, Peter Izsak, Daniel Korat*

- `1808.08953v2` - [abs](http://arxiv.org/abs/1808.08953v2) - [pdf](http://arxiv.org/pdf/1808.08953v2)

> We present SetExpander, a corpus-based system for expanding a seed set of terms into amore complete set of terms that belong to the same semantic class. SetExpander implements an iterative end-to-end workflow. It enables users to easily select a seed set of terms, expand it, view the expanded set, validate it, re-expand the validated set and store it, thus simplifying the extraction of domain-specific fine-grained semantic classes.SetExpander has been used successfully in real-life use cases including integration into an automated recruitment system and an issues and defects resolution system. A video demo of SetExpander is available at https://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images were blurred for privacy reasons)

</details>

<details>

<summary>2018-10-15 14:43:16 - Understanding the Role of Data-Centric Social Context in Personalized Mobile Applications</summary>

- *Iqbal H. Sarker*

- `1811.02615v1` - [abs](http://arxiv.org/abs/1811.02615v1) - [pdf](http://arxiv.org/pdf/1811.02615v1)

> Context-awareness in personalized mobile applications is a growing area of study. Social context is one of the most important sources of information in human-activity based applications. In this paper, we mainly focus on social relational context that represents the interpersonal relationship between individuals, and the role or influence of such context on users' diverse phone call activities in their real world life. Individuals different phone call activities such as making a phone call to a particular person or responding an incoming call may differ from person-to-person based on their interpersonal relationships such as family, friend, or colleague. However, it is very difficult to make the device understandable about such semantic relationships between individuals and the relevant context-aware applications. To address this issue, in this paper, we explore the data-centric social relational context that can play a significant role in building context-aware personalized mobile applications for various purposes in our real world life.

</details>

<details>

<summary>2018-10-15 17:45:02 - Visual Semantic Navigation using Scene Priors</summary>

- *Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi*

- `1810.06543v1` - [abs](http://arxiv.org/abs/1810.06543v1) - [pdf](http://arxiv.org/pdf/1810.06543v1)

> How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we search cabinets near the coffee machine and for fruits we try the fridge. In this work, we focus on incorporating semantic priors in the task of semantic navigation. We propose to use Graph Convolutional Networks for incorporating the prior knowledge into a deep reinforcement learning framework. The agent uses the features from the knowledge graph to predict the actions. For evaluation, we use the AI2-THOR framework. Our experiments show how semantic knowledge improves performance significantly. More importantly, we show improvement in generalization to unseen scenes and/or objects. The supplementary video can be accessed at the following link: https://youtu.be/otKjuO805dE .

</details>

<details>

<summary>2018-10-15 23:22:10 - Assessing the Contribution of Semantic Congruency to Multisensory Integration and Conflict Resolution</summary>

- *Di Fu, Pablo Barros, German I. Parisi, Haiyan Wu, Sven Magg, Xun Liu, Stefan Wermter*

- `1810.06748v1` - [abs](http://arxiv.org/abs/1810.06748v1) - [pdf](http://arxiv.org/pdf/1810.06748v1)

> The efficient integration of multisensory observations is a key property of the brain that yields the robust interaction with the environment. However, artificial multisensory perception remains an open issue especially in situations of sensory uncertainty and conflicts. In this work, we extend previous studies on audio-visual (AV) conflict resolution in complex environments. In particular, we focus on quantitatively assessing the contribution of semantic congruency during an AV spatial localization task. In addition to conflicts in the spatial domain (i.e. spatially misaligned stimuli), we consider gender-specific conflicts with male and female avatars. Our results suggest that while semantically related stimuli affect the magnitude of the visual bias (perceptually shifting the location of the sound towards a semantically congruent visual cue), humans still strongly rely on environmental statistics to solve AV conflicts. Together with previously reported results, this work contributes to a better understanding of how multisensory integration and conflict resolution can be modelled in artificial agents and robots operating in real-world environments.

</details>

<details>

<summary>2018-10-16 11:30:54 - CNN-based Preprocessing to Optimize Watershed-based Cell Segmentation in 3D Confocal Microscopy Images</summary>

- *Dennis Eschweiler, Thiago V. Spina, Rohan C. Choudhury, Elliot Meyerowitz, Alexandre Cunha, Johannes Stegmaier*

- `1810.06933v1` - [abs](http://arxiv.org/abs/1810.06933v1) - [pdf](http://arxiv.org/pdf/1810.06933v1)

> The quantitative analysis of cellular membranes helps understanding developmental processes at the cellular level. Particularly 3D microscopic image data offers valuable insights into cell dynamics, but error-free automatic segmentation remains challenging due to the huge amount of data generated and strong variations in image intensities. In this paper, we propose a new 3D segmentation approach which combines the discriminative power of convolutional neural networks (CNNs) for preprocessing and investigates the performance of three watershed-based postprocessing strategies (WS), which are well suited to segment object shapes, even when supplied with vague seed and boundary constraints. To leverage the full potential of the watershed algorithm, the multi-instance segmentation problem is initially interpreted as three-class semantic segmentation problem, which in turn is well-suited for the application of CNNs. Using manually annotated 3D confocal microscopy images of Arabidopsis thaliana, we show the superior performance of the proposed method compared to the state of the art.

</details>

<details>

<summary>2018-10-16 14:21:18 - Optimizing AIREBO: Navigating the Journey from Complex Legacy Code to High Performance</summary>

- *Markus Höhnerbach, Paolo Bientinesi*

- `1810.07026v1` - [abs](http://arxiv.org/abs/1810.07026v1) - [pdf](http://arxiv.org/pdf/1810.07026v1)

> Despite initiatives to improve the quality of scientific codes, there still is a large presence of legacy code. Such code often needs to implement a lot of functionality under time constrains, sacrificing quality. Additionally, quality is rarely improved by optimizations for new architectures. This development model leads to code that is increasingly difficult to work with. Our suggested solution includes complexity-reducing refactoring and hardware abstraction. We focus on the AIREBO potential from LAMMPS, where the challenge is that any potential kernel is rather large and complex, hindering systematic optimization. This issue is common to codes that model multiple physical phenomena. We present our journey from the C++ port of a previous Fortran code to performance-portable, KNC-hybrid, vectorized, scalable, optimized code supporting full and reduced precision. The journey includes extensive testing that fixed bugs in the original code. Large-scale, full-precision runs sustain speedups of more than 4x (KNL) and 3x (Skylake).

</details>

<details>

<summary>2018-10-16 23:57:37 - Exploring Sentence Vector Spaces through Automatic Summarization</summary>

- *Adly Templeton, Jugal Kalita*

- `1810.07320v1` - [abs](http://arxiv.org/abs/1810.07320v1) - [pdf](http://arxiv.org/pdf/1810.07320v1)

> Given vector representations for individual words, it is necessary to compute vector representations of sentences for many applications in a compositional manner, often using artificial neural networks.   Relatively little work has explored the internal structure and properties of such sentence vectors. In this paper, we explore the properties of sentence vectors in the context of automatic summarization. In particular, we show that cosine similarity between sentence vectors and document vectors is strongly correlated with sentence importance and that vector semantics can identify and correct gaps between the sentences chosen so far and the document. In addition, we identify specific dimensions which are linked to effective summaries. To our knowledge, this is the first time specific dimensions of sentence embeddings have been connected to sentence properties. We also compare the features of different methods of sentence embeddings. Many of these insights have applications in uses of sentence embeddings far beyond summarization.

</details>

<details>

<summary>2018-10-17 17:59:56 - The Institutional Approach</summary>

- *Robert E. Kent*

- `1810.08074v1` - [abs](http://arxiv.org/abs/1810.08074v1) - [pdf](http://arxiv.org/pdf/1810.08074v1)

> This chapter discusses the institutional approach for organizing and maintaining ontologies. The theory of institutions was named and initially developed by Joseph Goguen and Rod Burstall. This theory, a metatheory based on category theory, regards ontologies as logical theories or local logics. The theory of institutions uses the category-theoretic ideas of fibrations and indexed categories to develop logical theories. Institutions unite the lattice approach of Formal Concept Analysis of Ganter and Wille with the distributed logic of Information Flow of Barwise and Seligman. The institutional approach incorporates locally the lattice of theories idea of Sowa from the theory of knowledge representation. The Information Flow Framework, which was initiated within the IEEE Standard Upper Ontology project, uses the institutional approach in its applied aspect for the comparison, semantic integration and maintenance of ontologies. This chapter explains the central ideas of the institutional approach to ontologies in a careful and detailed manner.

</details>

<details>

<summary>2018-10-18 05:18:04 - Analyzing and Interpreting Convolutional Neural Networks in NLP</summary>

- *Mahnaz Koupaee, William Yang Wang*

- `1810.09312v1` - [abs](http://arxiv.org/abs/1810.09312v1) - [pdf](http://arxiv.org/pdf/1810.09312v1)

> Convolutional neural networks have been successfully applied to various NLP tasks. However, it is not obvious whether they model different linguistic patterns such as negation, intensification, and clause compositionality to help the decision-making process. In this paper, we apply visualization techniques to observe how the model can capture different linguistic features and how these features can affect the performance of the model. Later on, we try to identify the model errors and their sources. We believe that interpreting CNNs is the first step to understand the underlying semantic features which can raise awareness to further improve the performance and explainability of CNN models.

</details>

<details>

<summary>2018-10-18 08:22:49 - Semantic Parsing for Task Oriented Dialog using Hierarchical Representations</summary>

- *Sonal Gupta, Rushin Shah, Mrinal Mohit, Anuj Kumar, Mike Lewis*

- `1810.07942v1` - [abs](http://arxiv.org/abs/1810.07942v1) - [pdf](http://arxiv.org/pdf/1810.07942v1)

> Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots. Previous work on task oriented intent and slot-filling work has been restricted to one intent per query and one slot label per token, and thus cannot model complex compositional requests. Alternative semantic parsing systems have represented queries as logical forms, but these are challenging to annotate and parse. We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries, and can be efficiently and accurately parsed by standard constituency parsing models. We release a dataset of 44k annotated queries (fb.me/semanticparsingdialog), and show that parsing models outperform sequence-to-sequence approaches on this dataset.

</details>

<details>

<summary>2018-10-18 14:29:50 - Discourse Embellishment Using a Deep Encoder-Decoder Network</summary>

- *Leonid Berov, Kai Standvoss*

- `1810.08076v1` - [abs](http://arxiv.org/abs/1810.08076v1) - [pdf](http://arxiv.org/pdf/1810.08076v1)

> We suggest a new NLG task in the context of the discourse generation pipeline of computational storytelling systems. This task, textual embellishment, is defined by taking a text as input and generating a semantically equivalent output with increased lexical and syntactic complexity. Ideally, this would allow the authors of computational storytellers to implement just lightweight NLG systems and use a domain-independent embellishment module to translate its output into more literary text. We present promising first results on this task using LSTM Encoder-Decoder networks trained on the WikiLarge dataset. Furthermore, we introduce "Compiled Computer Tales", a corpus of computationally generated stories, that can be used to test the capabilities of embellishment algorithms.

</details>

<details>

<summary>2018-10-18 16:20:05 - TS-CNN: Text Steganalysis from Semantic Space Based on Convolutional Neural Network</summary>

- *Zhongliang Yang, Nan Wei, Junyi Sheng, Yongfeng Huang, Yu-Jin Zhang*

- `1810.08136v1` - [abs](http://arxiv.org/abs/1810.08136v1) - [pdf](http://arxiv.org/pdf/1810.08136v1)

> Steganalysis has been an important research topic in cybersecurity that helps to identify covert attacks in public network. With the rapid development of natural language processing technology in the past two years, coverless steganography has been greatly developed. Previous text steganalysis methods have shown unsatisfactory results on this new steganography technique and remain an unsolved challenge. Different from all previous text steganalysis methods, in this paper, we propose a text steganalysis method(TS-CNN) based on semantic analysis, which uses convolutional neural network(CNN) to extract high-level semantic features of texts, and finds the subtle distribution differences in the semantic space before and after embedding the secret information. To train and test the proposed model, we collected and released a large text steganalysis(CT-Steg) dataset, which contains a total number of 216,000 texts with various lengths and various embedding rates. Experimental results show that the proposed model can achieve nearly 100\% precision and recall, outperforms all the previous methods. Furthermore, the proposed model can even estimate the capacity of the hidden information inside. These results strongly support that using the subtle changes in the semantic space before and after embedding the secret information to conduct text steganalysis is feasible and effective.

</details>

<details>

<summary>2018-10-18 17:54:13 - Web Application for Collaborative Semantic Web Information Architecture</summary>

- *Massimiliano Dal Mas*

- `1810.08188v1` - [abs](http://arxiv.org/abs/1810.08188v1) - [pdf](http://arxiv.org/pdf/1810.08188v1)

> In this paper is analyzed the prototyping of the information visualization on a Web Application for community purposes in a collaborative environment representing an evolution of the actual social networks like Facebook, Instagram, Twitter, Linkedin, VirgilioPeople,... The intent of this work is to identify the most common features of Web App for the information visualization based on the Semantic Web and discuss how they support the user's requirements in a "collaborative" environment. A solution for the context-aware development of UI is based on "joint meaning" understood as a joint construal of the creator of the community contents and the user of the community contents thanks to the context and interface adaptation using the faced taxonomy with the Semantic Web. A proof-of concept prototype allows showing that the proposed methodological approach can also easily be applied to existing presentation components, built with different languages and/or component technologies.

</details>

<details>

<summary>2018-10-18 18:50:37 - Semantic Integration in the Information Flow Framework</summary>

- *Robert E. Kent*

- `1810.08236v1` - [abs](http://arxiv.org/abs/1810.08236v1) - [pdf](http://arxiv.org/pdf/1810.08236v1)

> The Information Flow Framework (IFF) is a descriptive category metatheory currently under development, which is being offered as the structural aspect of the Standard Upper Ontology (SUO). The architecture of the IFF is composed of metalevels, namespaces and meta-ontologies. The main application of the IFF is institutional: the notion of institutions and their morphisms are being axiomatized in the upper metalevels of the IFF, and the lower metalevel of the IFF has axiomatized various institutions in which semantic integration has a natural expression as the colimit of theories.

</details>

<details>

<summary>2018-10-19 01:08:05 - Domain-Invariant Projection Learning for Zero-Shot Recognition</summary>

- *An Zhao, Mingyu Ding, Jiechao Guan, Zhiwu Lu, Tao Xiang, Ji-Rong Wen*

- `1810.08326v1` - [abs](http://arxiv.org/abs/1810.08326v1) - [pdf](http://arxiv.org/pdf/1810.08326v1)

> Zero-shot learning (ZSL) aims to recognize unseen object classes without any training samples, which can be regarded as a form of transfer learning from seen classes to unseen ones. This is made possible by learning a projection between a feature space and a semantic space (e.g. attribute space). Key to ZSL is thus to learn a projection function that is robust against the often large domain gap between the seen and unseen classes. In this paper, we propose a novel ZSL model termed domain-invariant projection learning (DIPL). Our model has two novel components: (1) A domain-invariant feature self-reconstruction task is introduced to the seen/unseen class data, resulting in a simple linear formulation that casts ZSL into a min-min optimization problem. Solving the problem is non-trivial, and a novel iterative algorithm is formulated as the solver, with rigorous theoretic algorithm analysis provided. (2) To further align the two domains via the learned projection, shared semantic structure among seen and unseen classes is explored via forming superclasses in the semantic space. Extensive experiments show that our model outperforms the state-of-the-art alternatives by significant margins.

</details>

<details>

<summary>2018-10-19 01:21:08 - Transferrable Feature and Projection Learning with Class Hierarchy for Zero-Shot Learning</summary>

- *Aoxue Li, Zhiwu Lu, Jiechao Guan, Tao Xiang, Liwei Wang, Ji-Rong Wen*

- `1810.08329v1` - [abs](http://arxiv.org/abs/1810.08329v1) - [pdf](http://arxiv.org/pdf/1810.08329v1)

> Zero-shot learning (ZSL) aims to transfer knowledge from seen classes to unseen ones so that the latter can be recognised without any training samples. This is made possible by learning a projection function between a feature space and a semantic space (e.g. attribute space). Considering the seen and unseen classes as two domains, a big domain gap often exists which challenges ZSL. Inspired by the fact that an unseen class is not exactly `unseen' if it belongs to the same superclass as a seen class, we propose a novel inductive ZSL model that leverages superclasses as the bridge between seen and unseen classes to narrow the domain gap. Specifically, we first build a class hierarchy of multiple superclass layers and a single class layer, where the superclasses are automatically generated by data-driven clustering over the semantic representations of all seen and unseen class names. We then exploit the superclasses from the class hierarchy to tackle the domain gap challenge in two aspects: deep feature learning and projection function learning. First, to narrow the domain gap in the feature space, we integrate a recurrent neural network (RNN) defined with the superclasses into a convolutional neural network (CNN), in order to enforce the superclass hierarchy. Second, to further learn a transferrable projection function for ZSL, a novel projection function learning method is proposed by exploiting the superclasses to align the two domains. Importantly, our transferrable feature and projection learning methods can be easily extended to a closely related task -- few-shot learning (FSL). Extensive experiments show that the proposed model significantly outperforms the state-of-the-art alternatives in both ZSL and FSL tasks.

</details>

<details>

<summary>2018-10-19 01:52:03 - Zero and Few Shot Learning with Semantic Feature Synthesis and Competitive Learning</summary>

- *Zhiwu Lu, Jiechao Guan, Aoxue Li, Tao Xiang, An Zhao, Ji-Rong Wen*

- `1810.08332v1` - [abs](http://arxiv.org/abs/1810.08332v1) - [pdf](http://arxiv.org/pdf/1810.08332v1)

> Zero-shot learning (ZSL) is made possible by learning a projection function between a feature space and a semantic space (e.g.,~an attribute space). Key to ZSL is thus to learn a projection that is robust against the often large domain gap between the seen and unseen class domains. In this work, this is achieved by unseen class data synthesis and robust projection function learning. Specifically, a novel semantic data synthesis strategy is proposed, by which semantic class prototypes (e.g., attribute vectors) are used to simply perturb seen class data for generating unseen class ones. As in any data synthesis/hallucination approach, there are ambiguities and uncertainties on how well the synthesised data can capture the targeted unseen class data distribution. To cope with this, the second contribution of this work is a novel projection learning model termed competitive bidirectional projection learning (BPL) designed to best utilise the ambiguous synthesised data. Specifically, we assume that each synthesised data point can belong to any unseen class; and the most likely two class candidates are exploited to learn a robust projection function in a competitive fashion. As a third contribution, we show that the proposed ZSL model can be easily extended to few-shot learning (FSL) by again exploiting semantic (class prototype guided) feature synthesis and competitive BPL. Extensive experiments show that our model achieves the state-of-the-art results on both problems.

</details>

<details>

<summary>2018-10-19 06:26:33 - Developmental Bayesian Optimization of Black-Box with Visual Similarity-Based Transfer Learning</summary>

- *Maxime Petit, Amaury Depierre, Xiaofang Wang, Emmanuel Dellandréa, Liming Chen*

- `1809.10141v7` - [abs](http://arxiv.org/abs/1809.10141v7) - [pdf](http://arxiv.org/pdf/1809.10141v7)

> We present a developmental framework based on a long-term memory and reasoning mechanisms (Vision Similarity and Bayesian Optimisation). This architecture allows a robot to optimize autonomously hyper-parameters that need to be tuned from any action and/or vision module, treated as a black-box. The learning can take advantage of past experiences (stored in the episodic and procedural memories) in order to warm-start the exploration using a set of hyper-parameters previously optimized from objects similar to the new unknown one (stored in a semantic memory). As example, the system has been used to optimized 9 continuous hyper-parameters of a professional software (Kamido) both in simulation and with a real robot (industrial robotic arm Fanuc) with a total of 13 different objects. The robot is able to find a good object-specific optimization in 68 (simulation) or 40 (real) trials. In simulation, we demonstrate the benefit of the transfer learning based on visual similarity, as opposed to an amnesic learning (i.e. learning from scratch all the time). Moreover, with the real robot, we show that the method consistently outperforms the manual optimization from an expert with less than 2 hours of training time to achieve more than 88% of success.

</details>

<details>

<summary>2018-10-19 13:29:36 - A Framework for Robot Programming in Cobotic Environments: First user experiments</summary>

- *Ying Siu Liang, Damien Pellier, Humbert Fiorino, Sylvie Pesty*

- `1810.08492v1` - [abs](http://arxiv.org/abs/1810.08492v1) - [pdf](http://arxiv.org/pdf/1810.08492v1)

> The increasing presence of robots in industries has not gone unnoticed. Large industrial players have incorporated them into their production lines, but smaller companies hesitate due to high initial costs and the lack of programming expertise. In this work we introduce a framework that combines two disciplines, Programming by Demonstration and Automated Planning, to allow users without any programming knowledge to program a robot. The user teaches the robot atomic actions together with their semantic meaning and represents them in terms of preconditions and effects. Using these atomic actions the robot can generate action sequences autonomously to reach any goal given by the user. We evaluated the usability of our framework in terms of user experiments with a Baxter Research Robot and showed that it is well-adapted to users without any programming experience.

</details>

<details>

<summary>2018-10-19 19:20:17 - The Information Flow Foundation for Conceptual Knowledge Organization</summary>

- *Robert E. Kent*

- `1810.11369v1` - [abs](http://arxiv.org/abs/1810.11369v1) - [pdf](http://arxiv.org/pdf/1810.11369v1)

> The sharing of ontologies between diverse communities of discourse allows them to compare their own information structures with that of other communities that share a common terminology and semantics - ontology sharing facilitates interoperability between online knowledge organizations. This paper demonstrates how ontology sharing is formalizable within the conceptual knowledge model of Information Flow (IF). Information Flow indirectly represents sharing through a specifiable, ontology extension hierarchy augmented with synonymic type equivalencing - two ontologies share terminology and meaning through a common generic ontology that each extends. Using the paradigm of participant community ontologies formalized as IF logics, a common shared extensible ontology formalized as an IF theory, participant community specification links from the common ontology to the participating community ontology formalizable as IF theory interpretations, this paper argues that ontology sharing is concentrated in a virtual ontology of community connections, and demonstrates how this virtual ontology is computable as the fusion of the participant ontologies - the quotient of the sum of the participant ontologies modulo the ontological sharing structure.

</details>

<details>

<summary>2018-10-19 20:59:09 - Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts</summary>

- *Samuel Carton, Qiaozhu Mei, Paul Resnick*

- `1809.01499v2` - [abs](http://arxiv.org/abs/1809.01499v2) - [pdf](http://arxiv.org/pdf/1809.01499v2)

> We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate `default' behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.

</details>

<details>

<summary>2018-10-20 11:11:00 - Information, Meaning, and Intellectual Organization in Networks of Inter-Human Communication</summary>

- *Loet Leydesdorff*

- `1406.5688v3` - [abs](http://arxiv.org/abs/1406.5688v3) - [pdf](http://arxiv.org/pdf/1406.5688v3)

> The Shannon-Weaver model of linear information transmission is extended with two loops potentially generating redundancies: (i) meaning is provided locally to the information from the perspective of hindsight, and (ii) meanings can be codified differently and then refer to other horizons of meaning. Thus, three layers are distinguished: variations in the communications, historical organization at each moment of time, and evolutionary self-organization of the codes of communication over time. Furthermore, the codes of communication can functionally be different and then the system is both horizontally and vertically differentiated. All these subdynamics operate in parallel and necessarily generate uncertainty. However, meaningful information can be considered as the specific selection of a signal from the noise; the codes of communication are social constructs that can generate redundancy by giving different meanings to the same information. Reflexively, one can translate among codes in more elaborate discourses. The second (instantiating) layer can be operationalized in terms of semantic maps using the vector space model; the third in terms of mutual redundancy among the latent dimensions of the vector space. Using Blaise Cronin's {\oe}uvre, the different operations of the three layers are demonstrated empirically.

</details>

<details>

<summary>2018-10-22 04:52:39 - A general learning system based on neuron bursting and tonic firing</summary>

- *Hin Wai Lui*

- `1810.09084v1` - [abs](http://arxiv.org/abs/1810.09084v1) - [pdf](http://arxiv.org/pdf/1810.09084v1)

> This paper proposes a framework for the biological learning mechanism as a general learning system. The proposal is as follows. The bursting and tonic modes of firing patterns found in many neuron types in the brain correspond to two separate modes of information processing, with one mode resulting in awareness, and another mode being subliminal. In such a coding scheme, a neuron in bursting state codes for the highest level of perceptual abstraction representing a pattern of sensory stimuli, or volitional abstraction representing a pattern of muscle contraction sequences. Within the 50-250 ms minimum integration time of experience, the bursting neurons form synchrony ensembles to allow for binding of related percepts. The degree which different bursting neurons can be merged into the same synchrony ensemble depends on the underlying cortical connections that represent the degree of perceptual similarity. These synchrony ensembles compete for selective attention to remain active. The dominant synchrony ensemble triggers episodic memory recall in the hippocampus, while forming new episodic memory with current sensory stimuli, resulting in a stream of thoughts. Neuromodulation modulates both top-down selection of synchrony ensembles, and memory formation. Episodic memory stored in the hippocampus is transferred to semantic and procedural memory in the cortex during rapid eye movement sleep, by updating cortical neuron synaptic weights with spike timing dependent plasticity. With the update of synaptic weights, new neurons become bursting while previous bursting neurons become tonic, allowing bursting neurons to move up to a higher level of perceptual abstraction. Finally, the proposed learning mechanism is compared with the back-propagation algorithm used in deep neural networks, and a proposal of how the credit assignment problem can be addressed by the current proposal is presented.

</details>

<details>

<summary>2018-10-22 05:35:13 - Efficient Dependency-Guided Named Entity Recognition</summary>

- *Zhanming Jie, Aldrian Obaja Muis, Wei Lu*

- `1810.08436v2` - [abs](http://arxiv.org/abs/1810.08436v2) - [pdf](http://arxiv.org/pdf/1810.08436v2)

> Named entity recognition (NER), which focuses on the extraction of semantically meaningful named entities and their semantic classes from text, serves as an indispensable component for several down-stream natural language processing (NLP) tasks such as relation extraction and event extraction. Dependency trees, on the other hand, also convey crucial semantic-level information. It has been shown previously that such information can be used to improve the performance of NER (Sasano and Kurohashi 2008, Ling and Weld 2012). In this work, we investigate on how to better utilize the structured information conveyed by dependency trees to improve the performance of NER. Specifically, unlike existing approaches which only exploit dependency information for designing local features, we show that certain global structured information of the dependency trees can be exploited when building NER models where such information can provide guided learning and inference. Through extensive experiments, we show that our proposed novel dependency-guided NER model performs competitively with models based on conventional semi-Markov conditional random fields, while requiring significantly less running time.

</details>

<details>

<summary>2018-10-22 15:48:52 - Predictive Linguistic Features of Schizophrenia</summary>

- *Efsun Sarioglu Kayi, Mona Diab, Luca Pauselli, Michael Compton, Glen Coppersmith*

- `1810.09377v1` - [abs](http://arxiv.org/abs/1810.09377v1) - [pdf](http://arxiv.org/pdf/1810.09377v1)

> Schizophrenia is one of the most disabling and difficult to treat of all human medical/health conditions, ranking in the top ten causes of disability worldwide. It has been a puzzle in part due to difficulty in identifying its basic, fundamental components. Several studies have shown that some manifestations of schizophrenia (e.g., the negative symptoms that include blunting of speech prosody, as well as the disorganization symptoms that lead to disordered language) can be understood from the perspective of linguistics. However, schizophrenia research has not kept pace with technologies in computational linguistics, especially in semantics and pragmatics. As such, we examine the writings of schizophrenia patients analyzing their syntax, semantics and pragmatics. In addition, we analyze tweets of (self pro-claimed) schizophrenia patients who publicly discuss their diagnoses. For writing samples dataset, syntactic features are found to be the most successful in classification whereas for the less structured Twitter dataset, a combination of features performed the best.

</details>

<details>

<summary>2018-10-22 18:51:38 - Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation</summary>

- *Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, Spyridon Bakas*

- `1810.04304v2` - [abs](http://arxiv.org/abs/1810.04304v2) - [pdf](http://arxiv.org/pdf/1810.04304v2)

> Deep learning models for semantic segmentation of images require large amounts of data. In the medical imaging domain, acquiring sufficient data is a significant challenge. Labeling medical image data requires expert knowledge. Collaboration between institutions could address this challenge, but sharing medical data to a centralized location faces various legal, privacy, technical, and data-ownership challenges, especially among international institutions. In this study, we introduce the first use of federated learning for multi-institutional collaboration, enabling deep learning modeling without sharing patient data. Our quantitative results demonstrate that the performance of federated semantic segmentation models (Dice=0.852) on multimodal brain scans is similar to that of models trained by sharing data (Dice=0.862). We compare federated learning with two alternative collaborative learning methods and find that they fail to match the performance of federated learning.

</details>

<details>

<summary>2018-10-22 22:47:48 - Towards Universal Dialogue State Tracking</summary>

- *Liliang Ren, Kaige Xie, Lu Chen, Kai Yu*

- `1810.09587v1` - [abs](http://arxiv.org/abs/1810.09587v1) - [pdf](http://arxiv.org/pdf/1810.09587v1)

> Dialogue state tracking is the core part of a spoken dialogue system. It estimates the beliefs of possible user's goals at every dialogue turn. However, for most current approaches, it's difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don't work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.

</details>

<details>

<summary>2018-10-23 02:16:12 - A Neural Compositional Paradigm for Image Captioning</summary>

- *Bo Dai, Sanja Fidler, Dahua Lin*

- `1810.09630v1` - [abs](http://arxiv.org/abs/1810.09630v1) - [pdf](http://arxiv.org/pdf/1810.09630v1)

> Mainstream captioning models often follow a sequential structure to generate captions, leading to issues such as introduction of irrelevant semantics, lack of diversity in the generated captions, and inadequate generalization performance. In this paper, we present an alternative paradigm for image captioning, which factorizes the captioning procedure into two stages: (1) extracting an explicit semantic representation from the given image; and (2) constructing the caption based on a recursive compositional procedure in a bottom-up manner. Compared to conventional ones, our paradigm better preserves the semantic content through an explicit factorization of semantics and syntax. By using the compositional generation procedure, caption construction follows a recursive structure, which naturally fits the properties of human language. Moreover, the proposed compositional procedure requires less data to train, generalizes better, and yields more diverse captions.

</details>

<details>

<summary>2018-10-23 04:51:29 - Variational Knowledge Graph Reasoning</summary>

- *Wenhu Chen, Wenhan Xiong, Xifeng Yan, William Wang*

- `1803.06581v3` - [abs](http://arxiv.org/abs/1803.06581v3) - [pdf](http://arxiv.org/pdf/1803.06581v3)

> Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (\textsc{Diva}) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, \textsc{Diva} is better at handling noise and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.

</details>

<details>

<summary>2018-10-23 08:42:08 - Bridging Semantic Gaps between Natural Languages and APIs with Word Embedding</summary>

- *Xiaochen Li, He Jiang, Yasutaka Kamei, Xin Chen*

- `1810.09723v1` - [abs](http://arxiv.org/abs/1810.09723v1) - [pdf](http://arxiv.org/pdf/1810.09723v1)

> Developers increasingly rely on text matching tools to analyze the relation between natural language words and APIs. However, semantic gaps, namely textual mismatches between words and APIs, negatively affect these tools. Previous studies have transformed words or APIs into low-dimensional vectors for matching; however, inaccurate results were obtained due to the failure of modeling words and APIs simultaneously. To resolve this problem, two main challenges are to be addressed: the acquisition of massive words and APIs for mining and the alignment of words and APIs for modeling. Therefore, this study proposes Word2API to effectively estimate relatedness of words and APIs. Word2API collects millions of commonly used words and APIs from code repositories to address the acquisition challenge. Then, a shuffling strategy is used to transform related words and APIs into tuples to address the alignment challenge. Using these tuples, Word2API models words and APIs simultaneously. Word2API outperforms baselines by 10%-49.6% of relatedness estimation in terms of precision and NDCG. Word2API is also effective on solving typical software tasks, e.g., query expansion and API documents linking. A simple system with Word2API-expanded queries recommends up to 21.4% more related APIs for developers. Meanwhile, Word2API improves comparison algorithms by 7.9%-17.4% in linking questions in Question&Answer communities to API documents.

</details>

<details>

<summary>2018-10-23 14:23:43 - Feasibility of Supervised Machine Learning for Cloud Security</summary>

- *Deval Bhamare, Tara Salman, Mohammed Samaka, Aiman Erbad, Raj Jain*

- `1810.09878v1` - [abs](http://arxiv.org/abs/1810.09878v1) - [pdf](http://arxiv.org/pdf/1810.09878v1)

> Cloud computing is gaining significant attention, however, security is the biggest hurdle in its wide acceptance. Users of cloud services are under constant fear of data loss, security threats and availability issues. Recently, learning-based methods for security applications are gaining popularity in the literature with the advents in machine learning techniques. However, the major challenge in these methods is obtaining real-time and unbiased datasets. Many datasets are internal and cannot be shared due to privacy issues or may lack certain statistical characteristics. As a result of this, researchers prefer to generate datasets for training and testing purpose in the simulated or closed experimental environments which may lack comprehensiveness. Machine learning models trained with such a single dataset generally result in a semantic gap between results and their application. There is a dearth of research work which demonstrates the effectiveness of these models across multiple datasets obtained in different environments. We argue that it is necessary to test the robustness of the machine learning models, especially in diversified operating conditions, which are prevalent in cloud scenarios. In this work, we use the UNSW dataset to train the supervised machine learning models. We then test these models with ISOT dataset. We present our results and argue that more research in the field of machine learning is still required for its applicability to the cloud security.

</details>

<details>

<summary>2018-10-23 19:22:25 - Time-Agnostic Prediction: Predicting Predictable Video Frames</summary>

- *Dinesh Jayaraman, Frederik Ebert, Alexei A. Efros, Sergey Levine*

- `1808.07784v3` - [abs](http://arxiv.org/abs/1808.07784v3) - [pdf](http://arxiv.org/pdf/1808.07784v3)

> Prediction is arguably one of the most basic functions of an intelligent system. In general, the problem of predicting events in the future or between two waypoints is exceedingly difficult. However, most phenomena naturally pass through relatively predictable bottlenecks---while we cannot predict the precise trajectory of a robot arm between being at rest and holding an object up, we can be certain that it must have picked the object up. To exploit this, we decouple visual prediction from a rigid notion of time. While conventional approaches predict frames at regularly spaced temporal intervals, our time-agnostic predictors (TAP) are not tied to specific times so that they may instead discover predictable "bottleneck" frames no matter when they occur. We evaluate our approach for future and intermediate frame prediction across three robotic manipulation tasks. Our predictions are not only of higher visual quality, but also correspond to coherent semantic subgoals in temporally extended tasks.

</details>

<details>

<summary>2018-10-23 22:20:27 - A mathematical theory of semantic development in deep neural networks</summary>

- *Andrew M. Saxe, James L. McClelland, Surya Ganguli*

- `1810.10531v1` - [abs](http://arxiv.org/abs/1810.10531v1) - [pdf](http://arxiv.org/pdf/1810.10531v1)

> An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.

</details>

<details>

<summary>2018-10-24 11:07:44 - Coarse-to-fine volumetric segmentation of teeth in Cone-Beam CT</summary>

- *Matvey Ezhov, Adel Zakirov, Maxim Gusarev*

- `1810.10293v1` - [abs](http://arxiv.org/abs/1810.10293v1) - [pdf](http://arxiv.org/pdf/1810.10293v1)

> We consider the problem of localizing and segmenting individual teeth inside 3D Cone-Beam Computed Tomography (CBCT) images. To handle large image sizes we approach this task with a coarse-to-fine framework, where the whole volume is first analyzed as a 33-class semantic segmentation (adults have up to 32 teeth) in coarse resolution, followed by binary semantic segmentation of the cropped region of interest in original resolution. To improve the performance of the challenging 33-class segmentation, we first train the Coarse step model on a large weakly labeled dataset, then fine-tune it on a smaller precisely labeled dataset. The Fine step model is trained with precise labels only. Experiments using our in-house dataset show significant improvement for both weakly-supervised pretraining and for the addition of the Fine step. Empirically, this framework yields precise teeth masks with low localization errors sufficient for many real-world applications.

</details>

<details>

<summary>2018-10-24 15:07:16 - Entropy in Quantum Information Theory -- Communication and Cryptography</summary>

- *Christian Majenz*

- `1810.10436v1` - [abs](http://arxiv.org/abs/1810.10436v1) - [pdf](http://arxiv.org/pdf/1810.10436v1)

> In this Thesis, several results in quantum information theory are collected, most of which use entropy as the main mathematical tool. *While a direct generalization of the Shannon entropy to density matrices, the von Neumann entropy behaves differently. A long-standing open question is, whether there are quantum analogues of unconstrained non-Shannon type inequalities. Here, a new constrained non-von-Neumann type inequality is proven, a step towards a conjectured unconstrained inequality by Linden and Winter. *IID quantum state merging can be optimally achieved using the decoupling technique. The one-shot results by Berta et al. and Anshu at al., however, had to bring in additional mathematical machinery. We introduce a natural generalized decoupling paradigm, catalytic decoupling, that can reproduce the aforementioned results when used analogously to the application of standard decoupling in the asymptotic case. *Port based teleportation, a variant of standard quantum teleportation protocol, cannot be implemented perfectly. We prove several lower bounds on the necessary number of output ports N to achieve port based teleportation for given error and input dimension, showing that N diverges uniformly in the dimension of the teleported quantum system, for vanishing error. As a byproduct, a new lower bound for the size of the program register for an approximate universal programmable quantum processor is derived. *In the last part, we give a new definition for information-theoretic quantum non-malleability, strengthening the previous definition by Ambainis et al. We show that quantum non-malleability implies secrecy, analogous to quantum authentication. Furthermore, non-malleable encryption schemes can be used as a primitive to build authenticating encryption schemes. We also show that the strong notion of authentication recently proposed by Garg et al. can be fulfilled using 2-designs.

</details>

<details>

<summary>2018-10-24 20:43:26 - Alleviating Patch Overfitting with Automatic Test Generation: A Study of Feasibility and Effectiveness for the Nopol Repair System</summary>

- *Zhongxing Yu, Matias Martinez, Benjamin Danglot, Thomas Durieux, Martin Monperrus*

- `1810.10614v1` - [abs](http://arxiv.org/abs/1810.10614v1) - [pdf](http://arxiv.org/pdf/1810.10614v1)

> Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. However, test suites are in essence input-output specifications and are thus typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based repair techniques can just overfit to the used test suite, and fail to generalize to other tests. We deeply analyze the overfitting problem in program repair and give a classification of this problem. This classification will help the community to better understand and design techniques to defeat the overfitting problem. We further propose and evaluate an approach called UnsatGuided, which aims to alleviate the overfitting problem for synthesis-based repair techniques with automatic test case generation. The approach uses additional automatically generated tests to strengthen the repair constraint used by synthesis-based repair techniques. We analyze the effectiveness of UnsatGuided: 1) analytically with respect to alleviating two different kinds of overfitting issues; 2) empirically based on an experiment over the 224 bugs of the Defects4J repository. The main result is that automatic test generation is effective in alleviating one kind of overfitting issue--regression introduction, but due to oracle problem, has minimal positive impact on alleviating the other kind of overfitting issue--incomplete fixing.

</details>

<details>

<summary>2018-10-24 22:08:26 - Predicting the Semantic Textual Similarity with Siamese CNN and LSTM</summary>

- *Elvys Linhares Pontes, Stéphane Huet, Andréa Carneiro Linhares, Juan-Manuel Torres-Moreno*

- `1810.10641v1` - [abs](http://arxiv.org/abs/1810.10641v1) - [pdf](http://arxiv.org/pdf/1810.10641v1)

> Semantic Textual Similarity (STS) is the basis of many applications in Natural Language Processing (NLP). Our system combines convolution and recurrent neural networks to measure the semantic similarity of sentences. It uses a convolution network to take account of the local context of words and an LSTM to consider the global context of sentences. This combination of networks helps to preserve the relevant information of sentences and improves the calculation of the similarity between sentences. Our model has achieved good results and is competitive with the best state-of-the-art systems.

</details>

<details>

<summary>2018-10-25 07:48:10 - ESAS: An Efficient Semantic and Authorized Search Scheme over Encrypted Outsourced Data</summary>

- *Xueyan Liu, Zhitao Guan, Xiaojiang Du, Liehuang Zhu, Zhengtao Yu, Yinglong Ma*

- `1811.06917v1` - [abs](http://arxiv.org/abs/1811.06917v1) - [pdf](http://arxiv.org/pdf/1811.06917v1)

> Nowadays, a large amount of user privacy-sensitive data is outsourced to the cloud server in ciphertext, which is provided by the data owners and can be accessed by authorized data users. When accessing data, the user should be assigned with the access permission according to his identities or attributes. In addition, the search capabilities in encrypted outsourced data is expected to be enhanced, i.e., the search results can better pre-sent user's intentions. To address the above issues, ESAS, an Efficient Semantic and Authorized Search scheme over encrypt-ed outsourced data, is proposed. In ESAS, by integrating PRSCG (the privacy-preserving ranked search based on con-ceptual graph) and CP-ABE (ciphertext policy attribute-based encryption), semantic search with file-level fine-grained access authorization can be realized. In addition, search authorization can be done in an offline manner, which can improve search efficiency and reduce the response time. The security analysis indicate that the proposed ESAS meets security requirement.

</details>

<details>

<summary>2018-10-25 09:51:52 - Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training</summary>

- *Yang Zou, Zhiding Yu, B. V. K. Vijaya Kumar, Jinsong Wang*

- `1810.07911v2` - [abs](http://arxiv.org/abs/1810.07911v2) - [pdf](http://arxiv.org/pdf/1810.07911v2)

> Recent deep networks achieved state of the art performance on a variety of semantic segmentation tasks. Despite such progress, these models often face challenges in real world `wild tasks' where large difference between labeled training/source data and unseen test/target data exists. In particular, such difference is often referred to as `domain gap', and could cause significantly decreased performance which cannot be easily remedied by further increasing the representation power. Unsupervised domain adaptation (UDA) seeks to overcome such problem without target domain labels. In this paper, we propose a novel UDA framework based on an iterative self-training procedure, where the problem is formulated as latent variable loss minimization, and can be solved by alternatively generating pseudo labels on target data and re-training the model with these labels. On top of self-training, we also propose a novel class-balanced self-training framework to avoid the gradual dominance of large classes on pseudo-label generation, and introduce spatial priors to refine generated labels. Comprehensive experiments show that the proposed methods achieve state of the art semantic segmentation performance under multiple major UDA settings.

</details>

<details>

<summary>2018-10-25 10:42:56 - PQC: Triple Decomposition Problem Applied To GL(d, Fp) - A Secure Framework For Canonical Non-Commutative Cryptography</summary>

- *Pedro Hecht*

- `1810.08983v2` - [abs](http://arxiv.org/abs/1810.08983v2) - [pdf](http://arxiv.org/pdf/1810.08983v2)

> Post-Quantum Cryptography (PQC) attempts to find cryptographic protocols resistant to attacks using Shor polynomial time algorithm for numerical field problems or Grover search algorithm. A mostly overlooked but valuable line of solutions is provided by non-commutative algebraic structures, specifically canonical protocols that rely on one-way trapdoor functions (OWTF). Here we develop an algebraic framework who could be applied to different asymmetric protocols like D-H KE (Diffie-Hellman key exchange), Public Key Encryption, Digital Signature, ZKP (zero-knowledge proof) authentication, Oblivious Transfer, Multi-Party Computing, and so on. The trapdoor one-way functions selected are (a) Triple decomposition Problem (TDP) developed by Kurt, where a known element is factored into a product of three unknown factors and (b) a new version of conjugacy search that we refer from now on as Blind Conjugacy Search Problem (BCSP). Our platform structure is the general linear group GL(d,F_p) d-square non-singular matrices of prime field values. We give support to the fact that this framework is cryptographically secure against classical attacks like linear algebra attacks, length-based attacks, side-channel attacks against square (or duplicate) and multiply (or sum) algorithm, high sensitivity to pseudo random deterministic generators, etc. At same time it is immune against quantum attacks (using Grover and Shor), if the size parameters are carefully selected. Semantic security and IND-CCA2 compliance for this framework is discussed.

</details>

<details>

<summary>2018-10-25 12:48:11 - Hate Speech Detection: A Solved Problem? The Challenging Case of Long Tail on Twitter</summary>

- *Ziqi Zhang, Lei Luo*

- `1803.03662v2` - [abs](http://arxiv.org/abs/1803.03662v2) - [pdf](http://arxiv.org/pdf/1803.03662v2)

> In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and researchers. A large number of methods have been developed for automated hate speech detection online. This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. However, we notice significant difference between the performance of the two (i.e., non-hate v.s. hate). In this work, we argue for a focus on the latter problem for practical reasons. We show that it is a much more challenging task, as our analysis of the language in the typical datasets shows that hate speech lacks unique, discriminative features and therefore is found in the 'long tail' in a dataset that is difficult to discover. We then propose Deep Neural Network structures serving as feature extractors that are particularly effective for capturing the semantics of hate speech. Our methods are evaluated on the largest collection of hate speech datasets based on Twitter, and are shown to be able to outperform the best performing method by up to 5 percentage points in macro-average F1, or 8 percentage points in the more challenging case of identifying hateful content.

</details>

<details>

<summary>2018-10-25 17:34:43 - Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change</summary>

- *William L. Hamilton, Jure Leskovec, Dan Jurafsky*

- `1605.09096v6` - [abs](http://arxiv.org/abs/1605.09096v6) - [pdf](http://arxiv.org/pdf/1605.09096v6)

> Understanding how words change their meanings over time is key to models of language and cultural evolution, but historical data on meaning is scarce, making theories hard to develop and test. Word embeddings show promise as a diachronic tool, but have not been carefully evaluated. We develop a robust methodology for quantifying semantic change by evaluating word embeddings (PPMI, SVD, word2vec) against known historical changes. We then use this methodology to reveal statistical laws of semantic evolution. Using six historical corpora spanning four languages and two centuries, we propose two quantitative laws of semantic change: (i) the law of conformity---the rate of semantic change scales with an inverse power-law of word frequency; (ii) the law of innovation---independent of frequency, words that are more polysemous have higher rates of semantic change.

</details>

<details>

<summary>2018-10-26 02:01:30 - Efficient learning of neighbor representations for boundary trees and forests</summary>

- *Tharindu Adikari, Stark C. Draper*

- `1810.11165v1` - [abs](http://arxiv.org/abs/1810.11165v1) - [pdf](http://arxiv.org/pdf/1810.11165v1)

> We introduce a semiparametric approach to neighbor-based classification. We build off the recently proposed Boundary Trees algorithm by Mathy et al.(2015) which enables fast neighbor-based classification, regression and retrieval in large datasets. While boundary trees use an Euclidean measure of similarity, the Differentiable Boundary Tree algorithm by Zoran et al.(2017) was introduced to learn low-dimensional representations of complex input data, on which semantic similarity can be calculated to train boundary trees. As is pointed out by its authors, the differentiable boundary tree approach contains a few limitations that prevents it from scaling to large datasets. In this paper, we introduce Differentiable Boundary Sets, an algorithm that overcomes the computational issues of the differentiable boundary tree scheme and also improves its classification accuracy and data representability. Our algorithm is efficiently implementable with existing tools and offers a significant reduction in training time. We test and compare the algorithms on the well known MNIST handwritten digits dataset and the newer Fashion-MNIST dataset by Xiao et al.(2017).

</details>

<details>

<summary>2018-10-26 09:34:36 - From Word to Sense Embeddings: A Survey on Vector Representations of Meaning</summary>

- *Jose Camacho-Collados, Mohammad Taher Pilehvar*

- `1805.04032v3` - [abs](http://arxiv.org/abs/1805.04032v3) - [pdf](http://arxiv.org/pdf/1805.04032v3)

> Over the past years, distributed semantic representations have proved to be effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.

</details>

<details>

<summary>2018-10-26 13:52:41 - On the difficulty of a distributional semantics of spoken language</summary>

- *Grzegorz Chrupała, Lieke Gelderloos, Ákos Kádár, Afra Alishahi*

- `1803.08869v2` - [abs](http://arxiv.org/abs/1803.08869v2) - [pdf](http://arxiv.org/pdf/1803.08869v2)

> In the domain of unsupervised learning most work on speech has focused on discovering low-level constructs such as phoneme inventories or word-like units. In contrast, for written language, where there is a large body of work on unsupervised induction of semantic representations of words, whole sentences and longer texts. In this study we examine the challenges of adapting these approaches from written to spoken language. We conjecture that unsupervised learning of the semantics of spoken language becomes feasible if we abstract from the surface variability. We simulate this setting with a dataset of utterances spoken by a realistic but uniform synthetic voice. We evaluate two simple unsupervised models which, to varying degrees of success, learn semantic representations of speech fragments. Finally we present inconclusive results on human speech, and discuss the challenges inherent in learning distributional semantic representations on unrestricted natural spoken language.

</details>

<details>

<summary>2018-10-26 14:41:37 - Static and Dynamic Vector Semantics for Lambda Calculus Models of Natural Language</summary>

- *Mehrnoosh Sadrzadeh, Reinhard Muskens*

- `1810.11351v1` - [abs](http://arxiv.org/abs/1810.11351v1) - [pdf](http://arxiv.org/pdf/1810.11351v1)

> Vector models of language are based on the contextual aspects of language, the distributions of words and how they co-occur in text. Truth conditional models focus on the logical aspects of language, compositional properties of words and how they compose to form sentences. In the truth conditional approach, the denotation of a sentence determines its truth conditions, which can be taken to be a truth value, a set of possible worlds, a context change potential, or similar. In the vector models, the degree of co-occurrence of words in context determines how similar the meanings of words are. In this paper, we put these two models together and develop a vector semantics for language based on the simply typed lambda calculus models of natural language. We provide two types of vector semantics: a static one that uses techniques familiar from the truth conditional tradition and a dynamic one based on a form of dynamic interpretation inspired by Heim's context change potentials. We show how the dynamic model can be applied to entailment between a corpus and a sentence and we provide examples.

</details>

<details>

<summary>2018-10-26 18:44:52 - Parsing Coordination for Spoken Language Understanding</summary>

- *Sanchit Agarwal, Rahul Goel, Tagyoung Chung, Abhishek Sethi, Arindam Mandal, Spyros Matsoukas*

- `1810.11497v1` - [abs](http://arxiv.org/abs/1810.11497v1) - [pdf](http://arxiv.org/pdf/1810.11497v1)

> Typical spoken language understanding systems provide narrow semantic parses using a domain-specific ontology. The parses contain intents and slots that are directly consumed by downstream domain applications. In this work we discuss expanding such systems to handle compound entities and intents by introducing a domain-agnostic shallow parser that handles linguistic coordination. We show that our model for parsing coordination learns domain-independent and slot-independent features and is able to segment conjunct boundaries of many different phrasal categories. We also show that using adversarial training can be effective for improving generalization across different slot types for coordination parsing.

</details>

<details>

<summary>2018-10-26 20:24:02 - Whetstone: A Method for Training Deep Artificial Neural Networks for Binary Communication</summary>

- *William Severa, Craig M. Vineyard, Ryan Dellana, Stephen J. Verzi, James B. Aimone*

- `1810.11521v1` - [abs](http://arxiv.org/abs/1810.11521v1) - [pdf](http://arxiv.org/pdf/1810.11521v1)

> This paper presents a new technique for training networks for low-precision communication. Targeting minimal communication between nodes not only enables the use of emerging spiking neuromorphic platforms, but may additionally streamline processing conventionally. Low-power and embedded neuromorphic processors potentially offer dramatic performance-per-Watt improvements over traditional von Neumann processors, however programming these brain-inspired platforms generally requires platform-specific expertise which limits their applicability. To date, the majority of artificial neural networks have not operated using discrete spike-like communication.   We present a method for training deep spiking neural networks using an iterative modification of the backpropagation optimization algorithm. This method, which we call Whetstone, effectively and reliably configures a network for a spiking hardware target with little, if any, loss in performance. Whetstone networks use single time step binary communication and do not require a rate code or other spike-based coding scheme, thus producing networks comparable in timing and size to conventional ANNs, albeit with binarized communication. We demonstrate Whetstone on a number of image classification networks, describing how the sharpening process interacts with different training optimizers and changes the distribution of activity within the network. We further note that Whetstone is compatible with several non-classification neural network applications, such as autoencoders and semantic segmentation. Whetstone is widely extendable and currently implemented using custom activation functions within the Keras wrapper to the popular TensorFlow machine learning framework.

</details>

<details>

<summary>2018-10-27 05:58:36 - A Miniaturized Semantic Segmentation Method for Remote Sensing Image</summary>

- *Shou-Yu Chen, Guang-Sheng Chen, Wei-Peng Jing*

- `1810.11603v1` - [abs](http://arxiv.org/abs/1810.11603v1) - [pdf](http://arxiv.org/pdf/1810.11603v1)

> In order to save the memory, we propose a miniaturization method for neural network to reduce the parameter quantity existed in remote sensing (RS) image semantic segmentation model. The compact convolution optimization method is first used for standard U-Net to reduce the weights quantity. With the purpose of decreasing model performance loss caused by miniaturization and based on the characteristics of remote sensing image, fewer down-samplings and improved cascade atrous convolution are then used to improve the performance of the miniaturized U-Net. Compared with U-Net, our proposed Micro-Net not only achieves 29.26 times model compression, but also basically maintains the performance unchanged on the public dataset. We provide a Keras and Tensorflow hybrid programming implementation for our model: https://github.com/Isnot2bad/Micro-Net

</details>

<details>

<summary>2018-10-28 02:11:53 - Latent Semantic Analysis Approach for Document Summarization Based on Word Embeddings</summary>

- *Kamal Al-Sabahi, Zhang Zuping, Yang Kang*

- `1807.02748v2` - [abs](http://arxiv.org/abs/1807.02748v2) - [pdf](http://arxiv.org/pdf/1807.02748v2)

> Since the amount of information on the internet is growing rapidly, it is not easy for a user to find relevant information for his/her query. To tackle this issue, much attention has been paid to Automatic Document Summarization. The key point in any successful document summarizer is a good document representation. The traditional approaches based on word overlapping mostly fail to produce that kind of representation. Word embedding, distributed representation of words, has shown an excellent performance that allows words to match on semantic level. Naively concatenating word embeddings makes the common word dominant which in turn diminish the representation quality. In this paper, we employ word embeddings to improve the weighting schemes for calculating the input matrix of Latent Semantic Analysis method. Two embedding-based weighting schemes are proposed and then combined to calculate the values of this matrix. The new weighting schemes are modified versions of the augment weight and the entropy frequency. The new schemes combine the strength of the traditional weighting schemes and word embedding. The proposed approach is experimentally evaluated on three well-known English datasets, DUC 2002, DUC 2004 and Multilingual 2015 Single-document Summarization for English. The proposed model performs comprehensively better compared to the state-of-the-art methods, by at least 1% ROUGE points, leading to a conclusion that it provides a better document representation and a better document summary as a result.

</details>

<details>

<summary>2018-10-29 20:13:05 - Language Modeling with Sparse Product of Sememe Experts</summary>

- *Yihong Gu, Jun Yan, Hao Zhu, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Fen Lin, Leyu Lin*

- `1810.12387v1` - [abs](http://arxiv.org/abs/1810.12387v1) - [pdf](http://arxiv.org/pdf/1810.12387v1)

> Most language modeling methods rely on large-scale data to statistically learn the sequential patterns of words. In this paper, we argue that words are atomic language units but not necessarily atomic semantic units. Inspired by HowNet, we use sememes, the minimum semantic units in human languages, to represent the implicit semantics behind words for language modeling, named Sememe-Driven Language Model (SDLM). More specifically, to predict the next word, SDLM first estimates the sememe distribution gave textual context. Afterward, it regards each sememe as a distinct semantic expert, and these experts jointly identify the most probable senses and the corresponding word. In this way, SDLM enables language models to work beyond word-level manipulation to fine-grained sememe-level semantics and offers us more powerful tools to fine-tune language models and improve the interpretability as well as the robustness of language models. Experiments on language modeling and the downstream application of headline gener- ation demonstrate the significant effect of SDLM. Source code and data used in the experiments can be accessed at https:// github.com/thunlp/SDLM-pytorch.

</details>

<details>

<summary>2018-10-29 22:51:52 - Incremental Learning for Semantic Segmentation of Large-Scale Remote Sensing Data</summary>

- *Onur Tasar, Yuliya Tarabalka, Pierre Alliez*

- `1810.12448v1` - [abs](http://arxiv.org/abs/1810.12448v1) - [pdf](http://arxiv.org/pdf/1810.12448v1)

> In spite of remarkable success of the convolutional neural networks on semantic segmentation, they suffer from catastrophic forgetting: a significant performance drop for the already learned classes when new classes are added on the data, having no annotations for the old classes. We propose an incremental learning methodology, enabling to learn segmenting new classes without hindering dense labeling abilities for the previous classes, although the entire previous data are not accessible. The key points of the proposed approach are adapting the network to learn new as well as old classes on the new training data, and allowing it to remember the previously learned information for the old classes. For adaptation, we keep a frozen copy of the previously trained network, which is used as a memory for the updated network in absence of annotations for the former classes. The updated network minimizes a loss function, which balances the discrepancy between outputs for the previous classes from the memory and updated networks, and the mis-classification rate between outputs for the new classes from the updated network and the new ground-truth. For remembering, we either regularly feed samples from the stored, little fraction of the previous data or use the memory network, depending on whether the new data are collected from completely different geographic areas or from the same city. Our experimental results prove that it is possible to add new classes to the network, while maintaining its performance for the previous classes, despite the whole previous training data are not available.

</details>

<details>

<summary>2018-10-30 02:35:54 - Finding Cryptocurrency Attack Indicators Using Temporal Logic and Darkweb Data</summary>

- *Mohammed Almukaynizi, Vivin Paliath, Malay Shah, Malav Shah, Paulo Shakarian*

- `1810.12906v1` - [abs](http://arxiv.org/abs/1810.12906v1) - [pdf](http://arxiv.org/pdf/1810.12906v1)

> With the recent prevalence of darkweb/deepweb (D2web) sites specializing in the trade of exploit kits and malware, malicious actors have easy-access to a wide-range of tools that can empower their offensive capability. In this study, we apply concepts from causal reasoning, itemset mining, and logic programming on historical cryptocurrency-related cyber incidents with intelligence collected from over 400 D2web hacker forums. Our goal was to find indicators of cyber threats targeting cryptocurrency traders and exchange platforms from hacker activity. Our approach found interesting activities that, when observed together in the D2web, subsequent cryptocurrency-related incidents are at least twice as likely to occur than they would if no activity was observed. We also present an algorithmic extension to a previously-introduced algorithm called APT-Extract that allows to model new semantic structures that are specific to our application.

</details>

<details>

<summary>2018-10-30 05:39:08 - Object-Oriented Dynamics Predictor</summary>

- *Guangxiang Zhu, Zhiao Huang, Chongjie Zhang*

- `1806.07371v3` - [abs](http://arxiv.org/abs/1806.07371v3) - [pdf](http://arxiv.org/pdf/1806.07371v3)

> Generalization has been one of the major challenges for learning dynamics models in model-based reinforcement learning. However, previous work on action-conditioned dynamics prediction focuses on learning the pixel-level motion and thus does not generalize well to novel environments with different object layouts. In this paper, we present a novel object-oriented framework, called object-oriented dynamics predictor (OODP), which decomposes the environment into objects and predicts the dynamics of objects conditioned on both actions and object-to-object relations. It is an end-to-end neural network and can be trained in an unsupervised manner. To enable the generalization ability of dynamics learning, we design a novel CNN-based relation mechanism that is class-specific (rather than object-specific) and exploits the locality principle. Empirical results show that OODP significantly outperforms previous methods in terms of generalization over novel environments with various object layouts. OODP is able to learn from very few environments and accurately predict dynamics in a large number of unseen environments. In addition, OODP learns semantically and visually interpretable dynamics models.

</details>

<details>

<summary>2018-10-30 08:42:52 - Exploring Neural Methods for Parsing Discourse Representation Structures</summary>

- *Rik van Noord, Lasha Abzianidze, Antonio Toral, Johan Bos*

- `1810.12579v1` - [abs](http://arxiv.org/abs/1810.12579v1) - [pdf](http://arxiv.org/pdf/1810.12579v1)

> Neural methods have had several recent successes in semantic parsing, though they have yet to face the challenge of producing meaning representations based on formal semantics. We present a sequence-to-sequence neural semantic parser that is able to produce Discourse Representation Structures (DRSs) for English sentences with high accuracy, outperforming traditional DRS parsers. To facilitate the learning of the output, we represent DRSs as a sequence of flat clauses and introduce a method to verify that produced DRSs are well-formed and interpretable. We compare models using characters and words as input and see (somewhat surprisingly) that the former performs better than the latter. We show that eliminating variable names from the output using De Bruijn-indices increases parser performance. Adding silver training data boosts performance even further.

</details>

<details>

<summary>2018-10-30 09:45:07 - code2vec: Learning Distributed Representations of Code</summary>

- *Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav*

- `1803.09473v5` - [abs](http://arxiv.org/abs/1803.09473v5) - [pdf](http://arxiv.org/pdf/1803.09473v5)

> We present a neural model for representing snippets of code as continuous distributed vectors ("code embeddings"). The main idea is to represent a code snippet as a single fixed-length $\textit{code vector}$, which can be used to predict semantic properties of the snippet. This is performed by decomposing code to a collection of paths in its abstract syntax tree, and learning the atomic representation of each path $\textit{simultaneously}$ with learning how to aggregate a set of them. We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 14M methods. We show that code vectors trained on this dataset can predict method names from files that were completely unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies. Comparing previous techniques over the same data set, our approach obtains a relative improvement of over 75%, being the first to successfully predict method names based on a large, cross-project, corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data, and trained models are available at https://github.com/tech-srl/code2vec.

</details>

<details>

<summary>2018-10-30 11:13:35 - Cascaded CNN-resBiLSTM-CTC: An End-to-End Acoustic Model For Speech Recognition</summary>

- *Xinpei Zhou, Jiwei Li, Xi Zhou*

- `1810.12001v2` - [abs](http://arxiv.org/abs/1810.12001v2) - [pdf](http://arxiv.org/pdf/1810.12001v2)

> Automatic speech recognition (ASR) tasks are resolved by end-to-end deep learning models, which benefits us by less preparation of raw data, and easier transformation between languages. We propose a novel end-to-end deep learning model architecture namely cascaded CNN-resBiLSTM-CTC. In the proposed model, we add residual blocks in BiLSTM layers to extract sophisticated phoneme and semantic information together, and apply cascaded structure to pay more attention mining information of hard negative samples. By applying both simple Fast Fourier Transform (FFT) technique and n-gram language model (LM) rescoring method, we manage to achieve word error rate (WER) of 3.41% on LibriSpeech test clean corpora. Furthermore, we propose a new batch-varied method to speed up the training process in length-varied tasks, which result in 25% less training time.

</details>

<details>

<summary>2018-10-30 12:10:43 - Research Issues in Mining User Behavioral Rules for Context-Aware Intelligent Mobile Applications</summary>

- *Iqbal H. Sarker*

- `1810.12692v1` - [abs](http://arxiv.org/abs/1810.12692v1) - [pdf](http://arxiv.org/pdf/1810.12692v1)

> Context-awareness in smart mobile applications is a growing area of study, because of it's intelligence in the applications. In order to build context-aware intelligent applications, mining contextual behavioral rules of individual smartphone users utilizing their phone log data is the key. However, to mine these rules, a number of issues, such as the quality of smartphone data, understanding the relevancy of contexts, discretization of continuous contextual data, discovery of useful behavioral rules of individuals and their ordering, knowledge-based interactive post-mining for semantic understanding, and dynamic updating and management of rules according to their present behavior, are investigated. In this paper, we briefly discuss these issues and their potential solution directions for mining individuals' behavioral rules, for the purpose of building various context-aware intelligent mobile applications. We also summarize a number of real-life rule-based applications that intelligently assist individual smartphone users according to their behavioral rules in their daily activities.

</details>

<details>

<summary>2018-10-30 13:53:56 - Improving Multilingual Semantic Textual Similarity with Shared Sentence Encoder for Low-resource Languages</summary>

- *Xin Tang, Shanbo Cheng, Loc Do, Zhiyu Min, Feng Ji, Heng Yu, Ji Zhang, Haiqin Chen*

- `1810.08740v2` - [abs](http://arxiv.org/abs/1810.08740v2) - [pdf](http://arxiv.org/pdf/1810.08740v2)

> Measuring the semantic similarity between two sentences (or Semantic Textual Similarity - STS) is fundamental in many NLP applications. Despite the remarkable results in supervised settings with adequate labeling, little attention has been paid to this task in low-resource languages with insufficient labeling. Existing approaches mostly leverage machine translation techniques to translate sentences into rich-resource language. These approaches either beget language biases, or be impractical in industrial applications where spoken language scenario is more often and rigorous efficiency is required. In this work, we propose a multilingual framework to tackle the STS task in a low-resource language e.g. Spanish, Arabic , Indonesian and Thai, by utilizing the rich annotation data in a rich resource language, e.g. English. Our approach is extended from a basic monolingual STS framework to a shared multilingual encoder pretrained with translation task to incorporate rich-resource language data. By exploiting the nature of a shared multilingual encoder, one sentence can have multiple representations for different target translation language, which are used in an ensemble model to improve similarity evaluation. We demonstrate the superiority of our method over other state of the art approaches on SemEval STS task by its significant improvement on non-MT method, as well as an online industrial product where MT method fails to beat baseline while our approach still has consistently improvements.

</details>

<details>

<summary>2018-10-30 14:07:48 - DeepHTTP: Semantics-Structure Model with Attention for Anomalous HTTP Traffic Detection and Pattern Mining</summary>

- *Yuqi Yu, Hanbing Yan, Hongchao Guan, Hao Zhou*

- `1810.12751v1` - [abs](http://arxiv.org/abs/1810.12751v1) - [pdf](http://arxiv.org/pdf/1810.12751v1)

> In the Internet age, cyber-attacks occur frequently with complex types. Traffic generated by access activities can record website status and user request information, which brings a great opportunity for network attack detection. Among diverse network protocols, Hypertext Transfer Protocol (HTTP) is widely used in government, organizations and enterprises. In this work, we propose DeepHTTP, a semantics structure integration model utilizing Bidirectional Long Short-Term Memory (Bi-LSTM) with attention mechanism to model HTTP traffic as a natural language sequence. In addition to extracting traffic content information, we integrate structural information to enhance the generalization capabilities of the model. Moreover, the application of attention mechanism can assist in discovering critical parts of anomalous traffic and further mining attack patterns. Additionally, we demonstrate how to incrementally update the data set and retrain model so that it can be adapted to new anomalous traffic. Extensive experimental evaluations over large traffic data have illustrated that DeepHTTP has outstanding performance in traffic detection and pattern discovery.

</details>

<details>

<summary>2018-10-30 19:43:17 - Word Mover's Embedding: From Word2Vec to Document Embedding</summary>

- *Lingfei Wu, Ian E. H. Yen, Kun Xu, Fangli Xu, Avinash Balakrishnan, Pin-Yu Chen, Pradeep Ravikumar, Michael J. Witbrock*

- `1811.01713v1` - [abs](http://arxiv.org/abs/1811.01713v1) - [pdf](http://arxiv.org/pdf/1811.01713v1)

> While the celebrated Word2Vec technique yields semantically rich representations for individual words, there has been relatively less success in extending to generate unsupervised sentences or documents embeddings. Recent work has demonstrated that a distance measure between documents called \emph{Word Mover's Distance} (WMD) that aligns semantically similar words, yields unprecedented KNN classification accuracy. However, WMD is expensive to compute, and it is hard to extend its use beyond a KNN classifier. In this paper, we propose the \emph{Word Mover's Embedding } (WME), a novel approach to building an unsupervised document (sentence) embedding from pre-trained word embeddings. In our experiments on 9 benchmark text classification datasets and 22 textual similarity tasks, the proposed technique consistently matches or outperforms state-of-the-art techniques, with significantly higher accuracy on problems of short length.

</details>

<details>

<summary>2018-10-30 23:31:50 - Stress-Testing Neural Models of Natural Language Inference with Multiply-Quantified Sentences</summary>

- *Atticus Geiger, Ignacio Cases, Lauri Karttunen, Christopher Potts*

- `1810.13033v1` - [abs](http://arxiv.org/abs/1810.13033v1) - [pdf](http://arxiv.org/pdf/1810.13033v1)

> Standard evaluations of deep learning models for semantics using naturalistic corpora are limited in what they can tell us about the fidelity of the learned representations, because the corpora rarely come with good measures of semantic complexity. To overcome this limitation, we present a method for generating data sets of multiply-quantified natural language inference (NLI) examples in which semantic complexity can be precisely characterized, and we use this method to show that a variety of common architectures for NLI inevitably fail to encode crucial information; only a model with forced lexical alignments avoids this damaging information loss.

</details>

<details>

<summary>2018-10-31 10:07:47 - Infrastructure for the representation and electronic exchange of design knowledge</summary>

- *Laurent Buzon, Abdelaziz Bouras, Yacine Ouzrout*

- `1810.13191v1` - [abs](http://arxiv.org/abs/1810.13191v1) - [pdf](http://arxiv.org/pdf/1810.13191v1)

> This paper develops the concept of knowledge and its exchange using Semantic Web technologies. It points out that knowledge is more than information because it embodies the meaning, that is to say semantic and context. These characteristics will influence our approach to represent and to treat the knowledge. In order to be adopted, the developed system needs to be simple and to use standards. The goal of the paper is to find standards to model knowledge and exchange it with an other person. Therefore, we propose to model knowledge using UML models to show a graphical representation and to exchange it with XML to ensure the portability at low cost. We introduce the concept of ontology for organizing knowledge and for facilitating the knowledge exchange. Proposals have been tested by implementing an application on the design knowledge of a pen.

</details>

<details>

<summary>2018-10-31 11:38:40 - SURFACE: Semantically Rich Fact Validation with Explanations</summary>

- *Ankur Padia, Francis Ferraro, Tim Finin*

- `1810.13223v1` - [abs](http://arxiv.org/abs/1810.13223v1) - [pdf](http://arxiv.org/pdf/1810.13223v1)

> Judging the veracity of a sentence making one or more claims is an important and challenging problem with many dimensions. The recent FEVER task asked participants to classify input sentences as either SUPPORTED, REFUTED or NotEnoughInfo using Wikipedia as a source of true facts. SURFACE does this task and explains its decision through a selection of sentences from the trusted source. Our multi-task neural approach uses semantic lexical frames from FrameNet to jointly (i) find relevant evidential sentences in the trusted source and (ii) use them to classify the input sentence's veracity. An evaluation of our efficient three-parameter model on the FEVER dataset showed an improvement of 90% over the state-of-the-art baseline on retrieving relevant sentences and a 70% relative improvement in classification.

</details>

<details>

<summary>2018-10-31 13:58:31 - Semantic speech retrieval with a visually grounded model of untranscribed speech</summary>

- *Herman Kamper, Gregory Shakhnarovich, Karen Livescu*

- `1710.01949v2` - [abs](http://arxiv.org/abs/1710.01949v2) - [pdf](http://arxiv.org/pdf/1710.01949v2)

> There is growing interest in models that can learn from unlabelled speech paired with visual context. This setting is relevant for low-resource speech processing, robotics, and human language acquisition research. Here we study how a visually grounded speech model, trained on images of scenes paired with spoken captions, captures aspects of semantics. We use an external image tagger to generate soft text labels from images, which serve as targets for a neural model that maps untranscribed speech to (semantic) keyword labels. We introduce a newly collected data set of human semantic relevance judgements and an associated task, semantic speech retrieval, where the goal is to search for spoken utterances that are semantically relevant to a given text query. Without seeing any text, the model trained on parallel speech and images achieves a precision of almost 60% on its top ten semantic retrievals. Compared to a supervised model trained on transcriptions, our model matches human judgements better by some measures, especially in retrieving non-verbatim semantic matches. We perform an extensive analysis of the model and its resulting representations.

</details>

<details>

<summary>2018-10-31 14:37:01 - Learning to Warm-Start Bayesian Hyperparameter Optimization</summary>

- *Jungtaek Kim, Saehoon Kim, Seungjin Choi*

- `1710.06219v3` - [abs](http://arxiv.org/abs/1710.06219v3) - [pdf](http://arxiv.org/pdf/1710.06219v3)

> Hyperparameter optimization aims to find the optimal hyperparameter configuration of a machine learning model, which provides the best performance on a validation dataset. Manual search usually leads to get stuck in a local hyperparameter configuration, and heavily depends on human intuition and experience. A simple alternative of manual search is random/grid search on a space of hyperparameters, which still undergoes extensive evaluations of validation errors in order to find its best configuration. Bayesian optimization that is a global optimization method for black-box functions is now popular for hyperparameter optimization, since it greatly reduces the number of validation error evaluations required, compared to random/grid search. Bayesian optimization generally finds the best hyperparameter configuration from random initialization without any prior knowledge. This motivates us to let Bayesian optimization start from the configurations that were successful on similar datasets, which are able to remarkably minimize the number of evaluations. In this paper, we propose deep metric learning to learn meta-features over datasets such that the similarity over them is effectively measured by Euclidean distance between their associated meta-features. To this end, we introduce a Siamese network composed of deep feature and meta-feature extractors, where deep feature extractor provides a semantic representation of each instance in a dataset and meta-feature extractor aggregates a set of deep features to encode a single representation over a dataset. Then, our learned meta-features are used to select a few datasets similar to the new dataset, so that hyperparameters in similar datasets are adopted as initializations to warm-start Bayesian hyperparameter optimization.

</details>

<details>

<summary>2018-10-31 18:24:32 - Generating Texts with Integer Linear Programming</summary>

- *Gerasimos Lampouras, Ion Androutsopoulos*

- `1811.00051v1` - [abs](http://arxiv.org/abs/1811.00051v1) - [pdf](http://arxiv.org/pdf/1811.00051v1)

> Concept-to-text generation typically employs a pipeline architecture, which often leads to suboptimal texts. Content selection, for example, may greedily select the most important facts, which may require, however, too many words to express, and this may be undesirable when space is limited or expensive. Selecting other facts, possibly only slightly less important, may allow the lexicalization stage to use much fewer words, or to report more facts in the same space. Decisions made during content selection and lexicalization may also lead to more or fewer sentence aggregation opportunities, affecting the length and readability of the resulting texts. Building upon on a publicly available state of the art natural language generator for Semantic Web ontologies, this article presents an Integer Linear Programming model that, unlike pipeline architectures, jointly considers choices available in content selection, lexicalization, and sentence aggregation to avoid greedy local decisions and produce more compact texts, i.e., texts that report more facts per word. Compact texts are desirable, for example, when generating advertisements to be included in Web search results, or when summarizing structured information in limited space. An extended version of the proposed model also considers a limited form of referring expression generation and avoids redundant sentences. An approximation of the two models can be used when longer texts need to be generated. Experiments with three ontologies confirm that the proposed models lead to more compact texts, compared to pipeline systems, with no deterioration or with improvements in the perceived quality of the generated texts.

</details>

<details>

<summary>2018-10-31 18:53:28 - Direct Network Transfer: Transfer Learning of Sentence Embeddings for Semantic Similarity</summary>

- *Li Zhang, Steven R. Wilson, Rada Mihalcea*

- `1804.07835v2` - [abs](http://arxiv.org/abs/1804.07835v2) - [pdf](http://arxiv.org/pdf/1804.07835v2)

> Sentence encoders, which produce sentence embeddings using neural networks, are typically evaluated by how well they transfer to downstream tasks. This includes semantic similarity, an important task in natural language understanding. Although there has been much work dedicated to building sentence encoders, the accompanying transfer learning techniques have received relatively little attention. In this paper, we propose a transfer learning setting specialized for semantic similarity, which we refer to as direct network transfer. Through experiments on several standard text similarity datasets, we show that applying direct network transfer to existing encoders can lead to state-of-the-art performance. Additionally, we compare several approaches to transfer sentence encoders to semantic similarity tasks, showing that the choice of transfer learning setting greatly affects the performance in many cases, and differs by encoder and dataset.

</details>

<details>

<summary>2018-10-31 21:31:08 - Measuring Issue Ownership using Word Embeddings</summary>

- *Amaru Cuba Gyllensten, Magnus Sahlgren*

- `1811.00127v1` - [abs](http://arxiv.org/abs/1811.00127v1) - [pdf](http://arxiv.org/pdf/1811.00127v1)

> Sentiment and topic analysis are common methods used for social media monitoring. Essentially, these methods answers questions such as, "what is being talked about, regarding X", and "what do people feel, regarding X". In this paper, we investigate another venue for social media monitoring, namely issue ownership and agenda setting, which are concepts from political science that have been used to explain voter choice and electoral outcomes. We argue that issue alignment and agenda setting can be seen as a kind of semantic source similarity of the kind "how similar is source A to issue owner P, when talking about issue X", and as such can be measured using word/document embedding techniques. We present work in progress towards measuring that kind of conditioned similarity, and introduce a new notion of similarity for predictive embeddings. We then test this method by measuring the similarity between politically aligned media and political parties, conditioned on bloc-specific issues.

</details>

<details>

<summary>2018-10-31 21:55:10 - Structured Content Preservation for Unsupervised Text Style Transfer</summary>

- *Youzhi Tian, Zhiting Hu, Zhou Yu*

- `1810.06526v2` - [abs](http://arxiv.org/abs/1810.06526v2) - [pdf](http://arxiv.org/pdf/1810.06526v2)

> Text style transfer aims to modify the style of a sentence while keeping its content unchanged. Recent style transfer systems often fail to faithfully preserve the content after changing the style. This paper proposes a structured content preserving model that leverages linguistic information in the structured fine-grained supervisions to better preserve the style-independent content during style transfer. In particular, we achieve the goal by devising rich model objectives based on both the sentence's lexical information and a language model that conditions on content. The resulting model therefore is encouraged to retain the semantic meaning of the target sentences. We perform extensive experiments that compare our model to other existing approaches in the tasks of sentiment and political slant transfer. Our model achieves significant improvement in terms of both content preservation and style transfer in automatic and human evaluation.

</details>


## 2018-11

<details>

<summary>2018-11-01 01:52:38 - Towards Safer Smart Contracts: A Survey of Languages and Verification Methods</summary>

- *Dominik Harz, William Knottenbelt*

- `1809.09805v4` - [abs](http://arxiv.org/abs/1809.09805v4) - [pdf](http://arxiv.org/pdf/1809.09805v4)

> With a market capitalisation of over USD 205 billion in just under ten years, public distributed ledgers have experienced significant adoption. Apart from novel consensus mechanisms, their success is also accountable to smart contracts. These programs allow distrusting parties to enter agreements that are executed autonomously. However, implementation issues in smart contracts caused severe losses to the users of such contracts. Significant efforts are taken to improve their security by introducing new programming languages and advance verification methods. We provide a survey of those efforts in two parts. First, we introduce several smart contract languages focussing on security features. To that end, we present an overview concerning paradigm, type, instruction set, semantics, and metering. Second, we examine verification tools and methods for smart contract and distributed ledgers. Accordingly, we introduce their verification approach, level of automation, coverage, and supported languages. Last, we present future research directions including formal semantics, verified compilers, and automated verification.

</details>

<details>

<summary>2018-11-01 13:40:55 - BENGAL: An Automatic Benchmark Generator for Entity Recognition and Linking</summary>

- *Axel-Cyrille Ngonga Ngomo, Michael Röder, Diego Moussallem, Ricardo Usbeck, René Speck*

- `1710.08691v3` - [abs](http://arxiv.org/abs/1710.08691v3) - [pdf](http://arxiv.org/pdf/1710.08691v3)

> The manual creation of gold standards for named entity recognition and entity linking is time- and resource-intensive. Moreover, recent works show that such gold standards contain a large proportion of mistakes in addition to being difficult to maintain. We hence present BENGAL, a novel automatic generation of such gold standards as a complement to manually created benchmarks. The main advantage of our benchmarks is that they can be readily generated at any time. They are also cost-effective while being guaranteed to be free of annotation errors. We compare the performance of 11 tools on benchmarks in English generated by BENGAL and on 16benchmarks created manually. We show that our approach can be ported easily across languages by presenting results achieved by 4 tools on both Brazilian Portuguese and Spanish. Overall, our results suggest that our automatic benchmark generation approach can create varied benchmarks that have characteristics similar to those of existing benchmarks. Our approach is open-source. Our experimental results are available at http://faturl.com/bengalexpinlg and the code at https://github.com/dice-group/BENGAL.

</details>

<details>

<summary>2018-11-01 17:06:09 - Multilingual NMT with a language-independent attention bridge</summary>

- *Raúl Vázquez, Alessandro Raganato, Jörg Tiedemann, Mathias Creutz*

- `1811.00498v1` - [abs](http://arxiv.org/abs/1811.00498v1) - [pdf](http://arxiv.org/pdf/1811.00498v1)

> In this paper, we propose a multilingual encoder-decoder architecture capable of obtaining multilingual sentence representations by means of incorporating an intermediate {\em attention bridge} that is shared across all languages. That is, we train the model with language-specific encoders and decoders that are connected via self-attention with a shared layer that we call attention bridge. This layer exploits the semantics from each language for performing translation and develops into a language-independent meaning representation that can efficiently be used for transfer learning. We present a new framework for the efficient development of multilingual NMT using this model and scheduled training. We have tested the approach in a systematic way with a multi-parallel data set. We show that the model achieves substantial improvements over strong bilingual models and that it also works well for zero-shot translation, which demonstrates its ability of abstraction and transfer learning.

</details>

<details>

<summary>2018-11-01 17:48:18 - Improving Information Retrieval Results for Persian Documents using FarsNet</summary>

- *Adel Rahimi, Mohammad Bahrani*

- `1811.00854v1` - [abs](http://arxiv.org/abs/1811.00854v1) - [pdf](http://arxiv.org/pdf/1811.00854v1)

> In this paper, we propose a new method for query expansion, which uses FarsNet (Persian WordNet) to find similar tokens related to the query and expand the semantic meaning of the query. For this purpose, we use synonymy relations in FarsNet and extract the related synonyms to query words. This algorithm is used to enhance information retrieval systems and improve search results. The overall evaluation of this system in comparison to the baseline method (without using query expansion) shows an improvement of about 9 percent in Mean Average Precision (MAP).

</details>

<details>

<summary>2018-11-01 17:59:58 - Deep Structured Prediction with Nonlinear Output Transformations</summary>

- *Colin Graber, Ofer Meshi, Alexander Schwing*

- `1811.00539v1` - [abs](http://arxiv.org/abs/1811.00539v1) - [pdf](http://arxiv.org/pdf/1811.00539v1)

> Deep structured models are widely used for tasks like semantic segmentation, where explicit correlations between variables provide important prior information which generally helps to reduce the data needs of deep nets. However, current deep structured models are restricted by oftentimes very local neighborhood structure, which cannot be increased for computational complexity reasons, and by the fact that the output configuration, or a representation thereof, cannot be transformed further. Very recent approaches which address those issues include graphical model inference inside deep nets so as to permit subsequent non-linear output space transformations. However, optimization of those formulations is challenging and not well understood. Here, we develop a novel model which generalizes existing approaches, such as structured prediction energy networks, and discuss a formulation which maintains applicability of existing inference techniques.

</details>

<details>

<summary>2018-11-01 19:00:29 - Defining a Metric Space of Host Logs and Operational Use Cases</summary>

- *Miki E. Verma, Robert A. Bridges*

- `1811.00591v1` - [abs](http://arxiv.org/abs/1811.00591v1) - [pdf](http://arxiv.org/pdf/1811.00591v1)

> Host logs, in particular, Windows Event Logs, are a valuable source of information often collected by security operation centers (SOCs). The semi-structured nature of host logs inhibits automated analytics, and while manual analysis is common, the sheer volume makes manual inspection of all logs impossible. Although many powerful algorithms for analyzing time-series and sequential data exist, utilization of such algorithms for most cyber security applications is either infeasible or requires tailored, research-intensive preparations. In particular, basic mathematic and algorithmic developments for providing a generalized, meaningful similarity metric on system logs is needed to bridge the gap between many existing sequential data mining methods and this currently available but under-utilized data source. In this paper, we provide a rigorous definition of a metric product space on Windows Event Logs, providing an embedding that allows for the application of established machine learning and time-series analysis methods. We then demonstrate the utility and flexibility of this embedding with multiple use-cases on real data: (1) comparing known infected to new host log streams for attack detection and forensics, (2) collapsing similar streams of logs into semantically-meaningful groups (by user, by role), thereby reducing the quantity of data but not the content, (3) clustering logs as well as short sequences of logs to identify and visualize user behaviors and background processes over time. Overall, we provide a metric space framework for general host logs and log sequences that respects semantic similarity and facilitates a wide variety of data science analytics to these logs without data-specific preparations for each.

</details>

<details>

<summary>2018-11-01 19:59:06 - Exploring Semantic Incrementality with Dynamic Syntax and Vector Space Semantics</summary>

- *Mehrnoosh Sadrzadeh, Matthew Purver, Julian Hough, Ruth Kempson*

- `1811.00614v1` - [abs](http://arxiv.org/abs/1811.00614v1) - [pdf](http://arxiv.org/pdf/1811.00614v1)

> One of the fundamental requirements for models of semantic processing in dialogue is incrementality: a model must reflect how people interpret and generate language at least on a word-by-word basis, and handle phenomena such as fragments, incomplete and jointly-produced utterances. We show that the incremental word-by-word parsing process of Dynamic Syntax (DS) can be assigned a compositional distributional semantics, with the composition operator of DS corresponding to the general operation of tensor contraction from multilinear algebra. We provide abstract semantic decorations for the nodes of DS trees, in terms of vectors, tensors, and sums thereof; using the latter to model the underspecified elements crucial to assigning partial representations during incremental processing. As a working example, we give an instantiation of this theory using plausibility tensors of compositional distributional semantics, and show how our framework can incrementally assign a semantic plausibility measure as it parses phrases and sentences.

</details>

<details>

<summary>2018-11-02 01:11:32 - Design Verifiably Correct Model Patterns to Facilitate Modeling Medical Best Practice Guidelines with Statecharts (Technical Report)</summary>

- *Chunhui Guo, Zhicheng Fu, Zhenyu Zhang, Shangping Ren, Lui Sha*

- `1811.00694v1` - [abs](http://arxiv.org/abs/1811.00694v1) - [pdf](http://arxiv.org/pdf/1811.00694v1)

> Improving patient care safety is an ultimate objective for medical cyber-physical systems. A recent study shows that the patients' death rate can be significantly reduced by computerizing medical best practice guidelines. To facilitate the development of computerized medical best practice guidelines, statecharts are often used as a modeling tool because of their high resemblances to disease and treatment models and their capabilities to provide rapid prototyping and simulation for clinical validations. However, some implementations of statecharts, such as Yakindu statecharts, are priority-based and have synchronous execution semantics which makes it difficult to model certain functionalities that are essential in modeling medical guidelines, such as two-way communications and configurable execution orders. Rather than introducing new statechart elements or changing the statechart implementation's underline semantics, we use existing basic statechart elements to design model patterns for the commonly occurring issues. In particular, we show the design of model patterns for two-way communications and configurable execution orders and formally prove the correctness of these model patterns. We further use a simplified airway laser surgery scenario as a case study to demonstrate how the developed model patterns address the two-way communication and configurable execution order issues and their impact on validation and verification of medical safety properties.

</details>

<details>

<summary>2018-11-02 01:21:17 - Sequence Generation with Guider Network</summary>

- *Ruiyi Zhang, Changyou Chen, Zhe Gan, Wenlin Wang, Liqun Chen, Dinghan Shen, Guoyin Wang, Lawrence Carin*

- `1811.00696v1` - [abs](http://arxiv.org/abs/1811.00696v1) - [pdf](http://arxiv.org/pdf/1811.00696v1)

> Sequence generation with reinforcement learning (RL) has received significant attention recently. However, a challenge with such methods is the sparse-reward problem in the RL training process, in which a scalar guiding signal is often only available after an entire sequence has been generated. This type of sparse reward tends to ignore the global structural information of a sequence, causing generation of sequences that are semantically inconsistent. In this paper, we present a model-based RL approach to overcome this issue. Specifically, we propose a novel guider network to model the sequence-generation environment, which can assist next-word prediction and provide intermediate rewards for generator optimization. Extensive experiments show that the proposed method leads to improved performance for both unconditional and conditional sequence-generation tasks.

</details>

<details>

<summary>2018-11-02 01:54:47 - Batch Normalization Sampling</summary>

- *Zhaodong Chen, Lei Deng, Guoqi Li, Jiawei Sun, Xing Hu, Xin Ma, Yuan Xie*

- `1810.10962v2` - [abs](http://arxiv.org/abs/1810.10962v2) - [pdf](http://arxiv.org/pdf/1810.10962v2)

> Deep Neural Networks (DNNs) thrive in recent years in which Batch Normalization (BN) plays an indispensable role. However, it has been observed that BN is costly due to the reduction operations. In this paper, we propose alleviating this problem through sampling only a small fraction of data for normalization at each iteration. Specifically, we model it as a statistical sampling problem and identify that by sampling less correlated data, we can largely reduce the requirement of the number of data for statistics estimation in BN, which directly simplifies the reduction operations. Based on this conclusion, we propose two sampling strategies, "Batch Sampling" (randomly select several samples from each batch) and "Feature Sampling" (randomly select a small patch from each feature map of all samples), that take both computational efficiency and sample correlation into consideration. Furthermore, we introduce an extremely simple variant of BN, termed as Virtual Dataset Normalization (VDN), that can normalize the activations well with few synthetical random samples. All the proposed methods are evaluated on various datasets and networks, where an overall training speedup by up to 20% on GPU is practically achieved without the support of any specialized libraries, and the loss on accuracy and convergence rate are negligible. Finally, we extend our work to the "micro-batch normalization" problem and yield comparable performance with existing approaches at the case of tiny batch size.

</details>

<details>

<summary>2018-11-02 09:20:01 - Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information</summary>

- *Seonhoon Kim, Inho Kang, Nojun Kwak*

- `1805.11360v2` - [abs](http://arxiv.org/abs/1805.11360v2) - [pdf](http://arxiv.org/pdf/1805.11360v2)

> Sentence matching is widely used in various natural language tasks such as natural language inference, paraphrase identification, and question answering. For these tasks, understanding logical and semantic relationship between two sentences is required but it is yet challenging. Although attention mechanism is useful to capture the semantic relationship and to properly align the elements of two sentences, previous methods of attention mechanism simply use a summation operation which does not retain original features enough. Inspired by DenseNet, a densely connected convolutional network, we propose a densely-connected co-attentive recurrent neural network, each layer of which uses concatenated information of attentive features as well as hidden features of all the preceding recurrent layers. It enables preserving the original and the co-attentive feature information from the bottommost word embedding layer to the uppermost recurrent layer. To alleviate the problem of an ever-increasing size of feature vectors due to dense concatenation operations, we also propose to use an autoencoder after dense concatenation. We evaluate our proposed architecture on highly competitive benchmark datasets related to sentence matching. Experimental results show that our architecture, which retains recurrent and attentive features, achieves state-of-the-art performances for most of the tasks.

</details>

<details>

<summary>2018-11-02 22:52:22 - Neural Task Representations as Weak Supervision for Model Agnostic Cross-Lingual Transfer</summary>

- *Sujay Kumar Jauhar, Michael Gamon, Patrick Pantel*

- `1811.01115v1` - [abs](http://arxiv.org/abs/1811.01115v1) - [pdf](http://arxiv.org/pdf/1811.01115v1)

> Natural language processing is heavily Anglo-centric, while the demand for models that work in languages other than English is greater than ever. Yet, the task of transferring a model from one language to another can be expensive in terms of annotation costs, engineering time and effort. In this paper, we present a general framework for easily and effectively transferring neural models from English to other languages. The framework, which relies on task representations as a form of weak supervision, is model and task agnostic, meaning that many existing neural architectures can be ported to other languages with minimal effort. The only requirement is unlabeled parallel data, and a loss defined over task representations. We evaluate our framework by transferring an English sentiment classifier to three different languages. On a battery of tests, we show that our models outperform a number of strong baselines and rival state-of-the-art results, which rely on more complex approaches and significantly more resources and data. Additionally, we find that the framework proposed in this paper is able to capture semantically rich and meaningful representations across languages, despite the lack of direct supervision.

</details>

<details>

<summary>2018-11-03 18:58:50 - On GANs and GMMs</summary>

- *Eitan Richardson, Yair Weiss*

- `1805.12462v2` - [abs](http://arxiv.org/abs/1805.12462v2) - [pdf](http://arxiv.org/pdf/1805.12462v2)

> A longstanding problem in machine learning is to find unsupervised methods that can learn the statistical structure of high dimensional signals. In recent years, GANs have gained much attention as a possible solution to the problem, and in particular have shown the ability to generate remarkably realistic high resolution sampled images. At the same time, many authors have pointed out that GANs may fail to model the full distribution ("mode collapse") and that using the learned models for anything other than generating samples may be very difficult. In this paper, we examine the utility of GANs in learning statistical models of images by comparing them to perhaps the simplest statistical model, the Gaussian Mixture Model. First, we present a simple method to evaluate generative models based on relative proportions of samples that fall into predetermined bins. Unlike previous automatic methods for evaluating models, our method does not rely on an additional neural network nor does it require approximating intractable computations. Second, we compare the performance of GANs to GMMs trained on the same datasets. While GMMs have previously been shown to be successful in modeling small patches of images, we show how to train them on full sized images despite the high dimensionality. Our results show that GMMs can generate realistic samples (although less sharp than those of GANs) but also capture the full distribution, which GANs fail to do. Furthermore, GMMs allow efficient inference and explicit representation of the underlying statistical structure. Finally, we discuss how GMMs can be used to generate sharp images.

</details>

<details>

<summary>2018-11-03 23:43:38 - SimplerVoice: A Key Message & Visual Description Generator System for Illiteracy</summary>

- *Minh N. B. Nguyen, Samuel Thomas, Anne E. Gattiker, Sujatha Kashyap, Kush R. Varshney*

- `1811.01299v1` - [abs](http://arxiv.org/abs/1811.01299v1) - [pdf](http://arxiv.org/pdf/1811.01299v1)

> We introduce SimplerVoice: a key message and visual description generator system to help low-literate adults navigate the information-dense world with confidence, on their own. SimplerVoice can automatically generate sensible sentences describing an unknown object, extract semantic meanings of the object usage in the form of a query string, then, represent the string as multiple types of visual guidance (pictures, pictographs, etc.). We demonstrate SimplerVoice system in a case study of generating grocery products' manuals through a mobile application. To evaluate, we conducted a user study on SimplerVoice's generated description in comparison to the information interpreted by users from other methods: the original product package and search engines' top result, in which SimplerVoice achieved the highest performance score: 4.82 on 5-point mean opinion score scale. Our result shows that SimplerVoice is able to provide low-literate end-users with simple yet informative components to help them understand how to use the grocery products, and that the system may potentially provide benefits in other real-world use cases

</details>

<details>

<summary>2018-11-04 14:31:05 - Automatic Repair of Real Bugs in Java: A Large-Scale Experiment on the Defects4J Dataset</summary>

- *Matias Martinez, Thomas Durieux, Romain Sommerard, Jifeng Xuan, Martin Monperrus*

- `1811.02429v1` - [abs](http://arxiv.org/abs/1811.02429v1) - [pdf](http://arxiv.org/pdf/1811.02429v1)

> Defects4J is a large, peer-reviewed, structured dataset of real-world Java bugs. Each bug in Defects4J comes with a test suite and at least one failing test case that triggers the bug. In this paper, we report on an experiment to explore the effectiveness of automatic test-suite based repair on Defects4J. The result of our experiment shows that the considered state-of-the-art repair methods can generate patches for 47 out of 224 bugs. However, those patches are only test-suite adequate, which means that they pass the test suite and may potentially be incorrect beyond the test-suite satisfaction correctness criterion. We have manually analyzed 84 different patches to assess their real correctness. In total, 9 real Java bugs can be correctly repaired with test-suite based repair. This analysis shows that test-suite based repair suffers from under-specified bugs, for which trivial or incorrect patches still pass the test suite. With respect to practical applicability, it takes on average 14.8 minutes to find a patch. The experiment was done on a scientific grid, totaling 17.6 days of computation time. All the repair systems and experimental results are publicly available on Github in order to facilitate future research on automatic repair.

</details>

<details>

<summary>2018-11-04 17:57:07 - Semantic Role Labeling for Knowledge Graph Extraction from Text</summary>

- *Mehwish Alam, Aldo Gangemi, Valentina Presutti, Diego Reforgiato Recupero*

- `1811.01409v1` - [abs](http://arxiv.org/abs/1811.01409v1) - [pdf](http://arxiv.org/pdf/1811.01409v1)

> This paper introduces TakeFive, a new semantic role labeling method that transforms a text into a frame-oriented knowledge graph. It performs dependency parsing, identifies the words that evoke lexical frames, locates the roles and fillers for each frame, runs coercion techniques, and formalises the results as a knowledge graph. This formal representation complies with the frame semantics used in Framester, a factual-linguistic linked data resource. The obtained precision, recall and F1 values indicate that TakeFive is competitive with other existing methods such as SEMAFOR, Pikes, PathLSTM and FRED. We finally discuss how to combine TakeFive and FRED, obtaining higher values of precision, recall and F1.

</details>

<details>

<summary>2018-11-05 17:17:18 - Differences between Health Related News Articles from Reliable and Unreliable Media</summary>

- *Sameer Dhoju, Md Main Uddin Rony, Naeemul Hassan*

- `1811.01852v1` - [abs](http://arxiv.org/abs/1811.01852v1) - [pdf](http://arxiv.org/pdf/1811.01852v1)

> In this study, we examine a collection of health-related news articles published by reliable and unreliable media outlets. Our analysis shows that there are structural, topical, and semantic differences in the way reliable and unreliable media outlets conduct health journalism. We argue that the findings from this study will be useful for combating health disinformation problem.

</details>

<details>

<summary>2018-11-06 09:01:02 - Semantic bottleneck for computer vision tasks</summary>

- *Maxime Bucher, Stéphane Herbin, Frédéric Jurie*

- `1811.02234v1` - [abs](http://arxiv.org/abs/1811.02234v1) - [pdf](http://arxiv.org/pdf/1811.02234v1)

> This paper introduces a novel method for the representation of images that is semantic by nature, addressing the question of computation intelligibility in computer vision tasks. More specifically, our proposition is to introduce what we call a semantic bottleneck in the processing pipeline, which is a crossing point in which the representation of the image is entirely expressed with natural language , while retaining the efficiency of numerical representations. We show that our approach is able to generate semantic representations that give state-of-the-art results on semantic content-based image retrieval and also perform very well on image classification tasks. Intelligibility is evaluated through user centered experiments for failure detection.

</details>

<details>

<summary>2018-11-06 10:46:24 - Image-based Natural Language Understanding Using 2D Convolutional Neural Networks</summary>

- *Erinc Merdivan, Anastasios Vafeiadis, Dimitrios Kalatzis, Sten Hanke, Johannes Kropf, Konstantinos Votis, Dimitrios Giakoumis, Dimitrios Tzovaras, Liming Chen, Raouf Hamzaoui, Matthieu Geist*

- `1810.10401v2` - [abs](http://arxiv.org/abs/1810.10401v2) - [pdf](http://arxiv.org/pdf/1810.10401v2)

> We propose a new approach to natural language understanding in which we consider the input text as an image and apply 2D Convolutional Neural Networks to learn the local and global semantics of the sentences from the variations ofthe visual patterns of words. Our approach demonstrates that it is possible to get semantically meaningful features from images with text without using optical character recognition and sequential processing pipelines, techniques that traditional Natural Language Understanding algorithms require. To validate our approach, we present results for two applications: text classification and dialog modeling. Using a 2D Convolutional Neural Network, we were able to outperform the state-of-art accuracy results of non-Latin alphabet-based text classification and achieved promising results for eight text classification datasets. Furthermore, our approach outperformed the memory networks when using out of vocabulary entities fromtask 4 of the bAbI dialog dataset.

</details>

<details>

<summary>2018-11-06 11:26:35 - Defeating the Downgrade Attack on Identity Privacy in 5G</summary>

- *Mohsin Khan, Philip Ginzboorg, Kimmo Järvinen, Valtteri Niemi*

- `1811.02293v1` - [abs](http://arxiv.org/abs/1811.02293v1) - [pdf](http://arxiv.org/pdf/1811.02293v1)

> 3GPP Release 15, the first 5G standard, includes protection of user identity privacy against IMSI catchers. These protection mechanisms are based on public key encryption. Despite this protection, IMSI catching is still possible in LTE networks which opens the possibility of a downgrade attack on user identity privacy, where a fake LTE base station obtains the identity of a 5G user equipment. We propose (i) to use an existing pseudonym-based solution to protect user identity privacy of 5G user equipment against IMSI catchers in LTE and (ii) to include a mechanism for updating LTE pseudonyms in the public key encryption based 5G identity privacy procedure. The latter helps to recover from a loss of synchronization of LTE pseudonyms. Using this mechanism, pseudonyms in the user equipment and home network are automatically synchronized when the user equipment connects to 5G. Our mechanisms utilize existing LTE and 3GPP Release 15 messages and require modifications only in the user equipment and home network in order to provide identity privacy. Additionally, lawful interception requires minor patching in the serving network.

</details>

<details>

<summary>2018-11-06 16:08:31 - Semantic Term "Blurring" and Stochastic "Barcoding" for Improved Unsupervised Text Classification</summary>

- *Robert Frank Martorano III*

- `1811.02456v1` - [abs](http://arxiv.org/abs/1811.02456v1) - [pdf](http://arxiv.org/pdf/1811.02456v1)

> The abundance of text data being produced in the modern age makes it increasingly important to intuitively group, categorize, or classify text data by theme for efficient retrieval and search. Yet, the high dimensionality and imprecision of text data, or more generally language as a whole, prove to be challenging when attempting to perform unsupervised document clustering. In this thesis, we present two novel methods for improving unsupervised document clustering/classification by theme. The first is to improve document representations. We look to exploit "term neighborhoods" and "blur" semantic weight across neighboring terms. These neighborhoods are located in the semantic space afforded by "word embeddings." The second method is for cluster revision, based on what we deem as "stochastic barcoding", or "S- Barcode" patterns. Text data is inherently high dimensional, yet clustering typically takes place in a low dimensional representation space. Our method utilizes lower dimension clustering results as initial cluster configurations, and iteratively revises the configuration in the high dimensional space. We show with experimental results how both of the two methods improve the quality of document clustering. While this thesis elaborates on the two new conceptual contributions, a joint thesis by David Yan details the feature transformation and software architecture we developed for unsupervised document classification.

</details>

<details>

<summary>2018-11-06 16:12:00 - Parser Extraction of Triples in Unstructured Text</summary>

- *Shaun D'Souza*

- `1811.05768v1` - [abs](http://arxiv.org/abs/1811.05768v1) - [pdf](http://arxiv.org/pdf/1811.05768v1)

> The web contains vast repositories of unstructured text. We investigate the opportunity for building a knowledge graph from these text sources. We generate a set of triples which can be used in knowledge gathering and integration. We define the architecture of a language compiler for processing subject-predicate-object triples using the OpenNLP parser. We implement a depth-first search traversal on the POS tagged syntactic tree appending predicate and object information. A parser enables higher precision and higher recall extractions of syntactic relationships across conjunction boundaries. We are able to extract 2-2.5 times the correct extractions of ReVerb. The extractions are used in a variety of semantic web applications and question answering. We verify extraction of 50,000 triples on the ClueWeb dataset.

</details>

<details>

<summary>2018-11-06 23:25:45 - Proceedings of the 2018 Workshop on Compositional Approaches in Physics, NLP, and Social Sciences</summary>

- *Martha Lewis, Bob Coecke, Jules Hedges, Dimitri Kartsaklis, Dan Marsden*

- `1811.02701v1` - [abs](http://arxiv.org/abs/1811.02701v1) - [pdf](http://arxiv.org/pdf/1811.02701v1)

> The ability to compose parts to form a more complex whole, and to analyze a whole as a combination of elements, is desirable across disciplines. This workshop bring together researchers applying compositional approaches to physics, NLP, cognitive science, and game theory. Within NLP, a long-standing aim is to represent how words can combine to form phrases and sentences. Within the framework of distributional semantics, words are represented as vectors in vector spaces. The categorical model of Coecke et al. [2010], inspired by quantum protocols, has provided a convincing account of compositionality in vector space models of NLP. There is furthermore a history of vector space models in cognitive science. Theories of categorization such as those developed by Nosofsky [1986] and Smith et al. [1988] utilise notions of distance between feature vectors. More recently G\"ardenfors [2004, 2014] has developed a model of concepts in which conceptual spaces provide geometric structures, and information is represented by points, vectors and regions in vector spaces. The same compositional approach has been applied to this formalism, giving conceptual spaces theory a richer model of compositionality than previously [Bolt et al., 2018]. Compositional approaches have also been applied in the study of strategic games and Nash equilibria. In contrast to classical game theory, where games are studied monolithically as one global object, compositional game theory works bottom-up by building large and complex games from smaller components. Such an approach is inherently difficult since the interaction between games has to be considered. Research into categorical compositional methods for this field have recently begun [Ghani et al., 2018]. Moreover, the interaction between the three disciplines of cognitive science, linguistics and game theory is a fertile ground for research. Game theory in cognitive science is a well-established area [Camerer, 2011]. Similarly game theoretic approaches have been applied in linguistics [J\"ager, 2008]. Lastly, the study of linguistics and cognitive science is intimately intertwined [Smolensky and Legendre, 2006, Jackendoff, 2007]. Physics supplies compositional approaches via vector spaces and categorical quantum theory, allowing the interplay between the three disciplines to be examined.

</details>

<details>

<summary>2018-11-07 17:40:03 - IMS at the PolEval 2018: A Bulky Ensemble Depedency Parser meets 12 Simple Rules for Predicting Enhanced Dependencies in Polish</summary>

- *Agnieszka Falenska, Anders Björkelund, Xiang Yu, Jonas Kuhn*

- `1811.03036v1` - [abs](http://arxiv.org/abs/1811.03036v1) - [pdf](http://arxiv.org/pdf/1811.03036v1)

> This paper presents the IMS contribution to the PolEval 2018 Shared Task. We submitted systems for both of the Subtasks of Task 1. In Subtask (A), which was about dependency parsing, we used our ensemble system from the CoNLL 2017 UD Shared Task. The system first preprocesses the sentences with a CRF POS/morphological tagger and predicts supertags with a neural tagger. Then, it employs multiple instances of three different parsers and merges their outputs by applying blending. The system achieved the second place out of four participating teams. In this paper we show which components of the system were the most responsible for its final performance.   The goal of Subtask (B) was to predict enhanced graphs. Our approach consisted of two steps: parsing the sentences with our ensemble system from Subtask (A), and applying 12 simple rules to obtain the final dependency graphs. The rules introduce additional enhanced arcs only for tokens with "conj" heads (conjuncts). They do not predict semantic relations at all. The system ranked first out of three participating teams. In this paper we show examples of rules we designed and analyze the relation between the quality of automatically parsed trees and the accuracy of the enhanced graphs.

</details>

<details>

<summary>2018-11-08 03:19:59 - Evaluating the Complementarity of Taxonomic Relation Extraction Methods Across Different Languages</summary>

- *Roger Granada, Renata Vieira, Cassia Trojahn, Nathalie Aussenac-Gilles*

- `1811.03245v1` - [abs](http://arxiv.org/abs/1811.03245v1) - [pdf](http://arxiv.org/pdf/1811.03245v1)

> Modern information systems are changing the idea of "data processing" to the idea of "concept processing", meaning that instead of processing words, such systems process semantic concepts which carry meaning and share contexts with other concepts. Ontology is commonly used as a structure that captures the knowledge about a certain area via providing concepts and relations between them. Traditionally, concept hierarchies have been built manually by knowledge engineers or domain experts. However, the manual construction of a concept hierarchy suffers from several limitations such as its coverage and the enormous costs of its extension and maintenance. Ontology learning, usually referred to the (semi-)automatic support in ontology development, is usually divided into steps, going from concepts identification, passing through hierarchy and non-hierarchy relations detection and, seldom, axiom extraction. It is reasonable to say that among these steps the current frontier is in the establishment of concept hierarchies, since this is the backbone of ontologies and, therefore, a good concept hierarchy is already a valuable resource for many ontology applications. The automatic construction of concept hierarchies from texts is a complex task and much work have been proposing approaches to better extract relations between concepts. These different proposals have never been contrasted against each other on the same set of data and across different languages. Such comparison is important to see whether they are complementary or incremental. Also, we can see whether they present different tendencies towards recall and precision. This paper evaluates these different methods on the basis of hierarchy metrics such as density and depth, and evaluation metrics such as Recall and Precision. Results shed light over the comprehensive set of methods according to the literature in the area.

</details>

<details>

<summary>2018-11-08 05:10:34 - Information Flow in Pregroup Models of Natural Language</summary>

- *Peter M. Hines*

- `1811.03273v1` - [abs](http://arxiv.org/abs/1811.03273v1) - [pdf](http://arxiv.org/pdf/1811.03273v1)

> This paper is about pregroup models of natural languages, and how they relate to the explicitly categorical use of pregroups in Compositional Distributional Semantics and Natural Language Processing. These categorical interpretations make certain assumptions about the nature of natural languages that, when stated formally, may be seen to impose strong restrictions on pregroup grammars for natural languages.   We formalize this as a hypothesis about the form that pregroup models of natural languages must take, and demonstrate by an artificial language example that these restrictions are not imposed by the pregroup axioms themselves. We compare and contrast the artificial language examples with natural languages (using Welsh, a language where the 'noun' type cannot be taken as primitive, as an illustrative example).   The hypothesis is simply that there must exist a causal connection, or information flow, between the words of a sentence in a language whose purpose is to communicate information. This is not necessarily the case with formal languages that are simply generated by a series of 'meaning-free' rules. This imposes restrictions on the types of pregroup grammars that we expect to find in natural languages; we formalize this in algebraic, categorical, and graphical terms.   We take some preliminary steps in providing conditions that ensure pregroup models satisfy these conjectured properties, and discuss the more general forms this hypothesis may take.

</details>

<details>

<summary>2018-11-08 05:11:37 - Quantum Semantic Correlations in Hate and Non-Hate Speeches</summary>

- *Francesco Galofaro, Zeno Toffano, Bich-Liên Doan*

- `1811.03275v1` - [abs](http://arxiv.org/abs/1811.03275v1) - [pdf](http://arxiv.org/pdf/1811.03275v1)

> This paper aims to apply the notions of quantum geometry and correlation to the typification of semantic relations between couples of keywords in different documents. In particular we analysed texts classified as hate / non hate speeches, containing the keywords "women", "white", and "black". The paper compares this approach to cosine similarity, a classical methodology, to cast light on the notion of "similar meaning".

</details>

<details>

<summary>2018-11-08 05:11:59 - Internal Wiring of Cartesian Verbs and Prepositions</summary>

- *Bob Coecke, Martha Lewis, Dan Marsden*

- `1811.05770v1` - [abs](http://arxiv.org/abs/1811.05770v1) - [pdf](http://arxiv.org/pdf/1811.05770v1)

> Categorical compositional distributional semantics (CCDS) allows one to compute the meaning of phrases and sentences from the meaning of their constituent words. A type-structure carried over from the traditional categorial model of grammar a la Lambek becomes a 'wire-structure' that mediates the interaction of word meanings. However, CCDS has a much richer logical structure than plain categorical semantics in that certain words can also be given an 'internal wiring' that either provides their entire meaning or reduces the size their meaning space. Previous examples of internal wiring include relative pronouns and intersective adjectives. Here we establish the same for a large class of well-behaved transitive verbs to which we refer as Cartesian verbs, and reduce the meaning space from a ternary tensor to a unary one. Some experimental evidence is also provided.

</details>

<details>

<summary>2018-11-08 05:12:27 - Towards Functorial Language-Games</summary>

- *Jules Hedges, Martha Lewis*

- `1807.07828v2` - [abs](http://arxiv.org/abs/1807.07828v2) - [pdf](http://arxiv.org/pdf/1807.07828v2)

> In categorical compositional semantics of natural language one studies functors from a category of grammatical derivations (such as a Lambek pregroup) to a semantic category (such as real vector spaces). We compositionally build game-theoretic semantics of sentences by taking the semantic category to be the category whose morphisms are open games. This requires some modifications to the grammar category to compensate for the failure of open games to form a compact closed category. We illustrate the theory using simple examples of Wittgenstein's language-games.

</details>

<details>

<summary>2018-11-08 05:12:46 - Classical Copying versus Quantum Entanglement in Natural Language: The Case of VP-ellipsis</summary>

- *Gijs Wijnholds, Mehrnoosh Sadrzadeh*

- `1811.03276v1` - [abs](http://arxiv.org/abs/1811.03276v1) - [pdf](http://arxiv.org/pdf/1811.03276v1)

> This paper compares classical copying and quantum entanglement in natural language by considering the case of verb phrase (VP) ellipsis. VP ellipsis is a non-linear linguistic phenomenon that requires the reuse of resources, making it the ideal test case for a comparative study of different copying behaviours in compositional models of natural language. Following the line of research in compositional distributional semantics set out by (Coecke et al., 2010) we develop an extension of the Lambek calculus which admits a controlled form of contraction to deal with the copying of linguistic resources. We then develop two different compositional models of distributional meaning for this calculus. In the first model, we follow the categorical approach of (Coecke et al., 2013) in which a functorial passage sends the proofs of the grammar to linear maps on vector spaces and we use Frobenius algebras to allow for copying. In the second case, we follow the more traditional approach that one finds in categorial grammars, whereby an intermediate step interprets proofs as non-linear lambda terms, using multiple variable occurrences that model classical copying. As a case study, we apply the models to derive different readings of ambiguous elliptical phrases and compare the analyses that each model provides.

</details>

<details>

<summary>2018-11-08 05:14:19 - Towards Compositional Distributional Discourse Analysis</summary>

- *Bob Coecke, Giovanni de Felice, Dan Marsden, Alexis Toumi*

- `1811.03277v1` - [abs](http://arxiv.org/abs/1811.03277v1) - [pdf](http://arxiv.org/pdf/1811.03277v1)

> Categorical compositional distributional semantics provide a method to derive the meaning of a sentence from the meaning of its individual words: the grammatical reduction of a sentence automatically induces a linear map for composing the word vectors obtained from distributional semantics. In this paper, we extend this passage from word-to-sentence to sentence-to-discourse composition. To achieve this we introduce a notion of basic anaphoric discourses as a mid-level representation between natural language discourse formalised in terms of basic discourse representation structures (DRS); and knowledge base queries over the Semantic Web as described by basic graph patterns in the Resource Description Framework (RDF). This provides a high-level specification for compositional algorithms for question answering and anaphora resolution, and allows us to give a picture of natural language understanding as a process involving both statistical and logical resources.

</details>

<details>

<summary>2018-11-08 11:08:01 - On the Graded Acceptability of Arguments in Abstract and Instantiated Argumentation</summary>

- *Davide Grossi, Sanjay Modgil*

- `1811.03355v1` - [abs](http://arxiv.org/abs/1811.03355v1) - [pdf](http://arxiv.org/pdf/1811.03355v1)

> The paper develops a formal theory of the degree of justification of arguments, which relies solely on the structure of an argumentation framework, and which can be successfully interfaced with approaches to instantiated argumentation. The theory is developed in three steps. First, the paper introduces a graded generalization of the two key notions underpinning Dung's semantics: self-defense and conflict-freeness. This leads to a natural generalization of Dung's semantics, whereby standard extensions are weakened or strengthened depending on the level of self-defense and conflict-freeness they meet. The paper investigates the fixpoint theory of these semantics, establishing existence results for them. Second, the paper shows how graded semantics readily provide an approach to argument rankings, offering a novel contribution to the recently growing research programme on ranking-based semantics. Third, this novel approach to argument ranking is applied and studied in the context of instantiated argumentation frameworks, and in so doing is shown to account for a simple form of accrual of arguments within the Dung paradigm. Finally, the theory is compared in detail with existing approaches.

</details>

<details>

<summary>2018-11-08 11:57:12 - Named Entity Analysis and Extraction with Uncommon Words</summary>

- *Xiaoshi Zhong, Erik Cambria, Jagath C. Rajapakse*

- `1810.06818v2` - [abs](http://arxiv.org/abs/1810.06818v2) - [pdf](http://arxiv.org/pdf/1810.06818v2)

> Most previous research treats named entity extraction and classification as an end-to-end task. We argue that the two sub-tasks should be addressed separately. Entity extraction lies at the level of syntactic analysis while entity classification lies at the level of semantic analysis. According to Noam Chomsky's "Syntactic Structures," pp. 93-94 (Chomsky 1957), syntax is not appealed to semantics and semantics does not affect syntax. We analyze two benchmark datasets for the characteristics of named entities, finding that uncommon words can distinguish named entities from common text; where uncommon words are the words that hardly appear in common text and they are mainly the proper nouns. Experiments validate that lexical and syntactic features achieve state-of-the-art performance on entity extraction and that semantic features do not further improve the extraction performance, in both of our model and the state-of-the-art baselines. With Chomsky's view, we also explain the failure of joint syntactic and semantic parsings in other works.

</details>

<details>

<summary>2018-11-08 16:03:03 - Neural Relation Extraction via Inner-Sentence Noise Reduction and Transfer Learning</summary>

- *Tianyi Liu, Xinsong Zhang, Wanhao Zhou, Weijia Jia*

- `1808.06738v2` - [abs](http://arxiv.org/abs/1808.06738v2) - [pdf](http://arxiv.org/pdf/1808.06738v2)

> Extracting relations is critical for knowledge base completion and construction in which distant supervised methods are widely used to extract relational facts automatically with the existing knowledge bases. However, the automatically constructed datasets comprise amounts of low-quality sentences containing noisy words, which is neglected by current distant supervised methods resulting in unacceptable precisions. To mitigate this problem, we propose a novel word-level distant supervised approach for relation extraction. We first build Sub-Tree Parse(STP) to remove noisy words that are irrelevant to relations. Then we construct a neural network inputting the sub-tree while applying the entity-wise attention to identify the important semantic features of relational words in each instance. To make our model more robust against noisy words, we initialize our network with a priori knowledge learned from the relevant task of entity classification by transfer learning. We conduct extensive experiments using the corpora of New York Times(NYT) and Freebase. Experiments show that our approach is effective and improves the area of Precision/Recall(PR) from 0.35 to 0.39 over the state-of-the-art work.

</details>

<details>

<summary>2018-11-08 16:44:59 - Adaptive Semantic Segmentation with a Strategic Curriculum of Proxy Labels</summary>

- *Kashyap Chitta, Jianwei Feng, Martial Hebert*

- `1811.03542v1` - [abs](http://arxiv.org/abs/1811.03542v1) - [pdf](http://arxiv.org/pdf/1811.03542v1)

> Training deep networks for semantic segmentation requires annotation of large amounts of data, which can be time-consuming and expensive. Unfortunately, these trained networks still generalize poorly when tested in domains not consistent with the training data. In this paper, we show that by carefully presenting a mixture of labeled source domain and proxy-labeled target domain data to a network, we can achieve state-of-the-art unsupervised domain adaptation results. With our design, the network progressively learns features specific to the target domain using annotation from only the source domain. We generate proxy labels for the target domain using the network's own predictions. Our architecture then allows selective mining of easy samples from this set of proxy labels, and hard samples from the annotated source domain. We conduct a series of experiments with the GTA5, Cityscapes and BDD100k datasets on synthetic-to-real domain adaptation and geographic domain adaptation, showing the advantages of our method over baselines and existing approaches.

</details>

<details>

<summary>2018-11-08 20:32:48 - Modalities, Cohesion, and Information Flow</summary>

- *G. A. Kavvos*

- `1809.07897v2` - [abs](http://arxiv.org/abs/1809.07897v2) - [pdf](http://arxiv.org/pdf/1809.07897v2)

> It is informally understood that the purpose of modal type constructors in programming calculi is to control the flow of information between types. In order to lend rigorous support to this idea, we study the category of classified sets, a variant of a denotational semantics for information flow proposed by Abadi et al. We use classified sets to prove multiple noninterference theorems for modalities of a monadic and comonadic flavour. The common machinery behind our theorems stems from the the fact that classified sets are a (weak) model of Lawvere's theory of axiomatic cohesion. In the process, we show how cohesion can be used for reasoning about multi-modal settings. This leads to the conclusion that cohesion is a particularly useful setting for the study of both information flow, but also modalities in type theory and programming languages at large.

</details>

<details>

<summary>2018-11-09 00:23:48 - AnatomyNet: Deep Learning for Fast and Fully Automated Whole-volume Segmentation of Head and Neck Anatomy</summary>

- *Wentao Zhu, Yufang Huang, Liang Zeng, Xuming Chen, Yong Liu, Zhen Qian, Nan Du, Wei Fan, Xiaohui Xie*

- `1808.05238v2` - [abs](http://arxiv.org/abs/1808.05238v2) - [pdf](http://arxiv.org/pdf/1808.05238v2)

> Methods: Our deep learning model, called AnatomyNet, segments OARs from head and neck CT images in an end-to-end fashion, receiving whole-volume HaN CT images as input and generating masks of all OARs of interest in one shot. AnatomyNet is built upon the popular 3D U-net architecture, but extends it in three important ways: 1) a new encoding scheme to allow auto-segmentation on whole-volume CT images instead of local patches or subsets of slices, 2) incorporating 3D squeeze-and-excitation residual blocks in encoding layers for better feature representation, and 3) a new loss function combining Dice scores and focal loss to facilitate the training of the neural model. These features are designed to address two main challenges in deep-learning-based HaN segmentation: a) segmenting small anatomies (i.e., optic chiasm and optic nerves) occupying only a few slices, and b) training with inconsistent data annotations with missing ground truth for some anatomical structures.   Results: We collected 261 HaN CT images to train AnatomyNet, and used MICCAI Head and Neck Auto Segmentation Challenge 2015 as a benchmark dataset to evaluate the performance of AnatomyNet. The objective is to segment nine anatomies: brain stem, chiasm, mandible, optic nerve left, optic nerve right, parotid gland left, parotid gland right, submandibular gland left, and submandibular gland right. Compared to previous state-of-the-art results from the MICCAI 2015 competition, AnatomyNet increases Dice similarity coefficient by 3.3% on average. AnatomyNet takes about 0.12 seconds to fully segment a head and neck CT image of dimension 178 x 302 x 225, significantly faster than previous methods. In addition, the model is able to process whole-volume CT images and delineate all OARs in one pass, requiring little pre- or post-processing. https://github.com/wentaozhu/AnatomyNet-for-anatomical-segmentation.git.

</details>

<details>

<summary>2018-11-09 08:16:22 - Generative Models of Visually Grounded Imagination</summary>

- *Ramakrishna Vedantam, Ian Fischer, Jonathan Huang, Kevin Murphy*

- `1705.10762v8` - [abs](http://arxiv.org/abs/1705.10762v8) - [pdf](http://arxiv.org/pdf/1705.10762v8)

> It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison of our method with two existing joint image-attribute VAE methods (the JMVAE method of Suzuki et.al. and the BiVCCA method of Wang et.al.) by applying them to two datasets: the MNIST-with-attributes dataset (which we introduce here), and the CelebA dataset.

</details>

<details>

<summary>2018-11-09 11:44:05 - Learning Semantic Representations for Novel Words: Leveraging Both Form and Context</summary>

- *Timo Schick, Hinrich Schütze*

- `1811.03866v1` - [abs](http://arxiv.org/abs/1811.03866v1) - [pdf](http://arxiv.org/pdf/1811.03866v1)

> Word embeddings are a key component of high-performing natural language processing (NLP) systems, but it remains a challenge to learn good representations for novel words on the fly, i.e., for words that did not occur in the training data. The general problem setting is that word embeddings are induced on an unlabeled training corpus and then a model is trained that embeds novel words into this induced embedding space. Currently, two approaches for learning embeddings of novel words exist: (i) learning an embedding from the novel word's surface-form (e.g., subword n-grams) and (ii) learning an embedding from the context in which it occurs. In this paper, we propose an architecture that leverages both sources of information - surface-form and context - and show that it results in large increases in embedding quality. Our architecture obtains state-of-the-art results on the Definitional Nonce and Contextual Rare Words datasets. As input, we only require an embedding set and an unlabeled corpus for training our architecture to produce embeddings appropriate for the induced embedding space. Thus, our model can easily be integrated into any existing NLP system and enhance its capability to handle novel words.

</details>

<details>

<summary>2018-11-09 15:16:55 - Deep Compression of Sum-Product Networks on Tensor Networks</summary>

- *Ching-Yun Ko, Cong Chen, Yuke Zhang, Kim Batselier, Ngai Wong*

- `1811.03963v1` - [abs](http://arxiv.org/abs/1811.03963v1) - [pdf](http://arxiv.org/pdf/1811.03963v1)

> Sum-product networks (SPNs) represent an emerging class of neural networks with clear probabilistic semantics and superior inference speed over graphical models. This work reveals a strikingly intimate connection between SPNs and tensor networks, thus leading to a highly efficient representation that we call tensor SPNs (tSPNs). For the first time, through mapping an SPN onto a tSPN and employing novel optimization techniques, we demonstrate remarkable parameter compression with negligible loss in accuracy.

</details>

<details>

<summary>2018-11-09 21:00:46 - Reasoning over RDF Knowledge Bases using Deep Learning</summary>

- *Monireh Ebrahimi, Md Kamruzzaman Sarker, Federico Bianchi, Ning Xie, Derek Doran, Pascal Hitzler*

- `1811.04132v1` - [abs](http://arxiv.org/abs/1811.04132v1) - [pdf](http://arxiv.org/pdf/1811.04132v1)

> Semantic Web knowledge representation standards, and in particular RDF and OWL, often come endowed with a formal semantics which is considered to be of fundamental importance for the field. Reasoning, i.e., the drawing of logical inferences from knowledge expressed in such standards, is traditionally based on logical deductive methods and algorithms which can be proven to be sound and complete and terminating, i.e. correct in a very strong sense. For various reasons, though, in particular, the scalability issues arising from the ever-increasing amounts of Semantic Web data available and the inability of deductive algorithms to deal with noise in the data, it has been argued that alternative means of reasoning should be investigated which bear high promise for high scalability and better robustness. From this perspective, deductive algorithms can be considered the gold standard regarding correctness against which alternative methods need to be tested. In this paper, we show that it is possible to train a Deep Learning system on RDF knowledge graphs, such that it is able to perform reasoning over new RDF knowledge graphs, with high precision and recall compared to the deductive gold standard.

</details>

<details>

<summary>2018-11-09 23:55:56 - Computational Thinking with the Web Crowd using CodeMapper</summary>

- *Patrick Vanvorce, Hasan M. Jamil*

- `1811.04162v1` - [abs](http://arxiv.org/abs/1811.04162v1) - [pdf](http://arxiv.org/pdf/1811.04162v1)

> It has been argued that computational thinking should precede computer programming in the course of a career in computing. This argument is the basis for the slogan "logic first, syntax later" and the development of many cryptic syntax removed programming languages such as Scratch!, Blockly and Visual Logic. The goal is to focus on the structuring of the semantic relationships among the logical building blocks to yield solutions to computational problems. While this approach is helping novice programmers and early learners, the gap between computational thinking and professional programming using high level languages such as C++, Python and Java is quite wide. It is wide enough for about one third students in first college computer science classes to drop out or fail. In this paper, we introduce a new programming platform, called the CodeMapper, in which learners are able to build computational logic in independent modules and aggregate them to create complex modules. Code{\em Mapper} is an abstract development environment in which rapid visual prototyping of small to substantially large systems is possible by combining already developed independent modules in logical steps. The challenge we address involves supporting a visual development environment in which "annotated code snippets" authored by the masses in social computing sites such as SourceForge, StackOverflow or GitHub can also be used as is into prototypes and mapped to real executable programs. CodeMapper thus facilitates soft transition from visual programming to syntax driven programming without having to practice syntax too heavily.

</details>

<details>

<summary>2018-11-10 03:43:05 - CAPTAIN: Comprehensive Composition Assistance for Photo Taking</summary>

- *Farshid Farhat, Mohammad Mahdi Kamani, James Z. Wang*

- `1811.04184v1` - [abs](http://arxiv.org/abs/1811.04184v1) - [pdf](http://arxiv.org/pdf/1811.04184v1)

> Many people are interested in taking astonishing photos and sharing with others. Emerging hightech hardware and software facilitate ubiquitousness and functionality of digital photography. Because composition matters in photography, researchers have leveraged some common composition techniques to assess the aesthetic quality of photos computationally. However, composition techniques developed by professionals are far more diverse than well-documented techniques can cover. We leverage the vast underexplored innovations in photography for computational composition assistance. We propose a comprehensive framework, named CAPTAIN (Composition Assistance for Photo Taking), containing integrated deep-learned semantic detectors, sub-genre categorization, artistic pose clustering, personalized aesthetics-based image retrieval, and style set matching. The framework is backed by a large dataset crawled from a photo-sharing Website with mostly photography enthusiasts and professionals. The work proposes a sequence of steps that have not been explored in the past by researchers. The work addresses personal preferences for composition through presenting a ranked-list of photographs to the user based on user-specified weights in the similarity measure. The matching algorithm recognizes the best shot among a sequence of shots with respect to the user's preferred style set. We have conducted a number of experiments on the newly proposed components and reported findings. A user study demonstrates that the work is useful to those taking photos.

</details>

<details>

<summary>2018-11-10 07:59:04 - Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs</summary>

- *Jifeng Xuan, Matias Martinez, Favio Demarco, Maxime Clément, Sebastian Lamelas, Thomas Durieux, Daniel Le Berre, Martin Monperrus*

- `1811.04211v1` - [abs](http://arxiv.org/abs/1811.04211v1) - [pdf](http://arxiv.org/pdf/1811.04211v1)

> We propose NOPOL, an approach to automatic repair of buggy conditional statements (i.e., if-then-else statements). This approach takes a buggy program as well as a test suite as input and generates a patch with a conditional expression as output. The test suite is required to contain passing test cases to model the expected behavior of the program and at least one failing test case that reveals the bug to be repaired. The process of NOPOL consists of three major phases. First, NOPOL employs angelic fix localization to identify expected values of a condition during the test execution. Second, runtime trace collection is used to collect variables and their actual values, including primitive data types and objected-oriented features (e.g., nullness checks), to serve as building blocks for patch generation. Third, NOPOL encodes these collected data into an instance of a Satisfiability Modulo Theory (SMT) problem, then a feasible solution to the SMT instance is translated back into a code patch. We evaluate NOPOL on 22 real-world bugs (16 bugs with buggy IF conditions and 6 bugs with missing preconditions) on two large open-source projects, namely Apache Commons Math and Apache Commons Lang. Empirical analysis on these bugs shows that our approach can effectively fix bugs with buggy IF conditions and missing preconditions. We illustrate the capabilities and limitations of NOPOL using case studies of real bug fixes.

</details>

<details>

<summary>2018-11-10 11:20:18 - Towards Formula Translation using Recursive Neural Networks</summary>

- *Felix Petersen, Moritz Schubotz, Bela Gipp*

- `1811.04234v1` - [abs](http://arxiv.org/abs/1811.04234v1) - [pdf](http://arxiv.org/pdf/1811.04234v1)

> While it has become common to perform automated translations on natural language, performing translations between different representations of mathematical formulae has thus far not been possible. We implemented the first translator for mathematical formulae based on recursive neural networks. We chose recursive neural networks because mathematical formulae inherently include a structural encoding. In our implementation, we developed new techniques and topologies for recursive tree-to-tree neural networks based on multi-variate multi-valued Long Short-Term Memory cells. We propose a novel approach for mini-batch training that utilizes clustering and tree traversal. We evaluate our translator and analyze the behavior of our proposed topologies and techniques based on a translation from generic LaTeX to the semantic LaTeX notation. We use the semantic LaTeX notation from the Digital Library for Mathematical Formulae and the Digital Repository for Mathematical Formulae at the National Institute for Standards and Technology. We find that a simple heuristics-based clustering algorithm outperforms the conventional clustering algorithms on the task of clustering binary trees of mathematical formulae with respect to their topology. Furthermore, we find a mask for the loss function, which can prevent the neural network from finding a local minimum of the loss function. Given our preliminary results, a complete translation from formula to formula is not yet possible. However, we achieved a prediction accuracy of 47.05% for predicting symbols at the correct position and an accuracy of 92.3% when ignoring the predicted position. Concluding, our work advances the field of recursive neural networks by improving the training speed and quality of training. In the future, we will work towards a complete translation allowing a machine-interpretation of LaTeX formulae.

</details>

<details>

<summary>2018-11-10 21:02:10 - Joint Semantic Synthesis and Morphological Analysis of the Derived Word</summary>

- *Ryan Cotterell, Hinrich Schütze*

- `1701.00946v3` - [abs](http://arxiv.org/abs/1701.00946v3) - [pdf](http://arxiv.org/pdf/1701.00946v3)

> Much like sentences are composed of words, words themselves are composed of smaller units. For example, the English word questionably can be analyzed as question+able+ly. However, this structural decomposition of the word does not directly give us a semantic representation of the word's meaning. Since morphology obeys the principle of compositionality, the semantics of the word can be systematically derived from the meaning of its parts. In this work, we propose a novel probabilistic model of word formation that captures both the analysis of a word w into its constituents segments and the synthesis of the meaning of w from the meanings of those segments. Our model jointly learns to segment words into morphemes and compose distributional semantic vectors of those morphemes. We experiment with the model on English CELEX data and German DerivBase (Zeller et al., 2013) data. We show that jointly modeling semantics increases both segmentation accuracy and morpheme F1 by between 3% and 5%. Additionally, we investigate different models of vector composition, showing that recurrent neural networks yield an improvement over simple additive models. Finally, we study the degree to which the representations correspond to a linguist's notion of morphological productivity.

</details>

<details>

<summary>2018-11-11 05:37:37 - Semi-supervised Text Regression with Conditional Generative Adversarial Networks</summary>

- *Tao Li, Xudong Liu, Shihan Su*

- `1810.01165v2` - [abs](http://arxiv.org/abs/1810.01165v2) - [pdf](http://arxiv.org/pdf/1810.01165v2)

> Enormous online textual information provides intriguing opportunities for understandings of social and economic semantics. In this paper, we propose a novel text regression model based on a conditional generative adversarial network (GAN), with an attempt to associate textual data and social outcomes in a semi-supervised manner. Besides promising potential of predicting capabilities, our superiorities are twofold: (i) the model works with unbalanced datasets of limited labelled data, which align with real-world scenarios; and (ii) predictions are obtained by an end-to-end framework, without explicitly selecting high-level representations. Finally we point out related datasets for experiments and future research directions.

</details>

<details>

<summary>2018-11-11 16:49:47 - Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures</summary>

- *Gongbo Tang, Mathias Müller, Annette Rios, Rico Sennrich*

- `1808.08946v3` - [abs](http://arxiv.org/abs/1808.08946v3) - [pdf](http://arxiv.org/pdf/1808.08946v3)

> Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in neural machine translation. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks: subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2) self-attentional networks perform distinctly better than RNNs and CNNs on word sense disambiguation.

</details>

<details>

<summary>2018-11-11 19:02:50 - ReDecode Framework for Iterative Improvement in Paraphrase Generation</summary>

- *Milan Aggarwal, Nupur Kumari, Ayush Bansal, Balaji Krishnamurthy*

- `1811.04454v1` - [abs](http://arxiv.org/abs/1811.04454v1) - [pdf](http://arxiv.org/pdf/1811.04454v1)

> Generating paraphrases, that is, different variations of a sentence conveying the same meaning, is an important yet challenging task in NLP. Automatically generating paraphrases has its utility in many NLP tasks like question answering, information retrieval, conversational systems to name a few. In this paper, we introduce iterative refinement of generated paraphrases within VAE based generation framework. Current sequence generation models lack the capability to (1) make improvements once the sentence is generated; (2) rectify errors made while decoding. We propose a technique to iteratively refine the output using multiple decoders, each one attending on the output sentence generated by the previous decoder. We improve current state of the art results significantly - with over 9% and 28% absolute increase in METEOR scores on Quora question pairs and MSCOCO datasets respectively. We also show qualitatively through examples that our re-decoding approach generates better paraphrases compared to a single decoder by rectifying errors and making improvements in paraphrase structure, inducing variations and introducing new but semantically coherent information.

</details>

<details>

<summary>2018-11-11 19:12:35 - Semantic-Unit-Based Dilated Convolution for Multi-Label Text Classification</summary>

- *Junyang Lin, Qi Su, Pengcheng Yang, Shuming Ma, Xu Sun*

- `1808.08561v2` - [abs](http://arxiv.org/abs/1808.08561v2) - [pdf](http://arxiv.org/pdf/1808.08561v2)

> We propose a novel model for multi-label text classification, which is based on sequence-to-sequence learning. The model generates higher-level semantic unit representations with multi-level dilated convolution as well as a corresponding hybrid attention mechanism that extracts both the information at the word-level and the level of the semantic unit. Our designed dilated convolution effectively reduces dimension and supports an exponential expansion of receptive fields without loss of local information, and the attention-over-attention mechanism is able to capture more summary relevant information from the source context. Results of our experiments show that the proposed model has significant advantages over the baseline models on the dataset RCV1-V2 and Ren-CECps, and our analysis demonstrates that our model is competitive to the deterministic hierarchical models and it is more robust to classifying low-frequency labels.

</details>

<details>

<summary>2018-11-12 07:09:36 - Differentiating Concepts and Instances for Knowledge Graph Embedding</summary>

- *Xin Lv, Lei Hou, Juanzi Li, Zhiyuan Liu*

- `1811.04588v1` - [abs](http://arxiv.org/abs/1811.04588v1) - [pdf](http://arxiv.org/pdf/1811.04588v1)

> Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Specifically, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classification tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https:// github.com/davidlvxin/TransC.

</details>

<details>

<summary>2018-11-12 15:07:24 - Linguistically-Informed Self-Attention for Semantic Role Labeling</summary>

- *Emma Strubell, Patrick Verga, Daniel Andor, David Weiss, Andrew McCallum*

- `1804.08199v3` - [abs](http://arxiv.org/abs/1804.08199v3) - [pdf](http://arxiv.org/pdf/1804.08199v3)

> Current state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features. However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax. In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL. Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates. Syntax is incorporated by training one attention head to attend to syntactic parents for each token. Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model. In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10% reduction in error. On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1. LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.

</details>

<details>

<summary>2018-11-12 15:16:12 - Syntax Helps ELMo Understand Semantics: Is Syntax Still Relevant in a Deep Neural Architecture for SRL?</summary>

- *Emma Strubell, Andrew McCallum*

- `1811.04773v1` - [abs](http://arxiv.org/abs/1811.04773v1) - [pdf](http://arxiv.org/pdf/1811.04773v1)

> Do unsupervised methods for learning rich, contextualized token representations obviate the need for explicit modeling of linguistic structure in neural network models for semantic role labeling (SRL)? We address this question by incorporating the massively successful ELMo embeddings (Peters et al., 2018) into LISA (Strubell et al., 2018), a strong, linguistically-informed neural network architecture for SRL. In experiments on the CoNLL-2005 shared task we find that though ELMo out-performs typical word embeddings, beginning to close the gap in F1 between LISA with predicted and gold syntactic parses, syntactically-informed models still out-perform syntax-free models when both use ELMo, especially on out-of-domain data. Our results suggest that linguistic structures are indeed still relevant in this golden age of deep learning for NLP.

</details>

<details>

<summary>2018-11-12 17:06:53 - Bio-YODIE: A Named Entity Linking System for Biomedical Text</summary>

- *Genevieve Gorrell, Xingyi Song, Angus Roberts*

- `1811.04860v1` - [abs](http://arxiv.org/abs/1811.04860v1) - [pdf](http://arxiv.org/pdf/1811.04860v1)

> Ever-expanding volumes of biomedical text require automated semantic annotation techniques to curate and put to best use. An established field of research seeks to link mentions in text to knowledge bases such as those included in the UMLS (Unified Medical Language System), in order to enable a more sophisticated understanding. This work has yielded good results for tasks such as curating literature, but increasingly, annotation systems are more broadly applied. Medical vocabularies are expanding in size, and with them the extent of term ambiguity. Document collections are increasing in size and complexity, creating a greater need for speed and robustness. Furthermore, as the technologies are turned to new tasks, requirements change; for example greater coverage of expressions may be required in order to annotate patient records, and greater accuracy may be needed for applications that affect patients. This places new demands on the approaches currently in use. In this work, we present a new system, Bio-YODIE, and compare it to two other popular systems in order to give guidance about suitable approaches in different scenarios and how systems might be designed to accommodate future needs.

</details>

<details>

<summary>2018-11-12 20:02:00 - Unseen Word Representation by Aligning Heterogeneous Lexical Semantic Spaces</summary>

- *Victor Prokhorov, Mohammad Taher Pilehvar, Dimitri Kartsaklis, Pietro Lio, Nigel Collier*

- `1811.04983v1` - [abs](http://arxiv.org/abs/1811.04983v1) - [pdf](http://arxiv.org/pdf/1811.04983v1)

> Word embedding techniques heavily rely on the abundance of training data for individual words. Given the Zipfian distribution of words in natural language texts, a large number of words do not usually appear frequently or at all in the training data. In this paper we put forward a technique that exploits the knowledge encoded in lexical resources, such as WordNet, to induce embeddings for unseen words. Our approach adapts graph embedding and cross-lingual vector space transformation techniques in order to merge lexical knowledge encoded in ontologies with that derived from corpus statistics. We show that the approach can provide consistent performance improvements across multiple evaluation benchmarks: in-vitro, on multiple rare word similarity datasets, and in-vivo, in two downstream text classification tasks.

</details>

<details>

<summary>2018-11-12 22:05:25 - Improved Dynamic Memory Network for Dialogue Act Classification with Adversarial Training</summary>

- *Yao Wan, Wenqiang Yan, Jianwei Gao, Zhou Zhao, Jian Wu, Philip S. Yu*

- `1811.05021v1` - [abs](http://arxiv.org/abs/1811.05021v1) - [pdf](http://arxiv.org/pdf/1811.05021v1)

> Dialogue Act (DA) classification is a challenging problem in dialogue interpretation, which aims to attach semantic labels to utterances and characterize the speaker's intention. Currently, many existing approaches formulate the DA classification problem ranging from multi-classification to structured prediction, which suffer from two limitations: a) these methods are either handcrafted feature-based or have limited memories. b) adversarial examples can't be correctly classified by traditional training methods. To address these issues, in this paper we first cast the problem into a question and answering problem and proposed an improved dynamic memory networks with hierarchical pyramidal utterance encoder. Moreover, we apply adversarial training to train our proposed model. We evaluate our model on two public datasets, i.e., Switchboard dialogue act corpus and the MapTask corpus. Extensive experiments show that our proposed model is not only robust, but also achieves better performance when compared with some state-of-the-art baselines.

</details>

<details>

<summary>2018-11-13 06:22:02 - Modeling Local Dependence in Natural Language with Multi-channel Recurrent Neural Networks</summary>

- *Chang Xu, Weiran Huang, Hongwei Wang, Gang Wang, Tie-Yan Liu*

- `1811.05121v1` - [abs](http://arxiv.org/abs/1811.05121v1) - [pdf](http://arxiv.org/pdf/1811.05121v1)

> Recurrent Neural Networks (RNNs) have been widely used in processing natural language tasks and achieve huge success. Traditional RNNs usually treat each token in a sentence uniformly and equally. However, this may miss the rich semantic structure information of a sentence, which is useful for understanding natural languages. Since semantic structures such as word dependence patterns are not parameterized, it is a challenge to capture and leverage structure information. In this paper, we propose an improved variant of RNN, Multi-Channel RNN (MC-RNN), to dynamically capture and leverage local semantic structure information. Concretely, MC-RNN contains multiple channels, each of which represents a local dependence pattern at a time. An attention mechanism is introduced to combine these patterns at each step, according to the semantic information. Then we parameterize structure information by adaptively selecting the most appropriate connection structures among channels. In this way, diverse local structures and dependence patterns in sentences can be well captured by MC-RNN. To verify the effectiveness of MC-RNN, we conduct extensive experiments on typical natural language processing tasks, including neural machine translation, abstractive summarization, and language modeling. Experimental results on these tasks all show significant improvements of MC-RNN over current top systems.

</details>

<details>

<summary>2018-11-13 11:40:15 - Learning Segmentation Masks with the Independence Prior</summary>

- *Songmin Dai, Xiaoqiang Li, Lu Wang, Pin Wu, Weiqin Tong, Yimin Chen*

- `1811.04682v2` - [abs](http://arxiv.org/abs/1811.04682v2) - [pdf](http://arxiv.org/pdf/1811.04682v2)

> An instance with a bad mask might make a composite image that uses it look fake. This encourages us to learn segmentation by generating realistic composite images. To achieve this, we propose a novel framework that exploits a new proposed prior called the independence prior based on Generative Adversarial Networks (GANs). The generator produces an image with multiple category-specific instance providers, a layout module and a composition module. Firstly, each provider independently outputs a category-specific instance image with a soft mask. Then the provided instances' poses are corrected by the layout module. Lastly, the composition module combines these instances into a final image. Training with adversarial loss and penalty for mask area, each provider learns a mask that is as small as possible but enough to cover a complete category-specific instance. Weakly supervised semantic segmentation methods widely use grouping cues modeling the association between image parts, which are either artificially designed or learned with costly segmentation labels or only modeled on local pairs. Unlike them, our method automatically models the dependence between any parts and learns instance segmentation. We apply our framework in two cases: (1) Foreground segmentation on category-specific images with box-level annotation. (2) Unsupervised learning of instance appearances and masks with only one image of homogeneous object cluster (HOC). We get appealing results in both tasks, which shows the independence prior is useful for instance segmentation and it is possible to unsupervisedly learn instance masks with only one image.

</details>

<details>

<summary>2018-11-13 12:10:29 - A Multi-layer LSTM-based Approach for Robot Command Interaction Modeling</summary>

- *Martino Mensio, Emanuele Bastianelli, Ilaria Tiddi, Giuseppe Rizzo*

- `1811.05242v1` - [abs](http://arxiv.org/abs/1811.05242v1) - [pdf](http://arxiv.org/pdf/1811.05242v1)

> As the first robotic platforms slowly approach our everyday life, we can imagine a near future where service robots will be easily accessible by non-expert users through vocal interfaces. The capability of managing natural language would indeed speed up the process of integrating such platform in the ordinary life. Semantic parsing is a fundamental task of the Natural Language Understanding process, as it allows extracting the meaning of a user utterance to be used by a machine. In this paper, we present a preliminary study to semantically parse user vocal commands for a House Service robot, using a multi-layer Long-Short Term Memory neural network with attention mechanism. The system is trained on the Human Robot Interaction Corpus, and it is preliminarily compared with previous approaches.

</details>

<details>

<summary>2018-11-13 13:26:55 - Unsupervised Features Extraction for Binary Similarity Using Graph Embedding Neural Networks</summary>

- *Roberto Baldoni, Giuseppe Antonio Di Luna, Luca Massarelli, Fabio Petroni, Leonardo Querzoni*

- `1810.09683v2` - [abs](http://arxiv.org/abs/1810.09683v2) - [pdf](http://arxiv.org/pdf/1810.09683v2)

> In this paper we consider the binary similarity problem that consists in determining if two binary functions are similar only considering their compiled form. This problem is know to be crucial in several application scenarios, such as copyright disputes, malware analysis, vulnerability detection, etc. The current state-of-the-art solutions in this field work by creating an embedding model that maps binary functions into vectors in $\mathbb{R}^{n}$. Such embedding model captures syntactic and semantic similarity between binaries, i.e., similar binary functions are mapped to points that are close in the vector space. This strategy has many advantages, one of them is the possibility to precompute embeddings of several binary functions, and then compare them with simple geometric operations (e.g., dot product). In [32] functions are first transformed in Annotated Control Flow Graphs (ACFGs) constituted by manually engineered features and then graphs are embedded into vectors using a deep neural network architecture. In this paper we propose and test several ways to compute annotated control flow graphs that use unsupervised approaches for feature learning, without incurring a human bias. Our methods are inspired after techniques used in the natural language processing community (e.g., we use word2vec to encode assembly instructions). We show that our approach is indeed successful, and it leads to better performance than previous state-of-the-art solutions. Furthermore, we report on a qualitative analysis of functions embeddings. We found interesting cases in which embeddings are clustered according to the semantic of the original binary function.

</details>

<details>

<summary>2018-11-13 14:06:58 - Translating Natural Language to SQL using Pointer-Generator Networks and How Decoding Order Matters</summary>

- *Denis Lukovnikov, Nilesh Chakraborty, Jens Lehmann, Asja Fischer*

- `1811.05303v1` - [abs](http://arxiv.org/abs/1811.05303v1) - [pdf](http://arxiv.org/pdf/1811.05303v1)

> Translating natural language to SQL queries for table-based question answering is a challenging problem and has received significant attention from the research community. In this work, we extend a pointer-generator and investigate the order-matters problem in semantic parsing for SQL. Even though our model is a straightforward extension of a general-purpose pointer-generator, it outperforms early works for WikiSQL and remains competitive to concurrently introduced, more complex models. Moreover, we provide a deeper investigation of the potential order-matters problem that could arise due to having multiple correct decoding paths, and investigate the use of REINFORCE as well as a dynamic oracle in this context.

</details>

<details>

<summary>2018-11-13 17:18:48 - ABox Abduction via Forgetting in ALC (Long Version)</summary>

- *Warren Del-Pinto, Renate A. Schmidt*

- `1811.05420v1` - [abs](http://arxiv.org/abs/1811.05420v1) - [pdf](http://arxiv.org/pdf/1811.05420v1)

> Abductive reasoning generates explanatory hypotheses for new observations using prior knowledge. This paper investigates the use of forgetting, also known as uniform interpolation, to perform ABox abduction in description logic (ALC) ontologies. Non-abducibles are specified by a forgetting signature which can contain concept, but not role, symbols. The resulting hypotheses are semantically minimal and each consist of a set of disjuncts. These disjuncts are each independent explanations, and are not redundant with respect to the background ontology or the other disjuncts, representing a form of hypothesis space. The observations and hypotheses handled by the method can contain both atomic or complex ALC concepts, excluding role assertions, and are not restricted to Horn clauses. Two approaches to redundancy elimination are explored for practical use: full and approximate. Using a prototype implementation, experiments were performed over a corpus of real world ontologies to investigate the practicality of both approaches across several settings.

</details>

<details>

<summary>2018-11-13 19:14:50 - FermiNets: Learning generative machines to generate efficient neural networks via generative synthesis</summary>

- *Alexander Wong, Mohammad Javad Shafiee, Brendan Chwyl, Francis Li*

- `1809.05989v2` - [abs](http://arxiv.org/abs/1809.05989v2) - [pdf](http://arxiv.org/pdf/1809.05989v2)

> The tremendous potential exhibited by deep learning is often offset by architectural and computational complexity, making widespread deployment a challenge for edge scenarios such as mobile and other consumer devices. To tackle this challenge, we explore the following idea: Can we learn generative machines to automatically generate deep neural networks with efficient network architectures? In this study, we introduce the idea of generative synthesis, which is premised on the intricate interplay between a generator-inquisitor pair that work in tandem to garner insights and learn to generate highly efficient deep neural networks that best satisfies operational requirements. What is most interesting is that, once a generator has been learned through generative synthesis, it can be used to generate not just one but a large variety of different, unique highly efficient deep neural networks that satisfy operational requirements. Experimental results for image classification, semantic segmentation, and object detection tasks illustrate the efficacy of generative synthesis in producing generators that automatically generate highly efficient deep neural networks (which we nickname FermiNets) with higher model efficiency and lower computational costs (reaching >10x more efficient and fewer multiply-accumulate operations than several tested state-of-the-art networks), as well as higher energy efficiency (reaching >4x improvements in image inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As such, generative synthesis can be a powerful, generalized approach for accelerating and improving the building of deep neural networks for on-device edge scenarios.

</details>

<details>

<summary>2018-11-13 22:08:39 - Discourse in Multimedia: A Case Study in Information Extraction</summary>

- *Mrinmaya Sachan, Kumar Avinava Dubey, Eduard H. Hovy, Tom M. Mitchell, Dan Roth, Eric P. Xing*

- `1811.05546v1` - [abs](http://arxiv.org/abs/1811.05546v1) - [pdf](http://arxiv.org/pdf/1811.05546v1)

> To ensure readability, text is often written and presented with due formatting. These text formatting devices help the writer to effectively convey the narrative. At the same time, these help the readers pick up the structure of the discourse and comprehend the conveyed information. There have been a number of linguistic theories on discourse structure of text. However, these theories only consider unformatted text. Multimedia text contains rich formatting features which can be leveraged for various NLP tasks. In this paper, we study some of these discourse features in multimedia text and what communicative function they fulfil in the context. We examine how these multimedia discourse features can be used to improve an information extraction system. We show that the discourse and text layout features provide information that is complementary to lexical semantic information commonly used for information extraction. As a case study, we use these features to harvest structured subject knowledge of geometry from textbooks. We show that the harvested structured knowledge can be used to improve an existing solver for geometry problems, making it more accurate as well as more explainable.

</details>

<details>

<summary>2018-11-13 22:24:29 - An Analysis of the Semantic Annotation Task on the Linked Data Cloud</summary>

- *Gagnon Michel, Zouaq Amal, Aranha Francisco, Ensan Faezeh, Jean-Louis Ludovic*

- `1811.05549v1` - [abs](http://arxiv.org/abs/1811.05549v1) - [pdf](http://arxiv.org/pdf/1811.05549v1)

> Semantic annotation, the process of identifying key-phrases in texts and linking them to concepts in a knowledge base, is an important basis for semantic information retrieval and the Semantic Web uptake. Despite the emergence of semantic annotation systems, very few comparative studies have been published on their performance. In this paper, we provide an evaluation of the performance of existing systems over three tasks: full semantic annotation, named entity recognition, and keyword detection. More specifically, the spotting capability (recognition of relevant surface forms in text) is evaluated for all three tasks, whereas the disambiguation (correctly associating an entity from Wikipedia or DBpedia to the spotted surface forms) is evaluated only for the first two tasks. Our evaluation is twofold: First, we compute standard precision and recall on the output of semantic annotators on diverse datasets, each best suited for one of the identified tasks. Second, we build a statistical model using logistic regression to identify significant performance differences. Our results show that systems that provide full annotation perform better than named entities annotators and keyword extractors, for all three tasks. However, there is still much room for improvement for the identification of the most relevant entities described in a text.

</details>

<details>

<summary>2018-11-13 23:11:26 - Text Assisted Insight Ranking Using Context-Aware Memory Network</summary>

- *Qi Zeng, Liangchen Luo, Wenhao Huang, Yang Tang*

- `1811.05563v1` - [abs](http://arxiv.org/abs/1811.05563v1) - [pdf](http://arxiv.org/pdf/1811.05563v1)

> Extracting valuable facts or informative summaries from multi-dimensional tables, i.e. insight mining, is an important task in data analysis and business intelligence. However, ranking the importance of insights remains a challenging and unexplored task. The main challenge is that explicitly scoring an insight or giving it a rank requires a thorough understanding of the tables and costs a lot of manual efforts, which leads to the lack of available training data for the insight ranking problem. In this paper, we propose an insight ranking model that consists of two parts: A neural ranking model explores the data characteristics, such as the header semantics and the data statistical features, and a memory network model introduces table structure and context information into the ranking process. We also build a dataset with text assistance. Experimental results show that our approach largely improves the ranking precision as reported in multi evaluation metrics.

</details>

<details>

<summary>2018-11-14 01:03:47 - Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes</summary>

- *Yang Zhang, Philip David, Boqing Gong*

- `1707.09465v5` - [abs](http://arxiv.org/abs/1707.09465v5) - [pdf](http://arxiv.org/pdf/1707.09465v5)

> During the last half decade, convolutional neural networks (CNNs) have triumphed over semantic segmentation, which is one of the core tasks in many applications such as autonomous driving. However, to train CNNs requires a considerable amount of data, which is difficult to collect and laborious to annotate. Recent advances in computer graphics make it possible to train CNNs on photo-realistic synthetic imagery with computer-generated annotations. Despite this, the domain mismatch between the real images and the synthetic data cripples the models' performance. Hence, we propose a curriculum-style learning approach to minimize the domain gap in urban scenery semantic segmentation. The curriculum domain adaptation solves easy tasks first to infer necessary properties about the target domain; in particular, the first task is to learn global label distributions over images and local distributions over landmark superpixels. These are easy to estimate because images of urban scenes have strong idiosyncrasies (e.g., the size and spatial relations of buildings, streets, cars, etc.). We then train a segmentation network while regularizing its predictions in the target domain to follow those inferred properties. In experiments, our method outperforms the baselines on two datasets and two backbone networks. We also report extensive ablation studies about our approach.

</details>

<details>

<summary>2018-11-14 10:49:39 - A Deterministic Algorithm for Bridging Anaphora Resolution</summary>

- *Yufang Hou*

- `1811.05721v1` - [abs](http://arxiv.org/abs/1811.05721v1) - [pdf](http://arxiv.org/pdf/1811.05721v1)

> Previous work on bridging anaphora resolution (Poesio et al., 2004; Hou et al., 2013b) use syntactic preposition patterns to calculate word relatedness. However, such patterns only consider NPs' head nouns and hence do not fully capture the semantics of NPs. Recently, Hou (2018) created word embeddings (embeddings_PP) to capture associative similarity (ie, relatedness) between nouns by exploring the syntactic structure of noun phrases. But embeddings_PP only contains word representations for nouns. In this paper, we create new word vectors by combining embeddings_PP with GloVe. This new word embeddings (embeddings_bridging) are a more general lexical knowledge resource for bridging and allow us to represent the meaning of an NP beyond its head easily. We therefore develop a deterministic approach for bridging anaphora resolution, which represents the semantics of an NP based on its head noun and modifications. We show that this simple approach achieves the competitive results compared to the best system in Hou et al.(2013b) which explores Markov Logic Networks to model the problem. Additionally, we further improve the results for bridging anaphora resolution reported in Hou (2018) by combining our simple deterministic approach with Hou et al.(2013b)'s best system MLN II.

</details>

<details>

<summary>2018-11-14 11:02:55 - An Introduction to Fuzzy & Annotated Semantic Web Languages</summary>

- *Umberto Straccia*

- `1811.05724v1` - [abs](http://arxiv.org/abs/1811.05724v1) - [pdf](http://arxiv.org/pdf/1811.05724v1)

> We present the state of the art in representing and reasoning with fuzzy knowledge in Semantic Web Languages such as triple languages RDF/RDFS, conceptual languages of the OWL 2 family and rule languages. We further show how one may generalise them to so-called annotation domains, that cover also e.g. temporal and provenance extensions.

</details>

<details>

<summary>2018-11-14 14:45:35 - A Grammar-Based Structural CNN Decoder for Code Generation</summary>

- *Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong, Ge Li, Lu Zhang*

- `1811.06837v1` - [abs](http://arxiv.org/abs/1811.06837v1) - [pdf](http://arxiv.org/pdf/1811.06837v1)

> Code generation maps a program description to executable source code in a programming language. Existing approaches mainly rely on a recurrent neural network (RNN) as the decoder. However, we find that a program contains significantly more tokens than a natural language sentence, and thus it may be inappropriate for RNN to capture such a long sequence. In this paper, we propose a grammar-based structural convolutional neural network (CNN) for code generation. Our model generates a program by predicting the grammar rules of the programming language; we design several CNN modules, including the tree-based convolution and pre-order convolution, whose information is further aggregated by dedicated attentive pooling layers. Experimental results on the HearthStone benchmark dataset show that our CNN code generator significantly outperforms the previous state-of-the-art method by 5 percentage points; additional experiments on several semantic parsing tasks demonstrate the robustness of our model. We also conduct in-depth ablation test to better understand each component of our model.

</details>

<details>

<summary>2018-11-14 15:12:47 - Unsupervised Abstractive Meeting Summarization with Multi-Sentence Compression and Budgeted Submodular Maximization</summary>

- *Guokan Shang, Wensi Ding, Zekun Zhang, Antoine Jean-Pierre Tixier, Polykarpos Meladianos, Michalis Vazirgiannis, Jean-Pierre Lorré*

- `1805.05271v2` - [abs](http://arxiv.org/abs/1805.05271v2) - [pdf](http://arxiv.org/pdf/1805.05271v2)

> We introduce a novel graph-based framework for abstractive meeting speech summarization that is fully unsupervised and does not rely on any annotations. Our work combines the strengths of multiple recent approaches while addressing their weaknesses. Moreover, we leverage recent advances in word embeddings and graph degeneracy applied to NLP to take exterior semantic knowledge into account, and to design custom diversity and informativeness measures. Experiments on the AMI and ICSI corpus show that our system improves on the state-of-the-art. Code and data are publicly available, and our system can be interactively tested.

</details>

<details>

<summary>2018-11-14 15:24:51 - A task in a suit and a tie: paraphrase generation with semantic augmentation</summary>

- *Su Wang, Rahul Gupta, Nancy Chang, Jason Baldridge*

- `1811.00119v2` - [abs](http://arxiv.org/abs/1811.00119v2) - [pdf](http://arxiv.org/pdf/1811.00119v2)

> Paraphrasing is rooted in semantics. We show the effectiveness of transformers (Vaswani et al. 2017) for paraphrase generation and further improvements by incorporating PropBank labels via a multi-encoder. Evaluating on MSCOCO and WikiAnswers, we find that transformers are fast and effective, and that semantic augmentation for both transformers and LSTMs leads to sizable 2-3 point gains in BLEU, METEOR and TER. More importantly, we find surprisingly large gains on human evaluations compared to previous models. Nevertheless, manual inspection of generated paraphrases reveals ample room for improvement: even our best model produces human-acceptable paraphrases for only 28% of captions from the CHIA dataset (Sharma et al. 2018), and it fails spectacularly on sentences from Wikipedia. Overall, these results point to the potential for incorporating semantics in the task while highlighting the need for stronger evaluation.

</details>

<details>

<summary>2018-11-14 15:25:30 - Using Sparse Semantic Embeddings Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge</summary>

- *Steven Derby, Paul Miller, Brian Murphy, Barry Devereux*

- `1809.02534v3` - [abs](http://arxiv.org/abs/1809.02534v3) - [pdf](http://arxiv.org/pdf/1809.02534v3)

> Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms. However, the dimensions of dense embedding spaces are not designed to resemble human semantic knowledge. Moreover, embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception. In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding. Through in-depth analyses comparing these sparse models to human-derived behavioural and neuroimaging data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.

</details>

<details>

<summary>2018-11-14 15:30:31 - ColNet: Embedding the Semantics of Web Tables for Column Type Prediction</summary>

- *Jiaoyan Chen, Ernesto Jimenez-Ruiz, Ian Horrocks, Charles Sutton*

- `1811.01304v2` - [abs](http://arxiv.org/abs/1811.01304v2) - [pdf](http://arxiv.org/pdf/1811.01304v2)

> Automatically annotating column types with knowledge base (KB) concepts is a critical task to gain a basic understanding of web tables. Current methods rely on either table metadata like column name or entity correspondences of cells in the KB, and may fail to deal with growing web tables with incomplete meta information. In this paper we propose a neural network based column type annotation framework named ColNet which is able to integrate KB reasoning and lookup with machine learning and can automatically train Convolutional Neural Networks for prediction. The prediction model not only considers the contextual semantics within a cell using word representation, but also embeds the semantics of a column by learning locality features from multiple cells. The method is evaluated with DBPedia and two different web table datasets, T2Dv2 from the general Web and Limaye from Wikipedia pages, and achieves higher performance than the state-of-the-art approaches.

</details>

<details>

<summary>2018-11-14 16:58:25 - Blockchain-based Firmware Update Scheme Tailored for Autonomous Vehicles</summary>

- *Mohamed Baza, Mahmoud Nabil, Noureddine Lasla, Kemal Fidan, Mohamed Mahmoud, Mohamed Abdallah*

- `1811.05905v1` - [abs](http://arxiv.org/abs/1811.05905v1) - [pdf](http://arxiv.org/pdf/1811.05905v1)

> Recently, Autonomous Vehicles (AVs) have gained extensive attention from both academia and industry. AVs are a complex system composed of many subsystems, making them a typical target for attackers. Therefore, the firmware of the different subsystems needs to be updated to the latest version by the manufacturer to fix bugs and introduce new features, e.g., using security patches. In this paper, we propose a distributed firmware update scheme for the AVs' subsystems, leveraging blockchain and smart contract technology. A consortium blockchain made of different AVs manufacturers is used to ensure the authenticity and integrity of firmware updates. Instead of depending on centralized third parties to distribute the new updates, we enable AVs, namely distributors, to participate in the distribution process and we take advantage of their mobility to guarantee high availability and fast delivery of the updates. To incentivize AVs to distribute the updates, a reward system is established that maintains a credit reputation for each distributor account in the blockchain. A zero-knowledge proof protocol is used to exchange the update in return for a proof of distribution in a trust-less environment. Moreover, we use attribute-based encryption (ABE) scheme to ensure that only authorized AVs will be able to download and use a new update. Our analysis indicates that the additional cryptography primitives and exchanged transactions do not affect the operation of the AVs network. Also, our security analysis demonstrates that our scheme is efficient and secure against different attacks.

</details>

<details>

<summary>2018-11-14 18:08:39 - Interactive Semantic Parsing for If-Then Recipes via Hierarchical Reinforcement Learning</summary>

- *Ziyu Yao, Xiujun Li, Jianfeng Gao, Brian Sadler, Huan Sun*

- `1808.06740v2` - [abs](http://arxiv.org/abs/1808.06740v2) - [pdf](http://arxiv.org/pdf/1808.06740v2)

> Given a text description, most existing semantic parsers synthesize a program in one shot. However, it is quite challenging to produce a correct program solely based on the description, which in reality is often ambiguous or incomplete. In this paper, we investigate interactive semantic parsing, where the agent can ask the user clarification questions to resolve ambiguities via a multi-turn dialogue, on an important type of programs called "If-Then recipes." We develop a hierarchical reinforcement learning (HRL) based agent that significantly improves the parsing performance with minimal questions to the user. Results under both simulation and human evaluation show that our agent substantially outperforms non-interactive semantic parsers and rule-based agents.

</details>

<details>

<summary>2018-11-15 03:38:20 - Exploiting Sentence Embedding for Medical Question Answering</summary>

- *Yu Hao, Xien Liu, Ji Wu, Ping Lv*

- `1811.06156v1` - [abs](http://arxiv.org/abs/1811.06156v1) - [pdf](http://arxiv.org/pdf/1811.06156v1)

> Despite the great success of word embedding, sentence embedding remains a not-well-solved problem. In this paper, we present a supervised learning framework to exploit sentence embedding for the medical question answering task. The learning framework consists of two main parts: 1) a sentence embedding producing module, and 2) a scoring module. The former is developed with contextual self-attention and multi-scale techniques to encode a sentence into an embedding tensor. This module is shortly called Contextual self-Attention Multi-scale Sentence Embedding (CAMSE). The latter employs two scoring strategies: Semantic Matching Scoring (SMS) and Semantic Association Scoring (SAS). SMS measures similarity while SAS captures association between sentence pairs: a medical question concatenated with a candidate choice, and a piece of corresponding supportive evidence. The proposed framework is examined by two Medical Question Answering(MedicalQA) datasets which are collected from real-world applications: medical exam and clinical diagnosis based on electronic medical records (EMR). The comparison results show that our proposed framework achieved significant improvements compared to competitive baseline approaches. Additionally, a series of controlled experiments are also conducted to illustrate that the multi-scale strategy and the contextual self-attention layer play important roles for producing effective sentence embedding, and the two kinds of scoring strategies are highly complementary to each other for question answering problems.

</details>

<details>

<summary>2018-11-15 04:15:34 - Plan Interdiction Games</summary>

- *Yevgeniy Vorobeychik, Michael Pritchard*

- `1811.06162v1` - [abs](http://arxiv.org/abs/1811.06162v1) - [pdf](http://arxiv.org/pdf/1811.06162v1)

> We propose a framework for cyber risk assessment and mitigation which models attackers as formal planners and defenders as interdicting such plans. We illustrate the value of plan interdiction problems by first modeling network cyber risk through the use of formal planning, and subsequently formalizing an important question of prioritizing vulnerabilities for patching in the plan interdiction framework. In particular, we show that selectively patching relatively few vulnerabilities allows a network administrator to significantly reduce exposure to cyber risk. More broadly, we have developed a number of scalable approaches for plan interdiction problems, making especially significant advances when attack plans involve uncertainty about system dynamics. However, important open problems remain, including how to effectively capture information asymmetry between the attacker and defender, how to best model dynamics in the attacker-defender interaction, and how to develop scalable algorithms for solving associated plan interdiction games.

</details>

<details>

<summary>2018-11-15 04:49:21 - Leveraging Financial News for Stock Trend Prediction with Attention-Based Recurrent Neural Network</summary>

- *Huicheng Liu*

- `1811.06173v1` - [abs](http://arxiv.org/abs/1811.06173v1) - [pdf](http://arxiv.org/pdf/1811.06173v1)

> Stock market prediction is one of the most attractive research topic since the successful prediction on the market's future movement leads to significant profit. Traditional short term stock market predictions are usually based on the analysis of historical market data, such as stock prices, moving averages or daily returns. However, financial news also contains useful information on public companies and the market. Existing methods in finance literature exploit sentiment signal features, which are limited by not considering factors such as events and the news context. We address this issue by leveraging deep neural models to extract rich semantic features from news text. In particular, a Bidirectional-LSTM are used to encode the news text and capture the context information, self attention mechanism are applied to distribute attention on most relative words, news and days. In terms of predicting directional changes in both Standard & Poor's 500 index and individual companies stock price, we show that this technique is competitive with other state of the art approaches, demonstrating the effectiveness of recent NLP technology advances for computational finance.

</details>

<details>

<summary>2018-11-15 04:58:21 - Implementing a Portable Clinical NLP System with a Common Data Model - a Lisp Perspective</summary>

- *Yuan Luo, Peter Szolovits*

- `1811.06179v1` - [abs](http://arxiv.org/abs/1811.06179v1) - [pdf](http://arxiv.org/pdf/1811.06179v1)

> This paper presents a Lisp architecture for a portable NLP system, termed LAPNLP, for processing clinical notes. LAPNLP integrates multiple standard, customized and in-house developed NLP tools. Our system facilitates portability across different institutions and data systems by incorporating an enriched Common Data Model (CDM) to standardize necessary data elements. It utilizes UMLS to perform domain adaptation when integrating generic domain NLP tools. It also features stand-off annotations that are specified by positional reference to the original document. We built an interval tree based search engine to efficiently query and retrieve the stand-off annotations by specifying positional requirements. We also developed a utility to convert an inline annotation format to stand-off annotations to enable the reuse of clinical text datasets with inline annotations. We experimented with our system on several NLP facilitated tasks including computational phenotyping for lymphoma patients and semantic relation extraction for clinical notes. These experiments showcased the broader applicability and utility of LAPNLP.

</details>

<details>

<summary>2018-11-15 11:30:08 - Near-lossless Binarization of Word Embeddings</summary>

- *Julien Tissier, Christophe Gravier, Amaury Habrard*

- `1803.09065v3` - [abs](http://arxiv.org/abs/1803.09065v3) - [pdf](http://arxiv.org/pdf/1803.09065v3)

> Word embeddings are commonly used as a starting point in many NLP models to achieve state-of-the-art performances. However, with a large vocabulary and many dimensions, these floating-point representations are expensive both in terms of memory and calculations which makes them unsuitable for use on low-resource devices. The method proposed in this paper transforms real-valued embeddings into binary embeddings while preserving semantic information, requiring only 128 or 256 bits for each vector. This leads to a small memory footprint and fast vector operations. The model is based on an autoencoder architecture, which also allows to reconstruct original vectors from the binary ones. Experimental results on semantic similarity, text classification and sentiment analysis tasks show that the binarization of word embeddings only leads to a loss of ~2% in accuracy while vector size is reduced by 97%. Furthermore, a top-k benchmark demonstrates that using these binary vectors is 30 times faster than using real-valued vectors.

</details>

<details>

<summary>2018-11-15 17:49:50 - Development and Validation of a Deep Learning Algorithm for Improving Gleason Scoring of Prostate Cancer</summary>

- *Kunal Nagpal, Davis Foote, Yun Liu, Po-Hsuan, Chen, Ellery Wulczyn, Fraser Tan, Niels Olson, Jenny L. Smith, Arash Mohtashamian, James H. Wren, Greg S. Corrado, Robert MacDonald, Lily H. Peng, Mahul B. Amin, Andrew J. Evans, Ankur R. Sangoi, Craig H. Mermel, Jason D. Hipp, Martin C. Stumpe*

- `1811.06497v1` - [abs](http://arxiv.org/abs/1811.06497v1) - [pdf](http://arxiv.org/pdf/1811.06497v1)

> For prostate cancer patients, the Gleason score is one of the most important prognostic factors, potentially determining treatment independent of the stage. However, Gleason scoring is based on subjective microscopic examination of tumor morphology and suffers from poor reproducibility. Here we present a deep learning system (DLS) for Gleason scoring whole-slide images of prostatectomies. Our system was developed using 112 million pathologist-annotated image patches from 1,226 slides, and evaluated on an independent validation dataset of 331 slides, where the reference standard was established by genitourinary specialist pathologists. On the validation dataset, the mean accuracy among 29 general pathologists was 0.61. The DLS achieved a significantly higher diagnostic accuracy of 0.70 (p=0.002) and trended towards better patient risk stratification in correlations to clinical follow-up data. Our approach could improve the accuracy of Gleason scoring and subsequent therapy decisions, particularly where specialist expertise is unavailable. The DLS also goes beyond the current Gleason system to more finely characterize and quantitate tumor morphology, providing opportunities for refinement of the Gleason system itself.

</details>

<details>

<summary>2018-11-15 19:29:26 - Automatic Text Document Summarization using Semantic-based Analysis</summary>

- *Chandra Shekhar Yadav*

- `1811.06567v1` - [abs](http://arxiv.org/abs/1811.06567v1) - [pdf](http://arxiv.org/pdf/1811.06567v1)

> Since the advent of the web, the amount of data on wen has been increased several million folds. In recent years web data generated is more than data stored for years. One important data format is text. To answer user queries over the internet, and to overcome the problem of information overload one possible solution is text document summarization. This not only reduces query access time, but also optimize the document results according to specific users requirements. Summarization of text document can be categorized as abstractive and extractive. Most of the work has been done in the direction of Extractive summarization. Extractive summarized result is a subset of original documents with the objective of more content coverage and lea redundancy. Our work is based on Extractive approaches. In the first approach, we are using some statistical features and semantic-based features. To include sentiment as a feature is an idea cached from a view that emotion plays an important role. It effectively conveys a message. So, it may play a vital role in text document summarization.

</details>

<details>

<summary>2018-11-15 21:29:26 - On Generality and Knowledge Transferability in Cross-Domain Duplicate Question Detection for Heterogeneous Community Question Answering</summary>

- *Mohomed Shazan Mohomed Jabbar, Luke Kumar, Hamman Samuel, Mi-Young Kim, Sankalp Prabhakar, Randy Goebel, Osmar Zaïane*

- `1811.06596v1` - [abs](http://arxiv.org/abs/1811.06596v1) - [pdf](http://arxiv.org/pdf/1811.06596v1)

> Duplicate question detection is an ongoing challenge in community question answering because semantically equivalent questions can have significantly different words and structures. In addition, the identification of duplicate questions can reduce the resources required for retrieval, when the same questions are not repeated. This study compares the performance of deep neural networks and gradient tree boosting, and explores the possibility of domain adaptation with transfer learning to improve the under-performing target domains for the text-pair duplicates classification task, using three heterogeneous datasets: general-purpose Quora, technical Ask Ubuntu, and academic English Stack Exchange. Ultimately, our study exposes the alternative hypothesis that the meaning of a "duplicate" is not inherently general-purpose, but rather is dependent on the domain of learning, hence reducing the chance of transfer learning through adapting to the domain.

</details>

<details>

<summary>2018-11-15 23:47:39 - Nudging Neural Conversational Model with Domain Knowledge</summary>

- *Sungjin Lee*

- `1811.06630v1` - [abs](http://arxiv.org/abs/1811.06630v1) - [pdf](http://arxiv.org/pdf/1811.06630v1)

> Neural conversation models are attractive because one can train a model directly on dialog examples with minimal labeling. With a small amount of data, however, they often fail to generalize over test data since they tend to capture spurious features instead of semantically meaningful domain knowledge. To address this issue, we propose a novel approach that allows any human teachers to transfer their domain knowledge to the conversation model in the form of natural language rules. We tested our method with three different dialog datasets. The improved performance across all domains demonstrates the efficacy of our proposed method.

</details>

<details>

<summary>2018-11-16 03:29:34 - Composite Binary Decomposition Networks</summary>

- *You Qiaoben, Zheng Wang, Jianguo Li, Yinpeng Dong, Yu-Gang Jiang, Jun Zhu*

- `1811.06668v1` - [abs](http://arxiv.org/abs/1811.06668v1) - [pdf](http://arxiv.org/pdf/1811.06668v1)

> Binary neural networks have great resource and computing efficiency, while suffer from long training procedure and non-negligible accuracy drops, when comparing to the full-precision counterparts. In this paper, we propose the composite binary decomposition networks (CBDNet), which first compose real-valued tensor of each layer with a limited number of binary tensors, and then decompose some conditioned binary tensors into two low-rank binary tensors, so that the number of parameters and operations are greatly reduced comparing to the original ones. Experiments demonstrate the effectiveness of the proposed method, as CBDNet can approximate image classification network ResNet-18 using 5.25 bits, VGG-16 using 5.47 bits, DenseNet-121 using 5.72 bits, object detection networks SSD300 using 4.38 bits, and semantic segmentation networks SegNet using 5.18 bits, all with minor accuracy drops.

</details>

<details>

<summary>2018-11-16 05:36:16 - DeepHunter: Hunting Deep Neural Network Defects via Coverage-Guided Fuzzing</summary>

- *Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Hongxu Chen, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, Jianxiong Yin, Simon See*

- `1809.01266v3` - [abs](http://arxiv.org/abs/1809.01266v3) - [pdf](http://arxiv.org/pdf/1809.01266v3)

> In company with the data explosion over the past decade, deep neural network (DNN) based software has experienced unprecedented leap and is becoming the key driving force of many novel industrial applications, including many safety-critical scenarios such as autonomous driving. Despite great success achieved in various human intelligence tasks, similar to traditional software, DNNs could also exhibit incorrect behaviors caused by hidden defects causing severe accidents and losses. In this paper, we propose DeepHunter, an automated fuzz testing framework for hunting potential defects of general-purpose DNNs. DeepHunter performs metamorphic mutation to generate new semantically preserved tests, and leverages multiple plugable coverage criteria as feedback to guide the test generation from different perspectives. To be scalable towards practical-sized DNNs, DeepHunter maintains multiple tests in a batch, and prioritizes the tests selection based on active feedback. The effectiveness of DeepHunter is extensively investigated on 3 popular datasets (MNIST, CIFAR-10, ImageNet) and 7 DNNs with diverse complexities, under a large set of 6 coverage criteria as feedback. The large-scale experiments demonstrate that DeepHunter can (1) significantly boost the coverage with guidance; (2) generate useful tests to detect erroneous behaviors and facilitate the DNN model quality evaluation; (3) accurately capture potential defects during DNN quantization for platform migration.

</details>

<details>

<summary>2018-11-16 07:09:30 - Exploiting Coarse-to-Fine Task Transfer for Aspect-level Sentiment Classification</summary>

- *Zheng Li, Ying Wei, Yu Zhang, Xiang Zhang, Xin Li, Qiang Yang*

- `1811.10999v1` - [abs](http://arxiv.org/abs/1811.10999v1) - [pdf](http://arxiv.org/pdf/1811.10999v1)

> Aspect-level sentiment classification (ASC) aims at identifying sentiment polarities towards aspects in a sentence, where the aspect can behave as a general Aspect Category (AC) or a specific Aspect Term (AT). However, due to the especially expensive and labor-intensive labeling, existing public corpora in AT-level are all relatively small. Meanwhile, most of the previous methods rely on complicated structures with given scarce data, which largely limits the efficacy of the neural models. In this paper, we exploit a new direction named coarse-to-fine task transfer, which aims to leverage knowledge learned from a rich-resource source domain of the coarse-grained AC task, which is more easily accessible, to improve the learning in a low-resource target domain of the fine-grained AT task. To resolve both the aspect granularity inconsistency and feature mismatch between domains, we propose a Multi-Granularity Alignment Network (MGAN). In MGAN, a novel Coarse2Fine attention guided by an auxiliary task can help the AC task modeling at the same fine-grained level with the AT task. To alleviate the feature false alignment, a contrastive feature alignment method is adopted to align aspect-specific feature representations semantically. In addition, a large-scale multi-domain dataset for the AC task is provided. Empirically, extensive experiments demonstrate the effectiveness of the MGAN.

</details>

<details>

<summary>2018-11-16 11:47:44 - Ontology based Approach for Semantic Service Selection in Business Process Re-Engineering</summary>

- *Sophea Chhun, Néjib Moalla, Yacine Ouzrout*

- `1812.03802v1` - [abs](http://arxiv.org/abs/1812.03802v1) - [pdf](http://arxiv.org/pdf/1812.03802v1)

> This research aims to provide the possibility to the business analysts to be able to know whether their design business processes are feasible or not. In order to solve this problem, we proposed a model called BPMNSemAuto that makes use of the existing services stored in the service registry UDDI (Universal Description Discovery and Integration). From the data extracted from the UDDI, the WSDL files and the tracking data of service execution on the server, a Web Service Ontology (WSOnto) is generated to store all the existing services. The BPMNSemAuto model takes an input of business process design specifications, and it generates an executable business process as an output. It provides an interface for business analysts to specify the description of each service task of the design business process. For each service task, the business analysts specify the task objective (keywords), inputs, outputs and weights of the Quality of Service (QoS) properties. From the design business process with the service task specifications, a Business Process Ontology (BPOnto) is generated. A service selection algorithm performs the mapping between the instances of the WSOnto and the BPOnto to obtain possible mappings between these two ontologies. The obtained mappings help the model to acquire web services to execute the desired service tasks. Moreover, the consistency checking of the inputs of the proposed model is performed before executing the service selection algorithm. WordNet is used to solve the synonym problems and at the same time a keyword extraction method is presented in this paper.

</details>

<details>

<summary>2018-11-16 21:08:50 - Mining Entity Synonyms with Efficient Neural Set Generation</summary>

- *Jiaming Shen, Ruiliang Lyu, Xiang Ren, Michelle Vanni, Brian Sadler, Jiawei Han*

- `1811.07032v1` - [abs](http://arxiv.org/abs/1811.07032v1) - [pdf](http://arxiv.org/pdf/1811.07032v1)

> Mining entity synonym sets (i.e., sets of terms referring to the same entity) is an important task for many entity-leveraging applications. Previous work either rank terms based on their similarity to a given query term, or treats the problem as a two-phase task (i.e., detecting synonymy pairs, followed by organizing these pairs into synonym sets). However, these approaches fail to model the holistic semantics of a set and suffer from the error propagation issue. Here we propose a new framework, named SynSetMine, that efficiently generates entity synonym sets from a given vocabulary, using example sets from external knowledge bases as distant supervision. SynSetMine consists of two novel modules: (1) a set-instance classifier that jointly learns how to represent a permutation invariant synonym set and whether to include a new instance (i.e., a term) into the set, and (2) a set generation algorithm that enumerates the vocabulary only once and applies the learned set-instance classifier to detect all entity synonym sets in it. Experiments on three real datasets from different domains demonstrate both effectiveness and efficiency of SynSetMine for mining entity synonym sets.

</details>

<details>

<summary>2018-11-16 21:12:24 - Analyzing Compositionality-Sensitivity of NLI Models</summary>

- *Yixin Nie, Yicheng Wang, Mohit Bansal*

- `1811.07033v1` - [abs](http://arxiv.org/abs/1811.07033v1) - [pdf](http://arxiv.org/pdf/1811.07033v1)

> Success in natural language inference (NLI) should require a model to understand both lexical and compositional semantics. However, through adversarial evaluation, we find that several state-of-the-art models with diverse architectures are over-relying on the former and fail to use the latter. Further, this compositionality unawareness is not reflected via standard evaluation on current datasets. We show that removing RNNs in existing models or shuffling input words during training does not induce large performance loss despite the explicit removal of compositional information. Therefore, we propose a compositionality-sensitivity testing setup that analyzes models on natural examples from existing datasets that cannot be solved via lexical features alone (i.e., on which a bag-of-words model gives a high probability to one wrong label), hence revealing the models' actual compositionality awareness. We show that this setup not only highlights the limited compositional ability of current NLI models, but also differentiates model performance based on design, e.g., separating shallow bag-of-words models from deeper, linguistically-grounded tree-based models. Our evaluation setup is an important analysis tool: complementing currently existing adversarial and linguistically driven diagnostic evaluations, and exposing opportunities for future work on evaluating models' compositional understanding.

</details>

<details>

<summary>2018-11-16 21:37:59 - Combining Fact Extraction and Verification with Neural Semantic Matching Networks</summary>

- *Yixin Nie, Haonan Chen, Mohit Bansal*

- `1811.07039v1` - [abs](http://arxiv.org/abs/1811.07039v1) - [pdf](http://arxiv.org/pdf/1811.07039v1)

> The increasing concern with misinformation has stimulated research efforts on automatic fact checking. The recently-released FEVER dataset introduced a benchmark fact-verification task in which a system is asked to verify a claim using evidential sentences from Wikipedia documents. In this paper, we present a connected system consisting of three homogeneous neural semantic matching models that conduct document retrieval, sentence selection, and claim verification jointly for fact extraction and verification. For evidence retrieval (document retrieval and sentence selection), unlike traditional vector space IR models in which queries and sources are matched in some pre-designed term vector space, we develop neural models to perform deep semantic matching from raw textual input, assuming no intermediate term representation and no access to structured external knowledge bases. We also show that Pageview frequency can also help improve the performance of evidence retrieval results, that later can be matched by using our neural semantic matching network. For claim verification, unlike previous approaches that simply feed upstream retrieved evidence and the claim to a natural language inference (NLI) model, we further enhance the NLI model by providing it with internal semantic relatedness scores (hence integrating it with the evidence retrieval modules) and ontological WordNet features. Experiments on the FEVER dataset indicate that (1) our neural semantic matching method outperforms popular TF-IDF and encoder models, by significant margins on all evidence retrieval metrics, (2) the additional relatedness score and WordNet features improve the NLI model via better semantic awareness, and (3) by formalizing all three subtasks as a similar semantic matching problem and improving on all three stages, the complete model is able to achieve the state-of-the-art results on the FEVER test set.

</details>

<details>

<summary>2018-11-17 02:29:18 - An Affect-Rich Neural Conversational Model with Biased Attention and Weighted Cross-Entropy Loss</summary>

- *Peixiang Zhong, Di Wang, Chunyan Miao*

- `1811.07078v1` - [abs](http://arxiv.org/abs/1811.07078v1) - [pdf](http://arxiv.org/pdf/1811.07078v1)

> Affect conveys important implicit information in human communication. Having the capability to correctly express affect during human-machine conversations is one of the major milestones in artificial intelligence. In recent years, extensive research on open-domain neural conversational models has been conducted. However, embedding affect into such models is still under explored. In this paper, we propose an end-to-end affect-rich open-domain neural conversational model that produces responses not only appropriate in syntax and semantics, but also with rich affect. Our model extends the Seq2Seq model and adopts VAD (Valence, Arousal and Dominance) affective notations to embed each word with affects. In addition, our model considers the effect of negators and intensifiers via a novel affective attention mechanism, which biases attention towards affect-rich words in input sentences. Lastly, we train our model with an affect-incorporated objective function to encourage the generation of affect-rich words in the output responses. Evaluations based on both perplexity and human evaluations show that our model outperforms the state-of-the-art baseline model of comparable size in producing natural and affect-rich responses.

</details>

<details>

<summary>2018-11-17 09:29:17 - Advanced Memory Buoyancy for Forgetful Information Systems</summary>

- *Christian Jilek, Jessica Chwalek, Sven Schwarz, Markus Schröder, Heiko Maus, Andreas Dengel*

- `1811.12177v1` - [abs](http://arxiv.org/abs/1811.12177v1) - [pdf](http://arxiv.org/pdf/1811.12177v1)

> Knowledge workers face an ever increasing flood of information in their daily lives. To counter this and provide better support for information management and knowledge work in general, we have been investigating solutions inspired by human forgetting since 2013. These solutions are based on Semantic Desktop (SD) and Managed Forgetting (MF) technology. A key concept of the latter is the so-called Memory Buoyancy (MB), which is intended to represent an information item's current value for the user and allows to employ forgetting mechanisms. The SD thus continuously performs information value assessment updating MB and triggering respective MF measures. We extended an SD-based organizational memory system, which we have been using in daily work for over seven years now, with MF mechanisms directly embedding them in daily activities, too, and enabling us to test and optimize them in real-world scenarios. In this paper, we first present our initial version of MB and discuss success and failure stories we have been experiencing with it during three years of practical usage. We learned from cognitive psychology that our previous research on context can be beneficial for MF. Thus, we created an advanced MB version especially taking user context, and in particular context switches, into account. These enhancements as well as a first prototypical implementation are presented, too.

</details>

<details>

<summary>2018-11-17 20:20:20 - Correcting the Common Discourse Bias in Linear Representation of Sentences using Conceptors</summary>

- *Tianlin Liu, João Sedoc, Lyle Ungar*

- `1811.11002v1` - [abs](http://arxiv.org/abs/1811.11002v1) - [pdf](http://arxiv.org/pdf/1811.11002v1)

> Distributed representations of words, better known as word embeddings, have become important building blocks for natural language processing tasks. Numerous studies are devoted to transferring the success of unsupervised word embeddings to sentence embeddings. In this paper, we introduce a simple representation of sentences in which a sentence embedding is represented as a weighted average of word vectors followed by a soft projection. We demonstrate the effectiveness of this proposed method on the clinical semantic textual similarity task of the BioCreative/OHNLP Challenge 2018.

</details>

<details>

<summary>2018-11-18 02:39:45 - GLStyleNet: Higher Quality Style Transfer Combining Global and Local Pyramid Features</summary>

- *Zhizhong Wang, Lei Zhao, Wei Xing, Dongming Lu*

- `1811.07260v1` - [abs](http://arxiv.org/abs/1811.07260v1) - [pdf](http://arxiv.org/pdf/1811.07260v1)

> Recent studies using deep neural networks have shown remarkable success in style transfer especially for artistic and photo-realistic images. However, the approaches using global feature correlations fail to capture small, intricate textures and maintain correct texture scales of the artworks, and the approaches based on local patches are defective on global effect. In this paper, we present a novel feature pyramid fusion neural network, dubbed GLStyleNet, which sufficiently takes into consideration multi-scale and multi-level pyramid features by best aggregating layers across a VGG network, and performs style transfer hierarchically with multiple losses of different scales. Our proposed method retains high-frequency pixel information and low frequency construct information of images from two aspects: loss function constraint and feature fusion. Our approach is not only flexible to adjust the trade-off between content and style, but also controllable between global and local. Compared to state-of-the-art methods, our method can transfer not just large-scale, obvious style cues but also subtle, exquisite ones, and dramatically improves the quality of style transfer. We demonstrate the effectiveness of our approach on portrait style transfer, artistic style transfer, photo-realistic style transfer and Chinese ancient painting style transfer tasks. Experimental results indicate that our unified approach improves image style transfer quality over previous state-of-the-art methods, while also accelerating the whole process in a certain extent. Our code is available at https://github.com/EndyWon/GLStyleNet.

</details>

<details>

<summary>2018-11-18 05:19:54 - libmpk: Software Abstraction for Intel Memory Protection Keys</summary>

- *Soyeon Park, Sangho Lee, Wen Xu, Hyungon Moon, Taesoo Kim*

- `1811.07276v1` - [abs](http://arxiv.org/abs/1811.07276v1) - [pdf](http://arxiv.org/pdf/1811.07276v1)

> Intel memory protection keys (MPK) is a new hardware feature to support thread-local permission control on groups of pages without requiring modification of page tables. Unfortunately, its current hardware implementation and software supports suffer from security, scalability, and semantic-gap problems: (1) MPK is vulnerable to protection-key-use-after-free and protection-key corruption; (2) MPK does not scale due to hardware limitations; and (3) MPK is not perfectly compatible with mprotect() because it does not support permission synchronization across threads.   In this paper, we propose libmpk, a software abstraction for MPK. libmpk virtualizes protection keys to eliminate the protection-key-use-after-free and protection-key corruption problems while supporting a tremendous number of memory page groups. libmpk also prevents unauthorized writes to its metadata and supports inter-thread key synchronization. We apply libmpk to three real-world applications: OpenSSL, JavaScript JIT compiler, and Memcached for memory protection and isolation. An evaluation shows that libmpk introduces negligible performance overhead (<1%) compared with insecure versions, and improves their performance by 8.1x over secure equivalents using mprotect(). The source code of libmpk will be publicly available and maintained as an open source project.

</details>

<details>

<summary>2018-11-19 03:51:19 - Visual-Texual Emotion Analysis with Deep Coupled Video and Danmu Neural Networks</summary>

- *Chenchen Li, Jialin Wang, Hongwei Wang, Miao Zhao, Wenjie Li, Xiaotie Deng*

- `1811.07485v1` - [abs](http://arxiv.org/abs/1811.07485v1) - [pdf](http://arxiv.org/pdf/1811.07485v1)

> User emotion analysis toward videos is to automatically recognize the general emotional status of viewers from the multimedia content embedded in the online video stream. Existing works fall in two categories: 1) visual-based methods, which focus on visual content and extract a specific set of features of videos. However, it is generally hard to learn a mapping function from low-level video pixels to high-level emotion space due to great intra-class variance. 2) textual-based methods, which focus on the investigation of user-generated comments associated with videos. The learned word representations by traditional linguistic approaches typically lack emotion information and the global comments usually reflect viewers' high-level understandings rather than instantaneous emotions. To address these limitations, in this paper, we propose to jointly utilize video content and user-generated texts simultaneously for emotion analysis. In particular, we introduce exploiting a new type of user-generated texts, i.e., "danmu", which are real-time comments floating on the video and contain rich information to convey viewers' emotional opinions. To enhance the emotion discriminativeness of words in textual feature extraction, we propose Emotional Word Embedding (EWE) to learn text representations by jointly considering their semantics and emotions. Afterwards, we propose a novel visual-textual emotion analysis model with Deep Coupled Video and Danmu Neural networks (DCVDN), in which visual and textual features are synchronously extracted and fused to form a comprehensive representation by deep-canonically-correlated-autoencoder-based multi-view learning. Through extensive experiments on a self-crawled real-world video-danmu dataset, we prove that DCVDN significantly outperforms the state-of-the-art baselines.

</details>

<details>

<summary>2018-11-19 20:51:30 - A Map of Knowledge</summary>

- *Zachary A. Pardos, Andrew Joo Hun Nam*

- `1811.07974v1` - [abs](http://arxiv.org/abs/1811.07974v1) - [pdf](http://arxiv.org/pdf/1811.07974v1)

> Knowledge representation has gained in relevance as data from the ubiquitous digitization of behaviors amass and academia and industry seek methods to understand and reason about the information they encode. Success in this pursuit has emerged with data from natural language, where skip-grams and other linear connectionist models of distributed representation have surfaced scrutable relational structures which have also served as artifacts of anthropological interest. Natural language is, however, only a fraction of the big data deluge. Here we show that latent semantic structure, comprised of elements from digital records of our interactions, can be informed by behavioral data and that domain knowledge can be extracted from this structure through visualization and a novel mapping of the literal descriptions of elements onto this behaviorally informed representation. We use the course enrollment behaviors of 124,000 students at a public university to learn vector representations of its courses. From these behaviorally informed representations, a notable 88% of course attribute information were recovered (e.g., department and division), as well as 40% of course relationships constructed from prior domain knowledge and evaluated by analogy (e.g., Math 1B is to Math H1B as Physics 7B is to Physics H7B). To aid in interpretation of the learned structure, we create a semantic interpolation, translating course vectors to a bag-of-words of their respective catalog descriptions. We find that the representations learned from enrollments resolved course vectors to a level of semantic fidelity exceeding that of their catalog descriptions, depicting a vector space of high conceptual rationality. We end with a discussion of the possible mechanisms by which this knowledge structure may be informed and its implications for data science.

</details>

<details>

<summary>2018-11-20 02:59:30 - QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships</summary>

- *Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, Ashish Sabharwal*

- `1811.08048v1` - [abs](http://arxiv.org/abs/1811.08048v1) - [pdf](http://arxiv.org/pdf/1811.08048v1)

> Many natural language questions require recognizing and reasoning with qualitative relationships (e.g., in science, economics, and medicine), but are challenging to answer with corpus-based methods. Qualitative modeling provides tools that support such reasoning, but the semantic parsing task of mapping questions into those models has formidable challenges. We present QuaRel, a dataset of diverse story questions involving qualitative relationships that characterize these challenges, and techniques that begin to address them. The dataset has 2771 questions relating 19 different types of quantities. For example, "Jenny observes that the robot vacuum cleaner moves slower on the living room carpet than on the bedroom carpet. Which carpet has more friction?" We contribute (1) a simple and flexible conceptual framework for representing these kinds of questions; (2) the QuaRel dataset, including logical forms, exemplifying the parsing challenges; and (3) two novel models for this task, built as extensions of type-constrained semantic parsing. The first of these models (called QuaSP+) significantly outperforms off-the-shelf tools on QuaRel. The second (QuaSP+Zero) demonstrates zero-shot capability, i.e., the ability to handle new qualitative relationships without requiring additional training data, something not possible with previous models. This work thus makes inroads into answering complex, qualitative questions that require reasoning, and scaling to new relationships at low cost. The dataset and models are available at http://data.allenai.org/quarel.

</details>

<details>

<summary>2018-11-20 04:47:57 - GlobalTrait: Personality Alignment of Multilingual Word Embeddings</summary>

- *Farhad Bin Siddique, Dario Bertero, Pascale Fung*

- `1811.00240v2` - [abs](http://arxiv.org/abs/1811.00240v2) - [pdf](http://arxiv.org/pdf/1811.00240v2)

> We propose a multilingual model to recognize Big Five Personality traits from text data in four different languages: English, Spanish, Dutch and Italian. Our analysis shows that words having a similar semantic meaning in different languages do not necessarily correspond to the same personality traits. Therefore, we propose a personality alignment method, GlobalTrait, which has a mapping for each trait from the source language to the target language (English), such that words that correlate positively to each trait are close together in the multilingual vector space. Using these aligned embeddings for training, we can transfer personality related training features from high-resource languages such as English to other low-resource languages, and get better multilingual results, when compared to using simple monolingual and unaligned multilingual embeddings. We achieve an average F-score increase (across all three languages except English) from 65 to 73.4 (+8.4), when comparing our monolingual model to multilingual using CNN with personality aligned embeddings. We also show relatively good performance in the regression tasks, and better classification results when evaluating our model on a separate Chinese dataset.

</details>

<details>

<summary>2018-11-20 12:56:39 - A Semi-supervised Spatial Spectral Regularized Manifold Local Scaling Cut With HGF for Dimensionality Reduction of Hyperspectral Images</summary>

- *Ramanarayan Mohanty, SL Happy, Aurobinda Routray*

- `1811.08223v1` - [abs](http://arxiv.org/abs/1811.08223v1) - [pdf](http://arxiv.org/pdf/1811.08223v1)

> Hyperspectral images (HSI) contain a wealth of information over hundreds of contiguous spectral bands, making it possible to classify materials through subtle spectral discrepancies. However, the classification of this rich spectral information is accompanied by the challenges like high dimensionality, singularity, limited training samples, lack of labeled data samples, heteroscedasticity and nonlinearity. To address these challenges, we propose a semi-supervised graph based dimensionality reduction method named `semi-supervised spatial spectral regularized manifold local scaling cut' (S3RMLSC). The underlying idea of the proposed method is to exploit the limited labeled information from both the spectral and spatial domains along with the abundant unlabeled samples to facilitate the classification task by retaining the original distribution of the data. In S3RMLSC, a hierarchical guided filter (HGF) is initially used to smoothen the pixels of the HSI data to preserve the spatial pixel consistency. This step is followed by the construction of linear patches from the nonlinear manifold by using the maximal linear patch (MLP) criterion. Then the inter-patch and intra-patch dissimilarity matrices are constructed in both spectral and spatial domains by regularized manifold local scaling cut (RMLSC) and neighboring pixel manifold local scaling cut (NPMLSC) respectively. Finally, we obtain the projection matrix by optimizing the updated semi-supervised spatial-spectral between-patch and total-patch dissimilarity. The effectiveness of the proposed DR algorithm is illustrated with publicly available real-world HSI datasets.

</details>

<details>

<summary>2018-11-20 15:50:33 - Improving Natural Language Inference Using External Knowledge in the Science Questions Domain</summary>

- *Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni, Nicholas Mattei, Michael Witbrock*

- `1809.05724v2` - [abs](http://arxiv.org/abs/1809.05724v2) - [pdf](http://arxiv.org/pdf/1809.05724v2)

> Natural Language Inference (NLI) is fundamental to many Natural Language Processing (NLP) applications including semantic search and question answering. The NLI problem has gained significant attention thanks to the release of large scale, challenging datasets. Present approaches to the problem largely focus on learning-based methods that use only textual information in order to classify whether a given premise entails, contradicts, or is neutral with respect to a given hypothesis. Surprisingly, the use of methods based on structured knowledge -- a central topic in artificial intelligence -- has not received much attention vis-a-vis the NLI problem. While there are many open knowledge bases that contain various types of reasoning information, their use for NLI has not been well explored. To address this, we present a combination of techniques that harness knowledge graphs to improve performance on the NLI problem in the science questions domain. We present the results of applying our techniques on text, graph, and text-to-graph based models, and discuss implications for the use of external knowledge in solving the NLI problem. Our model achieves the new state-of-the-art performance on the NLI problem over the SciTail science questions dataset.

</details>

<details>

<summary>2018-11-20 16:00:22 - Automatic Test Improvement with DSpot: a Study with Ten Mature Open-Source Projects</summary>

- *Benjamin Danglot, Oscar Luis Vera-Pérez, Benoit Baudry, Martin Monperrus*

- `1811.08330v1` - [abs](http://arxiv.org/abs/1811.08330v1) - [pdf](http://arxiv.org/pdf/1811.08330v1)

> In the literature, there is a rather clear segregation between manually written tests by developers and automatically generated ones. In this paper, we explore a third solution: to automatically improve existing test cases written by developers. We present the concept, design, and implementation of a system called \dspot, that takes developer-written test cases as input (junit tests in Java) and synthesizes improved versions of them as output. Those test improvements are given back to developers as patches or pull requests, that can be directly integrated in the main branch of the test code base. We have evaluated DSpot in a deep, systematic manner over 40 real-world unit test classes from 10 notable and open-source software projects. We have amplified all test methods from those 40 unit test classes. In 26/40 cases, DSpot is able to automatically improve the test under study, by triggering new behaviors and adding new valuable assertions. Next, for ten projects under consideration, we have proposed a test improvement automatically synthesized by \dspot to the lead developers. In total, 13/19 proposed test improvements were accepted by the developers and merged into the main code base. This shows that DSpot is capable of automatically improving unit-tests in real-world, large-scale Java software.

</details>

<details>

<summary>2018-11-21 05:14:37 - Contextualized Non-local Neural Networks for Sequence Learning</summary>

- *Pengfei Liu, Shuaichen Chang, Xuanjing Huang, Jian Tang, Jackie Chi Kit Cheung*

- `1811.08600v1` - [abs](http://arxiv.org/abs/1811.08600v1) - [pdf](http://arxiv.org/pdf/1811.08600v1)

> Recently, a large number of neural mechanisms and models have been proposed for sequence learning, of which self-attention, as exemplified by the Transformer model, and graph neural networks (GNNs) have attracted much attention. In this paper, we propose an approach that combines and draws on the complementary strengths of these two methods. Specifically, we propose contextualized non-local neural networks (CN$^{\textbf{3}}$), which can both dynamically construct a task-specific structure of a sentence and leverage rich local dependencies within a particular neighborhood.   Experimental results on ten NLP tasks in text classification, semantic matching, and sequence labeling show that our proposed model outperforms competitive baselines and discovers task-specific dependency structures, thus providing better interpretability to users.

</details>

<details>

<summary>2018-11-21 12:14:12 - Inline Detection of Domain Generation Algorithms with Context-Sensitive Word Embeddings</summary>

- *Joewie J. Koh, Barton Rhodes*

- `1811.08705v1` - [abs](http://arxiv.org/abs/1811.08705v1) - [pdf](http://arxiv.org/pdf/1811.08705v1)

> Domain generation algorithms (DGAs) are frequently employed by malware to generate domains used for connecting to command-and-control (C2) servers. Recent work in DGA detection leveraged deep learning architectures like convolutional neural networks (CNNs) and character-level long short-term memory networks (LSTMs) to classify domains. However, these classifiers perform poorly with wordlist-based DGA families, which generate domains by pseudorandomly concatenating dictionary words. We propose a novel approach that combines context-sensitive word embeddings with a simple fully-connected classifier to perform classification of domains based on word-level information. The word embeddings were pre-trained on a large unrelated corpus and left frozen during the training on domain data. The resulting small number of trainable parameters enabled extremely short training durations, while the transfer of language knowledge stored in the representations allowed for high-performing models with small training datasets. We show that this architecture reliably outperformed existing techniques on wordlist-based DGA families with just 30 DGA training examples and achieved state-of-the-art performance with around 100 DGA training examples, all while requiring an order of magnitude less time to train compared to current techniques. Of special note is the technique's performance on the matsnu DGA: the classifier attained a 89.5% detection rate with a 1:1,000 false positive rate (FPR) after training on only 30 examples of the DGA domains, and a 91.2% detection rate with a 1:10,000 FPR after 90 examples. Considering that some of these DGAs have wordlists of several hundred words, our results demonstrate that this technique does not rely on the classifier learning the DGA wordlists. Instead, the classifier is able to learn the semantic signatures of the wordlist-based DGA families.

</details>

<details>

<summary>2018-11-21 16:43:11 - Facilitating the Manual Annotation of Sounds When Using Large Taxonomies</summary>

- *Xavier Favory, Eduardo Fonseca, Frederic Font, Xavier Serra*

- `1811.10988v1` - [abs](http://arxiv.org/abs/1811.10988v1) - [pdf](http://arxiv.org/pdf/1811.10988v1)

> Properly annotated multimedia content is crucial for supporting advances in many Information Retrieval applications. It enables, for instance, the development of automatic tools for the annotation of large and diverse multimedia collections. In the context of everyday sounds and online collections, the content to describe is very diverse and involves many different types of concepts, often organised in large hierarchical structures called taxonomies. This makes the task of manually annotating content arduous. In this paper, we present our user-centered development of two tools for the manual annotation of audio content from a wide range of types. We conducted a preliminary evaluation of functional prototypes involving real users. The goal is to evaluate them in a real context, engage in discussions with users, and inspire new ideas. A qualitative analysis was carried out including usability questionnaires and semi-structured interviews. This revealed interesting aspects to consider when developing tools for the manual annotation of audio content with labels drawn from large hierarchical taxonomies.

</details>

<details>

<summary>2018-11-21 17:37:22 - Integrating Reinforcement Learning to Self Training for Pulmonary Nodule Segmentation in Chest X-rays</summary>

- *Sejin Park, Woochan Hwang, Kyu-Hwan Jung*

- `1811.08840v1` - [abs](http://arxiv.org/abs/1811.08840v1) - [pdf](http://arxiv.org/pdf/1811.08840v1)

> Machine learning applications in medical imaging are frequently limited by the lack of quality labeled data. In this paper, we explore the self training method, a form of semi-supervised learning, to address the labeling burden. By integrating reinforcement learning, we were able to expand the application of self training to complex segmentation networks without any further human annotation. The proposed approach, reinforced self training (ReST), fine tunes a semantic segmentation networks by introducing a policy network that learns to generate pseudolabels. We incorporate an expert demonstration network, based on inverse reinforcement learning, to enhance clinical validity and convergence of the policy network. The model was tested on a pulmonary nodule segmentation task in chest X-rays and achieved the performance of a standard U-Net while using only 50% of the labeled data, by exploiting unlabeled data. When the same number of labeled data was used, a moderate to significant cross validation accuracy improvement was achieved depending on the absolute number of labels used.

</details>

<details>

<summary>2018-11-22 19:56:43 - Dialectical Rough Sets, Parthood and Figures of Opposition-1</summary>

- *A. Mani*

- `1703.10251v2` - [abs](http://arxiv.org/abs/1703.10251v2) - [pdf](http://arxiv.org/pdf/1703.10251v2)

> In one perspective, the main theme of this research revolves around the inverse problem in the context of general rough sets that concerns the existence of rough basis for given approximations in a context. Granular operator spaces and variants were recently introduced by the present author as an optimal framework for anti-chain based algebraic semantics of general rough sets and the inverse problem. In the framework, various sub-types of crisp and non-crisp objects are identifiable that may be missed in more restrictive formalism. This is also because in the latter cases concepts of complementation and negation are taken for granted - while in reality they have a complicated dialectical basis. This motivates a general approach to dialectical rough sets building on previous work of the present author and figures of opposition. In this paper dialectical rough logics are invented from a semantic perspective, a concept of dialectical predicates is formalised, connection with dialetheias and glutty negation are established, parthood analyzed and studied from the viewpoint of classical and dialectical figures of opposition by the present author. Her methods become more geometrical and encompass parthood as a primary relation (as opposed to roughly equivalent objects) for algebraic semantics.

</details>

<details>

<summary>2018-11-23 10:21:09 - Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning</summary>

- *Supasorn Suwajanakorn, Noah Snavely, Jonathan Tompson, Mohammad Norouzi*

- `1807.03146v2` - [abs](http://arxiv.org/abs/1807.03146v2) - [pdf](http://arxiv.org/pdf/1807.03146v2)

> This paper presents KeypointNet, an end-to-end geometric reasoning framework to learn an optimal set of category-specific 3D keypoints, along with their detectors. Given a single image, KeypointNet extracts 3D keypoints that are optimized for a downstream task. We demonstrate this framework on 3D pose estimation by proposing a differentiable objective that seeks the optimal set of keypoints for recovering the relative pose between two views of an object. Our model discovers geometrically and semantically consistent keypoints across viewing angles and instances of an object category. Importantly, we find that our end-to-end framework using no ground-truth keypoint annotations outperforms a fully supervised baseline using the same neural network architecture on the task of pose estimation. The discovered 3D keypoints on the car, chair, and plane categories of ShapeNet are visualized at http://keypointnet.github.io/.

</details>

<details>

<summary>2018-11-23 16:00:51 - Competency Questions and SPARQL-OWL Queries Dataset and Analysis</summary>

- *Dawid Wisniewski, Jedrzej Potoniec, Agnieszka Lawrynowicz, C. Maria Keet*

- `1811.09529v1` - [abs](http://arxiv.org/abs/1811.09529v1) - [pdf](http://arxiv.org/pdf/1811.09529v1)

> Competency Questions (CQs) are natural language questions outlining and constraining the scope of knowledge represented by an ontology. Despite that CQs are a part of several ontology engineering methodologies, we have observed that the actual publication of CQs for the available ontologies is very limited and even scarcer is the publication of their respective formalisations in terms of, e.g., SPARQL queries. This paper aims to contribute to addressing the engineering shortcomings of using CQs in ontology development, to facilitate wider use of CQs. In order to understand the relation between CQs and the queries over the ontology to test the CQs on an ontology, we gather, analyse, and publicly release a set of 234 CQs and their translations to SPARQL-OWL for several ontologies in different domains developed by different groups. We analysed the CQs in two principal ways. The first stage focused on a linguistic analysis of the natural language text itself, i.e., a lexico-syntactic analysis without any presuppositions of ontology elements, and a subsequent step of semantic analysis in order to find patterns. This increased diversity of CQ sources resulted in a 5-fold increase of hitherto published patterns, to 106 distinct CQ patterns, which have a limited subset of few patterns shared across the CQ sets from the different ontologies. Next, we analysed the relation between the found CQ patterns and the 46 SPARQL-OWL query signatures, which revealed that one CQ pattern may be realised by more than one SPARQL-OWL query signature, and vice versa. We hope that our work will contribute to establishing common practices, templates, automation, and user tools that will support CQ formulation, formalisation, execution, and general management.

</details>

<details>

<summary>2018-11-23 22:38:49 - Explicability? Legibility? Predictability? Transparency? Privacy? Security? The Emerging Landscape of Interpretable Agent Behavior</summary>

- *Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreedharan, David E. Smith, Subbarao Kambhampati*

- `1811.09722v1` - [abs](http://arxiv.org/abs/1811.09722v1) - [pdf](http://arxiv.org/pdf/1811.09722v1)

> There has been significant interest of late in generating behavior of agents that is interpretable to the human (observer) in the loop. However, the work in this area has typically lacked coherence on the topic, with proposed solutions for "explicable", "legible", "predictable" and "transparent" planning with overlapping, and sometimes conflicting, semantics all aimed at some notion of understanding what intentions the observer will ascribe to an agent by observing its behavior. This is also true for the recent works on "security" and "privacy" of plans which are also trying to answer the same question, but from the opposite point of view -- i.e. when the agent is trying to hide instead of revealing its intentions. This paper attempts to provide a workable taxonomy of relevant concepts in this exciting and emerging field of inquiry.

</details>

<details>

<summary>2018-11-23 23:22:19 - Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning</summary>

- *Xin Wang, Jiawei Wu, Da Zhang, Yu Su, William Yang Wang*

- `1811.02765v2` - [abs](http://arxiv.org/abs/1811.02765v2) - [pdf](http://arxiv.org/pdf/1811.02765v2)

> Although promising results have been achieved in video captioning, existing models are limited to the fixed inventory of activities in the training corpus, and do not generalize to open vocabulary scenarios. Here we introduce a novel task, zero-shot video captioning, that aims at describing out-of-domain videos of unseen activities. Videos of different activities usually require different captioning strategies in many aspects, i.e. word selection, semantic construction, and style expression etc, which poses a great challenge to depict novel activities without paired training data. But meanwhile, similar activities share some of those aspects in common. Therefore, We propose a principled Topic-Aware Mixture of Experts (TAMoE) model for zero-shot video captioning, which learns to compose different experts based on different topic embeddings, implicitly transferring the knowledge learned from seen activities to unseen ones. Besides, we leverage external topic-related text corpus to construct the topic embedding for each activity, which embodies the most relevant semantic vectors within the topic. Empirical results not only validate the effectiveness of our method in utilizing semantic knowledge for video captioning, but also show its strong generalization ability when describing novel activities.

</details>

<details>

<summary>2018-11-24 16:30:01 - How to Design a Program Repair Bot? Insights from the Repairnator Project</summary>

- *Simon Urli, Zhongxing Yu, Lionel Seinturier, Martin Monperrus*

- `1811.09852v1` - [abs](http://arxiv.org/abs/1811.09852v1) - [pdf](http://arxiv.org/pdf/1811.09852v1)

> Program repair research has made tremendous progress over the last few years, and software development bots are now being invented to help developers gain productivity. In this paper, we investigate the concept of a " program repair bot " and present Repairnator. The Repairnator bot is an autonomous agent that constantly monitors test failures, reproduces bugs, and runs program repair tools against each reproduced bug. If a patch is found, Repairnator bot reports it to the developers. At the time of writing, Repairnator uses three different program repair systems and has been operating since February 2017. In total, it has studied 11 317 test failures over 1 609 open-source software projects hosted on GitHub, and has generated patches for 17 different bugs. Over months, we hit a number of hard technical challenges and had to make various design and engineering decisions. This gives us a unique experience in this area. In this paper, we reflect upon Repairnator in order to share this knowledge with the automatic program repair community.

</details>

<details>

<summary>2018-11-25 01:30:16 - A Method for Analysis of Patient Speech in Dialogue for Dementia Detection</summary>

- *Saturnino Luz, Sofia de la Fuente, Pierre Albert*

- `1811.09919v1` - [abs](http://arxiv.org/abs/1811.09919v1) - [pdf](http://arxiv.org/pdf/1811.09919v1)

> We present an approach to automatic detection of Alzheimer's type dementia based on characteristics of spontaneous spoken language dialogue consisting of interviews recorded in natural settings. The proposed method employs additive logistic regression (a machine learning boosting method) on content-free features extracted from dialogical interaction to build a predictive model. The model training data consisted of 21 dialogues between patients with Alzheimer's and interviewers, and 17 dialogues between patients with other health conditions and interviewers. Features analysed included speech rate, turn-taking patterns and other speech parameters. Despite relying solely on content-free features, our method obtains overall accuracy of 86.5\%, a result comparable to those of state-of-the-art methods that employ more complex lexical, syntactic and semantic features. While further investigation is needed, the fact that we were able to obtain promising results using only features that can be easily extracted from spontaneous dialogues suggests the possibility of designing non-invasive and low-cost mental health monitoring tools for use at scale.

</details>

<details>

<summary>2018-11-26 06:01:35 - Implanting Rational Knowledge into Distributed Representation at Morpheme Level</summary>

- *Zi Lin, Yang Liu*

- `1811.10188v1` - [abs](http://arxiv.org/abs/1811.10188v1) - [pdf](http://arxiv.org/pdf/1811.10188v1)

> Previously, researchers paid no attention to the creation of unambiguous morpheme embeddings independent from the corpus, while such information plays an important role in expressing the exact meanings of words for parataxis languages like Chinese. In this paper, after constructing the Chinese lexical and semantic ontology based on word-formation, we propose a novel approach to implanting the structured rational knowledge into distributed representation at morpheme level, naturally avoiding heavy disambiguation in the corpus. We design a template to create the instances as pseudo-sentences merely from the pieces of knowledge of morphemes built in the lexicon. To exploit hierarchical information and tackle the data sparseness problem, the instance proliferation technique is applied based on similarity to expand the collection of pseudo-sentences. The distributed representation for morphemes can then be trained on these pseudo-sentences using word2vec. For evaluation, we validate the paradigmatic and syntagmatic relations of morpheme embeddings, and apply the obtained embeddings to word similarity measurement, achieving significant improvements over the classical models by more than 5 Spearman scores or 8 percentage points, which shows very promising prospects for adoption of the new source of knowledge.

</details>

<details>

<summary>2018-11-26 06:10:01 - Ontology Matching Techniques: A Gold Standard Model</summary>

- *Alok Chauhan, Vijayakumar V, Layth Sliman*

- `1811.10191v1` - [abs](http://arxiv.org/abs/1811.10191v1) - [pdf](http://arxiv.org/pdf/1811.10191v1)

> Typically an ontology matching technique is a combination of much different type of matchers operating at various abstraction levels such as structure, semantic, syntax, instance etc. An ontology matching technique which employs matchers at all possible abstraction levels is expected to give, in general, best results in terms of precision, recall and F-measure due to improvement in matching opportunities and if we discount efficiency issues which may improve with better computing resources such as parallel processing. A gold standard ontology matching model is derived from a model classification of ontology matching techniques. A suitable metric is also defined based on gold standard ontology matching model. A review of various ontology matching techniques specified in recent research papers in the area was undertaken to categorize an ontology matching technique as per newly proposed gold standard model and a metric value for the whole group was computed. The results of the above study support proposed gold standard ontology matching model.

</details>

<details>

<summary>2018-11-26 06:15:05 - A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks</summary>

- *Victor Sanh, Thomas Wolf, Sebastian Ruder*

- `1811.06031v2` - [abs](http://arxiv.org/abs/1811.06031v2) - [pdf](http://arxiv.org/pdf/1811.06031v2)

> Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.

</details>

<details>

<summary>2018-11-26 16:07:36 - Sentence Encoding with Tree-constrained Relation Networks</summary>

- *Lei Yu, Cyprien de Masson d'Autume, Chris Dyer, Phil Blunsom, Lingpeng Kong, Wang Ling*

- `1811.10475v1` - [abs](http://arxiv.org/abs/1811.10475v1) - [pdf](http://arxiv.org/pdf/1811.10475v1)

> The meaning of a sentence is a function of the relations that hold between its words. We instantiate this relational view of semantics in a series of neural models based on variants of relation networks (RNs) which represent a set of objects (for us, words forming a sentence) in terms of representations of pairs of objects. We propose two extensions to the basic RN model for natural language. First, building on the intuition that not all word pairs are equally informative about the meaning of a sentence, we use constraints based on both supervised and unsupervised dependency syntax to control which relations influence the representation. Second, since higher-order relations are poorly captured by a sum of pairwise relations, we use a recurrent extension of RNs to propagate information so as to form representations of higher order relations. Experiments on sentence classification, sentence pair classification, and machine translation reveal that, while basic RNs are only modestly effective for sentence representation, recurrent RNs with latent syntax are a reliably powerful representational device.

</details>

<details>

<summary>2018-11-26 23:19:43 - GANtruth - an unpaired image-to-image translation method for driving scenarios</summary>

- *Sebastian Bujwid, Miquel Martí, Hossein Azizpour, Alessandro Pieropan*

- `1812.01710v1` - [abs](http://arxiv.org/abs/1812.01710v1) - [pdf](http://arxiv.org/pdf/1812.01710v1)

> Synthetic image translation has significant potentials in autonomous transportation systems. That is due to the expense of data collection and annotation as well as the unmanageable diversity of real-words situations. The main issue with unpaired image-to-image translation is the ill-posed nature of the problem. In this work, we propose a novel method for constraining the output space of unpaired image-to-image translation. We make the assumption that the environment of the source domain is known (e.g. synthetically generated), and we propose to explicitly enforce preservation of the ground-truth labels on the translated images.   We experiment on preserving ground-truth information such as semantic segmentation, disparity, and instance segmentation. We show significant evidence that our method achieves improved performance over the state-of-the-art model of UNIT for translating images from SYNTHIA to Cityscapes. The generated images are perceived as more realistic in human surveys and outperforms UNIT when used in a domain adaptation scenario for semantic segmentation.

</details>

<details>

<summary>2018-11-27 08:27:49 - Sapiens Chain: A Blockchain-based Cybersecurity Framework</summary>

- *Yu Han, Zhongru Wang, Qiang Ruan, Binxing Fang*

- `1811.10868v1` - [abs](http://arxiv.org/abs/1811.10868v1) - [pdf](http://arxiv.org/pdf/1811.10868v1)

> Recently, cybersecurity becomes more and more important due to the rapid development of Internet. However, existing methods are in reality highly sensitive to attacks and are far more vulnerable than expected, as they are lack of trustable measures. In this paper, to address the aforementioned problems, we propose a blockchain-based cybersecurity framework, termed as Sapiens Chain, which can protect the privacy of the anonymous users and ensure that the transactions are immutable by providing decentralized and trustable services. Integrating semantic analysis, symbolic execution, and routing learning methods into intelligent auditing, this framework can achieve good accuracy for detecting hidden vulnerabilities. In addition, a revenue incentive mechanism, which aims to donate participants, is built. The practical results demonstrate the effectiveness of the proposed framework.

</details>

<details>

<summary>2018-11-27 10:22:09 - Making Agents' Abilities Explicit</summary>

- *Yedi Zhang, Fu Song, Taolue Chen*

- `1811.10901v1` - [abs](http://arxiv.org/abs/1811.10901v1) - [pdf](http://arxiv.org/pdf/1811.10901v1)

> Alternating-time temporal logics (ATL/ATL*) represent a family of modal logics for reasoning about agents' strategic abilities in multiagent systems (MAS). The interpretations of ATL/ATL* over the semantic model Concurrent Game Structures (CGS) usually vary depending on the agents' abilities, for instance, perfect vs. imperfect information, perfect vs. imperfect recall, resulting in a variety of variants which have been studied extensively in literature. However, they are defined at the semantic level, which may limit modeling flexibilities and may give counter-intuitive interpretations. To mitigate these issues, in this work, we propose to extend CGS with agents' abilities and study the new semantics of ATL/ATL* under this model. We give PSACE/2EXPTIME model-checking algorithms for ATL/ATL* and implement them as a prototype tool. Experiment results show the practical feasibility of the approach.

</details>

<details>

<summary>2018-11-27 13:45:48 - Automatic Severity Classification of Coronary Artery Disease via Recurrent Capsule Network</summary>

- *Qi Wang, Jiahui Qiu, Yangming Zhou, Tong Ruan, Daqi Gao, Ju Gao*

- `1807.06718v2` - [abs](http://arxiv.org/abs/1807.06718v2) - [pdf](http://arxiv.org/pdf/1807.06718v2)

> Coronary artery disease (CAD) is one of the leading causes of cardiovascular disease deaths. CAD condition progresses rapidly, if not diagnosed and treated at an early stage may eventually lead to an irreversible state of the heart muscle death. Invasive coronary arteriography is the gold standard technique for CAD diagnosis. Coronary arteriography texts describe which part has stenosis and how much stenosis is in details. It is crucial to conduct the severity classification of CAD. In this paper, we employ a recurrent capsule network (RCN) to extract semantic relations between clinical named entities in Chinese coronary arteriography texts, through which we can automatically find out the maximal stenosis for each lumen to inference how severe CAD is according to the improved method of Gensini. Experimental results on the corpus collected from Shanghai Shuguang Hospital show that our proposed method achieves an accuracy of 97.0\% in the severity classification of CAD.

</details>

<details>

<summary>2018-11-27 19:00:07 - Semantically-aware population health risk analyses</summary>

- *Alexander New, Sabbir M. Rashid, John S. Erickson, Deborah L. McGuinness, Kristin P. Bennett*

- `1811.11190v1` - [abs](http://arxiv.org/abs/1811.11190v1) - [pdf](http://arxiv.org/pdf/1811.11190v1)

> One primary task of population health analysis is the identification of risk factors that, for some subpopulation, have a significant association with some health condition. Examples include finding lifestyle factors associated with chronic diseases and finding genetic mutations associated with diseases in precision health. We develop a combined semantic and machine learning system that uses a health risk ontology and knowledge graph (KG) to dynamically discover risk factors and their associated subpopulations. Semantics and the novel supervised cadre model make our system explainable. Future population health studies are easily performed and documented with provenance by specifying additional input and output KG cartridges.

</details>

<details>

<summary>2018-11-28 07:48:27 - The MeSH-gram Neural Network Model: Extending Word Embedding Vectors with MeSH Concepts for UMLS Semantic Similarity and Relatedness in the Biomedical Domain</summary>

- *Saïd Abdeddaïm, Sylvestre Vimard, Lina Fatima Soualmia*

- `1812.02309v1` - [abs](http://arxiv.org/abs/1812.02309v1) - [pdf](http://arxiv.org/pdf/1812.02309v1)

> Eliciting semantic similarity between concepts in the biomedical domain remains a challenging task. Recent approaches founded on embedding vectors have gained in popularity as they risen to efficiently capture semantic relationships The underlying idea is that two words that have close meaning gather similar contexts. In this study, we propose a new neural network model named MeSH-gram which relies on a straighforward approach that extends the skip-gram neural network model by considering MeSH (Medical Subject Headings) descriptors instead words. Trained on publicly available corpus PubMed MEDLINE, MeSH-gram is evaluated on reference standards manually annotated for semantic similarity. MeSH-gram is first compared to skip-gram with vectors of size 300 and at several windows contexts. A deeper comparison is performed with tewenty existing models. All the obtained results of Spearman's rank correlations between human scores and computed similarities show that MeSH-gram outperforms the skip-gram model, and is comparable to the best methods but that need more computation and external resources.

</details>

<details>

<summary>2018-11-28 11:21:43 - Counting Complexity for Reasoning in Abstract Argumentation</summary>

- *Johannes K. Fichte, Markus Hecher, Arne Meier*

- `1811.11501v1` - [abs](http://arxiv.org/abs/1811.11501v1) - [pdf](http://arxiv.org/pdf/1811.11501v1)

> In this paper, we consider counting and projected model counting of extensions in abstract argumentation for various semantics. When asking for projected counts we are interested in counting the number of extensions of a given argumentation framework while multiple extensions that are identical when restricted to the projected arguments count as only one projected extension. We establish classical complexity results and parameterized complexity results when the problems are parameterized by treewidth of the undirected argumentation graph. To obtain upper bounds for counting projected extensions, we introduce novel algorithms that exploit small treewidth of the undirected argumentation graph of the input instance by dynamic programming (DP). Our algorithms run in time double or triple exponential in the treewidth depending on the considered semantics. Finally, we take the exponential time hypothesis (ETH) into account and establish lower bounds of bounded treewidth algorithms for counting extensions and projected extension.

</details>

<details>

<summary>2018-11-28 15:05:22 - Cluster-Based Learning from Weakly Labeled Bags in Digital Pathology</summary>

- *Shazia Akbar, Anne L. Martel*

- `1812.00884v1` - [abs](http://arxiv.org/abs/1812.00884v1) - [pdf](http://arxiv.org/pdf/1812.00884v1)

> To alleviate the burden of gathering detailed expert annotations when training deep neural networks, we propose a weakly supervised learning approach to recognize metastases in microscopic images of breast lymph nodes. We describe an alternative training loss which clusters weakly labeled bags in latent space to inform relevance of patch-instances during training of a convolutional neural network. We evaluate our method on the Camelyon dataset which contains high-resolution digital slides of breast lymph nodes, where labels are provided at the image-level and only subsets of patches are made available during training.

</details>

<details>

<summary>2018-11-29 02:44:07 - Multi-granularity hierarchical attention fusion networks for reading comprehension and question answering</summary>

- *Wei Wang, Ming Yan, Chen Wu*

- `1811.11934v1` - [abs](http://arxiv.org/abs/1811.11934v1) - [pdf](http://arxiv.org/pdf/1811.11934v1)

> This paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. In the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. Specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. Then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. Finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level softalignment. Extensive experiments on the large-scale SQuAD and TriviaQA datasets validate the effectiveness of the proposed method. At the time of writing the paper (Jan. 12th 2018), our model achieves the first position on the SQuAD leaderboard for both single and ensemble models. We also achieves state-of-the-art results on TriviaQA, AddSent and AddOne-Sent datasets.

</details>

<details>

<summary>2018-11-29 07:01:26 - Survey on Misbehavior Detection in Cooperative Intelligent Transportation Systems</summary>

- *Rens W. van der Heijden, Stefan Dietzel, Tim Leinmüller, Frank Kargl*

- `1610.06810v2` - [abs](http://arxiv.org/abs/1610.06810v2) - [pdf](http://arxiv.org/pdf/1610.06810v2)

> Cooperative Intelligent Transportation Systems (cITS) are a promising technology to enhance driving safety and efficiency. Vehicles communicate wirelessly with other vehicles and infrastructure, thereby creating a highly dynamic and heterogeneously managed ad-hoc network. It is these network properties that make it a challenging task to protect integrity of the data and guarantee its correctness. A major component is the problem that traditional security mechanisms like PKI-based asymmetric cryptography only exclude outsider attackers that do not possess key material. However, because attackers can be insiders within the network (i.e., possess valid key material), this approach cannot detect all possible attacks. In this survey, we present misbehavior detection mechanisms that can detect such insider attacks based on attacker behavior and information analysis. In contrast to well-known intrusion detection for classical IT systems, these misbehavior detection mechanisms analyze information semantics to detect attacks, which aligns better with highly application-tailored communication protocols foreseen for cITS. In our survey, we provide an extensive introduction to the cITS ecosystem and discuss shortcomings of PKI-based security. We derive and discuss a classification for misbehavior detection mechanisms, provide an in-depth overview of seminal papers on the topic, and highlight open issues and possible future research trends.

</details>

<details>

<summary>2018-11-29 07:49:44 - Sequence Learning with RNNs for Medical Concept Normalization in User-Generated Texts</summary>

- *Elena Tutubalina, Zulfat Miftahutdinov, Sergey Nikolenko, Valentin Malykh*

- `1811.11523v2` - [abs](http://arxiv.org/abs/1811.11523v2) - [pdf](http://arxiv.org/pdf/1811.11523v2)

> In this work, we consider the medical concept normalization problem, i.e., the problem of mapping a disease mention in free-form text to a concept in a controlled vocabulary, usually to the standard thesaurus in the Unified Medical Language System (UMLS). This task is challenging since medical terminology is very different when coming from health care professionals or from the general public in the form of social media texts. We approach it as a sequence learning problem, with recurrent neural networks trained to obtain semantic representations of one- and multi-word expressions. We develop end-to-end neural architectures tailored specifically to medical concept normalization, including bidirectional LSTM and GRU with an attention mechanism and additional semantic similarity features based on UMLS. Our evaluation over a standard benchmark shows that our model improves over a state of the art baseline for classification based on CNNs.

</details>

<details>

<summary>2018-11-29 08:15:00 - Neural Code Comprehension: A Learnable Representation of Code Semantics</summary>

- *Tal Ben-Nun, Alice Shoshana Jakobovits, Torsten Hoefler*

- `1806.07336v3` - [abs](http://arxiv.org/abs/1806.07336v3) - [pdf](http://arxiv.org/pdf/1806.07336v3)

> With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.

</details>

<details>

<summary>2018-11-29 13:52:13 - From Context to Concept: Exploring Semantic Relationships in Music with Word2Vec</summary>

- *Ching-Hua Chuan, Kat Agres, Dorien Herremans*

- `1811.12408v1` - [abs](http://arxiv.org/abs/1811.12408v1) - [pdf](http://arxiv.org/pdf/1811.12408v1)

> We explore the potential of a popular distributional semantics vector space model, word2vec, for capturing meaningful relationships in ecological (complex polyphonic) music. More precisely, the skip-gram version of word2vec is used to model slices of music from a large corpus spanning eight musical genres. In this newly learned vector space, a metric based on cosine distance is able to distinguish between functional chord relationships, as well as harmonic associations in the music. Evidence, based on cosine distance between chord-pair vectors, suggests that an implicit circle-of-fifths exists in the vector space. In addition, a comparison between pieces in different keys reveals that key relationships are represented in word2vec space. These results suggest that the newly learned embedded vector representation does in fact capture tonal and harmonic characteristics of music, without receiving explicit information about the musical content of the constituent slices. In order to investigate whether proximity in the discovered space of embeddings is indicative of `semantically-related' slices, we explore a music generation task, by automatically replacing existing slices from a given piece of music with new slices. We propose an algorithm to find substitute slices based on spatial proximity and the pitch class distribution inferred in the chosen subspace. The results indicate that the size of the subspace used has a significant effect on whether slices belonging to the same key are selected. In sum, the proposed word2vec model is able to learn music-vector embeddings that capture meaningful tonal and harmonic relationships in music, thereby providing a useful tool for exploring musical properties and comparisons across pieces, as a potential input representation for deep learning models, and as a music generation device.

</details>

<details>

<summary>2018-11-29 15:20:30 - Counterfactual Learning from Human Proofreading Feedback for Semantic Parsing</summary>

- *Carolin Lawrence, Stefan Riezler*

- `1811.12239v1` - [abs](http://arxiv.org/abs/1811.12239v1) - [pdf](http://arxiv.org/pdf/1811.12239v1)

> In semantic parsing for question-answering, it is often too expensive to collect gold parses or even gold answers as supervision signals. We propose to convert model outputs into a set of human-understandable statements which allow non-expert users to act as proofreaders, providing error markings as learning signals to the parser. Because model outputs were suggested by a historic system, we operate in a counterfactual, or off-policy, learning setup. We introduce new estimators which can effectively leverage the given feedback and which avoid known degeneracies in counterfactual learning, while still being applicable to stochastic gradient optimization for neural semantic parsing. Furthermore, we discuss how our feedback collection method can be seamlessly integrated into deployed virtual personal assistants that embed a semantic parser. Our work is the first to show that semantic parsers can be improved significantly by counterfactual learning from logged human feedback data.

</details>

<details>

<summary>2018-11-30 07:04:53 - Improving a Neural Semantic Parser by Counterfactual Learning from Human Bandit Feedback</summary>

- *Carolin Lawrence, Stefan Riezler*

- `1805.01252v2` - [abs](http://arxiv.org/abs/1805.01252v2) - [pdf](http://arxiv.org/pdf/1805.01252v2)

> Counterfactual learning from human bandit feedback describes a scenario where user feedback on the quality of outputs of a historic system is logged and used to improve a target system. We show how to apply this learning framework to neural semantic parsing. From a machine learning perspective, the key challenge lies in a proper reweighting of the estimator so as to avoid known degeneracies in counterfactual learning, while still being applicable to stochastic gradient optimization. To conduct experiments with human users, we devise an easy-to-use interface to collect human feedback on semantic parses. Our work is the first to show that semantic parsers can be improved significantly by counterfactual learning from logged human feedback data.

</details>

<details>

<summary>2018-11-30 08:43:00 - Instance-level Facial Attributes Transfer with Geometry-Aware Flow</summary>

- *Weidong Yin, Ziwei Liu, Chen Change Loy*

- `1811.12670v1` - [abs](http://arxiv.org/abs/1811.12670v1) - [pdf](http://arxiv.org/pdf/1811.12670v1)

> We address the problem of instance-level facial attribute transfer without paired training data, e.g. faithfully transferring the exact mustache from a source face to a target face. This is a more challenging task than the conventional semantic-level attribute transfer, which only preserves the generic attribute style instead of instance-level traits. We propose the use of geometry-aware flow, which serves as a well-suited representation for modeling the transformation between instance-level facial attributes. Specifically, we leverage the facial landmarks as the geometric guidance to learn the differentiable flows automatically, despite of the large pose gap existed. Geometry-aware flow is able to warp the source face attribute into the target face context and generate a warp-and-blend result. To compensate for the potential appearance gap between source and target faces, we propose a hallucination sub-network that produces an appearance residual to further refine the warp-and-blend result. Finally, a cycle-consistency framework consisting of both attribute transfer module and attribute removal module is designed, so that abundant unpaired face images can be used as training data. Extensive evaluations validate the capability of our approach in transferring instance-level facial attributes faithfully across large pose and appearance gaps. Thanks to the flow representation, our approach can readily be applied to generate realistic details on high-resolution images.

</details>

<details>

<summary>2018-11-30 11:01:47 - Completeness and Consistency Analysis for Evolving Knowledge Bases</summary>

- *Mohammad Rifat Ahmmad Rashid, Giuseppe Rizzo, Marco Torchiano, Nandana Mihindukulasooriya, Oscar Corcho, Raúl García-Castro*

- `1811.12721v1` - [abs](http://arxiv.org/abs/1811.12721v1) - [pdf](http://arxiv.org/pdf/1811.12721v1)

> Assessing the quality of an evolving knowledge base is a challenging task as it often requires to identify correct quality assessment procedures.   Since data is often derived from autonomous, and increasingly large data sources, it is impractical to manually curate the data, and challenging to continuously and automatically assess their quality.   In this paper, we explore two main areas of quality assessment related to evolving knowledge bases: (i) identification of completeness issues using knowledge base evolution analysis, and (ii) identification of consistency issues based on integrity constraints, such as minimum and maximum cardinality, and range constraints.   For completeness analysis, we use data profiling information from consecutive knowledge base releases to estimate completeness measures that allow predicting quality issues. Then, we perform consistency checks to validate the results of the completeness analysis using integrity constraints and learning models.   The approach has been tested both quantitatively and qualitatively by using a subset of datasets from both DBpedia and 3cixty knowledge bases. The performance of the approach is evaluated using precision, recall, and F1 score. From completeness analysis, we observe a 94% precision for the English DBpedia KB and 95% precision for the 3cixty Nice KB. We also assessed the performance of our consistency analysis by using five learning models over three sub-tasks, namely minimum cardinality, maximum cardinality, and range constraint. We observed that the best performing model in our experimental setup is the Random Forest, reaching an F1 score greater than 90% for minimum and maximum cardinality and 84% for range constraints.

</details>

<details>

<summary>2018-11-30 11:10:59 - Document Structure Measure for Hypernym discovery</summary>

- *Aswin Kannan, Shanmukha C Guttula, Balaji Ganesan, Hima P Karanam, Arun Kumar*

- `1811.12728v1` - [abs](http://arxiv.org/abs/1811.12728v1) - [pdf](http://arxiv.org/pdf/1811.12728v1)

> Hypernym discovery is the problem of finding terms that have is-a relationship with a given term. We introduce a new context type, and a relatedness measure to differentiate hypernyms from other types of semantic relationships. Our Document Structure measure is based on hierarchical position of terms in a document, and their presence or otherwise in definition text. This measure quantifies the document structure using multiple attributes, and classes of weighted distance functions.

</details>

<details>

<summary>2018-11-30 12:23:59 - Multiview Based 3D Scene Understanding On Partial Point Sets</summary>

- *Ye Zhu, Sven Ewan Shepstone, Pablo Martínez-Nuevo, Miklas Strøm Kristoffersen, Fabien Moutarde, Zhuang Fu*

- `1812.01712v1` - [abs](http://arxiv.org/abs/1812.01712v1) - [pdf](http://arxiv.org/pdf/1812.01712v1)

> Deep learning within the context of point clouds has gained much research interest in recent years mostly due to the promising results that have been achieved on a number of challenging benchmarks, such as 3D shape recognition and scene semantic segmentation. In many realistic settings however, snapshots of the environment are often taken from a single view, which only contains a partial set of the scene due to the field of view restriction of commodity cameras. 3D scene semantic understanding on partial point clouds is considered as a challenging task. In this work, we propose a processing approach for 3D point cloud data based on a multiview representation of the existing 360{\deg} point clouds. By fusing the original 360{\deg} point clouds and their corresponding 3D multiview representations as input data, a neural network is able to recognize partial point sets while improving the general performance on complete point sets, resulting in an overall increase of 31.9% and 4.3% in segmentation accuracy for partial and complete scene semantic understanding, respectively. This method can also be applied in a wider 3D recognition context such as 3D part segmentation.

</details>

<details>

<summary>2018-11-30 13:22:01 - Measure, Manifold, Learning, and Optimization: A Theory Of Neural Networks</summary>

- *Shuai Li*

- `1811.12783v1` - [abs](http://arxiv.org/abs/1811.12783v1) - [pdf](http://arxiv.org/pdf/1811.12783v1)

> We present a formal measure-theoretical theory of neural networks (NN) built on probability coupling theory. Our main contributions are summarized as follows.   * Built on the formalism of probability coupling theory, we derive an algorithm framework, named Hierarchical Measure Group and Approximate System (HMGAS), nicknamed S-System, that is designed to learn the complex hierarchical, statistical dependency in the physical world.   * We show that NNs are special cases of S-System when the probability kernels assume certain exponential family distributions. Activation Functions are derived formally. We further endow geometry on NNs through information geometry, show that intermediate feature spaces of NNs are stochastic manifolds, and prove that "distance" between samples is contracted as layers stack up.   * S-System shows NNs are inherently stochastic, and under a set of realistic boundedness and diversity conditions, it enables us to prove that for large size nonlinear deep NNs with a class of losses, including the hinge loss, all local minima are global minima with zero loss errors, and regions around the minima are flat basins where all eigenvalues of Hessians are concentrated around zero, using tools and ideas from mean field theory, random matrix theory, and nonlinear operator equations.   * S-System, the information-geometry structure and the optimization behaviors combined completes the analog between Renormalization Group (RG) and NNs. It shows that a NN is a complex adaptive system that estimates the statistic dependency of microscopic object, e.g., pixels, in multiple scales. Unlike clear-cut physical quantity produced by RG in physics, e.g., temperature, NNs renormalize/recompose manifolds emerging through learning/optimization that divide the sample space into highly semantically meaningful groups that are dictated by supervised labels (in supervised NNs).

</details>

<details>

<summary>2018-11-30 14:14:44 - Generative Models for Simulating Mobility Trajectories</summary>

- *Vaibhav Kulkarni, Natasa Tagasovska, Thibault Vatter, Benoit Garbinato*

- `1811.12801v1` - [abs](http://arxiv.org/abs/1811.12801v1) - [pdf](http://arxiv.org/pdf/1811.12801v1)

> Mobility datasets are fundamental for evaluating algorithms pertaining to geographic information systems and facilitating experimental reproducibility. But privacy implications restrict sharing such datasets, as even aggregated location-data is vulnerable to membership inference attacks. Current synthetic mobility dataset generators attempt to superficially match a priori modeled mobility characteristics which do not accurately reflect the real-world characteristics. Modeling human mobility to generate synthetic yet semantically and statistically realistic trajectories is therefore crucial for publishing trajectory datasets having satisfactory utility level while preserving user privacy. Specifically, long-range dependencies inherent to human mobility are challenging to capture with both discriminative and generative models. In this paper, we benchmark the performance of recurrent neural architectures (RNNs), generative adversarial networks (GANs) and nonparametric copulas to generate synthetic mobility traces. We evaluate the generated trajectories with respect to their geographic and semantic similarity, circadian rhythms, long-range dependencies, training and generation time. We also include two sample tests to assess statistical similarity between the observed and simulated distributions, and we analyze the privacy tradeoffs with respect to membership inference and location-sequence attacks.

</details>


## 2018-12

<details>

<summary>2018-12-01 06:27:20 - A Tight Approximation for Co-flow Scheduling for Minimizing Total Weighted Completion Time</summary>

- *Sungjin Im, Manish Purohit*

- `1707.04331v2` - [abs](http://arxiv.org/abs/1707.04331v2) - [pdf](http://arxiv.org/pdf/1707.04331v2)

> Co-flows model a modern scheduling setting that is commonly found in a variety of applications in distributed and cloud computing. In co-flow scheduling, there are $m$ input ports and $m$ output ports. Each co-flow $j \in J$ can be represented by a bipartite graph between the input and output ports, where each edge $(i,o)$ with demand $d_{i,o}^j$ means that $d_{i,o}^j$ units of packets must be delivered from port $i$ to port $o$. To complete co-flow $j$, we must satisfy all of its demands. Due to capacity constraints, a port can only transmit (or receive) one unit of data in unit time. A feasible schedule at each time $t$ must therefore be a bipartite matching.   We consider co-flow scheduling and seek to optimize the popular objective of total weighted completion time. Our main result is a $(2+\epsilon)$-approximation for this problem, which is essentially tight, as the problem is hard to approximate within a factor of $(2 - \epsilon)$. This improves upon the previous best known 4-approximation. Further, our result holds even when jobs have release times without any loss in the approximation guarantee. The key idea of our approach is to construct a continuous-time schedule using a configuration linear program and interpret each job's completion time therein as the job's deadline. The continuous-time schedule serves as a witness schedule meeting the discovered deadlines, which allows us to reduce the problem to a deadline-constrained scheduling problem.   * This result is flawed; see the first page for the details.

</details>

<details>

<summary>2018-12-01 12:19:48 - When a Patch is Not Enough - HardFails: Software-Exploitable Hardware Bugs</summary>

- *Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn, Arun Kanuparthi, Hareesh Khattri, Jason M. Fung, Ahmad-Reza Sadeghi, Jeyavijayan Rajendran*

- `1812.00197v1` - [abs](http://arxiv.org/abs/1812.00197v1) - [pdf](http://arxiv.org/pdf/1812.00197v1)

> In this paper, we take a deep dive into microarchitectural security from a hardware designer's perspective by reviewing the existing approaches to detect hardware vulnerabilities during the design phase. We show that a protection gap currently exists in practice that leaves chip designs vulnerable to software-based attacks. In particular, existing verification approaches fail to detect specific classes of vulnerabilities, which we call HardFails: these bugs evade detection by current verification techniques while being exploitable from software. We demonstrate such vulnerabilities in real-world SoCs using RISC-V to showcase and analyze concrete instantiations of HardFails. Patching these hardware bugs may not always be possible and can potentially result in a product recall. We base our findings on two extensive case studies: the recent Hack@DAC 2018 hardware security competition, where 54 independent teams of researchers competed world-wide over a period of 12 weeks to catch inserted security bugs in SoC RTL designs, and an in-depth systematic evaluation of state-of-the-art verification approaches. Our findings indicate that even combinations of techniques will miss high-impact bugs due to the large number of modules with complex interdependencies and fundamental limitations of current detection approaches. We also craft a real-world software attack that exploits one of the RTL bugs from Hack@DAC that evaded detection and discuss novel approaches to mitigate the growing problem of cross-layer bugs at design time.

</details>

<details>

<summary>2018-12-01 17:14:03 - Mixture of Regression Experts in fMRI Encoding</summary>

- *Subba Reddy Oota, Adithya Avvaru, Naresh Manwani, Raju S. Bapi*

- `1811.10740v2` - [abs](http://arxiv.org/abs/1811.10740v2) - [pdf](http://arxiv.org/pdf/1811.10740v2)

> fMRI semantic category understanding using linguistic encoding models attempt to learn a forward mapping that relates stimuli to the corresponding brain activation. Classical encoding models use linear multi-variate methods to predict the brain activation (all voxels) given the stimulus. However, these methods essentially assume multiple regions as one large uniform region or several independent regions, ignoring connections among them. In this paper, we present a mixture of experts-based model where a group of experts captures brain activity patterns related to particular regions of interest (ROI) and also show the discrimination across different experts. The model is trained word stimuli encoded as 25-dimensional feature vectors as input and the corresponding brain responses as output. Given a new word (25-dimensional feature vector), it predicts the entire brain activation as the linear combination of multiple experts brain activations. We argue that each expert learns a certain region of brain activations corresponding to its category of words, which solves the problem of identifying the regions with a simple encoding model. We showcase that proposed mixture of experts-based model indeed learns region-based experts to predict the brain activations with high spatial accuracy.

</details>

<details>

<summary>2018-12-02 10:27:57 - Unsupervised Post-processing of Word Vectors via Conceptor Negation</summary>

- *Tianlin Liu, Lyle Ungar, João Sedoc*

- `1811.11001v2` - [abs](http://arxiv.org/abs/1811.11001v2) - [pdf](http://arxiv.org/pdf/1811.11001v2)

> Word vectors are at the core of many natural language processing tasks. Recently, there has been interest in post-processing word vectors to enrich their semantic information. In this paper, we introduce a novel word vector post-processing technique based on matrix conceptors (Jaeger2014), a family of regularized identity maps. More concretely, we propose to use conceptors to suppress those latent features of word vectors having high variances. The proposed method is purely unsupervised: it does not rely on any corpus or external linguistic database. We evaluate the post-processed word vectors on a battery of intrinsic lexical evaluation tasks, showing that the proposed method consistently outperforms existing state-of-the-art alternatives. We also show that post-processed word vectors can be used for the downstream natural language processing task of dialogue state tracking, yielding improved results in different dialogue domains.

</details>

<details>

<summary>2018-12-02 12:41:03 - Improved and Robust Controversy Detection in General Web Pages Using Semantic Approaches under Large Scale Conditions</summary>

- *Jasper Linmans, Bob van de Velde, Evangelos Kanoulas*

- `1812.00382v1` - [abs](http://arxiv.org/abs/1812.00382v1) - [pdf](http://arxiv.org/pdf/1812.00382v1)

> Detecting controversy in general web pages is a daunting task, but increasingly essential to efficiently moderate discussions and effectively filter problematic content. Unfortunately, controversies occur across many topics and domains, with great changes over time. This paper investigates neural classifiers as a more robust methodology for controversy detection in general web pages. Current models have often cast controversy detection on general web pages as Wikipedia linking, or exact lexical matching tasks. The diverse and changing nature of controversies suggest that semantic approaches are better able to detect controversy. We train neural networks that can capture semantic information from texts using weak signal data. By leveraging the semantic properties of word embeddings we robustly improve on existing controversy detection methods. To evaluate model stability over time and to unseen topics, we asses model performance under varying training conditions to test cross-temporal, cross-topic, cross-domain performance and annotator congruence. In doing so, we demonstrate that weak-signal based neural approaches are closer to human estimates of controversy and are more robust to the inherent variability of controversies.

</details>

<details>

<summary>2018-12-02 15:40:30 - Dynamic Patch Generation for Null Pointer Exceptions using Metaprogramming</summary>

- *Thomas Durieux, Benoit Cornu, Lionel Seinturier, Martin Monperrus*

- `1812.00409v1` - [abs](http://arxiv.org/abs/1812.00409v1) - [pdf](http://arxiv.org/pdf/1812.00409v1)

> Null pointer exceptions (NPE) are the number one cause of uncaught crashing exceptions in production. In this paper, we aim at exploring the search space of possible patches for null pointer exceptions with metaprogramming. Our idea is to transform the program under repair with automated code transformation, so as to obtain a metaprogram. This metaprogram contains automatically injected hooks, that can be activated to emulate a null pointer exception patch. This enables us to perform a fine-grain analysis of the runtime context of null pointer exceptions. We set up an experiment with 16 real null pointer exceptions that have happened in the field. We compare the effectiveness of our metaprogramming approach against simple templates for repairing null pointer exceptions.

</details>

<details>

<summary>2018-12-02 15:53:24 - Ann: A domain-specific language for the effective design and validation of Java annotations</summary>

- *Irene Córdoba, Juan de Lara*

- `1812.00992v1` - [abs](http://arxiv.org/abs/1812.00992v1) - [pdf](http://arxiv.org/pdf/1812.00992v1)

> This paper describes a new modelling language for the effective design and validation of Java annotations. Since their inclusion in the 5th edition of Java, annotations have grown from a useful tool for the addition of meta-data to play a central role in many popular software projects. Usually they are not conceived in isolation, but in groups, with dependency and integrity constraints between them. However, the native support provided by Java for expressing this design is very limited.   To overcome its deficiencies and make explicit the rich conceptual model which lies behind a set of annotations, we propose a domain-specific modelling language. The proposal has been implemented as an Eclipse plug-in, including an editor and an integrated code generator that synthesises annotation processors. The environment also integrates a model finder, able to detect unsatisfiable constraints between different annotations, and to provide examples of correct annotation usages for validation. The language has been tested using a real set of annotations from the Java Persistence API (JPA). Within this subset we have found enough rich semantics expressible with Ann and omitted nowadays by the Java language, which shows the benefits of Ann in a relevant field of application.

</details>

<details>

<summary>2018-12-02 23:18:23 - Looking Deeper into Deep Learning Model: Attribution-based Explanations of TextCNN</summary>

- *Wenting Xiong, Iftitahu Ni'mah, Juan M. G. Huesca, Werner van Ipenburg, Jan Veldsink, Mykola Pechenizkiy*

- `1811.03970v2` - [abs](http://arxiv.org/abs/1811.03970v2) - [pdf](http://arxiv.org/pdf/1811.03970v2)

> Layer-wise Relevance Propagation (LRP) and saliency maps have been recently used to explain the predictions of Deep Learning models, specifically in the domain of text classification. Given different attribution-based explanations to highlight relevant words for a predicted class label, experiments based on word deleting perturbation is a common evaluation method. This word removal approach, however, disregards any linguistic dependencies that may exist between words or phrases in a sentence, which could semantically guide a classifier to a particular prediction. In this paper, we present a feature-based evaluation framework for comparing the two attribution methods on customer reviews (public data sets) and Customer Due Diligence (CDD) extracted reports (corporate data set). Instead of removing words based on the relevance score, we investigate perturbations based on embedded features removal from intermediate layers of Convolutional Neural Networks. Our experimental study is carried out on embedded-word, embedded-document, and embedded-ngrams explanations. Using the proposed framework, we provide a visualization tool to assist analysts in reasoning toward the model's final prediction.

</details>

<details>

<summary>2018-12-03 01:47:13 - Knowledge-driven generative subspaces for modeling multi-view dependencies in medical data</summary>

- *Parvathy Sudhir Pillai, Tze-Yun Leong*

- `1812.00509v1` - [abs](http://arxiv.org/abs/1812.00509v1) - [pdf](http://arxiv.org/pdf/1812.00509v1)

> Early detection of Alzheimer's disease (AD) and identification of potential risk/beneficial factors are important for planning and administering timely interventions or preventive measures. In this paper, we learn a disease model for AD that combines genotypic and phenotypic profiles, and cognitive health metrics of patients. We propose a probabilistic generative subspace that describes the correlative, complementary and domain-specific semantics of the dependencies in multi-view, multi-modality medical data. Guided by domain knowledge and using the latent consensus between abstractions of multi-view data, we model the fusion as a data generating process. We show that our approach can potentially lead to i) explainable clinical predictions and ii) improved AD diagnoses.

</details>

<details>

<summary>2018-12-03 06:21:36 - Learning From Weights: A Cost-Sensitive Approach For Ad Retrieval</summary>

- *Nikit Begwani, Shrutendra Harsola, Rahul Agrawal*

- `1811.12776v2` - [abs](http://arxiv.org/abs/1811.12776v2) - [pdf](http://arxiv.org/pdf/1811.12776v2)

> Retrieval models such as CLSM is trained on click-through data which treats each clicked query-document pair as equivalent. While training on click-through data is reasonable, this paper argues that it is sub-optimal because of its noisy and long-tail nature (especially for sponsored search). In this paper, we discuss the impact of incorporating or disregarding the long tail pairs in the training set. Also, we propose a weighing based strategy using which we can learn semantic representations for tail pairs without compromising the quality of retrieval. We conducted our experiments on Bing sponsored search and also on Amazon product recommendation to demonstrate that the methodology is domain agnostic.   Online A/B testing on live search engine traffic showed improvements in clicks (11.8\% higher CTR) and as well as improvement in quality (8.2\% lower bounce rate) when compared to the unweighted model. We also conduct the experiment on Amazon Product Recommendation data where we see slight improvements in NDCG Scores calculated by retrieving among co-purchased product.

</details>

<details>

<summary>2018-12-03 15:12:44 - Video-to-Video Synthesis</summary>

- *Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin Liu, Andrew Tao, Jan Kautz, Bryan Catanzaro*

- `1808.06601v2` - [abs](http://arxiv.org/abs/1808.06601v2) - [pdf](http://arxiv.org/pdf/1808.06601v2)

> We study the problem of video-to-video synthesis, whose goal is to learn a mapping function from an input source video (e.g., a sequence of semantic segmentation masks) to an output photorealistic video that precisely depicts the content of the source video. While its image counterpart, the image-to-image synthesis problem, is a popular topic, the video-to-video synthesis problem is less explored in the literature. Without understanding temporal dynamics, directly applying existing image synthesis approaches to an input video often results in temporally incoherent videos of low visual quality. In this paper, we propose a novel video-to-video synthesis approach under the generative adversarial learning framework. Through carefully-designed generator and discriminator architectures, coupled with a spatio-temporal adversarial objective, we achieve high-resolution, photorealistic, temporally coherent video results on a diverse set of input formats including segmentation masks, sketches, and poses. Experiments on multiple benchmarks show the advantage of our method compared to strong baselines. In particular, our model is capable of synthesizing 2K resolution videos of street scenes up to 30 seconds long, which significantly advances the state-of-the-art of video synthesis. Finally, we apply our approach to future video prediction, outperforming several state-of-the-art competing systems.

</details>

<details>

<summary>2018-12-03 17:12:23 - From the User to the Medium: Neural Profiling Across Web Communities</summary>

- *Mohammad Akbari, Kunal Relia, Anas Elghafari, Rumi Chunara*

- `1812.00912v1` - [abs](http://arxiv.org/abs/1812.00912v1) - [pdf](http://arxiv.org/pdf/1812.00912v1)

> Online communities provide a unique way for individuals to access information from those in similar circumstances, which can be critical for health conditions that require daily and personalized management. As these groups and topics often arise organically, identifying the types of topics discussed is necessary to understand their needs. As well, these communities and people in them can be quite diverse, and existing community detection methods have not been extended towards evaluating these heterogeneities. This has been limited as community detection methodologies have not focused on community detection based on semantic relations between textual features of the user-generated content. Thus here we develop an approach, NeuroCom, that optimally finds dense groups of users as communities in a latent space inferred by neural representation of published contents of users. By embedding of words and messages, we show that NeuroCom demonstrates improved clustering and identifies more nuanced discussion topics in contrast to other common unsupervised learning approaches.

</details>

<details>

<summary>2018-12-03 19:20:25 - Embedding Models for Episodic Knowledge Graphs</summary>

- *Yunpu Ma, Volker Tresp, Erik Daxberger*

- `1807.00228v2` - [abs](http://arxiv.org/abs/1807.00228v2) - [pdf](http://arxiv.org/pdf/1807.00228v2)

> In recent years a number of large-scale triple-oriented knowledge graphs have been generated and various models have been proposed to perform learning in those graphs. Most knowledge graphs are static and reflect the world in its current state. In reality, of course, the state of the world is changing: a healthy person becomes diagnosed with a disease and a new president is inaugurated. In this paper, we extend models for static knowledge graphs to temporal knowledge graphs. This enables us to store episodic data and to generalize to new facts (inductive learning). We generalize leading learning models for static knowledge graphs (i.e., Tucker, RESCAL, HolE, ComplEx, DistMult) to temporal knowledge graphs. In particular, we introduce a new tensor model, ConT, with superior generalization performance. The performances of all proposed models are analyzed on two different datasets: the Global Database of Events, Language, and Tone (GDELT) and the database for Integrated Conflict Early Warning System (ICEWS). We argue that temporal knowledge graph embeddings might be models also for cognitive episodic memory (facts we remember and can recollect) and that a semantic memory (current facts we know) can be generated from episodic memory by a marginalization operation. We validate this episodic-to-semantic projection hypothesis with the ICEWS dataset.

</details>

<details>

<summary>2018-12-04 03:28:28 - Twitter-based traffic information system based on vector representations for words</summary>

- *Sina Dabiri, Kevin Heaslip*

- `1812.01199v1` - [abs](http://arxiv.org/abs/1812.01199v1) - [pdf](http://arxiv.org/pdf/1812.01199v1)

> Recently, researchers have shown an increased interest in harnessing Twitter data for dynamic monitoring of traffic conditions. Bag-of-words representation is a common method in literature for tweet modeling and retrieving traffic information, yet it suffers from the curse of dimensionality and sparsity. To address these issues, our specific objective is to propose a simple and robust framework on the top of word embedding for distinguishing traffic-related tweets against non-traffic-related ones. In our proposed model, a tweet is classified as traffic-related if semantic similarity between its words and a small set of traffic keywords exceeds a threshold value. Semantic similarity between words is captured by means of word-embedding models, which is an unsupervised learning tool. The proposed model is as simple as having only one trainable parameter. The model takes advantage of outstanding merits, which are demonstrated through several evaluation steps. The state-of-the-art test accuracy for our proposed model is 95.9%.

</details>

<details>

<summary>2018-12-04 07:05:47 - Quantification and Analysis of Scientific Language Variation Across Research Fields</summary>

- *Pei Zhou, Muhao Chen, Kai-Wei Chang, Carlo Zaniolo*

- `1812.01250v1` - [abs](http://arxiv.org/abs/1812.01250v1) - [pdf](http://arxiv.org/pdf/1812.01250v1)

> Quantifying differences in terminologies from various academic domains has been a longstanding problem yet to be solved. We propose a computational approach for analyzing linguistic variation among scientific research fields by capturing the semantic change of terms based on a neural language model. The model is trained on a large collection of literature in five computer science research fields, for which we obtain field-specific vector representations for key terms, and global vector representations for other words. Several quantitative approaches are introduced to identify the terms whose semantics have drastically changed, or remain unchanged across different research fields. We also propose a metric to quantify the overall linguistic variation of research fields. After quantitative evaluation on human annotated data and qualitative comparison with other methods, we show that our model can improve cross-disciplinary data collaboration by identifying terms that potentially induce confusion during interdisciplinary studies.

</details>

<details>

<summary>2018-12-04 08:59:03 - Towards Continuous Domain adaptation for Healthcare</summary>

- *Rahul Venkataramani, Hariharan Ravishankar, Saihareesh Anamandra*

- `1812.01281v1` - [abs](http://arxiv.org/abs/1812.01281v1) - [pdf](http://arxiv.org/pdf/1812.01281v1)

> Deep learning algorithms have demonstrated tremendous success on challenging medical imaging problems. However, post-deployment, these algorithms are susceptible to data distribution variations owing to \emph{limited data issues} and \emph{diversity} in medical images. In this paper, we propose \emph{ContextNets}, a generic memory-augmented neural network framework for semantic segmentation to achieve continuous domain adaptation without the necessity of retraining. Unlike existing methods which require access to entire source and target domain images, our algorithm can adapt to a target domain with a few similar images. We condition the inference on any new input with features computed on its support set of images (and masks, if available) through contextual embeddings to achieve site-specific adaptation. We demonstrate state-of-the-art domain adaptation performance on the X-ray lung segmentation problem from three independent cohorts that differ in disease type, gender, contrast and intensity variations.

</details>

<details>

<summary>2018-12-04 15:35:35 - Deep metric learning using Triplet network</summary>

- *Elad Hoffer, Nir Ailon*

- `1412.6622v4` - [abs](http://arxiv.org/abs/1412.6622v4) - [pdf](http://arxiv.org/pdf/1412.6622v4)

> Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.

</details>

<details>

<summary>2018-12-04 15:47:44 - Generating High Fidelity Images with Subscale Pixel Networks and Multidimensional Upscaling</summary>

- *Jacob Menick, Nal Kalchbrenner*

- `1812.01608v1` - [abs](http://arxiv.org/abs/1812.01608v1) - [pdf](http://arxiv.org/pdf/1812.01608v1)

> The unconditional generation of high fidelity images is a longstanding benchmark for testing the performance of image decoders. Autoregressive image models have been able to generate small images unconditionally, but the extension of these methods to large images where fidelity can be more readily assessed has remained an open problem. Among the major challenges are the capacity to encode the vast previous context and the sheer difficulty of learning a distribution that preserves both global semantic coherence and exactness of detail. To address the former challenge, we propose the Subscale Pixel Network (SPN), a conditional decoder architecture that generates an image as a sequence of sub-images of equal size. The SPN compactly captures image-wide spatial dependencies and requires a fraction of the memory and the computation required by other fully autoregressive models. To address the latter challenge, we propose to use Multidimensional Upscaling to grow an image in both size and depth via intermediate stages utilising distinct SPNs. We evaluate SPNs on the unconditional generation of CelebAHQ of size 256 and of ImageNet from size 32 to 256. We achieve state-of-the-art likelihood results in multiple settings, set up new benchmark results in previously unexplored settings and are able to generate very high fidelity large scale samples on the basis of both datasets.

</details>

<details>

<summary>2018-12-04 17:07:27 - An Idea to Increase the Security of EAP-MD5 Protocol Against Dictionary Attack</summary>

- *Behrooz Khadem, Siavosh Abedi, Isa Sa-adatyar*

- `1812.01533v1` - [abs](http://arxiv.org/abs/1812.01533v1) - [pdf](http://arxiv.org/pdf/1812.01533v1)

> IEEE 802.1X is an international standard for Port-based Network Access Control which provides authentication for devices applicant of either local network or wireless local network. This standard defines the packing of EAP protocol on IEEE 802. In this standard, authentication protocols become a complementary part of network security. There is a variety in EAP family protocols, regarding their speed and security. One of the fastest of these protocols is EAP-MD5 which is the main subject of this paper. Moreover, in order to improve EAP-MD5 security, a series of attacks against it have been investigated. In this paper at first EAP-MD5 protocol is introduced briefly and a series of the dictionary attacks against it are described. Then, based on observed weaknesses, by proposing an appropriate idea while maintaining the speed of execution, its security against dictionary attack is improved.

</details>

<details>

<summary>2018-12-05 06:31:48 - Graph based Question Answering System</summary>

- *Piyush Mital, Saurabh Agarwal, Bhargavi Neti, Yashodhara Haribhakta, Vibhavari Kamble, Krishnanjan Bhattacharjee, Debashri Das, Swati Mehta, Ajai Kumar*

- `1812.01828v1` - [abs](http://arxiv.org/abs/1812.01828v1) - [pdf](http://arxiv.org/pdf/1812.01828v1)

> In today's digital age in the dawning era of big data analytics it is not the information but the linking of information through entities and actions which defines the discourse. Any textual data either available on the Internet off off-line (like newspaper data, Wikipedia dump, etc) is basically connect information which cannot be treated isolated for its wholesome semantics. There is a need for an automated retrieval process with proper information extraction to structure the data for relevant and fast text analytics. The first big challenge is the conversion of unstructured textual data to structured data. Unlike other databases, graph databases handle relationships and connections elegantly. Our project aims at developing a graph-based information extraction and retrieval system.

</details>

<details>

<summary>2018-12-05 09:58:54 - MedSim: A Novel Semantic Similarity Measure in Bio-medical Knowledge Graphs</summary>

- *Kai Lei, Kaiqi Yuan, Qiang Zhang, Ying Shen*

- `1812.01884v1` - [abs](http://arxiv.org/abs/1812.01884v1) - [pdf](http://arxiv.org/pdf/1812.01884v1)

> We present MedSim, a novel semantic SIMilarity method based on public well-established bio-MEDical knowledge graphs (KGs) and large-scale corpus, to study the therapeutic substitution of antibiotics. Besides hierarchy and corpus of KGs, MedSim further interprets medicine characteristics by constructing multi-dimensional medicine-specific feature vectors. Dataset of 528 antibiotic pairs scored by doctors is applied for evaluation and MedSim has produced statistically significant improvement over other semantic similarity methods. Furthermore, some promising applications of MedSim in drug substitution and drug abuse prevention are presented in case study.

</details>

<details>

<summary>2018-12-05 10:02:59 - Improving Medical Short Text Classification with Semantic Expansion Using Word-Cluster Embedding</summary>

- *Ying Shen, Qiang Zhang, Jin Zhang, Jiyue Huang, Yuming Lu, Kai Lei*

- `1812.01885v1` - [abs](http://arxiv.org/abs/1812.01885v1) - [pdf](http://arxiv.org/pdf/1812.01885v1)

> Automatic text classification (TC) research can be used for real-world problems such as the classification of in-patient discharge summaries and medical text reports, which is beneficial to make medical documents more understandable to doctors. However, in electronic medical records (EMR), the texts containing sentences are shorter than that in general domain, which leads to the lack of semantic features and the ambiguity of semantic. To tackle this challenge, we propose to add word-cluster embedding to deep neural network for improving short text classification. Concretely, we first use hierarchical agglomerative clustering to cluster the word vectors in the semantic space. Then we calculate the cluster center vector which represents the implicit topic information of words in the cluster. Finally, we expand word vector with cluster center vector, and implement classifiers using CNN and LSTM respectively. To evaluate the performance of our proposed method, we conduct experiments on public data sets TREC and the medical short sentences data sets which is constructed and released by us. The experimental results demonstrate that our proposed method outperforms state-of-the-art baselines in short sentence classification on both medical domain and general domain.

</details>

<details>

<summary>2018-12-05 10:08:29 - Approach for Semi-automatic Construction of Anti-infective Drug Ontology Based on Entity Linking</summary>

- *Ying Shen, Yang Deng, Kaiqi Yuan, Li Liu, Yong Liu*

- `1812.01887v1` - [abs](http://arxiv.org/abs/1812.01887v1) - [pdf](http://arxiv.org/pdf/1812.01887v1)

> Ontology can be used for the interpretation of natural language. To construct an anti-infective drug ontology, one needs to design and deploy a methodological step to carry out the entity discovery and linking. Medical synonym resources have been an important part of medical natural language processing (NLP). However, there are problems such as low precision and low recall rate. In this study, an NLP approach is adopted to generate candidate entities. Open ontology is analyzed to extract semantic relations. Six-word vector features and word-level features are selected to perform the entity linking. The extraction results of synonyms with a single feature and different combinations of features are studied. Experiments show that our selected features have achieved a precision rate of 86.77%, a recall rate of 89.03% and an F1 score of 87.89%. This paper finally presents the structure of the proposed ontology and its relevant statistical data.

</details>

<details>

<summary>2018-12-05 10:10:56 - A Knowledge Graph Based Solution for Entity Discovery and Linking in Open-Domain Questions</summary>

- *Kai Lei, Bing Zhang, Yong Liu, Yang Deng, Dongyu Zhang, Ying Shen*

- `1812.01889v1` - [abs](http://arxiv.org/abs/1812.01889v1) - [pdf](http://arxiv.org/pdf/1812.01889v1)

> Named entity discovery and linking is the fundamental and core component of question answering. In Question Entity Discovery and Linking (QEDL) problem, traditional methods are challenged because multiple entities in one short question are difficult to be discovered entirely and the incomplete information in short text makes entity linking hard to implement. To overcome these difficulties, we proposed a knowledge graph based solution for QEDL and developed a system consists of Question Entity Discovery (QED) module and Entity Linking (EL) module. The method of QED module is a tradeoff and ensemble of two methods. One is the method based on knowledge graph retrieval, which could extract more entities in questions and guarantee the recall rate, the other is the method based on Conditional Random Field (CRF), which improves the precision rate. The EL module is treated as a ranking problem and Learning to Rank (LTR) method with features such as semantic similarity, text similarity and entity popularity is utilized to extract and make full use of the information in short texts. On the official dataset of a shared QEDL evaluation task, our approach could obtain 64.44% F1 score of QED and 64.86% accuracy of EL, which ranks the 2nd place and indicates its practical use for QEDL problem.

</details>

<details>

<summary>2018-12-05 19:55:24 - Are you tough enough? Framework for Robustness Validation of Machine Comprehension Systems</summary>

- *Barbara Rychalska, Dominika Basaj, Przemyslaw Biecek*

- `1812.02205v1` - [abs](http://arxiv.org/abs/1812.02205v1) - [pdf](http://arxiv.org/pdf/1812.02205v1)

> Deep Learning NLP domain lacks procedures for the analysis of model robustness. In this paper we propose a framework which validates robustness of any Question Answering model through model explainers. We propose that a robust model should transgress the initial notion of semantic similarity induced by word embeddings to learn a more human-like understanding of meaning. We test this property by manipulating questions in two ways: swapping important question word for 1) its semantically correct synonym and 2) for word vector that is close in embedding space. We estimate importance of words in asked questions with Locally Interpretable Model Agnostic Explanations method (LIME). With these two steps we compare state-of-the-art Q&A models. We show that although accuracy of state-of-the-art models is high, they are very fragile to changes in the input. Moreover, we propose 2 adversarial training scenarios which raise model sensitivity to true synonyms by up to 7% accuracy measure. Our findings help to understand which models are more stable and how they can be improved. In addition, we have created and published a new dataset that may be used for validation of robustness of a Q&A model.

</details>

<details>

<summary>2018-12-06 02:54:49 - Adpositional Supersenses for Mandarin Chinese</summary>

- *Yilun Zhu, Yang Liu, Siyao Peng, Austin Blodgett, Yushi Zhao, Nathan Schneider*

- `1812.02317v1` - [abs](http://arxiv.org/abs/1812.02317v1) - [pdf](http://arxiv.org/pdf/1812.02317v1)

> This study adapts Semantic Network of Adposition and Case Supersenses (SNACS) annotation to Mandarin Chinese and demonstrates that the same supersense categories are appropriate for Chinese adposition semantics. We annotated 15 chapters of The Little Prince, with high interannotator agreement. The parallel corpus gives insight into differences in construal between the two languages' adpositions, namely a number of construals that are frequent in Chinese but rare or unattested in the English corpus. The annotated corpus can further support automatic disambiguation of adpositions in Chinese, and the common inventory of supersenses between the two languages can potentially serve cross-linguistic tasks such as machine translation.

</details>

<details>

<summary>2018-12-06 07:00:23 - Macquarie University at BioASQ 6b: Deep learning and deep reinforcement learning for query-based multi-document summarisation</summary>

- *Diego Mollá*

- `1809.05283v2` - [abs](http://arxiv.org/abs/1809.05283v2) - [pdf](http://arxiv.org/pdf/1809.05283v2)

> This paper describes Macquarie University's contribution to the BioASQ Challenge (BioASQ 6b, Phase B). We focused on the extraction of the ideal answers, and the task was approached as an instance of query-based multi-document summarisation. In particular, this paper focuses on the experiments related to the deep learning and reinforcement learning approaches used in the submitted runs. The best run used a deep learning model under a regression-based framework. The deep learning architecture used features derived from the output of LSTM chains on word embeddings, plus features based on similarity with the query, and sentence position. The reinforcement learning approach was a proof-of-concept prototype that trained a global policy using REINFORCE. The global policy was implemented as a neural network that used $tf.idf$ features encoding the candidate sentence, question, and context.

</details>

<details>

<summary>2018-12-06 18:57:52 - Project Rosetta: A Childhood Social, Emotional, and Behavioral Developmental Ontology</summary>

- *Alyson Maslowski, Halim Abbas, Kelley Abrams, Sharief Taraman, Ford Garberson, Susan Segar*

- `1812.02722v1` - [abs](http://arxiv.org/abs/1812.02722v1) - [pdf](http://arxiv.org/pdf/1812.02722v1)

> There is a wide array of existing instruments used to assess childhood behavior and development for the evaluation of social, emotional and behavioral disorders. Many of these instruments either focus on one diagnostic category or encompass a broad set of childhood behaviors. We built an extensive ontology of the questions associated with key features that have diagnostic relevance for child behavioral conditions, such as Autism Spectrum Disorder (ASD), attention-deficit/hyperactivity disorder (ADHD), and anxiety, by incorporating a subset of existing child behavioral instruments and categorizing each question into clinical domains. Each existing question and set of question responses were then mapped to a new unique Rosetta question and set of answer codes encompassing the semantic meaning and identified concept(s) of as many existing questions as possible. This resulted in 1274 existing instrument questions mapping to 209 Rosetta questions creating a minimal set of questions that are comprehensive of each topic and subtopic. This resulting ontology can be used to create more concise instruments across various ages and conditions, as well as create more robust overlapping datasets for both clinical and research use.

</details>

<details>

<summary>2018-12-06 19:34:33 - Knockoff Nets: Stealing Functionality of Black-Box Models</summary>

- *Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz*

- `1812.02766v1` - [abs](http://arxiv.org/abs/1812.02766v1) - [pdf](http://arxiv.org/pdf/1812.02766v1)

> Machine Learning (ML) models are increasingly deployed in the wild to perform a wide range of tasks. In this work, we ask to what extent can an adversary steal functionality of such "victim" models based solely on blackbox interactions: image in, predictions out. In contrast to prior work, we present an adversary lacking knowledge of train/test data used by the model, its internals, and semantics over model outputs. We formulate model functionality stealing as a two-step approach: (i) querying a set of input images to the blackbox model to obtain predictions; and (ii) training a "knockoff" with queried image-prediction pairs. We make multiple remarkable observations: (a) querying random images from a different distribution than that of the blackbox training data results in a well-performing knockoff; (b) this is possible even when the knockoff is represented using a different architecture; and (c) our reinforcement learning approach additionally improves query sample efficiency in certain settings and provides performance gains. We validate model functionality stealing on a range of datasets and tasks, as well as on a popular image analysis API where we create a reasonable knockoff for as little as $30.

</details>

<details>

<summary>2018-12-06 20:38:19 - Verification of deep probabilistic models</summary>

- *Krishnamurthy Dvijotham, Marta Garnelo, Alhussein Fawzi, Pushmeet Kohli*

- `1812.02795v1` - [abs](http://arxiv.org/abs/1812.02795v1) - [pdf](http://arxiv.org/pdf/1812.02795v1)

> Probabilistic models are a critical part of the modern deep learning toolbox - ranging from generative models (VAEs, GANs), sequence to sequence models used in machine translation and speech processing to models over functional spaces (conditional neural processes, neural processes). Given the size and complexity of these models, safely deploying them in applications requires the development of tools to analyze their behavior rigorously and provide some guarantees that these models are consistent with a list of desirable properties or specifications. For example, a machine translation model should produce semantically equivalent outputs for innocuous changes in the input to the model. A functional regression model that is learning a distribution over monotonic functions should predict a larger value at a larger input. Verification of these properties requires a new framework that goes beyond notions of verification studied in deterministic feedforward networks, since requiring worst-case guarantees in probabilistic models is likely to produce conservative or vacuous results. We propose a novel formulation of verification for deep probabilistic models that take in conditioning inputs and sample latent variables in the course of producing an output: We require that the output of the model satisfies a linear constraint with high probability over the sampling of latent variables and for every choice of conditioning input to the model. We show that rigorous lower bounds on the probability that the constraint is satisfied can be obtained efficiently. Experiments with neural processes show that several properties of interest while modeling functional spaces can be modeled within this framework (monotonicity, convexity) and verified efficiently using our algorithms

</details>

<details>

<summary>2018-12-07 05:09:34 - Dynamic Role Binding in Blockchain-Based Collaborative Business Processes</summary>

- *Orlenys López-Pintado, Marlon Dumas, Luciano García-Bañuelos, Ingo Weber*

- `1812.02909v1` - [abs](http://arxiv.org/abs/1812.02909v1) - [pdf](http://arxiv.org/pdf/1812.02909v1)

> Blockchain technology enables the execution of collaborative business processes involving mutually untrusted parties. Existing platforms allow such processes to be modeled using high-level notations and compiled into smart contracts that can be deployed on blockchain platforms. However, these platforms brush aside the question of who is allowed to execute which tasks in the process, either by deferring the question altogether or by adopting a static approach where all actors are bound to roles upon process instantiation. Yet, a key advantage of blockchains is their ability to support dynamic sets of actors. This paper presents a model for dynamic binding of actors to roles in collaborative processes and an associated binding policy specification language. The proposed language is endowed with a Petri net semantics, thus enabling policy consistency verification. The paper also outlines an approach to compile policy specifications into smart contracts for enforcement. An experimental evaluation shows that the cost of policy enforcement increases linearly with the number of roles and constraints.

</details>

<details>

<summary>2018-12-07 07:09:14 - Persistent Hidden States and Nonlinear Transformation for Long Short-Term Memory</summary>

- *Heeyoul Choi*

- `1806.08748v2` - [abs](http://arxiv.org/abs/1806.08748v2) - [pdf](http://arxiv.org/pdf/1806.08748v2)

> Recurrent neural networks (RNNs) have been drawing much attention with great success in many applications like speech recognition and neural machine translation. Long short-term memory (LSTM) is one of the most popular RNN units in deep learning applications. LSTM transforms the input and the previous hidden states to the next states with the affine transformation, multiplication operations and a nonlinear activation function, which makes a good data representation for a given task. The affine transformation includes rotation and reflection, which change the semantic or syntactic information of dimensions in the hidden states. However, considering that a model interprets the output sequence of LSTM over the whole input sequence, the dimensions of the states need to keep the same type of semantic or syntactic information regardless of the location in the sequence. In this paper, we propose a simple variant of the LSTM unit, persistent recurrent unit (PRU), where each dimension of hidden states keeps persistent information across time, so that the space keeps the same meaning over the whole sequence. In addition, to improve the nonlinear transformation power, we add a feedforward layer in the PRU structure. In the experiment, we evaluate our proposed methods with three different tasks, and the results confirm that our methods have better performance than the conventional LSTM.

</details>

<details>

<summary>2018-12-07 17:36:50 - Transferable Natural Language Interface to Structured Queries aided by Adversarial Generation</summary>

- *Hongyu Xiong, Ruixiao Sun*

- `1812.01245v2` - [abs](http://arxiv.org/abs/1812.01245v2) - [pdf](http://arxiv.org/pdf/1812.01245v2)

> A natural language interface (NLI) to structured query is intriguing due to its wide industrial applications and high economical values. In this work, we tackle the problem of domain adaptation for NLI with limited data on target domain. Two important approaches are considered: (a) effective general-knowledge-learning on source domain semantic parsing, and (b) data augmentation on target domain. We present a Structured Query Inference Network (SQIN) to enhance learning for domain adaptation, by separating schema information from NL and decoding SQL in a more structural-aware manner; we also propose a GAN-based augmentation technique (AugmentGAN) to mitigate the issue of lacking target domain data. We report solid results on GeoQuery, Overnight, and WikiSQL to demonstrate state-of-the-art performances for both in-domain and domain-transfer tasks.

</details>

<details>

<summary>2018-12-07 17:38:46 - Taking the Scenic Route: Automatic Exploration for Videogames</summary>

- *Zeping Zhan, Batu Aytemiz, Adam M. Smith*

- `1812.03125v1` - [abs](http://arxiv.org/abs/1812.03125v1) - [pdf](http://arxiv.org/pdf/1812.03125v1)

> Machine playtesting tools and game moment search engines require exposure to the diversity of a game's state space if they are to report on or index the most interesting moments of possible play. Meanwhile, mobile app distribution services would like to quickly determine if a freshly-uploaded game is fit to be published. Having access to a semantic map of reachable states in the game would enable efficient inference in these applications. However, human gameplay data is expensive to acquire relative to the coverage of a game that it provides. We show that off-the-shelf automatic exploration strategies can explore with an effectiveness comparable to human gameplay on the same timescale. We contribute generic methods for quantifying exploration quality as a function of time and demonstrate our metric on several elementary techniques and human players on a collection of commercial games sampled from multiple game platforms (from Atari 2600 to Nintendo 64). Emphasizing the diversity of states reached and the semantic map extracted, this work makes productive contrast with the focus on finding a behavior policy or optimizing game score used in most automatic game playing research.

</details>

<details>

<summary>2018-12-08 03:21:26 - An Exploratory Study of (#)Exercise in the Twittersphere</summary>

- *George Shaw, Amir Karami*

- `1812.03260v1` - [abs](http://arxiv.org/abs/1812.03260v1) - [pdf](http://arxiv.org/pdf/1812.03260v1)

> Social media analytics allows us to extract, analyze, and establish semantic from user-generated contents in social media platforms. This study utilized a mixed method including a three-step process of data collection, topic modeling, and data annotation for recognizing exercise related patterns. Based on the findings, 86% of the detected topics were identified as meaningful topics after conducting the data annotation process. The most discussed exercise-related topics were physical activity (18.7%), lifestyle behaviors (6.6%), and dieting (4%). The results from our experiment indicate that the exploratory data analysis is a practical approach to summarizing the various characteristics of text data for different health and medical applications.

</details>

<details>

<summary>2018-12-08 08:24:49 - Production-Driven Patch Generation</summary>

- *Thomas Durieux, Youssef Hamadi, Martin Monperrus*

- `1812.04475v1` - [abs](http://arxiv.org/abs/1812.04475v1) - [pdf](http://arxiv.org/pdf/1812.04475v1)

> We present an original concept for patch generation: we propose to do it directly in production. Our idea is to generate patches on-the-fly based on automated analysis of the failure context. By doing this in production, the repair process has complete access to the system state at the point of failure. We propose to perform live regression testing of the generated patches directly on the production traffic, by feeding a sandboxed version of the application with a copy of the production traffic, the 'shadow traffic'. Our concept widens the applicability of program repair, because it removes the requirements of having a failing test case.

</details>

<details>

<summary>2018-12-10 11:50:42 - Hybrid Self-Attention Network for Machine Translation</summary>

- *Kaitao Song, Xu Tan, Furong Peng, Jianfeng Lu*

- `1811.00253v3` - [abs](http://arxiv.org/abs/1811.00253v3) - [pdf](http://arxiv.org/pdf/1811.00253v3)

> The encoder-decoder is the typical framework for Neural Machine Translation (NMT), and different structures have been developed for improving the translation performance. Transformer is one of the most promising structures, which can leverage the self-attention mechanism to capture the semantic dependency from global view. However, it cannot distinguish the relative position of different tokens very well, such as the tokens located at the left or right of the current token, and cannot focus on the local information around the current token either. To alleviate these problems, we propose a novel attention mechanism named Hybrid Self-Attention Network (HySAN) which accommodates some specific-designed masks for self-attention network to extract various semantic, such as the global/local information, the left/right part context. Finally, a squeeze gate is introduced to combine different kinds of SANs for fusion. Experimental results on three machine translation tasks show that our proposed framework outperforms the Transformer baseline significantly and achieves superior results over state-of-the-art NMT systems.

</details>

<details>

<summary>2018-12-10 19:00:09 - Lévy Flights of the Collective Imagination</summary>

- *William H. W. Thompson, Zachary Wojtowicz, Simon DeDeo*

- `1812.04013v1` - [abs](http://arxiv.org/abs/1812.04013v1) - [pdf](http://arxiv.org/pdf/1812.04013v1)

> We present a structured random-walk model that captures key aspects of how people communicate in groups. Our model takes the form of a correlated L\'{e}vy flight that quantifies the balance between focused discussion of an idea and long-distance leaps in semantic space. We apply our model to three cases of increasing structural complexity: philosophical texts by Aristotle, Hume, and Kant; four days of parliamentary debate during the French Revolution; and branching comment trees on the discussion website Reddit. In the philosophical and parliamentary cases, the model parameters that describe this balance converge under coarse-graining to limit regions that demonstrate the emergence of large-scale structure, a result which is robust to translation between languages. Meanwhile, we find that the political forum we consider on Reddit exhibits a debate-like pattern, while communities dedicated to the discussion of science and news show much less temporal order, and may make use of the emergent, tree-like topology of comment replies to structure their epistemic explorations. Our model allows us to quantify the ways in which social technologies such as parliamentary procedures and online commenting systems shape the joint exploration of ideas.

</details>

<details>

<summary>2018-12-11 02:30:27 - Code-less Patching for Heap Vulnerabilities Using Targeted Calling Context Encoding</summary>

- *Qiang Zeng, Golam Kayas, Emil Mohammed, Lannan Luo, Xiaojiang Du, Junghwan Rhee*

- `1812.04191v1` - [abs](http://arxiv.org/abs/1812.04191v1) - [pdf](http://arxiv.org/pdf/1812.04191v1)

> Exploitation of heap vulnerabilities has been on the rise, leading to many devastating attacks. Conventional heap patch generation is a lengthy procedure, requiring intensive manual efforts. Worse, fresh patches tend to harm system dependability, hence deterring users from deploying them. We propose a heap patching system that simultaneously has the following prominent advantages: (1) generating patches without manual efforts; (2) installing patches without altering the code (so called code-less patching); (3) handling various heap vulnerability types; (4) imposing a very low overhead; and (5) no dependency on specific heap allocators. As a separate contribution, we propose targeted calling context encoding, which is a suite of algorithms for optimizing calling context encoding, an important technique with applications in many areas. The system properly combines heavyweight offline attack analysis with lightweight online defense generation, and provides a new countermeasure against heap attacks. The evaluation shows that the system is effective and efficient.

</details>

<details>

<summary>2018-12-11 04:00:24 - Android Malware Detection using Large-scale Network Representation Learning</summary>

- *Rui Zhu, Chenglin Li, Di Niu, Hongwen Zhang, Husam Kinawi*

- `1806.04847v2` - [abs](http://arxiv.org/abs/1806.04847v2) - [pdf](http://arxiv.org/pdf/1806.04847v2)

> With the growth of mobile devices and applications, the number of malicious software, or malware, is rapidly increasing in recent years, which calls for the development of advanced and effective malware detection approaches. Traditional methods such as signature-based ones cannot defend users from an increasing number of new types of malware or rapid malware behavior changes. In this paper, we propose a new Android malware detection approach based on deep learning and static analysis. Instead of using Application Programming Interfaces (APIs) only, we further analyze the source code of Android applications and create their higher-level graphical semantics, which makes it harder for attackers to evade detection. In particular, we use a call graph from method invocations in an Android application to represent the application, and further analyze method attributes to form a structured Program Representation Graph (PRG) with node attributes. Then, we use a graph convolutional network (GCN) to yield a graph representation of the application by embedding the entire graph into a dense vector, and classify whether it is a malware or not. To efficiently train such a graph convolutional network, we propose a batch training scheme that allows multiple heterogeneous graphs to be input as a batch. To the best of our knowledge, this is the first work to use graph representation learning for malware detection. We conduct extensive experiments from real-world sample collections and demonstrate that our developed system outperforms multiple other existing malware detection techniques.

</details>

<details>

<summary>2018-12-11 12:56:19 - Verified Low-Level Programming Embedded in F*</summary>

- *Jonathan Protzenko, Jean-Karim Zinzindohoué, Aseem Rastogi, Tahina Ramananandro, Peng Wang, Santiago Zanella-Béguelin, Antoine Delignat-Lavaud, Catalin Hritcu, Karthikeyan Bhargavan, Cédric Fournet, Nikhil Swamy*

- `1703.00053v6` - [abs](http://arxiv.org/abs/1703.00053v6) - [pdf](http://arxiv.org/pdf/1703.00053v6)

> We present Low*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low* is a shallow embedding of a small, sequential, well-behaved subset of C in F*, a dependently-typed variant of ML aimed at program verification. Departing from ML, Low* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model \`a la CompCert, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low* program is memory safe. In addition, the programmer can make full use of the verification power of F* to write high-level specifications and verify the functional correctness of Low* code using a combination of SMT automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code, specification and proof. We show that our Low* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.

</details>

<details>

<summary>2018-12-11 16:27:17 - ConceptNet 5.5: An Open Multilingual Graph of General Knowledge</summary>

- *Robyn Speer, Joshua Chin, Catherine Havasi*

- `1612.03975v2` - [abs](http://arxiv.org/abs/1612.03975v2) - [pdf](http://arxiv.org/pdf/1612.03975v2)

> Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings.   ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use.   When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.

</details>

<details>

<summary>2018-12-11 18:32:53 - ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge</summary>

- *Robyn Speer, Joanna Lowry-Duda*

- `1704.03560v2` - [abs](http://arxiv.org/abs/1704.03560v2) - [pdf](http://arxiv.org/pdf/1704.03560v2)

> This paper describes Luminoso's participation in SemEval 2017 Task 2, "Multilingual and Cross-lingual Semantic Word Similarity", with a system based on ConceptNet. ConceptNet is an open, multilingual knowledge graph that focuses on general knowledge that relates the meanings of words and phrases. Our submission to SemEval was an update of previous work that builds high-quality, multilingual word embeddings from a combination of ConceptNet and distributional semantics. Our system took first place in both subtasks. It ranked first in 4 out of 5 of the separate languages, and also ranked first in all 10 of the cross-lingual language pairs.

</details>

<details>

<summary>2018-12-11 18:51:42 - Luminoso at SemEval-2018 Task 10: Distinguishing Attributes Using Text Corpora and Relational Knowledge</summary>

- *Robyn Speer, Joanna Lowry-Duda*

- `1806.01733v2` - [abs](http://arxiv.org/abs/1806.01733v2) - [pdf](http://arxiv.org/pdf/1806.01733v2)

> Luminoso participated in the SemEval 2018 task on "Capturing Discriminative Attributes" with a system based on ConceptNet, an open knowledge graph focused on general knowledge. In this paper, we describe how we trained a linear classifier on a small number of semantically-informed features to achieve an $F_1$ score of 0.7368 on the task, close to the task's high score of 0.75.

</details>

<details>

<summary>2018-12-11 19:46:42 - Deep Semantic Segmentation in an AUV for Online Posidonia Oceanica Meadows identification</summary>

- *Miguel Martin-Abadal, Eric Guerrero-Font, Francisco Bonin-Font, Yolanda Gonzalez-Cid*

- `1807.03117v2` - [abs](http://arxiv.org/abs/1807.03117v2) - [pdf](http://arxiv.org/pdf/1807.03117v2)

> Recent studies have shown evidence of a significant decline of the Posidonia oceanica (P.O.) meadows on a global scale. The monitoring and mapping of these meadows are fundamental tools for measuring their status. We present an approach based on a deep neural network to automatically perform a high-precision semantic segmentation of P.O. meadows in sea-floor images, offering several improvements over the state of the art techniques. Our network demonstrates outstanding performance over diverse test sets, reaching a precision of 96.57% and an accuracy of 96.81%, surpassing the reliability of labelling the images manually. Also, the network is implemented in an Autonomous Underwater Vehicle (AUV), performing an online P.O. segmentation, which will be used to generate real-time semantic coverage maps.

</details>

<details>

<summary>2018-12-12 11:11:08 - SMT vs NMT: A Comparison over Hindi & Bengali Simple Sentences</summary>

- *Sainik Kumar Mahata, Soumil Mandal, Dipankar Das, Sivaji Bandyopadhyay*

- `1812.04898v1` - [abs](http://arxiv.org/abs/1812.04898v1) - [pdf](http://arxiv.org/pdf/1812.04898v1)

> In the present article, we identified the qualitative differences between Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) outputs. We have tried to answer two important questions: 1. Does NMT perform equivalently well with respect to SMT and 2. Does it add extra flavor in improving the quality of MT output by employing simple sentences as training units. In order to obtain insights, we have developed three core models viz., SMT model based on Moses toolkit, followed by character and word level NMT models. All of the systems use English-Hindi and English-Bengali language pairs containing simple sentences as well as sentences of other complexity. In order to preserve the translations semantics with respect to the target words of a sentence, we have employed soft-attention into our word level NMT model. We have further evaluated all the systems with respect to the scenarios where they succeed and fail. Finally, the quality of translation has been validated using BLEU and TER metrics along with manual parameters like fluency, adequacy etc. We observed that NMT outperforms SMT in case of simple sentences whereas SMT outperforms in case of all types of sentence.

</details>

<details>

<summary>2018-12-12 11:39:38 - On the potential for open-endedness in neural networks</summary>

- *Nicholas Guttenberg, Nathaniel Virgo, Alexandra Penn*

- `1812.04907v1` - [abs](http://arxiv.org/abs/1812.04907v1) - [pdf](http://arxiv.org/pdf/1812.04907v1)

> Natural evolution gives the impression of leading to an open-ended process of increasing diversity and complexity. If our goal is to produce such open-endedness artificially, this suggests an approach driven by evolutionary metaphor. On the other hand, techniques from machine learning and artificial intelligence are often considered too narrow to provide the sort of exploratory dynamics associated with evolution. In this paper, we hope to bridge that gap by reviewing common barriers to open-endedness in the evolution-inspired approach and how they are dealt with in the evolutionary case - collapse of diversity, saturation of complexity, and failure to form new kinds of individuality. We then show how these problems map onto similar issues in the machine learning approach, and discuss how the same insights and solutions which alleviated those barriers in evolutionary approaches can be ported over. At the same time, the form these issues take in the machine learning formulation suggests new ways to analyze and resolve barriers to open-endedness. Ultimately, we hope to inspire researchers to be able to interchangeably use evolutionary and gradient-descent-based machine learning methods to approach the design and creation of open-ended systems.

</details>

<details>

<summary>2018-12-12 16:11:31 - Temporal Analysis of Entity Relatedness and its Evolution using Wikipedia and DBpedia</summary>

- *Narumol Prangnawarat, John P. McCrae, Conor Hayes*

- `1812.05001v1` - [abs](http://arxiv.org/abs/1812.05001v1) - [pdf](http://arxiv.org/pdf/1812.05001v1)

> Many researchers have made use of the Wikipedia network for relatedness and similarity tasks. However, most approaches use only the most recent information and not historical changes in the network. We provide an analysis of entity relatedness using temporal graph-based approaches over different versions of the Wikipedia article link network and DBpedia, which is an open-source knowledge base extracted from Wikipedia. We consider creating the Wikipedia article link network as both a union and intersection of edges over multiple time points and present a novel variation of the Jaccard index to weight edges based on their transience. We evaluate our results against the KORE dataset, which was created in 2010, and show that using the 2010 Wikipedia article link network produces the strongest result, suggesting that semantic similarity is time sensitive. We then show that integrating multiple time frames in our methods can give a better overall similarity demonstrating that temporal evolution can have an important effect on entity relatedness.

</details>

<details>

<summary>2018-12-12 16:36:14 - Thwarting Adversarial Examples: An $L_0$-RobustSparse Fourier Transform</summary>

- *Mitali Bafna, Jack Murtagh, Nikhil Vyas*

- `1812.05013v1` - [abs](http://arxiv.org/abs/1812.05013v1) - [pdf](http://arxiv.org/pdf/1812.05013v1)

> We give a new algorithm for approximating the Discrete Fourier transform of an approximately sparse signal that has been corrupted by worst-case $L_0$ noise, namely a bounded number of coordinates of the signal have been corrupted arbitrarily. Our techniques generalize to a wide range of linear transformations that are used in data analysis such as the Discrete Cosine and Sine transforms, the Hadamard transform, and their high-dimensional analogs. We use our algorithm to successfully defend against well known $L_0$ adversaries in the setting of image classification. We give experimental results on the Jacobian-based Saliency Map Attack (JSMA) and the Carlini Wagner (CW) $L_0$ attack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch on the ImageNet dataset.

</details>

<details>

<summary>2018-12-13 01:41:49 - Secret Sharing with Binary Shares</summary>

- *Fuchun Lin, Mahdi Cheraghchi, Venkatesan Guruswami, Reihaneh Safavi-Naini, Huaxiong Wang*

- `1808.02974v3` - [abs](http://arxiv.org/abs/1808.02974v3) - [pdf](http://arxiv.org/pdf/1808.02974v3)

> Shamir's celebrated secret sharing scheme provides an efficient method for encoding a secret of arbitrary length $\ell$ among any $N \leq 2^\ell$ players such that for a threshold parameter $t$, (i) the knowledge of any $t$ shares does not reveal any information about the secret and, (ii) any choice of $t+1$ shares fully reveals the secret. It is known that any such threshold secret sharing scheme necessarily requires shares of length $\ell$, and in this sense Shamir's scheme is optimal. The more general notion of ramp schemes requires the reconstruction of secret from any $t+g$ shares, for a positive integer gap parameter $g$. Ramp secret sharing scheme necessarily requires shares of length $\ell/g$. Other than the bound related to secret length $\ell$, the share lengths of ramp schemes can not go below a quantity that depends only on the gap ratio $g/N$. In this work, we study secret sharing in the extremal case of bit-long shares and arbitrarily small gap ratio $g/N$, where standard ramp secret sharing becomes impossible. We show, however, that a slightly relaxed but equally effective notion of semantic security for the secret, and negligible reconstruction error probability, eliminate the impossibility. Moreover, we provide explicit constructions of such schemes. One of the consequences of our relaxation is that, unlike standard ramp schemes with perfect secrecy, adaptive and non-adaptive adversaries need different analysis and construction. For non-adaptive adversaries, we explicitly construct secret sharing schemes that provide secrecy against any $\tau$ fraction of observed shares, and reconstruction from any $\rho$ fraction of shares, for any choices of $0 \leq \tau < \rho \leq 1$. Our construction achieves secret length $N(\rho-\tau-o(1))$, which we show to be optimal. For adaptive adversaries, we construct explicit schemes attaining a secret length $\Omega(N(\rho-\tau))$.

</details>

<details>

<summary>2018-12-13 05:32:43 - TextBugger: Generating Adversarial Text Against Real-world Applications</summary>

- *Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, Ting Wang*

- `1812.05271v1` - [abs](http://arxiv.org/abs/1812.05271v1) - [pdf](http://arxiv.org/pdf/1812.05271v1)

> Deep Learning-based Text Understanding (DLTU) is the backbone technique behind various applications, including question answering, machine translation, and text classification. Despite its tremendous popularity, the security vulnerabilities of DLTU are still largely unknown, which is highly concerning given its increasing use in security-sensitive applications such as sentiment analysis and toxic content detection. In this paper, we show that DLTU is inherently vulnerable to adversarial text attacks, in which maliciously crafted texts trigger target DLTU systems and services to misbehave. Specifically, we present TextBugger, a general attack framework for generating adversarial texts. In contrast to prior works, TextBugger differs in significant ways: (i) effective -- it outperforms state-of-the-art attacks in terms of attack success rate; (ii) evasive -- it preserves the utility of benign text, with 94.9\% of the adversarial text correctly recognized by human readers; and (iii) efficient -- it generates adversarial text with computational complexity sub-linear to the text length. We empirically evaluate TextBugger on a set of real-world DLTU systems and services used for sentiment analysis and toxic content detection, demonstrating its effectiveness, evasiveness, and efficiency. For instance, TextBugger achieves 100\% success rate on the IMDB dataset based on Amazon AWS Comprehend within 4.61 seconds and preserves 97\% semantic similarity. We further discuss possible defense mechanisms to mitigate such attack and the adversary's potential countermeasures, which leads to promising directions for further research.

</details>

<details>

<summary>2018-12-13 13:13:23 - Abstractive Text Summarization by Incorporating Reader Comments</summary>

- *Shen Gao, Xiuying Chen, Piji Li, Zhaochun Ren, Lidong Bing, Dongyan Zhao, Rui Yan*

- `1812.05407v1` - [abs](http://arxiv.org/abs/1812.05407v1) - [pdf](http://arxiv.org/pdf/1812.05407v1)

> In neural abstractive summarization field, conventional sequence-to-sequence based models often suffer from summarizing the wrong aspect of the document with respect to the main aspect. To tackle this problem, we propose the task of reader-aware abstractive summary generation, which utilizes the reader comments to help the model produce better summary about the main aspect. Unlike traditional abstractive summarization task, reader-aware summarization confronts two main challenges: (1) Comments are informal and noisy; (2) jointly modeling the news document and the reader comments is challenging. To tackle the above challenges, we design an adversarial learning model named reader-aware summary generator (RASG), which consists of four components: (1) a sequence-to-sequence based summary generator; (2) a reader attention module capturing the reader focused aspects; (3) a supervisor modeling the semantic gap between the generated summary and reader focused aspects; (4) a goal tracker producing the goal for each generation step. The supervisor and the goal tacker are used to guide the training of our framework in an adversarial manner. Extensive experiments are conducted on our large-scale real-world text summarization dataset, and the results show that RASG achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations. The experimental results also demonstrate the effectiveness of each module in our framework. We release our large-scale dataset for further research.

</details>

<details>

<summary>2018-12-13 13:20:40 - Find a Reasonable Ending for Stories: Does Logic Relation Help the Story Cloze Test?</summary>

- *Mingyue Shang, Zhenxin Fu, Hongzhi Yin, Bo Tang, Dongyan Zhao, Rui Yan*

- `1812.05411v1` - [abs](http://arxiv.org/abs/1812.05411v1) - [pdf](http://arxiv.org/pdf/1812.05411v1)

> Natural language understanding is a challenging problem that covers a wide range of tasks. While previous methods generally train each task separately, we consider combining the cross-task features to enhance the task performance. In this paper, we incorporate the logic information with the help of the Natural Language Inference (NLI) task to the Story Cloze Test (SCT). Previous work on SCT considered various semantic information, such as sentiment and topic, but lack the logic information between sentences which is an essential element of stories. Thus we propose to extract the logic information during the course of the story to improve the understanding of the whole story. The logic information is modeled with the help of the NLI task. Experimental results prove the strength of the logic information.

</details>

<details>

<summary>2018-12-13 22:40:51 - The Language of Generalization</summary>

- *Michael Henry Tessler, Noah D. Goodman*

- `1608.02926v4` - [abs](http://arxiv.org/abs/1608.02926v4) - [pdf](http://arxiv.org/pdf/1608.02926v4)

> Language provides simple ways of communicating generalizable knowledge to each other (e.g., "Birds fly", "John hikes", "Fire makes smoke"). Though found in every language and emerging early in development, the language of generalization is philosophically puzzling and has resisted precise formalization. Here, we propose the first formal account of generalizations conveyed with language that makes quantitative predictions about human understanding. We test our model in three diverse domains: generalizations about categories (generic language), events (habitual language), and causes (causal language). The model explains the gradience in human endorsement through the interplay between a simple truth-conditional semantic theory and diverse beliefs about properties, formalized in a probabilistic model of language understanding. This work opens the door to understanding precisely how abstract knowledge is learned from language.

</details>

<details>

<summary>2018-12-13 22:50:04 - Multilayer Network Model of Movie Script</summary>

- *Youssef Mourchid, Benjamin Renoust, Hocine Cherifi, Mohammed El Hassouni*

- `1812.05718v1` - [abs](http://arxiv.org/abs/1812.05718v1) - [pdf](http://arxiv.org/pdf/1812.05718v1)

> Network models have been increasingly used in the past years to support summarization and analysis of narratives, such as famous TV series, books and news. Inspired by social network analysis, most of these models focus on the characters at play. The network model well captures all characters interactions, giving a broad picture of the narration's content. A few works went beyond by introducing additional semantic elements, always captured in a single layer network. In contrast, we introduce in this work a multilayer network model to capture more elements of the narration of a movie from its script: people, locations, and other semantic elements. This model enables new measures and insights on movies. We demonstrate this model on two very popular movies.

</details>

<details>

<summary>2018-12-14 13:54:34 - Sereum: Protecting Existing Smart Contracts Against Re-Entrancy Attacks</summary>

- *Michael Rodler, Wenting Li, Ghassan O. Karame, Lucas Davi*

- `1812.05934v1` - [abs](http://arxiv.org/abs/1812.05934v1) - [pdf](http://arxiv.org/pdf/1812.05934v1)

> Recently, a number of existing blockchain systems have witnessed major bugs and vulnerabilities within smart contracts. Although the literature features a number of proposals for securing smart contracts, these proposals mostly focus on proving the correctness or absence of a certain type of vulnerability within a contract, but cannot protect deployed (legacy) contracts from being exploited. In this paper, we address this problem in the context of re-entrancy exploits and propose a novel smart contract security technology, dubbed Sereum (Secure Ethereum), which protects existing, deployed contracts against re-entrancy attacks in a backwards compatible way based on run-time monitoring and validation. Sereum does neither require any modification nor any semantic knowledge of existing contracts. By means of implementation and evaluation using the Ethereum blockchain, we show that Sereum covers the actual execution flow of a smart contract to accurately detect and prevent attacks with a false positive rate as small as 0.06% and with negligible run-time overhead. As a by-product, we develop three advanced re-entrancy attacks to demonstrate the limitations of existing offline vulnerability analysis tools.

</details>

<details>

<summary>2018-12-16 02:44:20 - Efficient Super Resolution Using Binarized Neural Network</summary>

- *Yinglan Ma, Hongyu Xiong, Zhe Hu, Lizhuang Ma*

- `1812.06378v1` - [abs](http://arxiv.org/abs/1812.06378v1) - [pdf](http://arxiv.org/pdf/1812.06378v1)

> Deep convolutional neural networks (DCNNs) have recently demonstrated high-quality results in single-image super-resolution (SR). DCNNs often suffer from over-parametrization and large amounts of redundancy, which results in inefficient inference and high memory usage, preventing massive applications on mobile devices. As a way to significantly reduce model size and computation time, binarized neural network has only been shown to excel on semantic-level tasks such as image classification and recognition. However, little effort of network quantization has been spent on image enhancement tasks like SR, as network quantization is usually assumed to sacrifice pixel-level accuracy. In this work, we explore an network-binarization approach for SR tasks without sacrificing much reconstruction accuracy. To achieve this, we binarize the convolutional filters in only residual blocks, and adopt a learnable weight for each binary filter. We evaluate this idea on several state-of-the-art DCNN-based architectures, and show that binarized SR networks achieve comparable qualitative and quantitative results as their real-weight counterparts. Moreover, the proposed binarized strategy could help reduce model size by 80% when applying on SRResNet, and could potentially speed up inference by 5 times.

</details>

<details>

<summary>2018-12-16 21:50:13 - Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs</summary>

- *Fei Zuo, Xiaopeng Li, Patrick Young, Lannan Luo, Qiang Zeng, Zhexin Zhang*

- `1808.04706v2` - [abs](http://arxiv.org/abs/1808.04706v2) - [pdf](http://arxiv.org/pdf/1808.04706v2)

> Binary code analysis allows analyzing binary code without having access to the corresponding source code. A binary, after disassembly, is expressed in an assembly language. This inspires us to approach binary analysis by leveraging ideas and techniques from Natural Language Processing (NLP), a rich area focused on processing text of various natural languages. We notice that binary code analysis and NLP share a lot of analogical topics, such as semantics extraction, summarization, and classification. This work utilizes these ideas to address two important code similarity comparison problems. (I) Given a pair of basic blocks for different instruction set architectures (ISAs), determining whether their semantics is similar or not; and (II) given a piece of code of interest, determining if it is contained in another piece of assembly code for a different ISA. The solutions to these two problems have many applications, such as cross-architecture vulnerability discovery and code plagiarism detection. We implement a prototype system INNEREYE and perform a comprehensive evaluation. A comparison between our approach and existing approaches to Problem I shows that our system outperforms them in terms of accuracy, efficiency and scalability. And the case studies utilizing the system demonstrate that our solution to Problem II is effective. Moreover, this research showcases how to apply ideas and techniques from NLP to large-scale binary code analysis.

</details>

<details>

<summary>2018-12-17 03:52:11 - Siamese Networks for Semantic Pattern Similarity</summary>

- *Yassine Benajiba, Jin Sun, Yong Zhang, Longquan Jiang, Zhiliang Weng, Or Biran*

- `1812.06604v1` - [abs](http://arxiv.org/abs/1812.06604v1) - [pdf](http://arxiv.org/pdf/1812.06604v1)

> Semantic Pattern Similarity is an interesting, though not often encountered NLP task where two sentences are compared not by their specific meaning, but by their more abstract semantic pattern (e.g., preposition or frame). We utilize Siamese Networks to model this task, and show its usefulness in determining SQL patterns for unseen questions in a database-backed question answering scenario. Our approach achieves high accuracy and contains a built-in proxy for confidence, which can be used to keep precision arbitrarily high.

</details>

<details>

<summary>2018-12-17 11:28:05 - Not Using the Car to See the Sidewalk: Quantifying and Controlling the Effects of Context in Classification and Segmentation</summary>

- *Rakshith Shetty, Bernt Schiele, Mario Fritz*

- `1812.06707v1` - [abs](http://arxiv.org/abs/1812.06707v1) - [pdf](http://arxiv.org/pdf/1812.06707v1)

> Importance of visual context in scene understanding tasks is well recognized in the computer vision community. However, to what extent the computer vision models for image classification and semantic segmentation are dependent on the context to make their predictions is unclear. A model overly relying on context will fail when encountering objects in context distributions different from training data and hence it is important to identify these dependencies before we can deploy the models in the real-world. We propose a method to quantify the sensitivity of black-box vision models to visual context by editing images to remove selected objects and measuring the response of the target models. We apply this methodology on two tasks, image classification and semantic segmentation, and discover undesirable dependency between objects and context, for example that "sidewalk" segmentation relies heavily on "cars" being present in the image. We propose an object removal based data augmentation solution to mitigate this dependency and increase the robustness of classification and segmentation models to contextual variations. Our experiments show that the proposed data augmentation helps these models improve the performance in out-of-context scenarios, while preserving the performance on regular data.

</details>

<details>

<summary>2018-12-17 13:12:03 - Trichotomic Argumentation Representation</summary>

- *Merlin Göttlinger, Lutz Schröder*

- `1812.06745v1` - [abs](http://arxiv.org/abs/1812.06745v1) - [pdf](http://arxiv.org/pdf/1812.06745v1)

> The Aristotelian trichotomy distinguishes three aspects of argumentation: Logos, Ethos, and Pathos. Even rich argumentation representations like the Argument Interchange Format (AIF) are only concerned with capturing the Logos aspect. Inference Anchoring Theory (IAT) adds the possibility to represent ethical requirements on the illocutionary force edges linking locutions to illocutions, thereby allowing to capture some aspects of ethos. With the recent extensions AIF+ and Social Argument Interchange Format (S-AIF), which embed dialogue and speakers into the AIF argumentation representation, the basis for representing all three aspects identified by Aristotle was formed. In the present work, we develop the Trichotomic Argument Interchange Format (T-AIF), building on the idea from S-AIF of adding the speakers to the argumentation graph. We capture Logos in the usual known from AIF+, Ethos in form of weighted edges between actors representing trust, and Pathos via weighted edges from actors to illocutions representing their level of commitment to the propositions. This extended structured argumentation representation opens up new possibilities of defining semantic properties on this rich graph in order to characterize and profile the reasoning patterns of the participating actors.

</details>

<details>

<summary>2018-12-17 16:13:42 - BriarPatches: Pixel-Space Interventions for Inducing Demographic Parity</summary>

- *Alexey A. Gritsenko, Alex D'Amour, James Atwood, Yoni Halpern, D. Sculley*

- `1812.06869v1` - [abs](http://arxiv.org/abs/1812.06869v1) - [pdf](http://arxiv.org/pdf/1812.06869v1)

> We introduce the BriarPatch, a pixel-space intervention that obscures sensitive attributes from representations encoded in pre-trained classifiers. The patches encourage internal model representations not to encode sensitive information, which has the effect of pushing downstream predictors towards exhibiting demographic parity with respect to the sensitive information. The net result is that these BriarPatches provide an intervention mechanism available at user level, and complements prior research on fair representations that were previously only applicable by model developers and ML experts.

</details>

<details>

<summary>2018-12-17 16:15:13 - Analogy Search Engine: Finding Analogies in Cross-Domain Research Papers</summary>

- *Jieli Zhou, Yuntao Zhou, Yi Xu*

- `1812.06974v1` - [abs](http://arxiv.org/abs/1812.06974v1) - [pdf](http://arxiv.org/pdf/1812.06974v1)

> In recent years, with the rapid proliferation of research publications in the field of Artificial Intelligence, it is becoming increasingly difficult for researchers to effectively keep up with all the latest research in one's own domains. However, history has shown that scientific breakthroughs often come from collaborations of researchers from different domains. Traditional search algorithms like Lexical search, which look for literal matches or synonyms and variants of the query words, are not effective for discovering cross-domain research papers and meeting the needs of researchers in this age of information overflow. In this paper, we developed and tested an innovative semantic search engine, Analogy Search Engine (ASE), for 2000 AI research paper abstracts across domains like Language Technologies, Robotics, Machine Learning, Computational Biology, Human Computer Interactions, etc. ASE combines recent theories and methods from Computational Analogy and Natural Language Processing to go beyond keyword-based lexical search and discover the deeper analogical relationships among research paper abstracts. We experimentally show that ASE is capable of finding more interesting and useful research papers than baseline elasticsearch. Furthermore, we believe that the methods used in ASE go beyond academic paper and will benefit many other document search tasks.

</details>

<details>

<summary>2018-12-17 16:22:47 - Learning Common Representation from RGB and Depth Images</summary>

- *Giorgio Giannone, Boris Chidlovskii*

- `1812.06873v1` - [abs](http://arxiv.org/abs/1812.06873v1) - [pdf](http://arxiv.org/pdf/1812.06873v1)

> We propose a new deep learning architecture for the tasks of semantic segmentation and depth prediction from RGB-D images. We revise the state of art based on the RGB and depth feature fusion, where both modalities are assumed to be available at train and test time. We propose a new architecture where the feature fusion is replaced with a common deep representation. Combined with an encoder-decoder type of the network, the architecture can jointly learn models for semantic segmentation and depth estimation based on their common representation. This representation, inspired by multi-view learning, offers several important advantages, such as using one modality available at test time to reconstruct the missing modality. In the RGB-D case, this enables the cross-modality scenarios, such as using depth data for semantically segmentation and the RGB images for depth estimation. We demonstrate the effectiveness of the proposed network on two publicly available RGB-D datasets. The experimental results show that the proposed method works well in both semantic segmentation and depth estimation tasks.

</details>

<details>

<summary>2018-12-17 17:44:10 - CT-Wasm: Type-Driven Secure Cryptography for the Web Ecosystem</summary>

- *Conrad Watt, John Renner, Natalie Popescu, Sunjay Cauligi, Deian Stefan*

- `1808.01348v5` - [abs](http://arxiv.org/abs/1808.01348v5) - [pdf](http://arxiv.org/pdf/1808.01348v5)

> A significant amount of both client and server-side cryptography is implemented in JavaScript. Despite widespread concerns about its security, no other language has been able to match the convenience that comes from its ubiquitous support on the "web ecosystem" - the wide variety of technologies that collectively underpins the modern World Wide Web. With the new introduction of the WebAssembly bytecode language (Wasm) into the web ecosystem, we have a unique opportunity to advance a principled alternative to existing JavaScript cryptography use cases which does not compromise this convenience.   We present Constant-Time WebAssembly (CT-Wasm), a type-driven strict extension to WebAssembly which facilitates the verifiably secure implementation of cryptographic algorithms. CT-Wasm's type system ensures that code written in CT-Wasm is both information flow secure and resistant to timing side channel attacks; like base Wasm, these guarantees are verifiable in linear time. Building on an existing Wasm mechanization, we mechanize the full CT-Wasm specification, prove soundness of the extended type system, implement a verified type checker, and give several proofs of the language's security properties.   We provide two implementations of CT-Wasm: an OCaml reference interpreter and a native implementation for Node.js and Chromium that extends Google's V8 engine. We also implement a CT-Wasm to Wasm rewrite tool that allows developers to reap the benefits of CT-Wasm's type system today, while developing cryptographic algorithms for base Wasm environments. We evaluate the language, our implementations, and supporting tools by porting several cryptographic primitives - Salsa20, SHA-256, and TEA - and the full TweetNaCl library. We find that CT-Wasm is fast, expressive, and generates code that we experimentally measure to be constant-time.

</details>

<details>

<summary>2018-12-17 19:28:30 - Multi Instance Learning For Unbalanced Data</summary>

- *Mark Kozdoba, Edward Moroshko, Lior Shani, Takuya Takagi, Takashi Katoh, Shie Mannor, Koby Crammer*

- `1812.07010v1` - [abs](http://arxiv.org/abs/1812.07010v1) - [pdf](http://arxiv.org/pdf/1812.07010v1)

> In the context of Multi Instance Learning, we analyze the Single Instance (SI) learning objective. We show that when the data is unbalanced and the family of classifiers is sufficiently rich, the SI method is a useful learning algorithm. In particular, we show that larger data imbalance, a quality that is typically perceived as negative, in fact implies a better resilience of the algorithm to the statistical dependencies of the objects in bags. In addition, our results shed new light on some known issues with the SI method in the setting of linear classifiers, and we show that these issues are significantly less likely to occur in the setting of neural networks. We demonstrate our results on a synthetic dataset, and on the COCO dataset for the problem of patch classification with weak image level labels derived from captions.

</details>

<details>

<summary>2018-12-17 19:41:37 - From FiLM to Video: Multi-turn Question Answering with Multi-modal Context</summary>

- *Dat Tien Nguyen, Shikhar Sharma, Hannes Schulz, Layla El Asri*

- `1812.07023v1` - [abs](http://arxiv.org/abs/1812.07023v1) - [pdf](http://arxiv.org/pdf/1812.07023v1)

> Understanding audio-visual content and the ability to have an informative conversation about it have both been challenging areas for intelligent systems. The Audio Visual Scene-aware Dialog (AVSD) challenge, organized as a track of the Dialog System Technology Challenge 7 (DSTC7), proposes a combined task, where a system has to answer questions pertaining to a video given a dialogue with previous question-answer pairs and the video itself. We propose for this task a hierarchical encoder-decoder model which computes a multi-modal embedding of the dialogue context. It first embeds the dialogue history using two LSTMs. We extract video and audio frames at regular intervals and compute semantic features using pre-trained I3D and VGGish models, respectively. Before summarizing both modalities into fixed-length vectors using LSTMs, we use FiLM blocks to condition them on the embeddings of the current question, which allows us to reduce the dimensionality considerably. Finally, we use an LSTM decoder that we train with scheduled sampling and evaluate using beam search. Compared to the modality-fusing baseline model released by the AVSD challenge organizers, our model achieves a relative improvements of more than 16%, scoring 0.36 BLEU-4 and more than 33%, scoring 0.997 CIDEr.

</details>

<details>

<summary>2018-12-17 22:30:45 - Rethinking Epistemic Logic with Belief Bases</summary>

- *Emiliano Lorini*

- `1812.07079v1` - [abs](http://arxiv.org/abs/1812.07079v1) - [pdf](http://arxiv.org/pdf/1812.07079v1)

> We introduce a new semantics for a logic of explicit and implicit beliefs based on the concept of multi-agent belief base. Differently from existing Kripke-style semantics for epistemic logic in which the notions of possible world and doxastic/epistemic alternative are primitive, in our semantics they are non-primitive but are defined from the concept of belief base. We provide a complete axiomatization and prove decidability for our logic via a finite model argument. We also provide a polynomial embedding of our logic into Fagin & Halpern's logic of general awareness and establish a complexity result for our logic via the embedding.

</details>

<details>

<summary>2018-12-18 02:06:46 - Globalness Detection in Online Social Network</summary>

- *Yu-Cheng Lin, Chun-Ming Lai, S. Felix Wu, George A. Barnett*

- `1812.07135v1` - [abs](http://arxiv.org/abs/1812.07135v1) - [pdf](http://arxiv.org/pdf/1812.07135v1)

> Classification problems have made significant progress due to the maturity of artificial intelligence (AI). However, differentiating items from categories without noticeable boundaries is still a huge challenge for machines -- which is also crucial for machines to be intelligent.   In order to study the fuzzy concept on classification, we define and propose a globalness detection with the four-stage operational flow. We then demonstrate our framework on Facebook public pages inter-like graph with their geo-location. Our prediction algorithm achieves high precision (89%) and recall (88%) of local pages. We evaluate the results on both states and countries level, finding that the global node ratios are relatively high in those states (NY, CA) having large and international cities. Several global nodes examples have also been shown and studied in this paper.   It is our hope that our results unveil the perfect value from every classification problem and provide a better understanding of global and local nodes in Online Social Networks (OSNs).

</details>

<details>

<summary>2018-12-18 05:49:36 - Mining Interpretable AOG Representations from Convolutional Networks via Active Question Answering</summary>

- *Quanshi Zhang, Ruiming Cao, Ying Nian Wu, Song-Chun Zhu*

- `1812.07996v1` - [abs](http://arxiv.org/abs/1812.07996v1) - [pdf](http://arxiv.org/pdf/1812.07996v1)

> In this paper, we present a method to mine object-part patterns from conv-layers of a pre-trained convolutional neural network (CNN). The mined object-part patterns are organized by an And-Or graph (AOG). This interpretable AOG representation consists of a four-layer semantic hierarchy, i.e., semantic parts, part templates, latent patterns, and neural units. The AOG associates each object part with certain neural units in feature maps of conv-layers. The AOG is constructed in a weakly-supervised manner, i.e., very few annotations (e.g., 3-20) of object parts are used to guide the learning of AOGs. We develop a question-answering (QA) method that uses active human-computer communications to mine patterns from a pre-trained CNN, in order to incrementally explain more features in conv-layers. During the learning process, our QA method uses the current AOG for part localization. The QA method actively identifies objects, whose feature maps cannot be explained by the AOG. Then, our method asks people to annotate parts on the unexplained objects, and uses answers to discover CNN patterns corresponding to the newly labeled parts. In this way, our method gradually grows new branches and refines existing branches on the AOG to semanticize CNN representations. In experiments, our method exhibited a high learning efficiency. Our method used about 1/6-1/3 of the part annotations for training, but achieved similar or better part-localization performance than fast-RCNN methods.

</details>

<details>

<summary>2018-12-18 07:04:50 - Generating Distractors for Reading Comprehension Questions from Real Examinations</summary>

- *Yifan Gao, Lidong Bing, Piji Li, Irwin King, Michael R. Lyu*

- `1809.02768v2` - [abs](http://arxiv.org/abs/1809.02768v2) - [pdf](http://arxiv.org/pdf/1809.02768v2)

> We investigate the task of distractor generation for multiple choice reading comprehension questions from examinations. In contrast to all previous works, we do not aim at preparing words or short phrases distractors, instead, we endeavor to generate longer and semantic-rich distractors which are closer to distractors in real reading comprehension from examinations. Taking a reading comprehension article, a pair of question and its correct option as input, our goal is to generate several distractors which are somehow related to the answer, consistent with the semantic context of the question and have some trace in the article. We propose a hierarchical encoder-decoder framework with static and dynamic attention mechanisms to tackle this task. Specifically, the dynamic attention can combine sentence-level and word-level attention varying at each recurrent time step to generate a more readable sequence. The static attention is to modulate the dynamic attention not to focus on question irrelevant sentences or sentences which contribute to the correct option. Our proposed framework outperforms several strong baselines on the first prepared distractor generation dataset of real reading comprehension questions. For human evaluation, compared with those distractors generated by baselines, our generated distractors are more functional to confuse the annotators.

</details>

<details>

<summary>2018-12-18 15:02:26 - Impact of Tool Support in Patch Construction</summary>

- *Anil Koyuncu, Tegawendé F. Bissyandé, Dongsun Kim, Jacques Klein, Martin Monperrus, Yves Le Traon*

- `1812.07416v1` - [abs](http://arxiv.org/abs/1812.07416v1) - [pdf](http://arxiv.org/pdf/1812.07416v1)

> In this work, we investigate the practice of patch construction in the Linux kernel development, focusing on the differences between three patching processes: (1) patches crafted entirely manually to fix bugs, (2) those that are derived from warnings of bug detection tools, and (3) those that are automatically generated based on fix patterns. With this study, we provide to the research community concrete insights on the practice of patching as well as how the development community is currently embracing research and commercial patching tools to improve productivity in repair. The result of our study shows that tool-supported patches are increasingly adopted by the developer community while manually-written patches are accepted more quickly. Patch application tools enable developers to remain committed to contributing patches to the code base. Our findings also include that, in actual development processes, patches generally implement several change operations spread over the code, even for patches fixing warnings by bug detection tools. Finally, this study has shown that there is an opportunity to directly leverage the output of bug detection tools to readily generate patches that are appropriate for fixing the problem, and that are consistent with manually-written patches.

</details>

<details>

<summary>2018-12-19 00:41:53 - Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization</summary>

- *German I. Parisi, Jun Tani, Cornelius Weber, Stefan Wermter*

- `1805.10966v4` - [abs](http://arxiv.org/abs/1805.10966v4) - [pdf](http://arxiv.org/pdf/1805.10966v4)

> Artificial autonomous agents and robots interacting in complex environments are required to continually acquire and fine-tune knowledge over sustained periods of time. The ability to learn from continuous streams of information is referred to as lifelong learning and represents a long-standing challenge for neural network models due to catastrophic forgetting. Computational models of lifelong learning typically alleviate catastrophic forgetting in experimental scenarios with given datasets of static images and limited complexity, thereby differing significantly from the conditions artificial agents are exposed to. In more natural settings, sequential information may become progressively available over time and access to previous experience may be restricted. In this paper, we propose a dual-memory self-organizing architecture for lifelong learning scenarios. The architecture comprises two growing recurrent networks with the complementary tasks of learning object instances (episodic memory) and categories (semantic memory). Both growing networks can expand in response to novel sensory experience: the episodic memory learns fine-grained spatiotemporal representations of object instances in an unsupervised fashion while the semantic memory uses task-relevant signals to regulate structural plasticity levels and develop more compact representations from episodic experience. For the consolidation of knowledge in the absence of external sensory input, the episodic memory periodically replays trajectories of neural reactivations. We evaluate the proposed model on the CORe50 benchmark dataset for continuous object recognition, showing that we significantly outperform current methods of lifelong learning in three different incremental learning scenarios

</details>

<details>

<summary>2018-12-19 08:49:50 - Fast and Accurate 3D Medical Image Segmentation with Data-swapping Method</summary>

- *Haruki Imai, Samuel Matzek, Tung D. Le, Yasushi Negishi, Kiyokuni Kawachiya*

- `1812.07816v1` - [abs](http://arxiv.org/abs/1812.07816v1) - [pdf](http://arxiv.org/pdf/1812.07816v1)

> Deep neural network models used for medical image segmentation are large because they are trained with high-resolution three-dimensional (3D) images. Graphics processing units (GPUs) are widely used to accelerate the trainings. However, the memory on a GPU is not large enough to train the models. A popular approach to tackling this problem is patch-based method, which divides a large image into small patches and trains the models with these small patches. However, this method would degrade the segmentation quality if a target object spans multiple patches. In this paper, we propose a novel approach for 3D medical image segmentation that utilizes the data-swapping, which swaps out intermediate data from GPU memory to CPU memory to enlarge the effective GPU memory size, for training high-resolution 3D medical images without patching. We carefully tuned parameters in the data-swapping method to obtain the best training performance for 3D U-Net, a widely used deep neural network model for medical image segmentation. We applied our tuning to train 3D U-Net with full-size images of 192 x 192 x 192 voxels in brain tumor dataset. As a result, communication overhead, which is the most important issue, was reduced by 17.1%. Compared with the patch-based method for patches of 128 x 128 x 128 voxels, our training for full-size images achieved improvement on the mean Dice score by 4.48% and 5.32 % for detecting whole tumor sub-region and tumor core sub-region, respectively. The total training time was reduced from 164 hours to 47 hours, resulting in 3.53 times of acceleration.

</details>

<details>

<summary>2018-12-19 15:20:39 - COSMO: Contextualized Scene Modeling with Boltzmann Machines</summary>

- *Ilker Bozcan, Sinan Kalkan*

- `1807.00511v2` - [abs](http://arxiv.org/abs/1807.00511v2) - [pdf](http://arxiv.org/pdf/1807.00511v2)

> Scene modeling is very crucial for robots that need to perceive, reason about and manipulate the objects in their environments. In this paper, we adapt and extend Boltzmann Machines (BMs) for contextualized scene modeling. Although there are many models on the subject, ours is the first to bring together objects, relations, and affordances in a highly-capable generative model. For this end, we introduce a hybrid version of BMs where relations and affordances are introduced with shared, tri-way connections into the model. Moreover, we contribute a dataset for relation estimation and modeling studies. We evaluate our method in comparison with several baselines on object estimation, out-of-context object detection, relation estimation, and affordance estimation tasks. Moreover, to illustrate the generative capability of the model, we show several example scenes that the model is able to generate.

</details>

<details>

<summary>2018-12-19 15:54:41 - Semantic Frame Parsing for Information Extraction : the CALOR corpus</summary>

- *Gabriel Marzinotto, Jeremy Auguste, Frederic Bechet, Géraldine Damnati, Alexis Nasr*

- `1812.08039v1` - [abs](http://arxiv.org/abs/1812.08039v1) - [pdf](http://arxiv.org/pdf/1812.08039v1)

> This paper presents a publicly available corpus of French encyclopedic history texts annotated according to the Berkeley FrameNet formalism. The main difference in our approach compared to previous works on semantic parsing with FrameNet is that we are not interested here in full text parsing but rather on partial parsing. The goal is to select from the FrameNet resources the minimal set of frames that are going to be useful for the applicative framework targeted, in our case Information Extraction from encyclopedic documents. Such an approach leverages the manual annotation of larger corpora than those obtained through full text parsing and therefore opens the door to alternative methods for Frame parsing than those used so far on the FrameNet 1.5 benchmark corpus. The approaches compared in this study rely on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The models compared are CRFs and multitasks bi-LSTMs.

</details>

<details>

<summary>2018-12-19 15:59:31 - FrameNet automatic analysis : a study on a French corpus of encyclopedic texts</summary>

- *Gabriel Marzinotto, Géraldine Damnati, Frederic Bechet*

- `1812.08044v1` - [abs](http://arxiv.org/abs/1812.08044v1) - [pdf](http://arxiv.org/pdf/1812.08044v1)

> This article presents an automatic frame analysis system evaluated on a corpus of French encyclopedic history texts annotated according to the FrameNet formalism. The chosen approach relies on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The purpose of this study is to analyze the task complexity from several dimensions. Hence we provide detailed evaluations from a feature selection point of view and from the data point of view.

</details>

<details>

<summary>2018-12-20 01:07:04 - Recommendation System based on Semantic Scholar Mining and Topic modeling: A behavioral analysis of researchers from six conferences</summary>

- *Hamed Jelodar, Yongli Wang, Mahdi Rabbani, Ru-xin Zhao, Seyedvalyallah Ayobi, Peng Hu, Isma Masood*

- `1812.08304v1` - [abs](http://arxiv.org/abs/1812.08304v1) - [pdf](http://arxiv.org/pdf/1812.08304v1)

> Recommendation systems have an important place to help online users in the internet society. Recommendation Systems in computer science are of very practical use these days in various aspects of the Internet portals, such as social networks, and library websites. There are several approaches to implement recommendation systems, Latent Dirichlet Allocation (LDA) is one the popular techniques in Topic Modeling. Recently, researchers have proposed many approaches based on Recommendation Systems and LDA. According to importance of the subject, in this paper we discover the trends of the topics and find relationship between LDA topics and Scholar-Context-documents. In fact, We apply probabilistic topic modeling based on Gibbs sampling algorithms for a semantic mining from six conference publications in computer science from DBLP dataset. According to our experimental results, our semantic framework can be effective to help organizations to better organize these conferences and cover future research topics.

</details>

<details>

<summary>2018-12-20 02:25:15 - Learning Concept Embeddings for Efficient Bag-of-Concepts Densification</summary>

- *Walid Shalaby, Wlodek Zadrozny*

- `1702.03342v2` - [abs](http://arxiv.org/abs/1702.03342v2) - [pdf](http://arxiv.org/pdf/1702.03342v2)

> Explicit concept space models have proven efficacy for text representation in many natural language and text mining applications. The idea is to embed textual structures into a semantic space of concepts which captures the main ideas, objects, and the characteristics of these structures. The so called Bag of Concepts (BoC) representation suffers from data sparsity causing low similarity scores between similar texts due to low concept overlap. To address this problem, we propose two neural embedding models to learn continuous concept vectors. Once they are learned, we propose an efficient vector aggregation method to generate fully continuous BoC representations. We evaluate our concept embedding models on three tasks: 1) measuring entity semantic relatedness and ranking where we achieve 1.6% improvement in correlation scores, 2) dataless concept categorization where we achieve state-of-the-art performance and reduce the categorization error rate by more than 5% compared to five prior word and entity embedding models, and 3) dataless document classification where our models outperform the sparse BoC representations. In addition, by exploiting our efficient linear time vector aggregation method, we achieve better accuracy scores with much less concept dimensions compared to previous BoC densification methods which operate in polynomial time and require hundreds of dimensions in the BoC representation.

</details>

<details>

<summary>2018-12-20 05:30:17 - Interactive Naming for Explaining Deep Neural Networks: A Formative Study</summary>

- *Mandana Hamidi-Haines, Zhongang Qi, Alan Fern, Fuxin Li, Prasad Tadepalli*

- `1812.07150v2` - [abs](http://arxiv.org/abs/1812.07150v2) - [pdf](http://arxiv.org/pdf/1812.07150v2)

> We consider the problem of explaining the decisions of deep neural networks for image recognition in terms of human-recognizable visual concepts. In particular, given a test set of images, we aim to explain each classification in terms of a small number of image regions, or activation maps, which have been associated with semantic concepts by a human annotator. This allows for generating summary views of the typical reasons for classifications, which can help build trust in a classifier and/or identify example types for which the classifier may not be trusted. For this purpose, we developed a user interface for "interactive naming," which allows a human annotator to manually cluster significant activation maps in a test set into meaningful groups called "visual concepts". The main contribution of this paper is a systematic study of the visual concepts produced by five human annotators using the interactive naming interface. In particular, we consider the adequacy of the concepts for explaining the classification of test-set images, correspondence of the concepts to activations of individual neurons, and the inter-annotator agreement of visual concepts. We find that a large fraction of the activation maps have recognizable visual concepts, and that there is significant agreement between the different annotators about their denotations. Our work is an exploratory study of the interplay between machine learning and human recognition mediated by visualizations of the results of learning.

</details>

<details>

<summary>2018-12-20 11:36:30 - Automated CFI Policy Assessment with Reckon</summary>

- *Paul Muntean*

- `1812.08496v1` - [abs](http://arxiv.org/abs/1812.08496v1) - [pdf](http://arxiv.org/pdf/1812.08496v1)

> Protecting programs against control-flow hijacking attacks recently has become an arms race between defenders and attackers. While certain defenses, e.g., \textit{Control Flow Integrity} (CFI), restrict the targets of indirect control-flow transfers through static and dynamic analysis, attackers could search the program for available gadgets that fall into the legitimate target sets to bypass the defenses. There are several tools helping both attackers in developing exploits and analysts in strengthening their defenses. Yet, these tools fail to adequately (1) model the deployed defenses, (2) compare them in a head-to-head way, and (3) use program semantic information to help craft the attack and the countermeasures.   Control Flow Integrity (CFI) has proved to be one of the promising defenses against control flow hijacks and tons of efforts have been made to improve CFI in various ways in the past decade. However, there is a lack of a systematic assessment of the existing CFI defenses. In this paper, we present Reckon, a static source code analysis tool for assessing state-of-the-art static CFI defenses, by first precisely modeling them and then evaluating them in a unified framework. Reckon helps determine the level of security offered by different CFI defenses, and find usable code gadgets even after the CFI defenses were applied, thus providing an important step towards successful exploits and stronger defenses. We have used Reckon to assess eight state-of-the-art static CFI defenses on real-world programs such as Google's Chrome and Apache Httpd. Reckon provides precise measurements of the residual attack surfaces, and accordingly ranks CFI policies against each other. It also successfully paves the way to construct code reuse attacks and to eliminate the remaining attack surface, by disclosing calltargets under one of the most restrictive CFI defenses.

</details>

<details>

<summary>2018-12-20 22:53:33 - Variational Cross-domain Natural Language Generation for Spoken Dialogue Systems</summary>

- *Bo-Hsiang Tseng, Florian Kreyssig, Pawel Budzianowski, Inigo Casanueva, Yen-Chen Wu, Stefan Ultes, Milica Gasic*

- `1812.08879v1` - [abs](http://arxiv.org/abs/1812.08879v1) - [pdf](http://arxiv.org/pdf/1812.08879v1)

> Cross-domain natural language generation (NLG) is still a difficult task within spoken dialogue modelling. Given a semantic representation provided by the dialogue manager, the language generator should generate sentences that convey desired information. Traditional template-based generators can produce sentences with all necessary information, but these sentences are not sufficiently diverse. With RNN-based models, the diversity of the generated sentences can be high, however, in the process some information is lost. In this work, we improve an RNN-based generator by considering latent information at the sentence level during generation using the conditional variational autoencoder architecture. We demonstrate that our model outperforms the original RNN-based generator, while yielding highly diverse sentences. In addition, our model performs better when the training data is limited.

</details>

<details>

<summary>2018-12-21 05:02:02 - Enhancing Person-Job Fit for Talent Recruitment: An Ability-aware Neural Network Approach</summary>

- *Chuan Qin, Hengshu Zhu, Tong Xu, Chen Zhu, Liang Jiang, Enhong Chen, Hui Xiong*

- `1812.08947v1` - [abs](http://arxiv.org/abs/1812.08947v1) - [pdf](http://arxiv.org/pdf/1812.08947v1)

> The wide spread use of online recruitment services has led to information explosion in the job market. As a result, the recruiters have to seek the intelligent ways for Person Job Fit, which is the bridge for adapting the right job seekers to the right positions. Existing studies on Person Job Fit have a focus on measuring the matching degree between the talent qualification and the job requirements mainly based on the manual inspection of human resource experts despite of the subjective, incomplete, and inefficient nature of the human judgement. To this end, in this paper, we propose a novel end to end Ability aware Person Job Fit Neural Network model, which has a goal of reducing the dependence on manual labour and can provide better interpretation about the fitting results. The key idea is to exploit the rich information available at abundant historical job application data. Specifically, we propose a word level semantic representation for both job requirements and job seekers' experiences based on Recurrent Neural Network. Along this line, four hierarchical ability aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as measuring the different contribution of each job experience to a specific ability requirement. Finally, extensive experiments on a large scale real world data set clearly validate the effectiveness and interpretability of the APJFNN framework compared with several baselines.

</details>

<details>

<summary>2018-12-21 15:30:17 - Sources of Complexity in Semantic Frame Parsing for Information Extraction</summary>

- *Gabriel Marzinotto, Frédéric Béchet, Géraldine Damnati, Alexis Nasr*

- `1812.09193v1` - [abs](http://arxiv.org/abs/1812.09193v1) - [pdf](http://arxiv.org/pdf/1812.09193v1)

> This paper describes a Semantic Frame parsing System based on sequence labeling methods, precisely BiLSTM models with highway connections, for performing information extraction on a corpus of French encyclopedic history texts annotated according to the Berkeley FrameNet formalism. The approach proposed in this study relies on an integrated sequence labeling model which jointly optimizes frame identification and semantic role segmentation and identification. The purpose of this study is to analyze the task complexity, to highlight the factors that make Semantic Frame parsing a difficult task and to provide detailed evaluations of the performance on different types of frames and sentences.

</details>

<details>

<summary>2018-12-21 15:44:59 - Deep Graph Infomax</summary>

- *Petar Veličković, William Fedus, William L. Hamilton, Pietro Liò, Yoshua Bengio, R Devon Hjelm*

- `1809.10341v2` - [abs](http://arxiv.org/abs/1809.10341v2) - [pdf](http://arxiv.org/pdf/1809.10341v2)

> We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.

</details>

<details>

<summary>2018-12-21 19:00:54 - Attention Based Natural Language Grounding by Navigating Virtual Environment</summary>

- *Akilesh B, Abhishek Sinha, Mausoom Sarkar, Balaji Krishnamurthy*

- `1804.08454v2` - [abs](http://arxiv.org/abs/1804.08454v2) - [pdf](http://arxiv.org/pdf/1804.08454v2)

> In this work, we focus on the problem of grounding language by training an agent to follow a set of natural language instructions and navigate to a target object in an environment. The agent receives visual information through raw pixels and a natural language instruction telling what task needs to be achieved and is trained in an end-to-end way. We develop an attention mechanism for multi-modal fusion of visual and textual modalities that allows the agent to learn to complete the task and achieve language grounding. Our experimental results show that our attention mechanism outperforms the existing multi-modal fusion mechanisms proposed for both 2D and 3D environments in order to solve the above-mentioned task in terms of both speed and success rate. We show that the learnt textual representations are semantically meaningful as they follow vector arithmetic in the embedding space. The effectiveness of our attention approach over the contemporary fusion mechanisms is also highlighted from the textual embeddings learnt by the different approaches. We also show that our model generalizes effectively to unseen scenarios and exhibit zero-shot generalization capabilities both in 2D and 3D environments. The code for our 2D environment as well as the models that we developed for both 2D and 3D are available at https://github.com/rl-lang-grounding/rl-lang-ground.

</details>

<details>

<summary>2018-12-22 07:36:49 - Literature Review: Smart Contract Semantics</summary>

- *Varun Mathur*

- `1901.01815v1` - [abs](http://arxiv.org/abs/1901.01815v1) - [pdf](http://arxiv.org/pdf/1901.01815v1)

> This review presents and evaluates various formalisms for the purpose of modelling the semantics of financial derivatives contracts. The formalism proposed by Lee is selected as the best candidate among those initially reviewed. Further examination and evaluation of this formalism is done.

</details>

<details>

<summary>2018-12-22 19:13:26 - Translating Neuralese</summary>

- *Jacob Andreas, Anca Dragan, Dan Klein*

- `1704.06960v5` - [abs](http://arxiv.org/abs/1704.06960v5) - [pdf](http://arxiv.org/pdf/1704.06960v5)

> Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents' messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.

</details>

<details>

<summary>2018-12-23 03:35:56 - Improving Context-Aware Semantic Relationships in Sparse Mobile Datasets</summary>

- *Peter Hansel, Nik Marda, William Yin*

- `1812.09650v1` - [abs](http://arxiv.org/abs/1812.09650v1) - [pdf](http://arxiv.org/pdf/1812.09650v1)

> Traditional semantic similarity models often fail to encapsulate the external context in which texts are situated. However, textual datasets generated on mobile platforms can help us build a truer representation of semantic similarity by introducing multimodal data. This is especially important in sparse datasets, making solely text-driven interpretation of context more difficult. In this paper, we develop new algorithms for building external features into sentence embeddings and semantic similarity scores. Then, we test them on embedding spaces on data from Twitter, using each tweet's time and geolocation to better understand its context. Ultimately, we show that applying PCA with eight components to the embedding space and appending multimodal features yields the best outcomes. This yields a considerable improvement over pure text-based approaches for discovering similar tweets. Our results suggest that our new algorithm can help improve semantic understanding in various settings.

</details>

<details>

<summary>2018-12-23 03:44:03 - A Cross-Architecture Instruction Embedding Model for Natural Language Processing-Inspired Binary Code Analysis</summary>

- *Kimberly Redmond, Lannan Luo, Qiang Zeng*

- `1812.09652v1` - [abs](http://arxiv.org/abs/1812.09652v1) - [pdf](http://arxiv.org/pdf/1812.09652v1)

> Given a closed-source program, such as most of proprietary software and viruses, binary code analysis is indispensable for many tasks, such as code plagiarism detection and malware analysis. Today, source code is very often compiled for various architectures, making cross-architecture binary code analysis increasingly important. A binary, after being disassembled, is expressed in an assembly languages. Thus, recent work starts exploring Natural Language Processing (NLP) inspired binary code analysis. In NLP, words are usually represented in high-dimensional vectors (i.e., embeddings) to facilitate further processing, which is one of the most common and critical steps in many NLP tasks. We regard instructions as words in NLP-inspired binary code analysis, and aim to represent instructions as embeddings as well.   To facilitate cross-architecture binary code analysis, our goal is that similar instructions, regardless of their architectures, have embeddings close to each other. To this end, we propose a joint learning approach to generating instruction embeddings that capture not only the semantics of instructions within an architecture, but also their semantic relationships across architectures. To the best of our knowledge, this is the first work on building cross-architecture instruction embedding model. As a showcase, we apply the model to resolving one of the most fundamental problems for binary code similarity comparison---semantics-based basic block comparison, and the solution outperforms the code statistics based approach. It demonstrates that it is promising to apply the model to other cross-architecture binary code analysis tasks.

</details>

<details>

<summary>2018-12-24 12:05:42 - PatientEG Dataset: Bringing Event Graph Model with Temporal Relations to Electronic Medical Records</summary>

- *Xuli Liu, Jihao Jin, Qi Wang, Tong Ruan, Yangming Zhou, Daqi Gao, Yichao Yin*

- `1812.09905v1` - [abs](http://arxiv.org/abs/1812.09905v1) - [pdf](http://arxiv.org/pdf/1812.09905v1)

> Medical activities, such as diagnoses, medicine treatments, and laboratory tests, as well as temporal relations between these activities are the basic concepts in clinical research. However, existing relational data model on electronic medical records (EMRs) lacks explicit and accurate semantic definitions of these concepts. It leads to the inconvenience of query construction and the inefficiency of query execution where multi-table join queries are frequently required. In this paper, we propose a patient event graph (PatientEG) model to capture the characteristics of EMRs. We respectively define five types of medical entities, five types of medical events and five types of temporal relations. Based on the proposed model, we also construct a PatientEG dataset with 191,294 events, 3,429 distinct entities, and 545,993 temporal relations using EMRs from Shanghai Shuguang hospital. To help to normalize entity values which contain synonyms, hyponymies, and abbreviations, we link them with the Chinese biomedical knowledge graph. With the help of PatientEG dataset, we are able to conveniently perform complex queries for clinical research such as auxiliary diagnosis and therapeutic effectiveness analysis. In addition, we provide a SPARQL endpoint to access PatientEG dataset and the dataset is also publicly available online. Also, we list several illustrative SPARQL queries on our website.

</details>

<details>

<summary>2018-12-24 13:30:40 - Divide et Impera: MemoryRanger Runs Drivers in Isolated Kernel Spaces</summary>

- *Igor Korkin*

- `1812.09920v1` - [abs](http://arxiv.org/abs/1812.09920v1) - [pdf](http://arxiv.org/pdf/1812.09920v1)

> One of the main issues in the OS security is to provide trusted code execution in an untrusted environment. During executing, kernel-mode drivers allocate and process memory data: OS internal structures, users private information, and sensitive data of third-party drivers. All this data and the drivers code can be tampered with by kernel-mode malware. Microsoft security experts integrated new features to fill this gap, but they are not enough: allocated data can be stolen and patched and the drivers code can be dumped without any security reaction. The proposed hypervisor-based system (MemoryRanger) tackles this issue by executing drivers in separate kernel enclaves with specific memory attributes. MemoryRanger protects code and data using Intel VT-x and EPT features with low performance degradation on Windows 10 x64.

</details>

<details>

<summary>2018-12-25 04:08:27 - A Novel Framework for Robustness Analysis of Visual QA Models</summary>

- *Jia-Hong Huang, Cuong Duc Dao, Modar Alfadly, Bernard Ghanem*

- `1711.06232v3` - [abs](http://arxiv.org/abs/1711.06232v3) - [pdf](http://arxiv.org/pdf/1711.06232v3)

> Deep neural networks have been playing an essential role in many computer vision tasks including Visual Question Answering (VQA). Until recently, the study of their accuracy was the main focus of research but now there is a trend toward assessing the robustness of these models against adversarial attacks by evaluating their tolerance to varying noise levels. In VQA, adversarial attacks can target the image and/or the proposed main question and yet there is a lack of proper analysis of the later. In this work, we propose a flexible framework that focuses on the language part of VQA that uses semantically relevant questions, dubbed basic questions, acting as controllable noise to evaluate the robustness of VQA models. We hypothesize that the level of noise is positively correlated to the similarity of a basic question to the main question. Hence, to apply noise on any given main question, we rank a pool of basic questions based on their similarity by casting this ranking task as a LASSO optimization problem. Then, we propose a novel robustness measure, R_score, and two large-scale basic question datasets (BQDs) in order to standardize robustness analysis for VQA models.

</details>

<details>

<summary>2018-12-25 05:30:18 - Building a Neural Semantic Parser from a Domain Ontology</summary>

- *Jianpeng Cheng, Siva Reddy, Mirella Lapata*

- `1812.10037v1` - [abs](http://arxiv.org/abs/1812.10037v1) - [pdf](http://arxiv.org/pdf/1812.10037v1)

> Semantic parsing is the task of converting natural language utterances into machine interpretable meaning representations which can be executed against a real-world environment such as a database. Scaling semantic parsing to arbitrary domains faces two interrelated challenges: obtaining broad coverage training data effectively and cheaply; and developing a model that generalizes to compositional utterances and complex intentions. We address these challenges with a framework which allows to elicit training data from a domain ontology and bootstrap a neural parser which recursively builds derivations of logical forms. In our framework meaning representations are described by sequences of natural language templates, where each template corresponds to a decomposed fragment of the underlying meaning representation. Although artificial, templates can be understood and paraphrased by humans to create natural utterances, resulting in parallel triples of utterances, meaning representations, and their decompositions. These allow us to train a neural semantic parser which learns to compose rules in deriving meaning representations. We crowdsource training data on six domains, covering both single-turn utterances which exhibit rich compositionality, and sequential utterances where a complex task is procedurally performed in steps. We then develop neural semantic parsers which perform such compositional tasks. In general, our approach allows to deploy neural semantic parsers quickly and cheaply from a given domain ontology.

</details>

<details>

<summary>2018-12-25 10:13:53 - SOSA: A Lightweight Ontology for Sensors, Observations, Samples, and Actuators</summary>

- *Krzysztof Janowicz, Armin Haller, Simon J D Cox, Danh Le Phuoc, Maxime Lefrancois*

- `1805.09979v2` - [abs](http://arxiv.org/abs/1805.09979v2) - [pdf](http://arxiv.org/pdf/1805.09979v2)

> The Sensor, Observation, Sample, and Actuator (SOSA) ontology provides a formal but lightweight general-purpose specification for modeling the interaction between the entities involved in the acts of observation, actuation, and sampling. SOSA is the result of rethinking the W3C-XG Semantic Sensor Network (SSN) ontology based on changes in scope and target audience, technical developments, and lessons learned over the past years. SOSA also acts as a replacement of SSN's Stimulus Sensor Observation (SSO) core. It has been developed by the first joint working group of the Open Geospatial Consortium (OGC) and the World Wide Web Consortium (W3C) on \emph{Spatial Data on the Web}. In this work, we motivate the need for SOSA, provide an overview of the main classes and properties, and briefly discuss its integration with the new release of the SSN ontology as well as various other alignments to specifications such as OGC's Observations and Measurements (O\&M), Dolce-Ultralite (DUL), and other prominent ontologies. We will also touch upon common modeling problems and application areas related to publishing and searching observation, sampling, and actuation data on the Web. The SOSA ontology and standard can be accessed at \url{https://www.w3.org/TR/vocab-ssn/}.

</details>

<details>

<summary>2018-12-26 05:55:42 - A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling</summary>

- *Yu Wang, Yilin Shen, Hongxia Jin*

- `1812.10235v1` - [abs](http://arxiv.org/abs/1812.10235v1) - [pdf](http://arxiv.org/pdf/1812.10235v1)

> Intent detection and slot filling are two main tasks for building a spoken language understanding(SLU) system. Multiple deep learning based models have demonstrated good results on these tasks . The most effective algorithms are based on the structures of sequence to sequence models (or "encoder-decoder" models), and generate the intents and semantic tags either using separate models or a joint model. Most of the previous studies, however, either treat the intent detection and slot filling as two separate parallel tasks, or use a sequence to sequence model to generate both semantic tags and intent. Most of these approaches use one (joint) NN based model (including encoder-decoder structure) to model two tasks, hence may not fully take advantage of the cross-impact between them. In this paper, new Bi-model based RNN semantic frame parsing network structures are designed to perform the intent detection and slot filling tasks jointly, by considering their cross-impact to each other using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a decoder achieves state-of-the-art result on the benchmark ATIS data, with about 0.5$\%$ intent accuracy improvement and 0.9 $\%$ slot filling improvement.

</details>

<details>

<summary>2018-12-26 07:35:24 - Multi-resolution neural networks for tracking seismic horizons from few training images</summary>

- *Bas Peters, Justin Granek, Eldad Haber*

- `1812.11092v1` - [abs](http://arxiv.org/abs/1812.11092v1) - [pdf](http://arxiv.org/pdf/1812.11092v1)

> Detecting a specific horizon in seismic images is a valuable tool for geological interpretation. Because hand-picking the locations of the horizon is a time-consuming process, automated computational methods were developed starting three decades ago. Older techniques for such picking include interpolation of control points however, in recent years neural networks have been used for this task. Until now, most networks trained on small patches from larger images. This limits the networks ability to learn from large-scale geologic structures. Moreover, currently available networks and training strategies require label patches that have full and continuous annotations, which are also time-consuming to generate.   We propose a projected loss-function for training convolutional networks with a multi-resolution structure, including variants of the U-net. Our networks learn from a small number of large seismic images without creating patches. The projected loss-function enables training on labels with just a few annotated pixels and has no issue with the other unknown label pixels. Training uses all data without reserving some for validation. Only the labels are split into training/testing. Contrary to other work on horizon tracking, we train the network to perform non-linear regression, and not classification. As such, we propose labels as the convolution of a Gaussian kernel and the known horizon locations that indicate uncertainty in the labels. The network output is the probability of the horizon location. We demonstrate the proposed computational ingredients on two different datasets, for horizon extrapolation and interpolation. We show that the predictions of our methodology are accurate even in areas far from known horizon locations because our learning strategy exploits all data in large seismic images.

</details>

<details>

<summary>2018-12-26 21:05:27 - A Greedy Approach to $\ell_{0,\infty}$ Based Convolutional Sparse Coding</summary>

- *Elad Plaut, Raja Giryes*

- `1812.10538v1` - [abs](http://arxiv.org/abs/1812.10538v1) - [pdf](http://arxiv.org/pdf/1812.10538v1)

> Sparse coding techniques for image processing traditionally rely on a processing of small overlapping patches separately followed by averaging. This has the disadvantage that the reconstructed image no longer obeys the sparsity prior used in the processing. For this purpose convolutional sparse coding has been introduced, where a shift-invariant dictionary is used and the sparsity of the recovered image is maintained. Most such strategies target the $\ell_0$ "norm" or the $\ell_1$ norm of the whole image, which may create an imbalanced sparsity across various regions in the image. In order to face this challenge, the $\ell_{0,\infty}$ "norm" has been proposed as an alternative that "operates locally while thinking globally". The approaches taken for tackling the non-convexity of these optimization problems have been either using a convex relaxation or local pursuit algorithms. In this paper, we present an efficient greedy method for sparse coding and dictionary learning, which is specifically tailored to $\ell_{0,\infty}$, and is based on matching pursuit. We demonstrate the usage of our approach in salt-and-pepper noise removal and image inpainting. A code package which reproduces the experiments presented in this work is available at https://web.eng.tau.ac.il/~raja

</details>

<details>

<summary>2018-12-27 03:15:30 - Sanctorum: A lightweight security monitor for secure enclaves</summary>

- *Ilia Lebedev, Kyle Hogan, Jules Drean, David Kohlbrenner, Dayeol Lee, Krste Asanović, Dawn Song, Srinivas Devadas*

- `1812.10605v1` - [abs](http://arxiv.org/abs/1812.10605v1) - [pdf](http://arxiv.org/pdf/1812.10605v1)

> Enclaves have emerged as a particularly compelling primitive to implement trusted execution environments: strongly isolated sensitive user-mode processes in a largely untrusted software environment. While the threat models employed by various enclave systems differ, the high-level guarantees they offer are essentially the same: attestation of an enclave's initial state, as well as a guarantee of enclave integrity and privacy in the presence of an adversary.   This work describes Sanctorum, a small trusted code base (TCB), consisting of a generic enclave-capable system, which is sufficient to implement secure enclaves akin to the primitive offered by Intel's SGX. While enclaves may be implemented via unconditionally trusted hardware and microcode, as it is the case in SGX, we employ a smaller TCB principally consisting of authenticated, privileged software, which may be replaced or patched as needed. Sanctorum implements a formally verified specification for generic enclaves on an in-order multiprocessor system meeting baseline security requirements, e.g., the MIT Sanctum processor and the Keystone enclave framework. Sanctorum requires trustworthy hardware including a random number generator, a private cryptographic key pair derived via a secure bootstrapping protocol, and a robust isolation primitive to safeguard sensitive information. Sanctorum's threat model is informed by the threat model of the isolation primitive, and is suitable for adding enclaves to a variety of processor systems.

</details>

<details>

<summary>2018-12-28 06:15:53 - Knowledge Representation Learning: A Quantitative Review</summary>

- *Yankai Lin, Xu Han, Ruobing Xie, Zhiyuan Liu, Maosong Sun*

- `1812.10901v1` - [abs](http://arxiv.org/abs/1812.10901v1) - [pdf](http://arxiv.org/pdf/1812.10901v1)

> Knowledge representation learning (KRL) aims to represent entities and relations in knowledge graph in low-dimensional semantic space, which have been widely used in massive knowledge-driven tasks. In this article, we introduce the reader to the motivations for KRL, and overview existing approaches for KRL. Afterwards, we extensively conduct and quantitative comparison and analysis of several typical KRL methods on three evaluation tasks of knowledge acquisition including knowledge graph completion, triple classification, and relation extraction. We also review the real-world applications of KRL, such as language modeling, question answering, information retrieval, and recommender systems. Finally, we discuss the remaining challenges and outlook the future directions for KRL. The codes and datasets used in the experiments can be found in https://github.com/thunlp/OpenKE.

</details>

<details>

<summary>2018-12-28 15:12:58 - Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features</summary>

- *Matteo Pagliardini, Prakhar Gupta, Martin Jaggi*

- `1703.02507v3` - [abs](http://arxiv.org/abs/1703.02507v3) - [pdf](http://arxiv.org/pdf/1703.02507v3)

> The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings.

</details>

<details>

<summary>2018-12-30 09:19:55 - Impact of Ground Truth Annotation Quality on Performance of Semantic Image Segmentation of Traffic Conditions</summary>

- *Vlad Taran, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko*

- `1901.00001v1` - [abs](http://arxiv.org/abs/1901.00001v1) - [pdf](http://arxiv.org/pdf/1901.00001v1)

> Preparation of high-quality datasets for the urban scene understanding is a labor-intensive task, especially, for datasets designed for the autonomous driving applications. The application of the coarse ground truth (GT) annotations of these datasets without detriment to the accuracy of semantic image segmentation (by the mean intersection over union - mIoU) could simplify and speedup the dataset preparation and model fine tuning before its practical application. Here the results of the comparative analysis for semantic segmentation accuracy obtained by PSPNet deep learning architecture are presented for fine and coarse annotated images from Cityscapes dataset. Two scenarios were investigated: scenario 1 - the fine GT images for training and prediction, and scenario 2 - the fine GT images for training and the coarse GT images for prediction. The obtained results demonstrated that for the most important classes the mean accuracy values of semantic image segmentation for coarse GT annotations are higher than for the fine GT ones, and the standard deviation values are vice versa. It means that for some applications some unimportant classes can be excluded and the model can be tuned further for some classes and specific regions on the coarse GT dataset without loss of the accuracy even. Moreover, this opens the perspectives to use deep neural networks for the preparation of such coarse GT datasets.

</details>

<details>

<summary>2018-12-30 09:51:05 - DSKG: A Deep Sequential Model for Knowledge Graph Completion</summary>

- *Lingbing Guo, Qingheng Zhang, Weiyi Ge, Wei Hu, Yuzhong Qu*

- `1810.12582v2` - [abs](http://arxiv.org/abs/1810.12582v2) - [pdf](http://arxiv.org/pdf/1810.12582v2)

> Knowledge graph (KG) completion aims to fill the missing facts in a KG, where a fact is represented as a triple in the form of $(subject, relation, object)$. Current KG completion models compel two-thirds of a triple provided (e.g., $subject$ and $relation$) to predict the remaining one. In this paper, we propose a new model, which uses a KG-specific multi-layer recurrent neural network (RNN) to model triples in a KG as sequences. It outperformed several state-of-the-art KG completion models on the conventional entity prediction task for many evaluation metrics, based on two benchmark datasets and a more difficult dataset. Furthermore, our model is enabled by the sequential characteristic and thus capable of predicting the whole triples only given one entity. Our experiments demonstrated that our model achieved promising performance on this new triple prediction task.

</details>

<details>

<summary>2018-12-30 15:38:25 - Monte-Carlo Sampling applied to Multiple Instance Learning for Histological Image Classification</summary>

- *Marc Combalia, Veronica Vilaplana*

- `1812.11560v1` - [abs](http://arxiv.org/abs/1812.11560v1) - [pdf](http://arxiv.org/pdf/1812.11560v1)

> We propose a patch sampling strategy based on a sequential Monte-Carlo method for high resolution image classification in the context of Multiple Instance Learning. When compared with grid sampling and uniform sampling techniques, it achieves higher generalization performance. We validate the strategy on two artificial datasets and two histological datasets for breast cancer and sun exposure classification.

</details>

<details>

<summary>2018-12-31 03:01:40 - Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities</summary>

- *Martin White, Michele Tufano, Matias Martinez, Martin Monperrus, Denys Poshyvanyk*

- `1707.04742v2` - [abs](http://arxiv.org/abs/1707.04742v2) - [pdf](http://arxiv.org/pdf/1707.04742v2)

> In the field of automated program repair, the redundancy assumption claims large programs contain the seeds of their own repair. However, most redundancy-based program repair techniques do not reason about the repair ingredients---the code that is reused to craft a patch. We aim to reason about the repair ingredients by using code similarities to prioritize and transform statements in a codebase for patch generation. Our approach, DeepRepair, relies on deep learning to reason about code similarities. Code fragments at well-defined levels of granularity in a codebase can be sorted according to their similarity to suspicious elements (i.e., code elements that contain suspicious statements) and statements can be transformed by mapping out-of-scope identifiers to similar identifiers in scope. We examined these new search strategies for patch generation with respect to effectiveness from the viewpoint of a software maintainer. Our comparative experiments were executed on six open-source Java projects including 374 buggy program revisions and consisted of 19,949 trials spanning 2,616 days of computation time. DeepRepair's search strategy using code similarities generally found compilable ingredients faster than the baseline, jGenProg, but this improvement neither yielded test-adequate patches in fewer attempts (on average) nor found significantly more patches than the baseline. Although the patch counts were not statistically different, there were notable differences between the nature of DeepRepair patches and baseline patches. The results demonstrate that our learning-based approach finds patches that cannot be found by existing redundancy-based repair techniques.

</details>

<details>

<summary>2018-12-31 16:30:21 - Sentence-Level Sentiment Analysis of Financial News Using Distributed Text Representations and Multi-Instance Learning</summary>

- *Bernhard Lutz, Nicolas Pröllochs, Dirk Neumann*

- `1901.00400v1` - [abs](http://arxiv.org/abs/1901.00400v1) - [pdf](http://arxiv.org/pdf/1901.00400v1)

> Researchers and financial professionals require robust computerized tools that allow users to rapidly operationalize and assess the semantic textual content in financial news. However, existing methods commonly work at the document-level while deeper insights into the actual structure and the sentiment of individual sentences remain blurred. As a result, investors are required to apply the utmost attention and detailed, domain-specific knowledge in order to assess the information on a fine-grained basis. To facilitate this manual process, this paper proposes the use of distributed text representations and multi-instance learning to transfer information from the document-level to the sentence-level. Compared to alternative approaches, this method features superior predictive performance while preserving context and interpretability. Our analysis of a manually-labeled dataset yields a predictive accuracy of up to 69.90%, exceeding the performance of alternative approaches by at least 3.80 percentage points. Accordingly, this study not only benefits investors with regard to their financial decision-making, but also helps companies to communicate their messages as intended.

</details>

<details>

<summary>2018-12-31 20:25:14 - Connectionist Recommendation in the Wild: On the utility and scrutability of neural networks for personalized course guidance</summary>

- *Zachary A. Pardos, Zihao Fan, Weijie Jiang*

- `1803.09535v3` - [abs](http://arxiv.org/abs/1803.09535v3) - [pdf](http://arxiv.org/pdf/1803.09535v3)

> The aggregate behaviors of users can collectively encode deep semantic information about the objects with which they interact. In this paper, we demonstrate novel ways in which the synthesis of these data can illuminate the terrain of users' environment and support them in their decision making and wayfinding. A novel application of Recurrent Neural Networks and skip-gram models, approaches popularized by their application to modeling language, are brought to bear on student university enrollment sequences to create vector representations of courses and map out traversals across them. We present demonstrations of how scrutability from these neural networks can be gained and how the combination of these techniques can be seen as an evolution of content tagging and a means for a recommender to balance user preferences inferred from data with those explicitly specified. From validation of the models to the development of a UI, we discuss additional requisite functionality informed by the results of a usability study leading to the ultimate deployment of the system at a university.

</details>

