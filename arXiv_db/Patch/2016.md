# 2016

## TOC

- [2016-01](#2016-01)
- [2016-02](#2016-02)
- [2016-03](#2016-03)
- [2016-04](#2016-04)
- [2016-05](#2016-05)
- [2016-06](#2016-06)
- [2016-07](#2016-07)
- [2016-08](#2016-08)
- [2016-09](#2016-09)
- [2016-10](#2016-10)
- [2016-11](#2016-11)
- [2016-12](#2016-12)

## 2016-01

<details>

<summary>2016-01-04 00:42:07 - Unsupervised Learning of Video Representations using LSTMs</summary>

- *Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov*

- `1502.04681v3` - [abs](http://arxiv.org/abs/1502.04681v3) - [pdf](http://arxiv.org/pdf/1502.04681v3)

> We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.

</details>


## 2016-02

<details>

<summary>2016-02-17 02:51:49 - Code Drones</summary>

- *Mithun P. Acharya, Chris Parnin, Nicholas A. Kraft, Aldo Dagnino, Xiao Qu*

- `1411.6118v4` - [abs](http://arxiv.org/abs/1411.6118v4) - [pdf](http://arxiv.org/pdf/1411.6118v4)

> We propose and explore a new paradigm called Code Drones in which every software artifact such as a class is an intelligent and socially active entity. In this paradigm, humanized artifacts take the lead and choreograph (socially, in collaboration with other intelligent software artifacts and humans) automated software engineering solutions to a myriad of development and maintenance challenges, including API migration, reuse, documentation, testing, patching, and refactoring. We discuss the implications of having social and intelligent/cognitive software artifacts that guide their own self-improvement.

</details>

<details>

<summary>2016-02-18 01:09:39 - An Analysis of the Search Spaces for Generate and Validate Patch Generation Systems</summary>

- *Fan Long, Martin Rinard*

- `1602.05643v1` - [abs](http://arxiv.org/abs/1602.05643v1) - [pdf](http://arxiv.org/pdf/1602.05643v1)

> We present the first systematic analysis of the characteristics of patch search spaces for automatic patch generation systems. We analyze the search spaces of two current state-of-the-art systems, SPR and Prophet, with 16 different search space configurations. Our results are derived from an analysis of 1104 different search spaces and 768 patch generation executions. Together these experiments consumed over 9000 hours of CPU time on Amazon EC2.   The analysis shows that 1) correct patches are sparse in the search spaces (typically at most one correct patch per search space per defect), 2) incorrect patches that nevertheless pass all of the test cases in the validation test suite are typically orders of magnitude more abundant, and 3) leveraging information other than the test suite is therefore critical for enabling the system to successfully isolate correct patches.   We also characterize a key tradeoff in the structure of the search spaces. Larger and richer search spaces that contain correct patches for more defects can actually cause systems to find fewer, not more, correct patches. We identify two reasons for this phenomenon: 1) increased validation times because of the presence of more candidate patches and 2) more incorrect patches that pass the test suite and block the discovery of correct patches. These fundamental properties, which are all characterized for the first time in this paper, help explain why past systems often fail to generate correct patches and help identify challenges, opportunities, and productive future directions for the field.

</details>

<details>

<summary>2016-02-29 17:56:29 - Generating Images from Captions with Attention</summary>

- *Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov*

- `1511.02793v2` - [abs](http://arxiv.org/abs/1511.02793v2) - [pdf](http://arxiv.org/pdf/1511.02793v2)

> Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset.

</details>

<details>

<summary>2016-02-29 21:07:30 - Density Modeling of Images using a Generalized Normalization Transformation</summary>

- *Johannes Ballé, Valero Laparra, Eero P. Simoncelli*

- `1511.06281v4` - [abs](http://arxiv.org/abs/1511.06281v4) - [pdf](http://arxiv.org/pdf/1511.06281v4)

> We introduce a parametric nonlinear transformation that is well-suited for Gaussianizing data from natural images. The data are linearly transformed, and each component is then normalized by a pooled activity measure, computed by exponentiating a weighted sum of rectified and exponentiated components and a constant. We optimize the parameters of the full transformation (linear transform, exponents, weights, constant) over a database of natural images, directly minimizing the negentropy of the responses. The optimized transformation substantially Gaussianizes the data, achieving a significantly smaller mutual information between transformed components than alternative methods including ICA and radial Gaussianization. The transformation is differentiable and can be efficiently inverted, and thus induces a density model on images. We show that samples of this model are visually similar to samples of natural image patches. We demonstrate the use of the model as a prior probability density that can be used to remove additive noise. Finally, we show that the transformation can be cascaded, with each layer optimized using the same Gaussianization objective, thus offering an unsupervised method of optimizing a deep network architecture.

</details>


## 2016-03

<details>

<summary>2016-03-11 07:13:59 - Watch-n-Patch: Unsupervised Learning of Actions and Relations</summary>

- *Chenxia Wu, Jiemi Zhang, Ozan Sener, Bart Selman, Silvio Savarese, Ashutosh Saxena*

- `1603.03541v1` - [abs](http://arxiv.org/abs/1603.03541v1) - [pdf](http://arxiv.org/pdf/1603.03541v1)

> There is a large variation in the activities that humans perform in their everyday lives. We consider modeling these composite human activities which comprises multiple basic level actions in a completely unsupervised setting. Our model learns high-level co-occurrence and temporal relations between the actions. We consider the video as a sequence of short-term action clips, which contains human-words and object-words. An activity is about a set of action-topics and object-topics indicating which actions are present and which objects are interacting with. We then propose a new probabilistic model relating the words and the topics. It allows us to model long-range action relations that commonly exist in the composite activities, which is challenging in previous works. We apply our model to the unsupervised action segmentation and clustering, and to a novel application that detects forgotten actions, which we call action patching. For evaluation, we contribute a new challenging RGB-D activity video dataset recorded by the new Kinect v2, which contains several human daily activities as compositions of multiple actions interacting with different objects. Moreover, we develop a robotic system that watches people and reminds people by applying our action patching algorithm. Our robotic setup can be easily deployed on any assistive robot.

</details>

<details>

<summary>2016-03-19 03:06:58 - Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering</summary>

- *Huijuan Xu, Kate Saenko*

- `1511.05234v2` - [abs](http://arxiv.org/abs/1511.05234v2) - [pdf](http://arxiv.org/pdf/1511.05234v2)

> We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. Recent approaches have applied deep image captioning methods based on convolutional-recurrent networks to this problem, but have failed to model spatial inference. To remedy this, we propose a model we call the Spatial Memory Network and apply it to the VQA task. Memory networks are recurrent neural networks with an explicit attention mechanism that selects certain parts of the information stored in memory. Our Spatial Memory Network stores neuron activations from different spatial regions of the image in its memory, and uses the question to choose relevant regions for computing the answer, a process of which constitutes a single "hop" in the network. We propose a novel spatial attention architecture that aligns words with image patches in the first hop, and obtain improved results by adding a second attention hop which considers the whole question to choose visual evidence based on the results of the first hop. To better understand the inference process learned by the network, we design synthetic questions that specifically require spatial inference and visualize the attention weights. We evaluate our model on two published visual question answering datasets, DAQUAR [1] and VQA [2], and obtain improved results compared to a strong deep baseline model (iBOWIMG) which concatenates image and question features to predict the answer [3].

</details>

<details>

<summary>2016-03-24 15:44:17 - BanditRepair: Speculative Exploration of Runtime Patches</summary>

- *Thomas Durieux, Youssef Hamadi, Martin Monperrus*

- `1603.07631v1` - [abs](http://arxiv.org/abs/1603.07631v1) - [pdf](http://arxiv.org/pdf/1603.07631v1)

> We propose, BanditRepair, a system that systematically explores and assesses a set of possible runtime patches. The system is grounded on so-called bandit algorithms, that are online machine learning algorithms, designed for constantly balancing exploitation and exploration. BanditRepair's runtime patches are based on modifying the execution state for repairing null dereferences. BanditRepair constantly trades the ratio of automatically handled failures for searching for new runtime patches and vice versa. We evaluate the system with 16 null dereference field bugs, where BanditRepair identifies a total of 8460 different runtime patches, which are composed of 1 up to 8 decisions (execution modifications) taken in a row. We are the first to finely characterize the search space and the outcomes of runtime repair based on execution modification.

</details>

<details>

<summary>2016-03-31 10:15:16 - Operators for Space and Time in BeSpaceD</summary>

- *Jan Olaf Blech, Keith Foster*

- `1602.08809v2` - [abs](http://arxiv.org/abs/1602.08809v2) - [pdf](http://arxiv.org/pdf/1602.08809v2)

> In this report, we present some spatio-temporal operators for our BeSpaceD framework. We port operators known from functional programming languages such as filtering, folding and normalization on abstract data structures to the BeSpaceD specification language. We present the general ideas behind the operators, highlight implementation details and present some simple examples.

</details>


## 2016-04

<details>

<summary>2016-04-14 13:12:07 - Self-taught learning of a deep invariant representation for visual tracking via temporal slowness principle</summary>

- *Jason Kuen, Kian Ming Lim, Chin Poo Lee*

- `1604.04144v1` - [abs](http://arxiv.org/abs/1604.04144v1) - [pdf](http://arxiv.org/pdf/1604.04144v1)

> Visual representation is crucial for a visual tracking method's performances. Conventionally, visual representations adopted in visual tracking rely on hand-crafted computer vision descriptors. These descriptors were developed generically without considering tracking-specific information. In this paper, we propose to learn complex-valued invariant representations from tracked sequential image patches, via strong temporal slowness constraint and stacked convolutional autoencoders. The deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker. The proposed observational model retains old training samples to alleviate drift, and collect negative samples which are coherent with target's motion pattern for better discriminative tracking. With the learned representation and online training samples, a logistic regression classifier is adopted to distinguish target from background, and retrained online to adapt to appearance changes. Subsequently, the observational model is integrated into a particle filter framework to peform visual tracking. Experimental results on various challenging benchmark sequences demonstrate that the proposed tracker performs favourably against several state-of-the-art trackers.

</details>

<details>

<summary>2016-04-18 07:55:06 - Impact of Knowledge on Election Time in Anonymous Networks</summary>

- *Yoann Dieudonné, Andrzej Pelc*

- `1604.05023v1` - [abs](http://arxiv.org/abs/1604.05023v1) - [pdf](http://arxiv.org/pdf/1604.05023v1)

> Leader election is one of the basic problems in distributed computing. For anonymous networks, the task of leader election is formulated as follows: every node v of the network must output a simple path, which is coded as a sequence of port numbers, such that all these paths end at a common node, the leader. In this paper, we study deterministic leader election in arbitrary anonymous networks. It is well known that leader election is impossible in some networks, regardless of the allocated amount of time, even if nodes know the map of the network. However, even in networks in which it is possible to elect a leader knowing the map, the task may be still impossible without any knowledge, regardless of the allocated time. On the other hand, for any network in which leader election is possible knowing the map, there is a minimum time, called the election index, in which this can be done. Informally, the election index of a network is the minimum depth at which views of all nodes are distinct. Our aim is to establish tradeoffs between the allocated time $\tau$ and the amount of information that has to be given a priori to the nodes to enable leader election in time $\tau$ in all networks for which leader election in this time is at all possible. Following the framework of algorithms with advice, this information is provided to all nodes at the start by an oracle knowing the entire network. The length of this string (its number of bits) is called the size of advice. For a given time $\tau$ allocated to leader election, we give upper and lower bounds on the minimum size of advice sufficient to perform leader election in time $\tau$. We focus on the two sides of the time spectrum and give tight (or almost tight) bounds on the minimum size of advice for these extremes. We also show that constant advice is not sufficient for leader election in all graphs, regardless of the allocated time.

</details>

<details>

<summary>2016-04-27 15:31:01 - Global-Local Face Upsampling Network</summary>

- *Oncel Tuzel, Yuichi Taguchi, John R. Hershey*

- `1603.07235v2` - [abs](http://arxiv.org/abs/1603.07235v2) - [pdf](http://arxiv.org/pdf/1603.07235v2)

> Face hallucination, which is the task of generating a high-resolution face image from a low-resolution input image, is a well-studied problem that is useful in widespread application areas. Face hallucination is particularly challenging when the input face resolution is very low (e.g., 10 x 12 pixels) and/or the image is captured in an uncontrolled setting with large pose and illumination variations. In this paper, we revisit the algorithm introduced in [1] and present a deep interpretation of this framework that achieves state-of-the-art under such challenging scenarios. In our deep network architecture the global and local constraints that define a face can be efficiently modeled and learned end-to-end using training data. Conceptually our network design can be partitioned into two sub-networks: the first one implements the holistic face reconstruction according to global constraints, and the second one enhances face-specific details and enforces local patch statistics. We optimize the deep network using a new loss function for super-resolution that combines reconstruction error with a learned face quality measure in adversarial setting, producing improved visual results. We conduct extensive experiments in both controlled and uncontrolled setups and show that our algorithm improves the state of the art both numerically and visually.

</details>


## 2016-05

<details>

<summary>2016-05-04 14:01:42 - Video (language) modeling: a baseline for generative models of natural videos</summary>

- *MarcAurelio Ranzato, Arthur Szlam, Joan Bruna, Michael Mathieu, Ronan Collobert, Sumit Chopra*

- `1412.6604v5` - [abs](http://arxiv.org/abs/1412.6604v5) - [pdf](http://arxiv.org/pdf/1412.6604v5)

> We propose a strong baseline model for unsupervised feature learning using video data. By learning to predict missing frames or extrapolate future frames from an input video sequence, the model discovers both spatial and temporal correlations which are useful to represent complex deformations and motion patterns. The models we propose are largely borrowed from the language modeling literature, and adapted to the vision domain by quantizing the space of image patches into a large dictionary. We demonstrate the approach on both a filling and a generation task. For the first time, we show that, after training on natural videos, such a model can predict non-trivial motions over short video sequences.

</details>

<details>

<summary>2016-05-04 16:16:12 - Single Channel Speech Enhancement Using Outlier Detection</summary>

- *Eunjoon Cho, Bowon Lee, Ronald Schafer, Bernard Widrow*

- `1605.01329v1` - [abs](http://arxiv.org/abs/1605.01329v1) - [pdf](http://arxiv.org/pdf/1605.01329v1)

> Distortion of the underlying speech is a common problem for single-channel speech enhancement algorithms, and hinders such methods from being used more extensively. A dictionary based speech enhancement method that emphasizes preserving the underlying speech is proposed. Spectral patches of clean speech are sampled and clustered to train a dictionary. Given a noisy speech spectral patch, the best matching dictionary entry is selected and used to estimate the noise power at each time-frequency bin. The noise estimation step is formulated as an outlier detection problem, where the noise at each bin is assumed present only if it is an outlier to the corresponding bin of the best matching dictionary entry. This framework assigns higher priority in removing spectral elements that strongly deviate from a typical spoken unit stored in the trained dictionary. Even without the aid of a separate noise model, this method can achieve significant noise reduction for various non-stationary noises, while effectively preserving the underlying speech in more challenging noisy environments.

</details>

<details>

<summary>2016-05-05 20:33:38 - Rank Ordered Autoencoders</summary>

- *Paul Bertens*

- `1605.01749v1` - [abs](http://arxiv.org/abs/1605.01749v1) - [pdf](http://arxiv.org/pdf/1605.01749v1)

> A new method for the unsupervised learning of sparse representations using autoencoders is proposed and implemented by ordering the output of the hidden units by their activation value and progressively reconstructing the input in this order. This can be done efficiently in parallel with the use of cumulative sums and sorting only slightly increasing the computational costs. Minimizing the difference of this progressive reconstruction with respect to the input can be seen as minimizing the number of active output units required for the reconstruction of the input. The model thus learns to reconstruct optimally using the least number of active output units. This leads to high sparsity without the need for extra hyperparameters, the amount of sparsity is instead implicitly learned by minimizing this progressive reconstruction error. Results of the trained model are given for patches of the CIFAR10 dataset, showing rapid convergence of features and extremely sparse output activations while maintaining a minimal reconstruction error and showing extreme robustness to overfitting. Additionally the reconstruction as function of number of active units is presented which shows the autoencoder learns a rank order code over the input where the highest ranked units correspond to the highest decrease in reconstruction error.

</details>

<details>

<summary>2016-05-18 19:53:41 - Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches</summary>

- *Jure Žbontar, Yann LeCun*

- `1510.05970v2` - [abs](http://arxiv.org/abs/1510.05970v2) - [pdf](http://arxiv.org/pdf/1510.05970v2)

> We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.

</details>

<details>

<summary>2016-05-24 15:55:41 - ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation</summary>

- *Francesco Visin, Marco Ciccone, Adriana Romero, Kyle Kastner, Kyunghyun Cho, Yoshua Bengio, Matteo Matteucci, Aaron Courville*

- `1511.07053v3` - [abs](http://arxiv.org/abs/1511.07053v3) - [pdf](http://arxiv.org/pdf/1511.07053v3)

> We propose a structured prediction architecture, which exploits the local generic features extracted by Convolutional Neural Networks and the capacity of Recurrent Neural Networks (RNN) to retrieve distant dependencies. The proposed architecture, called ReSeg, is based on the recently introduced ReNet model for image classification. We modify and extend it to perform the more challenging task of semantic segmentation. Each ReNet layer is composed of four RNN that sweep the image horizontally and vertically in both directions, encoding patches or activations, and providing relevant global information. Moreover, ReNet layers are stacked on top of pre-trained convolutional layers, benefiting from generic local features. Upsampling layers follow ReNet layers to recover the original image resolution in the final predictions. The proposed ReSeg architecture is efficient, flexible and suitable for a variety of semantic segmentation tasks. We evaluate ReSeg on several widely-used semantic segmentation datasets: Weizmann Horse, Oxford Flower, and CamVid; achieving state-of-the-art performance. Results show that ReSeg can act as a suitable architecture for semantic segmentation tasks, and may have further applications in other structured prediction problems. The source code and model hyperparameters are available on https://github.com/fvisin/reseg.

</details>


## 2016-06

<details>

<summary>2016-06-23 00:50:19 - Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</summary>

- *Minh-Thang Luong, Christopher D. Manning*

- `1604.00788v2` - [abs](http://arxiv.org/abs/1604.00788v2) - [pdf](http://arxiv.org/pdf/1604.00788v2)

> Nearly all previous work on neural machine translation (NMT) has used quite restricted vocabularies, perhaps with a subsequent method to patch in unknown words. This paper presents a novel word-character solution to achieving open vocabulary NMT. We build hybrid systems that translate mostly at the word level and consult the character components for rare words. Our character-level recurrent neural networks compute source word representations and recover unknown target words when needed. The twofold advantage of such a hybrid approach is that it is much faster and easier to train than character-based ones; at the same time, it never produces unknown words as in the case of word-based models. On the WMT'15 English to Czech translation task, this hybrid approach offers an addition boost of +2.1-11.4 BLEU points over models that already handle unknown words. Our best system achieves a new state-of-the-art result with 20.7 BLEU score. We demonstrate that our character models can successfully learn to not only generate well-formed words for Czech, a highly-inflected language with a very complex vocabulary, but also build correct representations for English source words.

</details>


## 2016-07

<details>

<summary>2016-07-04 14:32:07 - Observing Custom Software Modifications: A Quantitative Approach of Tracking the Evolution of Patch Stacks</summary>

- *Ralf Ramsauer, Daniel Lohmann, Wolfgang Mauerer*

- `1607.00905v1` - [abs](http://arxiv.org/abs/1607.00905v1) - [pdf](http://arxiv.org/pdf/1607.00905v1)

> Modifications to open-source software (OSS) are often provided in the form of "patch stacks" - sets of changes (patches) that modify a given body of source code. Maintaining patch stacks over extended periods of time is problematic when the underlying base project changes frequently. This necessitates a continuous and engineering-intensive adaptation of the stack. Nonetheless, long-term maintenance is an important problem for changes that are not integrated into projects, for instance when they are controversial or only of value to a limited group of users.   We present and implement a methodology to systematically examine the temporal evolution of patch stacks, track non-functional properties like integrability and maintainability, and estimate the eventual economic and engineering effort required to successfully develop and maintain patch stacks.   Our results provide a basis for quantitative research on patch stacks, including statistical analyses and other methods that lead to actionable advice on the construction and long-term maintenance of custom extensions to OSS.

</details>

<details>

<summary>2016-07-06 10:15:17 - Structural Synthesis for GXW Specifications</summary>

- *Chih-Hong Cheng, Yassine Hamza, Harald Ruess*

- `1605.01153v3` - [abs](http://arxiv.org/abs/1605.01153v3) - [pdf](http://arxiv.org/pdf/1605.01153v3)

> We define the GXW fragment of linear temporal logic (LTL) as the basis for synthesizing embedded control software for safety-critical applications. Since GXW includes the use of a weak-until operator we are able to specify a number of diverse programmable logic control (PLC) problems, which we have compiled from industrial training sets. For GXW controller specifications, we develop a novel approach for synthesizing a set of synchronously communicating actor-based controllers. This synthesis algorithm proceeds by means of recursing over the structure of GXW specifications, and generates a set of dedicated and synchronously communicating sub-controllers according to the formula structure. In a subsequent step, 2QBF constraint solving identifies and tries to resolve potential conflicts between individual GXW specifications. This structural approach to GXW synthesis supports traceability between requirements and the generated control code as mandated by certification regimes for safety-critical software. Synthesis for GXW specifications is in PSPACE compared to 2EXPTIME-completeness of full-fledged LTL synthesis. Indeed our experimental results suggest that GXW synthesis scales well to industrial-sized control synthesis problems with 20 input and output ports and beyond.

</details>

<details>

<summary>2016-07-20 21:02:16 - Sequence to sequence learning for unconstrained scene text recognition</summary>

- *Ahmed Mamdouh A. Hassanien*

- `1607.06125v1` - [abs](http://arxiv.org/abs/1607.06125v1) - [pdf](http://arxiv.org/pdf/1607.06125v1)

> In this work we present a state-of-the-art approach for unconstrained natural scene text recognition. We propose a cascade approach that incorporates a convolutional neural network (CNN) architecture followed by a long short term memory model (LSTM). The CNN learns visual features for the characters and uses them with a softmax layer to detect sequence of characters. While the CNN gives very good recognition results, it does not model relation between characters, hence gives rise to false positive and false negative cases (confusing characters due to visual similarities like "g" and "9", or confusing background patches with characters; either removing existing characters or adding non-existing ones) To alleviate these problems we leverage recent developments in LSTM architectures to encode contextual information. We show that the LSTM can dramatically reduce such errors and achieve state-of-the-art accuracy in the task of unconstrained natural scene text recognition. Moreover we manually remove all occurrences of the words that exist in the test set from our training set to test whether our approach will generalize to unseen data. We use the ICDAR 13 test set for evaluation and compare the results with the state of the art approaches [11, 18]. We finally present an application of the work in the domain of for traffic monitoring.

</details>

<details>

<summary>2016-07-26 18:06:16 - Conforming restricted Delaunay mesh generation for piecewise smooth complexes</summary>

- *Darren Engwirda*

- `1606.01289v2` - [abs](http://arxiv.org/abs/1606.01289v2) - [pdf](http://arxiv.org/pdf/1606.01289v2)

> A Frontal-Delaunay refinement algorithm for mesh generation in piecewise smooth domains is described. Built using a restricted Delaunay framework, this new algorithm combines a number of novel features, including: (i) an unweighted, conforming restricted Delaunay representation for domains specified as a (non-manifold) collection of piecewise smooth surface patches and curve segments, (ii) a protection strategy for domains containing curve segments that subtend sharply acute angles, and (iii) a new class of off-centre refinement rules designed to achieve high-quality point-placement along embedded curve features. Experimental comparisons show that the new Frontal-Delaunay algorithm outperforms a classical (statically weighted) restricted Delaunay-refinement technique for a number of three-dimensional benchmark problems.

</details>

<details>

<summary>2016-07-30 08:38:15 - DeepSoft: A vision for a deep model of software</summary>

- *Hoa Khanh Dam, Truyen Tran, John Grundy, Aditya Ghose*

- `1608.00092v1` - [abs](http://arxiv.org/abs/1608.00092v1) - [pdf](http://arxiv.org/pdf/1608.00092v1)

> Although software analytics has experienced rapid growth as a research area, it has not yet reached its full potential for wide industrial adoption. Most of the existing work in software analytics still relies heavily on costly manual feature engineering processes, and they mainly address the traditional classification problems, as opposed to predicting future events. We present a vision for \emph{DeepSoft}, an \emph{end-to-end} generic framework for modeling software and its development process to predict future risks and recommend interventions. DeepSoft, partly inspired by human memory, is built upon the powerful deep learning-based Long Short Term Memory architecture that is capable of learning long-term temporal dependencies that occur in software evolution. Such deep learned patterns of software can be used to address a range of challenging problems such as code and task recommendation and prediction. DeepSoft provides a new approach for research into modeling of source code, risk prediction and mitigation, developer modeling, and automatically generating code patches from bug reports.

</details>


## 2016-08

<details>

<summary>2016-08-03 09:53:47 - DOLPHIn - Dictionary Learning for Phase Retrieval</summary>

- *Andreas M. Tillmann, Yonina C. Eldar, Julien Mairal*

- `1602.02263v2` - [abs](http://arxiv.org/abs/1602.02263v2) - [pdf](http://arxiv.org/pdf/1602.02263v2)

> We propose a new algorithm to learn a dictionary for reconstructing and sparsely encoding signals from measurements without phase. Specifically, we consider the task of estimating a two-dimensional image from squared-magnitude measurements of a complex-valued linear transformation of the original image. Several recent phase retrieval algorithms exploit underlying sparsity of the unknown signal in order to improve recovery performance. In this work, we consider such a sparse signal prior in the context of phase retrieval, when the sparsifying dictionary is not known in advance. Our algorithm jointly reconstructs the unknown signal - possibly corrupted by noise - and learns a dictionary such that each patch of the estimated image can be sparsely represented. Numerical experiments demonstrate that our approach can obtain significantly better reconstructions for phase retrieval problems with noise than methods that cannot exploit such "hidden" sparsity. Moreover, on the theoretical side, we provide a convergence result for our method.

</details>

<details>

<summary>2016-08-04 15:01:36 - Learning by tracking: Siamese CNN for robust target association</summary>

- *Laura Leal-Taixé, Cristian Canton Ferrer, Konrad Schindler*

- `1604.07866v3` - [abs](http://arxiv.org/abs/1604.07866v3) - [pdf](http://arxiv.org/pdf/1604.07866v3)

> This paper introduces a novel approach to the task of data association within the context of pedestrian tracking, by introducing a two-stage learning scheme to match pairs of detections. First, a Siamese convolutional neural network (CNN) is trained to learn descriptors encoding local spatio-temporal structures between the two input image patches, aggregating pixel values and optical flow information. Second, a set of contextual features derived from the position and size of the compared input patches are combined with the CNN output by means of a gradient boosting classifier to generate the final matching probability. This learning approach is validated by using a linear programming based multi-person tracker showing that even a simple and efficient tracker may outperform much more complex models when fed with our learned matching probabilities. Results on publicly available sequences show that our method meets state-of-the-art standards in multiple people tracking.

</details>

<details>

<summary>2016-08-09 08:59:47 - OnionNet: Sharing Features in Cascaded Deep Classifiers</summary>

- *Martin Simonovsky, Nikos Komodakis*

- `1608.02728v1` - [abs](http://arxiv.org/abs/1608.02728v1) - [pdf](http://arxiv.org/pdf/1608.02728v1)

> The focus of our work is speeding up evaluation of deep neural networks in retrieval scenarios, where conventional architectures may spend too much time on negative examples. We propose to replace a monolithic network with our novel cascade of feature-sharing deep classifiers, called OnionNet, where subsequent stages may add both new layers as well as new feature channels to the previous ones. Importantly, intermediate feature maps are shared among classifiers, preventing them from the necessity of being recomputed. To accomplish this, the model is trained end-to-end in a principled way under a joint loss. We validate our approach in theory and on a synthetic benchmark. As a result demonstrated in three applications (patch matching, object detection, and image retrieval), our cascade can operate significantly faster than both monolithic networks and traditional cascades without sharing at the cost of marginal decrease in precision.

</details>

<details>

<summary>2016-08-18 22:35:40 - A Model of Navigation History</summary>

- *Connor G. Brewster, Alan Jeffrey*

- `1608.05444v1` - [abs](http://arxiv.org/abs/1608.05444v1) - [pdf](http://arxiv.org/pdf/1608.05444v1)

> Navigation has been a core component of the web since its inception: users and scripts can follow hyperlinks, and can go back or forwards through the navigation history. In this paper, we present a formal model aligned with the WHATWG specification of navigation history, and investigate its properties. The fundamental property of navigation history is that traversing the history by delta then by delta' should be the same as traversing by delta+delta'. In particular, traversing by +1 (forward) then by -1 (back) is the same as traversing by 0 (doing nothing). We show that the specification-aligned model does not satisfy this property, by exhibiting a series of counter-examples, which motivate four patches to the model. We present a series of experiments, showing that browsers are inconsistent in their implementation of navigation history, but that their behaviour is closer to the patched model than to the specification-aligned model. We propose patches to the specification to align it with the patched model.

</details>

<details>

<summary>2016-08-27 08:24:18 - Passive Fingerprinting of SCADA in Critical Infrastructure Network without Deep Packet Inspection</summary>

- *Sungho Jeon, Jeong-Han Yun, Seungoh Choi, Woo-Nyon Kim*

- `1608.07679v1` - [abs](http://arxiv.org/abs/1608.07679v1) - [pdf](http://arxiv.org/pdf/1608.07679v1)

> We present the first technique of passive fingerprinting for Supervisory Control And Data Acquisition (SCADA) networks without Deep Packet Inspection (DPI) and experience on real environment. Unlike existing work, our method does not rely on the functions of a specific product or DPI of the SCADA protocol. Our inference method, which is based on the intrinsic characteristics of SCADA, first identifies the network port used for the SCADA protocol, then consecutively infers the field devices and master server. We evaluated the effectiveness of our method using two network traces collected from a real environment for a month and a half, three days from different CI respectively. This confirmed the ability of our method to capture most of the SCADA with high F-score nearly 1, except for HMIs connected to master server, and demonstrated the practical applicability of the method.

</details>

<details>

<summary>2016-08-30 13:47:41 - BreakID: Static Symmetry Breaking for ASP (System Description)</summary>

- *Jo Devriendt, Bart Bogaerts*

- `1608.08447v1` - [abs](http://arxiv.org/abs/1608.08447v1) - [pdf](http://arxiv.org/pdf/1608.08447v1)

> Symmetry breaking has been proven to be an efficient preprocessing technique for satisfiability solving (SAT). In this paper, we port the state-of-the-art SAT symmetry breaker BreakID to answer set programming (ASP). The result is a lightweight tool that can be plugged in between the grounding and the solving phases that are common when modelling in ASP. We compare our tool with sbass, the current state-of-the-art symmetry breaker for ASP.

</details>


## 2016-09

<details>

<summary>2016-09-20 19:16:30 - Adaptive Mitigation of Multi-Virus Propagation: A Passivity-Based Approach</summary>

- *Phillip Lee, Andrew Clark, Basel Alomair, Linda Bushnell, Radha Poovendran*

- `1603.04374v2` - [abs](http://arxiv.org/abs/1603.04374v2) - [pdf](http://arxiv.org/pdf/1603.04374v2)

> Malware propagation poses a growing threat to networked systems such as computer networks and cyber-physical systems. Current approaches to defending against malware propagation are based on patching or filtering susceptible nodes at a fixed rate. When the propagation dynamics are unknown or uncertain, however, the static rate that is chosen may be either insufficient to remove all viruses or too high, incurring additional performance cost. In this paper, we formulate adaptive strategies for mitigating multiple malware epidemics when the propagation rate is unknown, using patching and filtering-based defense mechanisms. In order to identify conditions for ensuring that all viruses are asymptotically removed, we show that the malware propagation, patching, and filtering processes can be modeled as coupled passive dynamical systems. We prove that the patching rate required to remove all viruses is bounded above by the passivity index of the coupled system, and formulate the problem of selecting the minimum-cost mitigation strategy. Our results are evaluated through numerical study.

</details>

<details>

<summary>2016-09-23 21:18:31 - Fast Learning of Clusters and Topics via Sparse Posteriors</summary>

- *Michael C. Hughes, Erik B. Sudderth*

- `1609.07521v1` - [abs](http://arxiv.org/abs/1609.07521v1) - [pdf](http://arxiv.org/pdf/1609.07521v1)

> Mixture models and topic models generate each observation from a single cluster, but standard variational posteriors for each observation assign positive probability to all possible clusters. This requires dense storage and runtime costs that scale with the total number of clusters, even though typically only a few clusters have significant posterior mass for any data point. We propose a constrained family of sparse variational distributions that allow at most $L$ non-zero entries, where the tunable threshold $L$ trades off speed for accuracy. Previous sparse approximations have used hard assignments ($L=1$), but we find that moderate values of $L>1$ provide superior performance. Our approach easily integrates with stochastic or incremental optimization algorithms to scale to millions of examples. Experiments training mixture models of image patches and topic models for news articles show that our approach produces better-quality models in far less time than baseline methods.

</details>

<details>

<summary>2016-09-29 00:01:08 - Your Computer is Leaking</summary>

- *Dennis Hollenbeck, Ian Malloy*

- `1609.09157v1` - [abs](http://arxiv.org/abs/1609.09157v1) - [pdf](http://arxiv.org/pdf/1609.09157v1)

> This presentation focuses on differences between quantum computing and quantum cryptography. Both are discussed related to classical computer systems in terms of vulnerability. Research concerning quantum cryptography is analyzed in terms of work done by the University of Cambridge in partnership with a division of Toshiba, and also attacks demonstrated by Swedish researchers against QKD of energy-time entangled systems. Quantum computing is covered in terms of classical cryptography related to weaknesses presented by Shor's algorithm. Previous classical vulnerabilities also discussed were conducted by Israeli researchers as a side-channel attack using parabolic curve microphones, which has since been patched.

</details>


## 2016-10

<details>

<summary>2016-10-01 04:15:01 - Data-Driven Learning of a Union of Sparsifying Transforms Model for Blind Compressed Sensing</summary>

- *Saiprasad Ravishankar, Yoram Bresler*

- `1511.01289v2` - [abs](http://arxiv.org/abs/1511.01289v2) - [pdf](http://arxiv.org/pdf/1511.01289v2)

> Compressed sensing is a powerful tool in applications such as magnetic resonance imaging (MRI). It enables accurate recovery of images from highly undersampled measurements by exploiting the sparsity of the images or image patches in a transform domain or dictionary. In this work, we focus on blind compressed sensing (BCS), where the underlying sparse signal model is a priori unknown, and propose a framework to simultaneously reconstruct the underlying image as well as the unknown model from highly undersampled measurements. Specifically, our model is that the patches of the underlying image(s) are approximately sparse in a transform domain. We also extend this model to a union of transforms model that better captures the diversity of features in natural images. The proposed block coordinate descent type algorithms for blind compressed sensing are highly efficient, and are guaranteed to converge to at least the partial global and partial local minimizers of the highly non-convex BCS problems. Our numerical experiments show that the proposed framework usually leads to better quality of image reconstructions in MRI compared to several recent image reconstruction methods. Importantly, the learning of a union of sparsifying transforms leads to better image reconstructions than a single adaptive transform.

</details>

<details>

<summary>2016-10-06 19:22:49 - Scalable Machine Translation in Memory Constrained Environments</summary>

- *Paul Baltescu*

- `1610.02003v1` - [abs](http://arxiv.org/abs/1610.02003v1) - [pdf](http://arxiv.org/pdf/1610.02003v1)

> Machine translation is the discipline concerned with developing automated tools for translating from one human language to another. Statistical machine translation (SMT) is the dominant paradigm in this field. In SMT, translations are generated by means of statistical models whose parameters are learned from bilingual data. Scalability is a key concern in SMT, as one would like to make use of as much data as possible to train better translation systems.   In recent years, mobile devices with adequate computing power have become widely available. Despite being very successful, mobile applications relying on NLP systems continue to follow a client-server architecture, which is of limited use because access to internet is often limited and expensive. The goal of this dissertation is to show how to construct a scalable machine translation system that can operate with the limited resources available on a mobile device.   The main challenge for porting translation systems on mobile devices is memory usage. The amount of memory available on a mobile device is far less than what is typically available on the server side of a client-server application. In this thesis, we investigate alternatives for the two components which prevent standard translation systems from working on mobile devices due to high memory usage. We show that once these standard components are replaced with our proposed alternatives, we obtain a scalable translation system that can work on a device with limited memory.

</details>

<details>

<summary>2016-10-10 22:37:55 - Convolutional Neural Networks Analyzed via Convolutional Sparse Coding</summary>

- *Vardan Papyan, Yaniv Romano, Michael Elad*

- `1607.08194v4` - [abs](http://arxiv.org/abs/1607.08194v4) - [pdf](http://arxiv.org/pdf/1607.08194v4)

> Convolutional neural networks (CNN) have led to many state-of-the-art results spanning through various fields. However, a clear and profound theoretical understanding of the forward pass, the core algorithm of CNN, is still lacking. In parallel, within the wide field of sparse approximation, Convolutional Sparse Coding (CSC) has gained increasing attention in recent years. A theoretical study of this model was recently conducted, establishing it as a reliable and stable alternative to the commonly practiced patch-based processing. Herein, we propose a novel multi-layer model, ML-CSC, in which signals are assumed to emerge from a cascade of CSC layers. This is shown to be tightly connected to CNN, so much so that the forward pass of the CNN is in fact the thresholding pursuit serving the ML-CSC model. This connection brings a fresh view to CNN, as we are able to attribute to this architecture theoretical claims such as uniqueness of the representations throughout the network, and their stable estimation, all guaranteed under simple local sparsity conditions. Lastly, identifying the weaknesses in the above pursuit scheme, we propose an alternative to the forward pass, which is connected to deconvolutional, recurrent and residual networks, and has better theoretical guarantees.

</details>

<details>

<summary>2016-10-11 02:48:13 - Long Short-Term Memory based Convolutional Recurrent Neural Networks for Large Vocabulary Speech Recognition</summary>

- *Xiangang Li, Xihong Wu*

- `1610.03165v1` - [abs](http://arxiv.org/abs/1610.03165v1) - [pdf](http://arxiv.org/pdf/1610.03165v1)

> Long short-term memory (LSTM) recurrent neural networks (RNNs) have been shown to give state-of-the-art performance on many speech recognition tasks, as they are able to provide the learned dynamically changing contextual window of all sequence history. On the other hand, the convolutional neural networks (CNNs) have brought significant improvements to deep feed-forward neural networks (FFNNs), as they are able to better reduce spectral variation in the input signal. In this paper, a network architecture called as convolutional recurrent neural network (CRNN) is proposed by combining the CNN and LSTM RNN. In the proposed CRNNs, each speech frame, without adjacent context frames, is organized as a number of local feature patches along the frequency axis, and then a LSTM network is performed on each feature patch along the time axis. We train and compare FFNNs, LSTM RNNs and the proposed LSTM CRNNs at various number of configurations. Experimental results show that the LSTM CRNNs can exceed state-of-the-art speech recognition performance.

</details>

<details>

<summary>2016-10-31 13:48:29 - Hybrid CPU-GPU generation of the Hamiltonian and Overlap matrices in FLAPW methods</summary>

- *Diego Fabregat-Traver, Davor Davidović, Markus Höhnerbach, Edoardo Di Napoli*

- `1611.00606v1` - [abs](http://arxiv.org/abs/1611.00606v1) - [pdf](http://arxiv.org/pdf/1611.00606v1)

> In this paper we focus on the integration of high-performance numerical libraries in ab initio codes and the portability of performance and scalability. The target of our work is FLEUR, a software for electronic structure calculations developed in the Forschungszentrum J\"ulich over the course of two decades. The presented work follows up on a previous effort to modernize legacy code by re-engineering and rewriting it in terms of highly optimized libraries. We illustrate how this initial effort to get efficient and portable shared-memory code enables fast porting of the code to emerging heterogeneous architectures. More specifically, we port the code to nodes equipped with multiple GPUs. We divide our study in two parts. First, we show considerable speedups attained by minor and relatively straightforward code changes to off-load parts of the computation to the GPUs. Then, we identify further possible improvements to achieve even higher performance and scalability. On a system consisting of 16-cores and 2 GPUs, we observe speedups of up to 5x with respect to our optimized shared-memory code, which in turn means between 7.5x and 12.5x speedup with respect to the original FLEUR code.

</details>


## 2016-11

<details>

<summary>2016-11-02 19:48:34 - Porting the LSST Data Management Pipeline Software to Python 3</summary>

- *Tim Jenness*

- `1611.00751v1` - [abs](http://arxiv.org/abs/1611.00751v1) - [pdf](http://arxiv.org/pdf/1611.00751v1)

> The LSST data management science pipelines software consists of more than 100,000 lines of Python 2 code. LSST operations will begin after support for Python 2 has been dropped by the Python community in 2020, and we must therefore plan to migrate the codebase to Python 3. During the transition period we must also support our community of active Python 2 users and this complicates the porting significantly. We have decided to use the Python future package as the basis for our port to enable support for Python 2 and Python 3 simultaneously, whilst developing with a mindset more suited to Python 3. In this paper we report on the current status of the port and the difficulties that have been encountered.

</details>

<details>

<summary>2016-11-04 02:04:52 - Sparse-promoting Full Waveform Inversion based on Online Orthonormal Dictionary Learning</summary>

- *Lingchen Zhu, Entao Liu, James H. McClellan*

- `1511.05194v2` - [abs](http://arxiv.org/abs/1511.05194v2) - [pdf](http://arxiv.org/pdf/1511.05194v2)

> Full waveform inversion (FWI) delivers high-resolution images of the subsurface by minimizing iteratively the misfit between the recorded and calculated seismic data. It has been attacked successfully with the Gauss-Newton method and sparsity promoting regularization based on fixed multiscale transforms that permit significant subsampling of the seismic data when the model perturbation at each FWI data-fitting iteration can be represented with sparse coefficients. Rather than using analytical transforms with predefined dictionaries to achieve sparse representation, we introduce an adaptive transform called the Sparse Orthonormal Transform (SOT) whose dictionary is learned from many small training patches taken from the model perturbations in previous iterations. The patch-based dictionary is constrained to be orthonormal and trained with an online approach to provide the best sparse representation of the complex features and variations of the entire model perturbation. The complexity of the training method is proportional to the cube of the number of samples in one small patch. By incorporating both compressive subsampling and the adaptive SOT-based representation into the Gauss-Newton least-squares problem for each FWI iteration, the model perturbation can be recovered after an l1-norm sparsity constraint is applied on the SOT coefficients. Numerical experiments on synthetic models demonstrate that the SOT-based sparsity promoting regularization can provide robust FWI results with reduced computation.

</details>

<details>

<summary>2016-11-12 13:37:07 - Unsupervised learning of object semantic parts from internal states of CNNs by population encoding</summary>

- *Jianyu Wang, Zhishuai Zhang, Cihang Xie, Vittal Premachandran, Alan Yuille*

- `1511.06855v3` - [abs](http://arxiv.org/abs/1511.06855v3) - [pdf](http://arxiv.org/pdf/1511.06855v3)

> We address the key question of how object part representations can be found from the internal states of CNNs that are trained for high-level tasks, such as object classification. This work provides a new unsupervised method to learn semantic parts and gives new understanding of the internal representations of CNNs. Our technique is based on the hypothesis that semantic parts are represented by populations of neurons rather than by single filters. We propose a clustering technique to extract part representations, which we call Visual Concepts. We show that visual concepts are semantically coherent in that they represent semantic parts, and visually coherent in that corresponding image patches appear very similar. Also, visual concepts provide full spatial coverage of the parts of an object, rather than a few sparse parts as is typically found in keypoint annotations. Furthermore, We treat single visual concept as part detector and evaluate it for keypoint detection using the PASCAL3D+ dataset and for part detection using our newly annotated ImageNetPart dataset. The experiments demonstrate that visual concepts can be used to detect parts. We also show that some visual concepts respond to several semantic parts, provided these parts are visually similar. Thus visual concepts have the essential properties: semantic meaning and detection capability. Note that our ImageNetPart dataset gives rich part annotations which cover the whole object, making it useful for other part-related applications.

</details>

<details>

<summary>2016-11-16 02:00:33 - Deterministic Graph Exploration with Advice</summary>

- *Barun Gorain, Andrzej Pelc*

- `1607.01657v2` - [abs](http://arxiv.org/abs/1607.01657v2) - [pdf](http://arxiv.org/pdf/1607.01657v2)

> We consider the task of graph exploration. An $n$-node graph has unlabeled nodes, and all ports at any node of degree $d$ are arbitrarily numbered $0,\dots, d-1$. A mobile agent has to visit all nodes and stop. The exploration time is the number of edge traversals. We consider the problem of how much knowledge the agent has to have a priori, in order to explore the graph in a given time, using a deterministic algorithm. This a priori information (advice) is provided to the agent by an oracle, in the form of a binary string, whose length is called the size of advice. We consider two types of oracles. The instance oracle knows the entire instance of the exploration problem, i.e., the port-numbered map of the graph and the starting node of the agent in this map. The map oracle knows the port-numbered map of the graph but does not know the starting node of the agent.   We first consider exploration in polynomial time, and determine the exact minimum size of advice to achieve it. This size is $\log\log\log n -\Theta(1)$, for both types of oracles.   When advice is large, there are two natural time thresholds: $\Theta(n^2)$ for a map oracle, and $\Theta(n)$ for an instance oracle, that can be achieved with sufficiently large advice. We show that, with a map oracle, time $\Theta(n^2)$ cannot be improved in general, regardless of the size of advice. We also show that the smallest size of advice to achieve this time is larger than $n^\delta$, for any $\delta <1/3$.   For an instance oracle, advice of size $O(n\log n)$ is enough to achieve time $O(n)$. We show that, with any advice of size $o(n\log n)$, the time of exploration must be at least $n^\epsilon$, for any $\epsilon <2$, and with any advice of size $O(n)$, the time must be $\Omega(n^2)$.   We also investigate minimum advice sufficient for fast exploration of hamiltonian graphs.

</details>


## 2016-12

<details>

<summary>2016-12-02 14:05:49 - Identifying and Categorizing Anomalies in Retinal Imaging Data</summary>

- *Philipp Seeböck, Sebastian Waldstein, Sophie Klimscha, Bianca S. Gerendas, René Donner, Thomas Schlegl, Ursula Schmidt-Erfurth, Georg Langs*

- `1612.00686v1` - [abs](http://arxiv.org/abs/1612.00686v1) - [pdf](http://arxiv.org/pdf/1612.00686v1)

> The identification and quantification of markers in medical images is critical for diagnosis, prognosis and management of patients in clinical practice. Supervised- or weakly supervised training enables the detection of findings that are known a priori. It does not scale well, and a priori definition limits the vocabulary of markers to known entities reducing the accuracy of diagnosis and prognosis. Here, we propose the identification of anomalies in large-scale medical imaging data using healthy examples as a reference. We detect and categorize candidates for anomaly findings untypical for the observed data. A deep convolutional autoencoder is trained on healthy retinal images. The learned model generates a new feature representation, and the distribution of healthy retinal patches is estimated by a one-class support vector machine. Results demonstrate that we can identify pathologic regions in images without using expert annotations. A subsequent clustering categorizes findings into clinically meaningful classes. In addition the learned features outperform standard embedding approaches in a classification task.

</details>

<details>

<summary>2016-12-02 18:26:18 - When to Reset Your Keys: Optimal Timing of Security Updates via Learning</summary>

- *Zizhan Zheng, Ness B. Shroff, Prasant Mohapatra*

- `1612.00108v2` - [abs](http://arxiv.org/abs/1612.00108v2) - [pdf](http://arxiv.org/pdf/1612.00108v2)

> Cybersecurity is increasingly threatened by advanced and persistent attacks. As these attacks are often designed to disable a system (or a critical resource, e.g., a user account) repeatedly, it is crucial for the defender to keep updating its security measures to strike a balance between the risk of being compromised and the cost of security updates. Moreover, these decisions often need to be made with limited and delayed feedback due to the stealthy nature of advanced attacks. In addition to targeted attacks, such an optimal timing policy under incomplete information has broad applications in cybersecurity. Examples include key rotation, password change, application of patches, and virtual machine refreshing. However, rigorous studies of optimal timing are rare. Further, existing solutions typically rely on a pre-defined attack model that is known to the defender, which is often not the case in practice. In this work, we make an initial effort towards achieving optimal timing of security updates in the face of unknown stealthy attacks. We consider a variant of the influential FlipIt game model with asymmetric feedback and unknown attack time distribution, which provides a general model to consecutive security updates. The defender's problem is then modeled as a time associative bandit problem with dependent arms. We derive upper confidence bound based learning policies that achieve low regret compared with optimal periodic defense strategies that can only be derived when attack time distributions are known.

</details>

<details>

<summary>2016-12-13 11:21:47 - IoT Sentinel: Automated Device-Type Identification for Security Enforcement in IoT</summary>

- *Markus Miettinen, Samuel Marchal, Ibbad Hafeez, N. Asokan, Ahmad-Reza Sadeghi, Sasu Tarkoma*

- `1611.04880v2` - [abs](http://arxiv.org/abs/1611.04880v2) - [pdf](http://arxiv.org/pdf/1611.04880v2)

> With the rapid growth of the Internet-of-Things (IoT), concerns about the security of IoT devices have become prominent. Several vendors are producing IP-connected devices for home and small office networks that often suffer from flawed security designs and implementations. They also tend to lack mechanisms for firmware updates or patches that can help eliminate security vulnerabilities. Securing networks where the presence of such vulnerable devices is given, requires a brownfield approach: applying necessary protection measures within the network so that potentially vulnerable devices can coexist without endangering the security of other devices in the same network. In this paper, we present IOT SENTINEL, a system capable of automatically identifying the types of devices being connected to an IoT network and enabling enforcement of rules for constraining the communications of vulnerable devices so as to minimize damage resulting from their compromise. We show that IOT SENTINEL is effective in identifying device types and has minimal performance overhead.

</details>

<details>

<summary>2016-12-13 20:05:37 - Fast Patch-based Style Transfer of Arbitrary Style</summary>

- *Tian Qi Chen, Mark Schmidt*

- `1612.04337v1` - [abs](http://arxiv.org/abs/1612.04337v1) - [pdf](http://arxiv.org/pdf/1612.04337v1)

> Artistic style transfer is an image synthesis problem where the content of an image is reproduced with the style of another. Recent works show that a visually appealing style transfer can be achieved by using the hidden activations of a pretrained convolutional neural network. However, existing methods either apply (i) an optimization procedure that works for any style image but is very expensive, or (ii) an efficient feedforward network that only allows a limited number of trained styles. In this work we propose a simpler optimization objective based on local matching that combines the content structure and style textures in a single layer of the pretrained network. We show that our objective has desirable properties such as a simpler optimization landscape, intuitive parameter tuning, and consistent frame-by-frame performance on video. Furthermore, we use 80,000 natural images and 80,000 paintings to train an inverse network that approximates the result of the optimization. This results in a procedure for artistic style transfer that is efficient but also allows arbitrary content and style images.

</details>

<details>

<summary>2016-12-18 18:31:11 - Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification</summary>

- *Wentao Zhu, Qi Lou, Yeeleng Scott Vang, Xiaohui Xie*

- `1612.05968v1` - [abs](http://arxiv.org/abs/1612.05968v1) - [pdf](http://arxiv.org/pdf/1612.05968v1)

> Mammogram classification is directly related to computer-aided diagnosis of breast cancer. Traditional methods requires great effort to annotate the training data by costly manual labeling and specialized computational models to detect these annotations during test. Inspired by the success of using deep convolutional features for natural image analysis and multi-instance learning for labeling a set of instances/patches, we propose end-to-end trained deep multi-instance networks for mass classification based on whole mammogram without the aforementioned costly need to annotate the training data. We explore three different schemes to construct deep multi-instance networks for whole mammogram classification. Experimental results on the INbreast dataset demonstrate the robustness of proposed deep networks compared to previous work using segmentation and detection annotations in the training.

</details>

