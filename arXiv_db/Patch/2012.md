# 2012

## TOC

- [2012-01](#2012-01)
- [2012-02](#2012-02)
- [2012-03](#2012-03)
- [2012-04](#2012-04)
- [2012-05](#2012-05)
- [2012-06](#2012-06)
- [2012-07](#2012-07)
- [2012-08](#2012-08)
- [2012-09](#2012-09)
- [2012-10](#2012-10)
- [2012-11](#2012-11)

## 2012-01

<details>

<summary>2012-01-12 17:54:00 - Hybrid GPS-GSM Localization of Automobile Tracking System</summary>

- *Mohammad A. Al-Khedher*

- `1201.2630v1` - [abs](http://arxiv.org/abs/1201.2630v1) - [pdf](http://arxiv.org/pdf/1201.2630v1)

> An integrated GPS-GSM system is proposed to track vehicles using Google Earth application. The remote module has a GPS mounted on the moving vehicle to identify its current position, and to be transferred by GSM with other parameters acquired by the automobile's data port as an SMS to a recipient station. The received GPS coordinates are filtered using a Kalman filter to enhance the accuracy of measured position. After data processing, Google Earth application is used to view the current location and status of each vehicle. This goal of this system is to manage fleet, police automobiles distribution and car theft cautions.

</details>


## 2012-02

<details>

<summary>2012-02-02 04:53:09 - Cryptographic Path Hardening: Hiding Vulnerabilities in Software through Cryptography</summary>

- *Vijay Ganesh, Michael Carbin, Martin Rinard*

- `1202.0359v1` - [abs](http://arxiv.org/abs/1202.0359v1) - [pdf](http://arxiv.org/pdf/1202.0359v1)

> We propose a novel approach to improving software security called Cryptographic Path Hardening, which is aimed at hiding security vulnerabilities in software from attackers through the use of provably secure and obfuscated cryptographic devices to harden paths in programs.   By "harden" we mean that certain error-checking if-conditionals in a given program P are replaced by equivalent" we mean that adversaries cannot use semi-automatic program analysis techniques to reason about the hardened program paths and thus cannot discover as-yet-unknown errors along those paths, except perhaps through black-box dictionary attacks or random testing (which we can never prevent).   Other than these unpreventable attack methods, we can make program analysis aimed at error-finding "provably hard" for a resource-bounded attacker, in the same sense that cryptographic schemes are hard to break. Unlike security-through-obscurity, in Cryptographic Path Hardening we use provably-secure crypto devices to hide errors and our mathematical arguments of security are the same as the standard ones used in cryptography.   One application of Cryptographic Path Hardening is that software patches or filters often reveal enough information to an attacker that they can be used to construct error-revealing inputs to exploit an unpatched version of the program. By "hardening" the patch we make it difficult for the attacker to analyze the patched program to construct error-revealing inputs, and thus prevent him from potentially constructing exploits.

</details>


## 2012-03

<details>

<summary>2012-03-02 02:24:58 - Eigenvector Synchronization, Graph Rigidity and the Molecule Problem</summary>

- *Mihai Cucuringu, Amit Singer, David Cowburn*

- `1111.3304v3` - [abs](http://arxiv.org/abs/1111.3304v3) - [pdf](http://arxiv.org/pdf/1111.3304v3)

> The graph realization problem has received a great deal of attention in recent years, due to its importance in applications such as wireless sensor networks and structural biology. In this paper, we extend on previous work and propose the 3D-ASAP algorithm, for the graph realization problem in $\mathbb{R}^3$, given a sparse and noisy set of distance measurements. 3D-ASAP is a divide and conquer, non-incremental and non-iterative algorithm, which integrates local distance information into a global structure determination. Our approach starts with identifying, for every node, a subgraph of its 1-hop neighborhood graph, which can be accurately embedded in its own coordinate system. In the noise-free case, the computed coordinates of the sensors in each patch must agree with their global positioning up to some unknown rigid motion, that is, up to translation, rotation and possibly reflection. In other words, to every patch there corresponds an element of the Euclidean group Euc(3) of rigid transformations in $\mathbb{R}^3$, and the goal is to estimate the group elements that will properly align all the patches in a globally consistent way. Furthermore, 3D-ASAP successfully incorporates information specific to the molecule problem in structural biology, in particular information on known substructures and their orientation. In addition, we also propose 3D-SP-ASAP, a faster version of 3D-ASAP, which uses a spectral partitioning algorithm as a preprocessing step for dividing the initial graph into smaller subgraphs. Our extensive numerical simulations show that 3D-ASAP and 3D-SP-ASAP are very robust to high levels of noise in the measured distances and to sparse connectivity in the measurement graph, and compare favorably to similar state-of-the art localization algorithms.

</details>


## 2012-04

<details>

<summary>2012-04-02 16:38:01 - Time Synchronization Attack in Smart Grid-Part II: Cross Layer Detection Mechanism</summary>

- *Zhenghao Zhang, Matthew Trinkle, Aleksandar D. Dimitrovski, Husheng Li*

- `1204.0462v1` - [abs](http://arxiv.org/abs/1204.0462v1) - [pdf](http://arxiv.org/pdf/1204.0462v1)

> A novel time synchronization attack (TSA) on wide area monitoring systems in smart grid has been identified in the first part of this paper. A cross layer detection mechanism is proposed to combat TSA in part II of this paper. In the physical layer, we propose a GPS carrier signal noise ratio (C/No) based spoofing detection technique. In addition, a patch-monopole hybrid antenna is applied to receive GPS signal. By computing the standard deviation of the C/No difference from two GPS receivers, a priori probability of spoofing detection is fed to the upper layer, where power system state is estimated and controlled. A trustworthiness based evaluation method is applied to identify the PMU being under TSA. Both the physical layer and upper layer algorithms are integrated to detect the TSA, thus forming a cross layer mechanism. Experiment is carried out to verify the effectiveness of the proposed TSA detection algorithm.

</details>

<details>

<summary>2012-04-09 17:38:47 - New Sequential Methods for Detecting Portscanners</summary>

- *Xinjia Chen*

- `1204.1935v1` - [abs](http://arxiv.org/abs/1204.1935v1) - [pdf](http://arxiv.org/pdf/1204.1935v1)

> In this paper, we propose new sequential methods for detecting port-scan attackers which routinely perform random "portscans" of IP addresses to find vulnerable servers to compromise. In addition to rigorously control the probability of falsely implicating benign remote hosts as malicious, our method performs significantly faster than other current solutions. Moreover, our method guarantees that the maximum amount of observational time is bounded. In contrast to the previous most effective method, Threshold Random Walk Algorithm, which is explicit and analytical in nature, our proposed algorithm involve parameters to be determined by numerical methods. We have developed computational techniques such as iterative minimax optimization for quick determination of the parameters of the new detection algorithm. A framework of multi-valued decision for testing portscanners is also proposed.

</details>


## 2012-05

<details>

<summary>2012-05-10 18:57:36 - A Multi-Dimensional approach towards Intrusion Detection System</summary>

- *Manoj Rameshchandra Thakur, Sugata Sanyal*

- `1205.2340v1` - [abs](http://arxiv.org/abs/1205.2340v1) - [pdf](http://arxiv.org/pdf/1205.2340v1)

> In this paper, we suggest a multi-dimensional approach towards intrusion detection. Network and system usage parameters like source and destination IP addresses; source and destination ports; incoming and outgoing network traffic data rate and number of CPU cycles per request are divided into multiple dimensions. Rather than analyzing raw bytes of data corresponding to the values of the network parameters, a mature function is inferred during the training phase for each dimension. This mature function takes a dimension value as an input and returns a value that represents the level of abnormality in the system usage with respect to that dimension. This mature function is referred to as Individual Anomaly Indicator. Individual Anomaly Indicators recorded for each of the dimensions are then used to generate a Global Anomaly Indicator, a function with n variables (n is the number of dimensions) that provides the Global Anomaly Factor, an indicator of anomaly in the system usage based on all the dimensions considered together. The Global Anomaly Indicator inferred during the training phase is then used to detect anomaly in the network traffic during the detection phase. Network traffic data encountered during the detection phase is fed back to the system to improve the maturity of the Individual Anomaly Indicators and hence the Global Anomaly Indicator.

</details>

<details>

<summary>2012-05-17 19:19:01 - Fragmentation Considered Poisonous</summary>

- *Amir Herzberg, Haya Shulman*

- `1205.4011v1` - [abs](http://arxiv.org/abs/1205.4011v1) - [pdf](http://arxiv.org/pdf/1205.4011v1)

> We present practical poisoning and name-server block- ing attacks on standard DNS resolvers, by off-path, spoofing adversaries. Our attacks exploit large DNS responses that cause IP fragmentation; such long re- sponses are increasingly common, mainly due to the use of DNSSEC. In common scenarios, where DNSSEC is partially or incorrectly deployed, our poisoning attacks allow 'com- plete' domain hijacking. When DNSSEC is fully de- ployed, attacker can force use of fake name server; we show exploits of this allowing off-path traffic analy- sis and covert channel. When using NSEC3 opt-out, attacker can also create fake subdomains, circumvent- ing same origin restrictions. Our attacks circumvent resolver-side defenses, e.g., port randomisation, IP ran- domisation and query randomisation. The (new) name server (NS) blocking attacks force re- solver to use specific name server. This attack allows Degradation of Service, traffic-analysis and covert chan- nel, and also facilitates DNS poisoning. We validated the attacks using standard resolver soft- ware and standard DNS name servers and zones, e.g., org.

</details>

<details>

<summary>2012-05-23 14:52:40 - Security of Patched DNS</summary>

- *Amir Herzberg, Haya Shulman*

- `1205.5190v1` - [abs](http://arxiv.org/abs/1205.5190v1) - [pdf](http://arxiv.org/pdf/1205.5190v1)

> In spite of the availability of DNSSEC, which protects against cache poisoning even by MitM attackers, many caching DNS resolvers still rely for their security against poisoning on merely validating that DNS responses contain some 'unpredictable' values, copied from the re- quest. These values include the 16 bit identifier field, and other fields, randomised and validated by different 'patches' to DNS. We investigate the prominent patches, and show how attackers can circumvent all of them, namely: - We show how attackers can circumvent source port randomisation, in the (common) case where the resolver connects to the Internet via different NAT devices. - We show how attackers can circumvent IP address randomisation, using some (standard-conforming) resolvers. - We show how attackers can circumvent query randomisation, including both randomisation by prepending a random nonce and case randomisation (0x20 encoding). We present countermeasures preventing our attacks; however, we believe that our attacks provide additional motivation for adoption of DNSSEC (or other MitM-secure defenses).

</details>


## 2012-06

<details>

<summary>2012-06-18 15:30:35 - Bayesian Watermark Attacks</summary>

- *Ivo Shterev, David Dunson*

- `1206.4662v1` - [abs](http://arxiv.org/abs/1206.4662v1) - [pdf](http://arxiv.org/pdf/1206.4662v1)

> This paper presents an application of statistical machine learning to the field of watermarking. We propose a new attack model on additive spread-spectrum watermarking systems. The proposed attack is based on Bayesian statistics. We consider the scenario in which a watermark signal is repeatedly embedded in specific, possibly chosen based on a secret message bitstream, segments (signals) of the host data. The host signal can represent a patch of pixels from an image or a video frame. We propose a probabilistic model that infers the embedded message bitstream and watermark signal, directly from the watermarked data, without access to the decoder. We develop an efficient Markov chain Monte Carlo sampler for updating the model parameters from their conjugate full conditional posteriors. We also provide a variational Bayesian solution, which further increases the convergence speed of the algorithm. Experiments with synthetic and real image signals demonstrate that the attack model is able to correctly infer a large part of the message bitstream and obtain a very accurate estimate of the watermark signal.

</details>


## 2012-07

<details>

<summary>2012-07-06 18:12:08 - Performance Evaluation of Widely used Portknoking Algorithms</summary>

- *Z. A. Khan, N. Javaid, M. H. Arshad, A. Bibi, B. Qasim*

- `1207.1700v1` - [abs](http://arxiv.org/abs/1207.1700v1) - [pdf](http://arxiv.org/pdf/1207.1700v1)

> Port knocking is a technique by which only a single packet or special sequence will permit the firewall to open a port on a machine where all ports are blocked by default. It is a passive authorization technique which offers firewall-level authentication to ensure authorized access to potentially vulnerable network services. In this paper, we present performance evaluation and analytical comparison of three widely used port knocking (PK) algorithms, Aldaba, FWKNOP and SIG-2. Comparative analysis is based upon ten selected parameters; Platforms (Supported OS), Implementation (PK, SPA or both), Protocols (UDP, TCP, ICMP), Out of Order packet delivery, NAT (Network Address Translation), Encryption Algorithms, Root privileges (For installation and operation), Weak Passwords, Replay Attacks and IPv6 compatibility. Based upon these parameters, relative performance score has been given to each algorithm. Finally, we deduce that FWKNOP due to compatibility with windows client is the most efficient among chosen PK implementations.

</details>

<details>

<summary>2012-07-12 15:37:29 - Detection of Configuration Vulnerabilities in Distributed (Web) Environments</summary>

- *Matteo Maria Casalino, Michele Mangili, Henrik Plate, Serena Elisa Ponta*

- `1206.6757v2` - [abs](http://arxiv.org/abs/1206.6757v2) - [pdf](http://arxiv.org/pdf/1206.6757v2)

> Many tools and libraries are readily available to build and operate distributed Web applications. While the setup of operational environments is comparatively easy, practice shows that their continuous secure operation is more difficult to achieve, many times resulting in vulnerable systems exposed to the Internet. Authenticated vulnerability scanners and validation tools represent a means to detect security vulnerabilities caused by missing patches or misconfiguration, but current approaches center much around the concepts of hosts and operating systems. This paper presents a language and an approach for the declarative specification and execution of machine-readable security checks for sets of more fine-granular system components depending on each other in a distributed environment. Such a language, building on existing standards, fosters the creation and sharing of security content among security stakeholders. Our approach is exemplified by vulnerabilities of and corresponding checks for Open Source Software commonly used in today's Internet applications.

</details>

<details>

<summary>2012-07-17 19:05:18 - A Two-Stage Combined Classifier in Scale Space Texture Classification</summary>

- *Mehrdad J. Gangeh, Robert P. W. Duin, Bart M. ter Haar Romeny, Mohamed S. Kamel*

- `1207.4089v1` - [abs](http://arxiv.org/abs/1207.4089v1) - [pdf](http://arxiv.org/pdf/1207.4089v1)

> Textures often show multiscale properties and hence multiscale techniques are considered useful for texture analysis. Scale-space theory as a biologically motivated approach may be used to construct multiscale textures. In this paper various ways are studied to combine features on different scales for texture classification of small image patches. We use the N-jet of derivatives up to the second order at different scales to generate distinct pattern representations (DPR) of feature subsets. Each feature subset in the DPR is given to a base classifier (BC) of a two-stage combined classifier. The decisions made by these BCs are combined in two stages over scales and derivatives. Various combining systems and their significances and differences are discussed. The learning curves are used to evaluate the performances. We found for small sample sizes combining classifiers performs significantly better than combining feature spaces (CFS). It is also shown that combining classifiers performs better than the support vector machine on CFS in multiscale texture classification.

</details>


## 2012-08

<details>

<summary>2012-08-11 15:07:54 - TCP Injections for Fun and Clogging</summary>

- *Yossi Gilad, Amir Herzberg*

- `1208.2357v1` - [abs](http://arxiv.org/abs/1208.2357v1) - [pdf](http://arxiv.org/pdf/1208.2357v1)

> We present a new type of clogging DoS attacks, with the highest amplification factors achieved by off-path attackers, using only puppets, i.e., sandboxed malware on victim machines. Specifically, we present off-path variants of the Opt-ack, Ack-storm and Coremelt DoS attacks, achieving results comparable to these achieved previously achieved by eavesdropping/MitM attackers and (unrestricted) malware. In contrast to previous off-path attacks, which attacked the client (machine) running the malware, our attacks address a very different goal: large-scale clogging DoS of a third party, or even of backbone connections.   Our clogging attacks are based on off-path TCP injections. Indeed, as an additional contribution, we present improved off-path TCP injection attacks. Our new attacks significantly relax the requirements cf. to the known attacks; specifically, our injection attack requires only a Java script in browser sandbox (not 'restricted malware'), does not depend on specific operating system properties, and is efficient even when client's port is determined using recommended algorithm. Our attacks are constructed modularly, allowing reuse of modules for other scenarios and replacing modules as necessary. We present specific defenses, however, this work is further proof to the need to base security on sound foundations, using cryptography to provide security even against MitM attackers.

</details>

<details>

<summary>2012-08-14 09:36:08 - An Optimal Lower Bound for Buffer Management in Multi-Queue Switches</summary>

- *Marcin Bienkowski*

- `1007.1535v3` - [abs](http://arxiv.org/abs/1007.1535v3) - [pdf](http://arxiv.org/pdf/1007.1535v3)

> In the online packet buffering problem (also known as the unweighted FIFO variant of buffer management), we focus on a single network packet switching device with several input ports and one output port. This device forwards unit-size, unit-value packets from input ports to the output port. Buffers attached to input ports may accumulate incoming packets for later transmission; if they cannot accommodate all incoming packets, their excess is lost. A packet buffering algorithm has to choose from which buffers to transmit packets in order to minimize the number of lost packets and thus maximize the throughput.   We present a tight lower bound of e/(e-1) ~ 1.582 on the competitive ratio of the throughput maximization, which holds even for fractional or randomized algorithms. This improves the previously best known lower bound of 1.4659 and matches the performance of the algorithm Random Schedule. Our result contradicts the claimed performance of the algorithm Random Permutation; we point out a flaw in its original analysis.

</details>

<details>

<summary>2012-08-18 04:16:13 - Unsupervised Discovery of Mid-Level Discriminative Patches</summary>

- *Saurabh Singh, Abhinav Gupta, Alexei A. Efros*

- `1205.3137v2` - [abs](http://arxiv.org/abs/1205.3137v2) - [pdf](http://arxiv.org/pdf/1205.3137v2)

> The goal of this paper is to discover a set of discriminative patches which can serve as a fully unsupervised mid-level visual representation. The desired patches need to satisfy two requirements: 1) to be representative, they need to occur frequently enough in the visual world; 2) to be discriminative, they need to be different enough from the rest of the visual world. The patches could correspond to parts, objects, "visual phrases", etc. but are not restricted to be any one of them. We pose this as an unsupervised discriminative clustering problem on a huge dataset of image patches. We use an iterative procedure which alternates between clustering and training discriminative classifiers, while applying careful cross-validation at each step to prevent overfitting. The paper experimentally demonstrates the effectiveness of discriminative patches as an unsupervised mid-level visual representation, suggesting that it could be used in place of visual words for many tasks. Furthermore, discriminative patches can also be used in a supervised regime, such as scene classification, where they demonstrate state-of-the-art performance on the MIT Indoor-67 dataset.

</details>


## 2012-09

<details>

<summary>2012-09-07 10:28:00 - Unilateral Antidotes to DNS Cache Poisoning</summary>

- *Amir Herzberg, Haya Shulman*

- `1209.1482v1` - [abs](http://arxiv.org/abs/1209.1482v1) - [pdf](http://arxiv.org/pdf/1209.1482v1)

> We investigate defenses against DNS cache poisoning focusing on mechanisms that can be readily deployed unilaterally by the resolving organisation, preferably in a single gateway or a proxy. DNS poisoning is (still) a major threat to Internet security; determined spoofing attackers are often able to circumvent currently deployed antidotes such as port randomisation. The adoption of DNSSEC, which would foil DNS poisoning, remains a long-term challenge. We discuss limitations of the prominent resolver-only defenses, mainly port and IP randomisation, 0x20 encoding and birthday protection. We then present two new (unilateral) defenses: the sandwich antidote and the NAT antidote. The defenses are simple, effective and efficient, and can be implemented in a gateway connecting the resolver to the Internet. The sandwich antidote is composed of two phases: poisoning-attack detection and then prevention. The NAT antidote adds entropy to DNS requests by switching the resolver's IP address to a random address (belonging to the same autonomous system). Finally, we show how to implement the birthday protection mechanism in the gateway, thus allowing to restrict the number of DNS requests with the same query to 1 even when the resolver does not support this.

</details>


## 2012-10

<details>

<summary>2012-10-01 09:20:39 - Statistical methods for tissue array images - algorithmic scoring and co-training</summary>

- *Donghui Yan, Pei Wang, Michael Linden, Beatrice Knudsen, Timothy Randolph*

- `1102.0059v2` - [abs](http://arxiv.org/abs/1102.0059v2) - [pdf](http://arxiv.org/pdf/1102.0059v2)

> Recent advances in tissue microarray technology have allowed immunohistochemistry to become a powerful medium-to-high throughput analysis tool, particularly for the validation of diagnostic and prognostic biomarkers. However, as study size grows, the manual evaluation of these assays becomes a prohibitive limitation; it vastly reduces throughput and greatly increases variability and expense. We propose an algorithm - Tissue Array Co-Occurrence Matrix Analysis (TACOMA) - for quantifying cellular phenotypes based on textural regularity summarized by local inter-pixel relationships. The algorithm can be easily trained for any staining pattern, is absent of sensitive tuning parameters and has the ability to report salient pixels in an image that contribute to its score. Pathologists' input via informative training patches is an important aspect of the algorithm that allows the training for any specific marker or cell type. With co-training, the error rate of TACOMA can be reduced substantially for a very small training sample (e.g., with size 30). We give theoretical insights into the success of co-training via thinning of the feature set in a high-dimensional setting when there is "sufficient" redundancy among the features. TACOMA is flexible, transparent and provides a scoring process that can be evaluated with clarity and confidence. In a study based on an estrogen receptor (ER) marker, we show that TACOMA is comparable to, or outperforms, pathologists' performance in terms of accuracy and repeatability.

</details>

<details>

<summary>2012-10-16 17:37:41 - Exploiting compositionality to explore a large space of model structures</summary>

- *Roger Grosse, Ruslan R Salakhutdinov, William T. Freeman, Joshua B. Tenenbaum*

- `1210.4856v1` - [abs](http://arxiv.org/abs/1210.4856v1) - [pdf](http://arxiv.org/pdf/1210.4856v1)

> The recent proliferation of richly structured probabilistic models raises the question of how to automatically determine an appropriate model for a dataset. We investigate this question for a space of matrix decomposition models which can express a variety of widely used models from unsupervised learning. To enable model selection, we organize these models into a context-free grammar which generates a wide variety of structures through the compositional application of a few simple rules. We use our grammar to generically and efficiently infer latent components and estimate predictive likelihood for nearly 2500 structures using a small toolbox of reusable algorithms. Using a greedy search over our grammar, we automatically choose the decomposition structure from raw data by evaluating only a small fraction of all models. The proposed method typically finds the correct structure for synthetic data and backs off gracefully to simpler models under heavy noise. It learns sensible structures for datasets as diverse as image patches, motion capture, 20 Questions, and U.S. Senate votes, all using exactly the same code.

</details>

<details>

<summary>2012-10-16 17:41:42 - Nested Dictionary Learning for Hierarchical Organization of Imagery and Text</summary>

- *Lingbo Li, XianXing Zhang, Mingyuan Zhou, Lawrence Carin*

- `1210.4872v1` - [abs](http://arxiv.org/abs/1210.4872v1) - [pdf](http://arxiv.org/pdf/1210.4872v1)

> A tree-based dictionary learning model is developed for joint analysis of imagery and associated text. The dictionary learning may be applied directly to the imagery from patches, or to general feature vectors extracted from patches or superpixels (using any existing method for image feature extraction). Each image is associated with a path through the tree (from root to a leaf), and each of the multiple patches in a given image is associated with one node in that path. Nodes near the tree root are shared between multiple paths, representing image characteristics that are common among different types of images. Moving toward the leaves, nodes become specialized, representing details in image classes. If available, words (text) are also jointly modeled, with a path-dependent probability over words. The tree structure is inferred via a nested Dirichlet process, and a retrospective stick-breaking sampler is used to infer the tree depth and width.

</details>


## 2012-11

<details>

<summary>2012-11-09 10:36:22 - Image denoising with multi-layer perceptrons, part 1: comparison with existing algorithms and with bounds</summary>

- *Harold Christopher Burger, Christian J. Schuler, Stefan Harmeling*

- `1211.1544v3` - [abs](http://arxiv.org/abs/1211.1544v3) - [pdf](http://arxiv.org/pdf/1211.1544v3)

> Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this mapping directly with plain multi layer perceptrons (MLP) applied to image patches. We will show that by training on large image databases we are able to outperform the current state-of-the-art image denoising methods. In addition, our method achieves results that are superior to one type of theoretical bound and goes a large way toward closing the gap with a second type of theoretical bound. Our approach is easily adapted to less extensively studied types of noise, such as mixed Poisson-Gaussian noise, JPEG artifacts, salt-and-pepper noise and noise resembling stripes, for which we achieve excellent results as well. We will show that combining a block-matching procedure with MLPs can further improve the results on certain images. In a second paper, we detail the training trade-offs and the inner mechanisms of our MLPs.

</details>

<details>

<summary>2012-11-17 09:15:07 - Implementing the Stochastics Brane Calculus in a Generic Stochastic Abstract Machine</summary>

- *Marino Miculan, Ilaria Sambarino*

- `1211.4094v1` - [abs](http://arxiv.org/abs/1211.4094v1) - [pdf](http://arxiv.org/pdf/1211.4094v1)

> In this paper, we deal with the problem of implementing an abstract machine for a stochastic version of the Brane Calculus. Instead of defining an ad hoc abstract machine, we consider the generic stochastic abstract machine introduced by Lakin, Paulev\'e and Phillips. The nested structure of membranes is flattened into a set of species where the hierarchical structure is represented by means of names. In order to reduce the overhead introduced by this encoding, we modify the machine by adding a copy-on-write optimization strategy. We prove that this implementation is adequate with respect to the stochastic structural operational semantics recently given for the Brane Calculus. These techniques can be ported also to other stochastic calculi dealing with nested structures.

</details>

<details>

<summary>2012-11-21 12:40:27 - Modeling Earthen Dike Stability: Sensitivity Analysis and Automatic Calibration of Diffusivities Based on Live Sensor Data</summary>

- *N. B. Melnikova, V. V. Krzhizhanovskaya, P. M. A. Sloot*

- `1211.4218v2` - [abs](http://arxiv.org/abs/1211.4218v2) - [pdf](http://arxiv.org/pdf/1211.4218v2)

> The paper describes concept and implementation details of integrating a finite element module for dike stability analysis Virtual Dike into an early warning system for flood protection. The module operates in real-time mode and includes fluid and structural sub-models for simulation of porous flow through the dike and for dike stability analysis. Real-time measurements obtained from pore pressure sensors are fed into the simulation module, to be compared with simulated pore pressure dynamics. Implementation of the module has been performed for a real-world test case - an earthen levee protecting a sea-port in Groningen, the Netherlands. Sensitivity analysis and calibration of diffusivities have been performed for tidal fluctuations. An algorithm for automatic diffusivities calibration for a heterogeneous dike is proposed and studied. Analytical solutions describing tidal propagation in one-dimensional saturated aquifer are employed in the algorithm to generate initial estimates of diffusivities.

</details>

