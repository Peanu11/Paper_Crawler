# 2020

## TOC

- [2020-01](#2020-01)
- [2020-02](#2020-02)
- [2020-03](#2020-03)
- [2020-04](#2020-04)
- [2020-05](#2020-05)
- [2020-06](#2020-06)
- [2020-07](#2020-07)
- [2020-08](#2020-08)
- [2020-09](#2020-09)
- [2020-10](#2020-10)
- [2020-11](#2020-11)
- [2020-12](#2020-12)

## 2020-01

<details>

<summary>2020-01-04 23:19:04 - A Study of Bug Resolution Characteristics in Popular Programming Languages</summary>

- *Jie M. Zhang, Feng Li, Dan Hao, Meng Wang, Hao Tang, Lu Zhang, Mark Harman*

- `1801.01025v2` - [abs](http://arxiv.org/abs/1801.01025v2) - [pdf](http://arxiv.org/pdf/1801.01025v2)

> This paper presents a large-scale study that investigates the bug resolution characteristics among popular Github projects written in different programming languages. We explore correlations but, of course, we cannot infer causation. Specifically, we analyse bug resolution data from approximately 70 million Source Line of Code, drawn from 3 million commits to 600 GitHub projects, primarily written in 10 programming languages. We find notable variations in apparent bug resolution time and patch (fix) size. While interpretation of results from such large-scale empirical studies is inherently difficult, we believe that the differences in medians are sufficiently large to warrant further investigation, replication, re-analysis and follow up research. For example, in our corpus, the median apparent bug resolution time (elapsed time from raise to resolve) for Ruby was 4X that for Go and 2.5X for Java. We also found that patches tend to touch more files for the corpus of strongly typed and for statically typed programs. However, we also found evidence for a lower elapsed resolution time for bug resolution committed to projects constructed from statically typed languages. These findings, if replicated in subsequent follow on studies, may shed further empirical light on the debate about the importance of static typing.

</details>

<details>

<summary>2020-01-05 06:28:59 - COCO-GAN: Generation by Parts via Conditional Coordinating</summary>

- *Chieh Hubert Lin, Chia-Che Chang, Yu-Sheng Chen, Da-Cheng Juan, Wei Wei, Hwann-Tzong Chen*

- `1904.00284v4` - [abs](http://arxiv.org/abs/1904.00284v4) - [pdf](http://arxiv.org/pdf/1904.00284v4)

> Humans can only interact with part of the surrounding environment due to biological restrictions. Therefore, we learn to reason the spatial relationships across a series of observations to piece together the surrounding environment. Inspired by such behavior and the fact that machines also have computational constraints, we propose \underline{CO}nditional \underline{CO}ordinate GAN (COCO-GAN) of which the generator generates images by parts based on their spatial coordinates as the condition. On the other hand, the discriminator learns to justify realism across multiple assembled patches by global coherence, local appearance, and edge-crossing continuity. Despite the full images are never generated during training, we show that COCO-GAN can produce \textbf{state-of-the-art-quality} full images during inference. We further demonstrate a variety of novel applications enabled by teaching the network to be aware of coordinates. First, we perform extrapolation to the learned coordinate manifold and generate off-the-boundary patches. Combining with the originally generated full image, COCO-GAN can produce images that are larger than training samples, which we called "beyond-boundary generation". We then showcase panorama generation within a cylindrical coordinate system that inherently preserves horizontally cyclic topology. On the computation side, COCO-GAN has a built-in divide-and-conquer paradigm that reduces memory requisition during training and inference, provides high-parallelism, and can generate parts of images on-demand.

</details>

<details>

<summary>2020-01-05 07:07:53 - Semantic Image Completion and Enhancement using Deep Learning</summary>

- *Vaishnav Chandak, Priyansh Saxena, Manisha Pattanaik, Gaurav Kaushal*

- `1911.02222v2` - [abs](http://arxiv.org/abs/1911.02222v2) - [pdf](http://arxiv.org/pdf/1911.02222v2)

> In real-life applications, certain images utilized are corrupted in which the image pixels are damaged or missing, which increases the complexity of computer vision tasks. In this paper, a deep learning architecture is proposed to deal with image completion and enhancement. Generative Adversarial Networks (GAN), has been turned out to be helpful in picture completion tasks. Therefore, in GANs, Wasserstein GAN architecture is used for image completion which creates the coarse patches to filling the missing region in the distorted picture, and the enhancement network will additionally refine the resultant pictures utilizing residual learning procedures and hence give better complete pictures for computer vision applications. Experimental outcomes show that the proposed approach improves the Peak Signal to Noise ratio and Structural Similarity Index values by 2.45% and 4% respectively when compared to the recently reported data.

</details>

<details>

<summary>2020-01-06 21:43:25 - Plug-and-Play Rescaling Based Crowd Counting in Static Images</summary>

- *Usman Sajid, Guanghui Wang*

- `2001.01786v1` - [abs](http://arxiv.org/abs/2001.01786v1) - [pdf](http://arxiv.org/pdf/2001.01786v1)

> Crowd counting is a challenging problem especially in the presence of huge crowd diversity across images and complex cluttered crowd-like background regions, where most previous approaches do not generalize well and consequently produce either huge crowd underestimation or overestimation. To address these challenges, we propose a new image patch rescaling module (PRM) and three independent PRM employed crowd counting methods. The proposed frameworks use the PRM module to rescale the image regions (patches) that require special treatment, whereas the classification process helps in recognizing and discarding any cluttered crowd-like background regions which may result in overestimation. Experiments on three standard benchmarks and cross-dataset evaluation show that our approach outperforms the state-of-the-art models in the RMSE evaluation metric with an improvement up to 10.4%, and possesses superior generalization ability to new datasets.

</details>

<details>

<summary>2020-01-13 20:59:14 - On Demand Solid Texture Synthesis Using Deep 3D Networks</summary>

- *Jorge Gutierrez, Julien Rabin, Bruno Galerne, Thomas Hurtut*

- `2001.04528v1` - [abs](http://arxiv.org/abs/2001.04528v1) - [pdf](http://arxiv.org/pdf/2001.04528v1)

> This paper describes a novel approach for on demand volumetric texture synthesis based on a deep learning framework that allows for the generation of high quality 3D data at interactive rates. Based on a few example images of textures, a generative network is trained to synthesize coherent portions of solid textures of arbitrary sizes that reproduce the visual characteristics of the examples along some directions. To cope with memory limitations and computation complexity that are inherent to both high resolution and 3D processing on the GPU, only 2D textures referred to as "slices" are generated during the training stage. These synthetic textures are compared to exemplar images via a perceptual loss function based on a pre-trained deep network. The proposed network is very light (less than 100k parameters), therefore it only requires sustainable training (i.e. few hours) and is capable of very fast generation (around a second for $256^3$ voxels) on a single GPU. Integrated with a spatially seeded PRNG the proposed generator network directly returns an RGB value given a set of 3D coordinates. The synthesized volumes have good visual results that are at least equivalent to the state-of-the-art patch based approaches. They are naturally seamlessly tileable and can be fully generated in parallel.

</details>

<details>

<summary>2020-01-16 17:09:15 - Elements of Scheduling</summary>

- *Jan Karel Lenstra, David B. Shmoys*

- `2001.06005v1` - [abs](http://arxiv.org/abs/2001.06005v1) - [pdf](http://arxiv.org/pdf/2001.06005v1)

> In the winter of 1976, Alexander Rinnooy Kan and Jan Karel Lenstra defended their PhD theses at the University of Amsterdam. Gene Lawler was on their committees. It was a natural idea to turn the theses into a textbook on scheduling. They set out to compile a survey with Ron Graham (1979), but progress on the book was hampered by the many research opportunities offered by the field. After David Shmoys joined the team in the mid 1980's, several chapters were drafted, and the survey was rewritten (1993). Gene passed away in 1994. Colleagues were asked to contribute chapters or to complete existing drafts. However, by the turn of the century the project was losing its momentum, and finite convergence to completion fell beyond our reach.   Over the years, several chapters have been used in the classroom. We continue to receive requests from colleagues who look for a text on the elements of scheduling at an advanced undergraduate or early graduate level. This document is a compilation of what currently exists. We have made a marginal effort in patching it up at some places but is essentially what was written long ago. We did make an attempt to include most of the citations in the bibliography.

</details>

<details>

<summary>2020-01-21 08:14:35 - Manifold Modeling in Embedded Space: A Perspective for Interpreting Deep Image Prior</summary>

- *Tatsuya Yokota, Hidekata Hontani, Qibin Zhao, Andrzej Cichocki*

- `1908.02995v2` - [abs](http://arxiv.org/abs/1908.02995v2) - [pdf](http://arxiv.org/pdf/1908.02995v2)

> Deep image prior (DIP), which utilizes a deep convolutional network (ConvNet) structure itself as an image prior, has attracted attentions in computer vision and machine learning communities. It empirically shows the effectiveness of ConvNet structure for various image restoration applications. However, why the DIP works so well is still unknown, and why convolution operation is useful for image reconstruction or enhancement is not very clear. In this study, we tackle these questions. The proposed approach is dividing the convolution into ``delay-embedding'' and ``transformation (\ie encoder-decoder)'', and proposing a simple, but essential, image/tensor modeling method which is closely related to dynamical systems and self-similarity. The proposed method named as manifold modeling in embedded space (MMES) is implemented by using a novel denoising-auto-encoder in combination with multi-way delay-embedding transform. In spite of its simplicity, the image/tensor completion, super-resolution, deconvolution, and denoising results of MMES are quite similar even competitive to DIP in our extensive experiments, and these results would help us for reinterpreting/characterizing the DIP from a perspective of ``low-dimensional patch-manifold prior''.

</details>

<details>

<summary>2020-01-22 11:52:58 - Neural Networks-based Regularization for Large-Scale Medical Image Reconstruction</summary>

- *Andreas Kofler, Markus Haltmeier, Tobias Schaeffter, Marc Kachelrieß, Marc Dewey, Christian Wald, Christoph Kolbitsch*

- `1912.09395v2` - [abs](http://arxiv.org/abs/1912.09395v2) - [pdf](http://arxiv.org/pdf/1912.09395v2)

> In this paper we present a generalized Deep Learning-based approach for solving ill-posed large-scale inverse problems occuring in medical image reconstruction. Recently, Deep Learning methods using iterative neural networks and cascaded neural networks have been reported to achieve state-of-the-art results with respect to various quantitative quality measures as PSNR, NRMSE and SSIM across different imaging modalities. However, the fact that these approaches employ the forward and adjoint operators repeatedly in the network architecture requires the network to process the whole images or volumes at once, which for some applications is computationally infeasible. In this work, we follow a different reconstruction strategy by decoupling the regularization of the solution from ensuring consistency with the measured data. The regularization is given in the form of an image prior obtained by the output of a previously trained neural network which is used in a Tikhonov regularization framework. By doing so, more complex and sophisticated network architectures can be used for the removal of the artefacts or noise than it is usually the case in iterative networks. Due to the large scale of the considered problems and the resulting computational complexity of the employed networks, the priors are obtained by processing the images or volumes as patches or slices. We evaluated the method for the cases of 3D cone-beam low dose CT and undersampled 2D radial cine MRI and compared it to a total variation-minimization-based reconstruction algorithm as well as to a method with regularization based on learned overcomplete dictionaries. The proposed method outperformed all the reported methods with respect to all chosen quantitative measures and further accelerates the regularization step in the reconstruction by several orders of magnitude.

</details>

<details>

<summary>2020-01-22 23:41:29 - Using a Generative Adversarial Network for CT Normalization and its Impact on Radiomic Features</summary>

- *Leihao Wei, Yannan Lin, William Hsu*

- `2001.08741v1` - [abs](http://arxiv.org/abs/2001.08741v1) - [pdf](http://arxiv.org/pdf/2001.08741v1)

> Computer-Aided-Diagnosis (CADx) systems assist radiologists with identifying and classifying potentially malignant pulmonary nodules on chest CT scans using morphology and texture-based (radiomic) features. However, radiomic features are sensitive to differences in acquisitions due to variations in dose levels and slice thickness. This study investigates the feasibility of generating a normalized scan from heterogeneous CT scans as input. We obtained projection data from 40 low-dose chest CT scans, simulating acquisitions at 10%, 25% and 50% dose and reconstructing the scans at 1.0mm and 2.0mm slice thickness. A 3D generative adversarial network (GAN) was used to simultaneously normalize reduced dose, thick slice (2.0mm) images to normal dose (100%), thinner slice (1.0mm) images. We evaluated the normalized image quality using peak signal-to-noise ratio (PSNR), structural similarity index (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS). Our GAN improved perceptual similarity by 35%, compared to a baseline CNN method. Our analysis also shows that the GAN-based approach led to a significantly smaller error (p-value < 0.05) in nine studied radiomic features. These results indicated that GANs could be used to normalize heterogeneous CT images and reduce the variability in radiomic feature values.

</details>

<details>

<summary>2020-01-23 05:44:11 - Adaptation of a deep learning malignancy model from full-field digital mammography to digital breast tomosynthesis</summary>

- *Sadanand Singh, Thomas Paul Matthews, Meet Shah, Brent Mombourquette, Trevor Tsue, Aaron Long, Ranya Almohsen, Stefano Pedemonte, Jason Su*

- `2001.08381v1` - [abs](http://arxiv.org/abs/2001.08381v1) - [pdf](http://arxiv.org/pdf/2001.08381v1)

> Mammography-based screening has helped reduce the breast cancer mortality rate, but has also been associated with potential harms due to low specificity, leading to unnecessary exams or procedures, and low sensitivity. Digital breast tomosynthesis (DBT) improves on conventional mammography by increasing both sensitivity and specificity and is becoming common in clinical settings. However, deep learning (DL) models have been developed mainly on conventional 2D full-field digital mammography (FFDM) or scanned film images. Due to a lack of large annotated DBT datasets, it is difficult to train a model on DBT from scratch. In this work, we present methods to generalize a model trained on FFDM images to DBT images. In particular, we use average histogram matching (HM) and DL fine-tuning methods to generalize a FFDM model to the 2D maximum intensity projection (MIP) of DBT images. In the proposed approach, the differences between the FFDM and DBT domains are reduced via HM and then the base model, which was trained on abundant FFDM images, is fine-tuned. When evaluating on image patches extracted around identified findings, we are able to achieve similar areas under the receiver operating characteristic curve (ROC AUC) of $\sim 0.9$ for FFDM and $\sim 0.85$ for MIP images, as compared to a ROC AUC of $\sim 0.75$ when tested directly on MIP images.

</details>

<details>

<summary>2020-01-24 18:58:50 - Learning to Catch Security Patches</summary>

- *Arthur D. Sawadogo, Tegawendé F. Bissyandé, Naouel Moha, Kevin Allix, Jacques Klein, Li Li, Yves Le Traon*

- `2001.09148v1` - [abs](http://arxiv.org/abs/2001.09148v1) - [pdf](http://arxiv.org/pdf/2001.09148v1)

> Timely patching is paramount to safeguard users and maintainers against dire consequences of malicious attacks. In practice, patching is prioritized following the nature of the code change that is committed in the code repository. When such a change is labeled as being security-relevant, i.e., as fixing a vulnerability, maintainers rapidly spread the change and users are notified about the need to update to a new version of the library or of the application. Unfortunately, oftentimes, some security-relevant changes go unnoticed as they represent silent fixes of vulnerabilities. In this paper, we propose a Co-Training-based approach to catch security patches as part of an automatic monitoring service of code repositories. Leveraging different classes of features, we empirically show that such automation is feasible and can yield a precision of over 90% in identifying security patches, with an unprecedented recall of over 80%. Beyond such a benchmarking with ground truth data which demonstrates an improvement over the state-of-the-art, we confirmed that our approach can help catch security patches that were not reported as such.

</details>

<details>

<summary>2020-01-31 10:57:59 - Unsupervised deep clustering for predictive texture pattern discovery in medical images</summary>

- *Matthias Perkonigg, Daniel Sobotka, Ahmed Ba-Ssalamah, Georg Langs*

- `2002.03721v1` - [abs](http://arxiv.org/abs/2002.03721v1) - [pdf](http://arxiv.org/pdf/2002.03721v1)

> Predictive marker patterns in imaging data are a means to quantify disease and progression, but their identification is challenging, if the underlying biology is poorly understood. Here, we present a method to identify predictive texture patterns in medical images in an unsupervised way. Based on deep clustering networks, we simultaneously encode and cluster medical image patches in a low-dimensional latent space. The resulting clusters serve as features for disease staging, linking them to the underlying disease. We evaluate the method on 70 T1-weighted magnetic resonance images of patients with different stages of liver steatosis. The deep clustering approach is able to find predictive clusters with a stable ranking, differentiating between low and high steatosis with an F1-Score of 0.78.

</details>


## 2020-02

<details>

<summary>2020-02-03 10:57:24 - Volumetric Lung Nodule Segmentation using Adaptive ROI with Multi-View Residual Learning</summary>

- *Muhammad Usman, Byoung-Dai Lee, Shi Sub Byon, Sung Hyun Kim, Byung-ilLee*

- `1912.13335v2` - [abs](http://arxiv.org/abs/1912.13335v2) - [pdf](http://arxiv.org/pdf/1912.13335v2)

> Accurate quantification of pulmonary nodules can greatly assist the early diagnosis of lung cancer, which can enhance patient survival possibilities. A number of nodule segmentation techniques have been proposed, however, all of the existing techniques rely on radiologist 3-D volume of interest (VOI) input or use the constant region of interest (ROI) and only investigate the presence of nodule voxels within the given VOI. Such approaches restrain the solutions to investigate the nodule presence outside the given VOI and also include the redundant structures into VOI, which may lead to inaccurate nodule segmentation. In this work, a novel semi-automated approach for 3-D segmentation of nodule in volumetric computerized tomography (CT) lung scans has been proposed. The proposed technique can be segregated into two stages, at the first stage, it takes a 2-D ROI containing the nodule as input and it performs patch-wise investigation along the axial axis with a novel adaptive ROI strategy. The adaptive ROI algorithm enables the solution to dynamically select the ROI for the surrounding slices to investigate the presence of nodule using deep residual U-Net architecture. The first stage provides the initial estimation of nodule which is further utilized to extract the VOI. At the second stage, the extracted VOI is further investigated along the coronal and sagittal axis with two different networks and finally, all the estimated masks are fed into the consensus module to produce the final volumetric segmentation of nodule. The proposed approach has been rigorously evaluated on the LIDC dataset, which is the largest publicly available dataset. The result suggests that the approach is significantly robust and accurate as compared to the previous state of the art techniques.

</details>

<details>

<summary>2020-02-04 19:34:34 - Bicycle Attacks Considered Harmful: Quantifying the Damage of Widespread Password Length Leakage</summary>

- *Benjamin Harsha, Robert Morton, Jeremiah Blocki, John Springer, Melissa Dark*

- `2002.01513v1` - [abs](http://arxiv.org/abs/2002.01513v1) - [pdf](http://arxiv.org/pdf/2002.01513v1)

> We examine the issue of password length leakage via encrypted traffic i.e., bicycle attacks. We aim to quantify both the prevalence of password length leakage bugs as well as the potential harm to users. In an observational study, we find that {\em most} of the Alexa top 100 rates sites are vulnerable to bicycle attacks meaning that an eavesdropping attacker can infer the exact length of a password based on the length the encrypted packet containing the password. We discuss several ways in which an eavesdropping attacker could link this password length with a particular user account e.g., a targeted campaign against a smaller group of users or via DNS hijacking for larger scale campaigns. We next use a decision-theoretic model to quantify the extent to which password length leakage might help an attacker to crack user passwords. In our analysis, we consider three different levels of password attackers: hacker, criminal and nation-state. In all cases, we find that such an attacker who knows the length of each user password gains a significant advantage over one without knowing the password length. As part of this analysis, we also release a new differentially private password frequency dataset from the 2016 LinkedIn breach using a differentially private algorithm of Blocki et al. (NDSS 2016) to protect user accounts. The LinkedIn frequency corpus is based on over 170 million passwords making it the largest frequency corpus publicly available to password researchers. While the defense against bicycle attacks is straightforward (i.e., ensure that passwords are always padded before encryption), we discuss several practical challenges organizations may face when attempting to patch this vulnerability. We advocate for a new W3C standard on how password fields are handled which would effectively eliminate most instances of password length leakage.

</details>

<details>

<summary>2020-02-07 17:03:50 - Ensembles of Locally Independent Prediction Models</summary>

- *Andrew Slavin Ross, Weiwei Pan, Leo Anthony Celi, Finale Doshi-Velez*

- `1911.01291v3` - [abs](http://arxiv.org/abs/1911.01291v3) - [pdf](http://arxiv.org/pdf/1911.01291v3)

> Ensembles depend on diversity for improved performance. Many ensemble training methods, therefore, attempt to optimize for diversity, which they almost always define in terms of differences in training set predictions. In this paper, however, we demonstrate the diversity of predictions on the training set does not necessarily imply diversity under mild covariate shift, which can harm generalization in practical settings. To address this issue, we introduce a new diversity metric and associated method of training ensembles of models that extrapolate differently on local patches of the data manifold. Across a variety of synthetic and real-world tasks, we find that our method improves generalization and diversity in qualitatively novel ways, especially under data limits and covariate shift.

</details>

<details>

<summary>2020-02-08 01:40:57 - Generation of smoothly-varying infill configurations from a continuous menu of cell patterns and the asymptotic analysis of its mechanical behaviour</summary>

- *Dingchuan Xue, Yichao Zhu, Xu Guo*

- `2002.01894v2` - [abs](http://arxiv.org/abs/2002.01894v2) - [pdf](http://arxiv.org/pdf/2002.01894v2)

> We here introduce a novel scheme for generating smoothly-varying infill graded microstructural (IGM) configurations from a given menu of generating cells. The scheme was originally proposed for essentially improving the variety of describable configurations in a modified asymptotic homogenisation-based topology optimisation framework [1] for fast IGM design. But the proposed scheme, after modification, also demonstrates its unique values in two aspects of applications. First, it provides a fairly simple way of generating an IGM configuration continuously patching any given cell configurations. Second, it tenders a straightforward mean for decorating microstructures on a given manifold. We will further show that the form of topology description function given here effectively offers a platform for unifying most existing approaches for IGM generation. Fuelled by asymptotic analysis of the mechanical behaviour of the resulting IGM configurations, a topology optimisation scheme for compliance minimisation is introduced. We will finally show that, the use of the present scheme helps reduce the compliance value of an optimised structure by nearly a half, if compared with that from the original framework [1].

</details>

<details>

<summary>2020-02-08 20:27:07 - Free-breathing Cardiovascular MRI Using a Plug-and-Play Method with Learned Denoiser</summary>

- *Sizhuo Liu, Edward Reehorst, Philip Schniter, Rizwan Ahmad*

- `2002.03226v1` - [abs](http://arxiv.org/abs/2002.03226v1) - [pdf](http://arxiv.org/pdf/2002.03226v1)

> Cardiac magnetic resonance imaging (CMR) is a noninvasive imaging modality that provides a comprehensive evaluation of the cardiovascular system. The clinical utility of CMR is hampered by long acquisition times, however. In this work, we propose and validate a plug-and-play (PnP) method for CMR reconstruction from undersampled multi-coil data. To fully exploit the rich image structure inherent in CMR, we pair the PnP framework with a deep learning (DL)-based denoiser that is trained using spatiotemporal patches from high-quality, breath-held cardiac cine images. The resulting "PnP-DL" method iterates over data consistency and denoising subroutines. We compare the reconstruction performance of PnP-DL to that of compressed sensing (CS) using eight breath-held and ten real-time (RT) free-breathing cardiac cine datasets. We find that, for breath-held datasets, PnP-DL offers more than one dB advantage over commonly used CS methods. For RT free-breathing datasets, where ground truth is not available, PnP-DL receives higher scores in qualitative evaluation. The results highlight the potential of PnP-DL to accelerate RT CMR.

</details>

<details>

<summary>2020-02-10 14:47:20 - Unsupervised Adaptive Neural Network Regularization for Accelerated Radial Cine MRI</summary>

- *Andreas Kofler, Marc Dewey, Tobias Schaeffter, Christoph Kolbitsch, Markus Haltmeier*

- `2002.03820v1` - [abs](http://arxiv.org/abs/2002.03820v1) - [pdf](http://arxiv.org/pdf/2002.03820v1)

> In this work, we propose an iterative reconstruction scheme (ALONE - Adaptive Learning Of NEtworks) for 2D radial cine MRI based on ground truth-free unsupervised learning of shallow convolutional neural networks. The network is trained to approximate patches of the current estimate of the solution during the reconstruction. By imposing a shallow network topology and constraining the $L_2$-norm of the learned filters, the network's representation power is limited in order not to be able to recover noise. Therefore, the network can be interpreted to perform a low dimensional approximation of the patches for stabilizing the inversion process. We compare the proposed reconstruction scheme to two ground truth-free reconstruction methods, namely a well known Total Variation (TV) minimization and an unsupervised adaptive Dictionary Learning (DIC) method. The proposed method outperforms both methods with respect to all reported quantitative measures. Further, in contrast to DIC, where the sparse approximation of the patches involves the solution of a complex optimization problem, ALONE only requires a forward pass of all patches through the shallow network and therefore significantly accelerates the reconstruction.

</details>

<details>

<summary>2020-02-15 10:01:40 - Prediction and optimization of NaV1.7 inhibitors based on machine learning methods</summary>

- *Weikaixin Kong, Xinyu Tu, Zhengwei Xie, Zhuo Huang*

- `1912.05903v2` - [abs](http://arxiv.org/abs/1912.05903v2) - [pdf](http://arxiv.org/pdf/1912.05903v2)

> We used machine learning methods to predict NaV1.7 inhibitors and found the model RF-CDK that performed best on the imbalanced dataset. Using the RF-CDK model for screening drugs, we got effective compounds K1. We use the cell patch clamp method to verify K1. However, because the model evaluation method in this article is not comprehensive enough, there is still a lot of research work to be performed, such as comparison with other existing methods.   The target protein has multiple active sites and requires our further research. We need more detailed models to consider this biological process and compare it with the current results, which is an error in this article.   So we want to withdraw this article.

</details>

<details>

<summary>2020-02-16 10:29:16 - Breast Cancer Histopathology Image Classification and Localization using Multiple Instance Learning</summary>

- *Abhijeet Patil, Dipesh Tamboli, Swati Meena, Deepak Anand, Amit Sethi*

- `2003.00823v1` - [abs](http://arxiv.org/abs/2003.00823v1) - [pdf](http://arxiv.org/pdf/2003.00823v1)

> Breast cancer has the highest mortality among cancers in women. Computer-aided pathology to analyze microscopic histopathology images for diagnosis with an increasing number of breast cancer patients can bring the cost and delays of diagnosis down. Deep learning in histopathology has attracted attention over the last decade of achieving state-of-the-art performance in classification and localization tasks. The convolutional neural network, a deep learning framework, provides remarkable results in tissue images analysis, but lacks in providing interpretation and reasoning behind the decisions. We aim to provide a better interpretation of classification results by providing localization on microscopic histopathology images. We frame the image classification problem as weakly supervised multiple instance learning problem where an image is collection of patches i.e. instances. Attention-based multiple instance learning (A-MIL) learns attention on the patches from the image to localize the malignant and normal regions in an image and use them to classify the image. We present classification and localization results on two publicly available BreakHIS and BACH dataset. The classification and visualization results are compared with other recent techniques. The proposed method achieves better localization results without compromising classification accuracy.

</details>

<details>

<summary>2020-02-18 00:39:49 - TensorShield: Tensor-based Defense Against Adversarial Attacks on Images</summary>

- *Negin Entezari, Evangelos E. Papalexakis*

- `2002.10252v1` - [abs](http://arxiv.org/abs/2002.10252v1) - [pdf](http://arxiv.org/pdf/2002.10252v1)

> Recent studies have demonstrated that machine learning approaches like deep neural networks (DNNs) are easily fooled by adversarial attacks. Subtle and imperceptible perturbations of the data are able to change the result of deep neural networks. Leveraging vulnerable machine learning methods raises many concerns especially in domains where security is an important factor. Therefore, it is crucial to design defense mechanisms against adversarial attacks. For the task of image classification, unnoticeable perturbations mostly occur in the high-frequency spectrum of the image. In this paper, we utilize tensor decomposition techniques as a preprocessing step to find a low-rank approximation of images which can significantly discard high-frequency perturbations. Recently a defense framework called Shield could "vaccinate" Convolutional Neural Networks (CNN) against adversarial examples by performing random-quality JPEG compressions on local patches of images on the ImageNet dataset. Our tensor-based defense mechanism outperforms the SLQ method from Shield by 14% against FastGradient Descent (FGSM) adversarial attacks, while maintaining comparable speed.

</details>

<details>

<summary>2020-02-18 11:11:02 - An Empirical Assessment of Security Risks of Global Android Banking Apps</summary>

- *Sen Chen, Lingling Fan, Guozhu Meng, Ting Su, Minhui Xue, Yinxing Xue, Yang Liu, Lihua Xu*

- `1805.05236v5` - [abs](http://arxiv.org/abs/1805.05236v5) - [pdf](http://arxiv.org/pdf/1805.05236v5)

> Mobile banking apps, belonging to the most security-critical app category, render massive and dynamic transactions susceptible to security risks. Given huge potential financial loss caused by vulnerabilities, existing research lacks a comprehensive empirical study on the security risks of global banking apps to provide useful insights and improve the security of banking apps.   Since data-related weaknesses in banking apps are critical and may directly cause serious financial loss, this paper first revisits the state-of-the-art available tools and finds that they have limited capability in identifying data-related security weaknesses of banking apps. To complement the capability of existing tools in data-related weakness detection, we propose a three-phase automated security risk assessment system, named AUSERA, which leverages static program analysis techniques and sensitive keyword identification. By leveraging AUSERA, we collect 2,157 weaknesses in 693 real-world banking apps across 83 countries, which we use as a basis to conduct a comprehensive empirical study from different aspects, such as global distribution and weakness evolution during version updates. We find that apps owned by subsidiary banks are always less secure than or equivalent to those owned by parent banks. In addition, we also track the patching of weaknesses and receive much positive feedback from banking entities so as to improve the security of banking apps in practice. To date, we highlight that 21 banks have confirmed the weaknesses we reported. We also exchange insights with 7 banks, such as HSBC in UK and OCBC in Singapore, via in-person or online meetings to help them improve their apps. We hope that the insights developed in this paper will inform the communities about the gaps among multiple stakeholders, including banks, academic researchers, and third-party security companies.

</details>

<details>

<summary>2020-02-19 14:28:35 - Ada-LISTA: Learned Solvers Adaptive to Varying Models</summary>

- *Aviad Aberdam, Alona Golts, Michael Elad*

- `2001.08456v2` - [abs](http://arxiv.org/abs/2001.08456v2) - [pdf](http://arxiv.org/pdf/2001.08456v2)

> Neural networks that are based on unfolding of an iterative solver, such as LISTA (learned iterative soft threshold algorithm), are widely used due to their accelerated performance. Nevertheless, as opposed to non-learned solvers, these networks are trained on a certain dictionary, and therefore they are inapplicable for varying model scenarios. This work introduces an adaptive learned solver, termed Ada-LISTA, which receives pairs of signals and their corresponding dictionaries as inputs, and learns a universal architecture to serve them all. We prove that this scheme is guaranteed to solve sparse coding in linear rate for varying models, including dictionary perturbations and permutations. We also provide an extensive numerical study demonstrating its practical adaptation capabilities. Finally, we deploy Ada-LISTA to natural image inpainting, where the patch-masks vary spatially, thus requiring such an adaptation.

</details>

<details>

<summary>2020-02-19 19:28:11 - A subtractive manufacturing constraint for level set topology optimization</summary>

- *Nigel Morris, Adrian Butscher, Francesco Iorio*

- `2002.10246v1` - [abs](http://arxiv.org/abs/2002.10246v1) - [pdf](http://arxiv.org/pdf/2002.10246v1)

> We present a method for enforcing manufacturability constraints in generated parts such that they will be automatically ready for fabrication using a subtractive approach. We primarily target multi-axis CNC milling approaches but the method should generalize to other subtractive methods as well. To this end, we take as user input: the radius of curvature of the tool bit, a coarse model of the tool head and optionally a set of milling directions. This allows us to enforce the following manufacturability conditions: 1) surface smoothness such that the radius of curvature of the part does not exceed the milling bit radius, 2) orientation such that every part of the surface to be milled is visible from at least one milling direction, 3) accessibility such that every surface patch can be reached by the tool bit without interference with the tool or head mount. We will show how to efficiently enforce the constraint during level set-based topology optimization modifying the advection velocity such that at each iteration the topology optimization maintains a descent optimization direction and does not violate any of the manufacturability conditions. This approach models the actual subtractive process by carving away material accessible to the machine at each iteration until a local optimum is achieved.

</details>

<details>

<summary>2020-02-19 21:12:49 - SD-GAN: Structural and Denoising GAN reveals facial parts under occlusion</summary>

- *Samik Banerjee, Sukhendu Das*

- `2002.08448v1` - [abs](http://arxiv.org/abs/2002.08448v1) - [pdf](http://arxiv.org/pdf/2002.08448v1)

> Certain facial parts are salient (unique) in appearance, which substantially contribute to the holistic recognition of a subject. Occlusion of these salient parts deteriorates the performance of face recognition algorithms. In this paper, we propose a generative model to reconstruct the missing parts of the face which are under occlusion. The proposed generative model (SD-GAN) reconstructs a face preserving the illumination variation and identity of the face. A novel adversarial training algorithm has been designed for a bimodal mutually exclusive Generative Adversarial Network (GAN) model, for faster convergence. A novel adversarial "structural" loss function is also proposed, comprising of two components: a holistic and a local loss, characterized by SSIM and patch-wise MSE. Ablation studies on real and synthetically occluded face datasets reveal that our proposed technique outperforms the competing methods by a considerable margin, even for boosting the performance of Face Recognition.

</details>

<details>

<summary>2020-02-19 21:35:51 - A Recurrent Neural Network Based Patch Recommender for Linux Kernel Bugs</summary>

- *Anusha Bableshwar, Arun Ravindran, Manoj Iyer*

- `2002.08454v1` - [abs](http://arxiv.org/abs/2002.08454v1) - [pdf](http://arxiv.org/pdf/2002.08454v1)

> Software bugs in a production environment have an undesirable impact on quality of service, unplanned system downtime, and disruption in good customer experience, resulting in loss of revenue and reputation. Existing approaches to automated software bug repair focuses on known bug templates detected using static code analysis tools and test suites, and in automatic generation of patch code for these bugs. We describe the typical bug fixing process employed in the Linux kernel, and motivate the need for a new automated tool flow to fix bugs. We present an initial design of such an automated tool that uses Recurrent Neural Network (RNN) based Natural Language Processing to generate patch recommendations from user generated bug reports. At the 50th percentile of the test bugs, the correct patch occurs within the top 11.5 patch recommendations output by the model. Further, we present a Linux kernel developer's assessment of the quality of patches recommended for new unresolved kernel bugs.

</details>

<details>

<summary>2020-02-20 17:57:06 - Deep Multi-Facial Patches Aggregation Network For Facial Expression Recognition</summary>

- *Ahmed Rachid Hazourli, Amine Djeghri, Hanan Salam, Alice Othmani*

- `2002.09298v1` - [abs](http://arxiv.org/abs/2002.09298v1) - [pdf](http://arxiv.org/pdf/2002.09298v1)

> In this paper, we propose an approach for Facial Expressions Recognition (FER) based on a deep multi-facial patches aggregation network. Deep features are learned from facial patches using deep sub-networks and aggregated within one deep architecture for expression classification . Several problems may affect the performance of deep-learning based FER approaches, in particular, the small size of existing FER datasets which might not be sufficient to train large deep learning networks. Moreover, it is extremely time-consuming to collect and annotate a large number of facial images. To account for this, we propose two data augmentation techniques for facial expression generation to expand FER labeled training datasets. We evaluate the proposed framework on three FER datasets. Results show that the proposed approach achieves state-of-art FER deep learning approaches performance when the model is trained and tested on images from the same dataset. Moreover, the proposed data augmentation techniques improve the expression recognition rate, and thus can be a solution for training deep learning FER models using small datasets. The accuracy degrades significantly when testing for dataset bias.

</details>

<details>

<summary>2020-02-22 05:25:07 - An Empirical Study of Android Security Bulletins in Different Vendors</summary>

- *Sadegh Farhang, Mehmet Bahadir Kirdan, Aron Laszka, Jens Grossklags*

- `2002.09629v1` - [abs](http://arxiv.org/abs/2002.09629v1) - [pdf](http://arxiv.org/pdf/2002.09629v1)

> Mobile devices encroach on almost every part of our lives, including work and leisure, and contain a wealth of personal and sensitive information. It is, therefore, imperative that these devices uphold high security standards. A key aspect is the security of the underlying operating system. In particular, Android plays a critical role due to being the most dominant platform in the mobile ecosystem with more than one billion active devices and due to its openness, which allows vendors to adopt and customize it. Similar to other platforms, Android maintains security by providing monthly security patches and announcing them via the Android security bulletin. To absorb this information successfully across the Android ecosystem, impeccable coordination by many different vendors is required.   In this paper, we perform a comprehensive study of 3,171 Android-related vulnerabilities and study to which degree they are reflected in the Android security bulletin, as well as in the security bulletins of three leading vendors: Samsung, LG, and Huawei. In our analysis, we focus on the metadata of these security bulletins (e.g., timing, affected layers, severity, and CWE data) to better understand the similarities and differences among vendors. We find that (i) the studied vendors in the Android ecosystem have adopted different structures for vulnerability reporting, (ii) vendors are less likely to react with delay for CVEs with Android Git repository references, (iii) vendors handle Qualcomm-related CVEs differently from the rest of external layer CVEs.

</details>

<details>

<summary>2020-02-24 11:52:19 - Deep Multi-Facial patches Aggregation Network for Expression Classification from Face Images</summary>

- *Amine Djerghri, Ahmed Rachid Hazourli, Alice Othmani*

- `1909.10305v2` - [abs](http://arxiv.org/abs/1909.10305v2) - [pdf](http://arxiv.org/pdf/1909.10305v2)

> Emotional Intelligence in Human-Computer Interaction has attracted increasing attention from researchers in multidisciplinary research fields including psychology, computer vision, neuroscience, artificial intelligence, and related disciplines. Human prone to naturally interact with computers face-to-face. Human Expressions is an important key to better link human and computers. Thus, designing interfaces able to understand human expressions and emotions can improve Human-Computer Interaction (HCI) for better communication. In this paper, we investigate HCI via a deep multi-facial patches aggregation network for Face Expression Recognition (FER). Deep features are extracted from facial parts and aggregated for expression classification. Several problems may affect the performance of the proposed framework like the small size of FER datasets and the high number of parameters to learn. For That, two data augmentation techniques are proposed for facial expression generation to expand the labeled training. The proposed framework is evaluated on the extended Cohn-Konade dataset (CK+) and promising results are achieved.

</details>

<details>

<summary>2020-02-27 16:57:04 - ZoomCount: A Zooming Mechanism for Crowd Counting in Static Images</summary>

- *Usman Sajid, Hasan Sajid, Hongcheng Wang, Guanghui Wang*

- `2002.12256v1` - [abs](http://arxiv.org/abs/2002.12256v1) - [pdf](http://arxiv.org/pdf/2002.12256v1)

> This paper proposes a novel approach for crowd counting in low to high density scenarios in static images. Current approaches cannot handle huge crowd diversity well and thus perform poorly in extreme cases, where the crowd density in different regions of an image is either too low or too high, leading to crowd underestimation or overestimation. The proposed solution is based on the observation that detecting and handling such extreme cases in a specialized way leads to better crowd estimation. Additionally, existing methods find it hard to differentiate between the actual crowd and the cluttered background regions, resulting in further count overestimation. To address these issues, we propose a simple yet effective modular approach, where an input image is first subdivided into fixed-size patches and then fed to a four-way classification module labeling each image patch as low, medium, high-dense or no-crowd. This module also provides a count for each label, which is then analyzed via a specifically devised novel decision module to decide whether the image belongs to any of the two extreme cases (very low or very high density) or a normal case. Images, specified as high- or low-density extreme or a normal case, pass through dedicated zooming or normal patch-making blocks respectively before routing to the regressor in the form of fixed-size patches for crowd estimate. Extensive experimental evaluations demonstrate that the proposed approach outperforms the state-of-the-art methods on four benchmarks under most of the evaluation criteria.

</details>

<details>

<summary>2020-02-28 07:57:56 - Regional Registration of Whole Slide Image Stacks Containing Highly Deformed Artefacts</summary>

- *Mahsa Paknezhad, Sheng Yang Michael Loh, Yukti Choudhury, Valerie Koh Cui Koh, TimothyTay Kwang Yong, Hui Shan Tan, Ravindran Kanesvaran, Puay Hoon Tan, John Yuen Shyi Peng, Weimiao Yu, Yongcheng Benjamin Tan, Yong Zhen Loy, Min-Han Tan, Hwee Kuan Lee*

- `2002.12588v1` - [abs](http://arxiv.org/abs/2002.12588v1) - [pdf](http://arxiv.org/pdf/2002.12588v1)

> Motivation: High resolution 2D whole slide imaging provides rich information about the tissue structure. This information can be a lot richer if these 2D images can be stacked into a 3D tissue volume. A 3D analysis, however, requires accurate reconstruction of the tissue volume from the 2D image stack. This task is not trivial due to the distortions that each individual tissue slice experiences while cutting and mounting the tissue on the glass slide. Performing registration for the whole tissue slices may be adversely affected by the deformed tissue regions. Consequently, regional registration is found to be more effective. In this paper, we propose an accurate and robust regional registration algorithm for whole slide images which incrementally focuses registration on the area around the region of interest. Results: Using mean similarity index as the metric, the proposed algorithm (mean $\pm$ std: $0.84 \pm 0.11$) followed by a fine registration algorithm ($0.86 \pm 0.08$) outperformed the state-of-the-art linear whole tissue registration algorithm ($0.74 \pm 0.19$) and the regional version of this algorithm ($0.81 \pm 0.15$). The proposed algorithm also outperforms the state-of-the-art nonlinear registration algorithm (original : $0.82 \pm 0.12$, regional : $0.77 \pm 0.22$) for whole slide images and a recently proposed patch-based registration algorithm (patch size 256: $0.79 \pm 0.16$ , patch size 512: $0.77 \pm 0.16$) for medical images. Availability: The C++ implementation code is available online at the github repository: https://github.com/MahsaPaknezhad/WSIRegistration

</details>


## 2020-03

<details>

<summary>2020-03-03 20:35:25 - Security of Deep Learning based Lane Keeping System under Physical-World Adversarial Attack</summary>

- *Takami Sato, Junjie Shen, Ningfei Wang, Yunhan Jack Jia, Xue Lin, Qi Alfred Chen*

- `2003.01782v1` - [abs](http://arxiv.org/abs/2003.01782v1) - [pdf](http://arxiv.org/pdf/2003.01782v1)

> Lane-Keeping Assistance System (LKAS) is convenient and widely available today, but also extremely security and safety critical. In this work, we design and implement the first systematic approach to attack real-world DNN-based LKASes. We identify dirty road patches as a novel and domain-specific threat model for practicality and stealthiness. We formulate the attack as an optimization problem, and address the challenge from the inter-dependencies among attacks on consecutive camera frames. We evaluate our approach on a state-of-the-art LKAS and our preliminary results show that our attack can successfully cause it to drive off lane boundaries within as short as 1.3 seconds.

</details>

<details>

<summary>2020-03-04 03:20:21 - Weighted Encoding Based Image Interpolation With Nonlocal Linear Regression Model</summary>

- *Junchao Zhang*

- `2003.04811v1` - [abs](http://arxiv.org/abs/2003.04811v1) - [pdf](http://arxiv.org/pdf/2003.04811v1)

> Image interpolation is a special case of image super-resolution, where the low-resolution image is directly down-sampled from its high-resolution counterpart without blurring and noise. Therefore, assumptions adopted in super-resolution models are not valid for image interpolation. To address this problem, we propose a novel image interpolation model based on sparse representation. Two widely used priors including sparsity and nonlocal self-similarity are used as the regularization terms to enhance the stability of interpolation model. Meanwhile, we incorporate the nonlocal linear regression into this model since nonlocal similar patches could provide a better approximation to a given patch. Moreover, we propose a new approach to learn adaptive sub-dictionary online instead of clustering. For each patch, similar patches are grouped to learn adaptive sub-dictionary, generating a more sparse and accurate representation. Finally, the weighted encoding is introduced to suppress tailing of fitting residuals in data fidelity. Abundant experimental results demonstrate that our proposed method outperforms several state-of-the-art methods in terms of quantitative measures and visual quality.

</details>

<details>

<summary>2020-03-05 07:57:53 - Structured Compression by Weight Encryption for Unstructured Pruning and Quantization</summary>

- *Se Jung Kwon, Dongsoo Lee, Byeongwook Kim, Parichay Kapoor, Baeseong Park, Gu-Yeon Wei*

- `1905.10138v2` - [abs](http://arxiv.org/abs/1905.10138v2) - [pdf](http://arxiv.org/pdf/1905.10138v2)

> Model compression techniques, such as pruning and quantization, are becoming increasingly important to reduce the memory footprints and the amount of computations. Despite model size reduction, achieving performance enhancement on devices is, however, still challenging mainly due to the irregular representations of sparse matrix formats. This paper proposes a new weight representation scheme for Sparse Quantized Neural Networks, specifically achieved by fine-grained and unstructured pruning method. The representation is encrypted in a structured regular format, which can be efficiently decoded through XOR-gate network during inference in a parallel manner. We demonstrate various deep learning models that can be compressed and represented by our proposed format with fixed and high compression ratio. For example, for fully-connected layers of AlexNet on ImageNet dataset, we can represent the sparse weights by only 0.28 bits/weight for 1-bit quantization and 91% pruning rate with a fixed decoding rate and full memory bandwidth usage. Decoding through XOR-gate network can be performed without any model accuracy degradation with additional patch data associated with small overhead.

</details>

<details>

<summary>2020-03-09 16:12:39 - Z-Net: an Anisotropic 3D DCNN for Medical CT Volume Segmentation</summary>

- *Peichao Li, Xiao-Yun Zhou, Zhao-Yang Wang, Guang-Zhong Yang*

- `1909.07480v2` - [abs](http://arxiv.org/abs/1909.07480v2) - [pdf](http://arxiv.org/pdf/1909.07480v2)

> Accurate volume segmentation from the Computed Tomography (CT) scan is a common prerequisite for pre-operative planning, intra-operative guidance and quantitative assessment of therapeutic outcomes in robot-assisted Minimally Invasive Surgery (MIS). 3D Deep Convolutional Neural Network (DCNN) is a viable solution for this task, but is memory intensive. Small isotropic patches are cropped from the original and large CT volume to mitigate this issue in practice, but it may cause discontinuities between the adjacent patches and severe class-imbalances within individual sub-volumes. This paper presents a new 3D DCNN framework, namely Z-Net, to tackle the discontinuity and class-imbalance issue by preserving a full field-of-view of the objects in the XY planes using anisotropic spatial separable convolutions. The proposed Z-Net can be seamlessly integrated into existing 3D DCNNs with isotropic convolutions such as 3D U-Net and V-Net, with improved volume segmentation Intersection over Union (IoU) - up to $12.6\%$. Detailed validation of Z-Net is provided for CT aortic, liver and lung segmentation, demonstrating the effectiveness and practical value of Z-Net for intra-operative 3D navigation in robot-assisted MIS.

</details>

<details>

<summary>2020-03-12 05:03:46 - CC2Vec: Distributed Representations of Code Changes</summary>

- *Thong Hoang, Hong Jin Kang, Julia Lawall, David Lo*

- `2003.05620v1` - [abs](http://arxiv.org/abs/2003.05620v1) - [pdf](http://arxiv.org/pdf/2003.05620v1)

> Existing work on software patches often use features specific to a single task. These works often rely on manually identified features, and human effort is required to identify these features for each task. In this work, we propose CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes. CC2Vec models the hierarchical structure of a code change with the help of the attention mechanism and uses multiple comparison functions to identify the differences between the removed and added code.   To evaluate if CC2Vec can produce a distributed representation of code changes that is general and useful for multiple tasks on software patches, we use the vectors produced by CC2Vec for three tasks: log message generation, bug fixing patch identification, and just-in-time defect prediction. In all tasks, the models using CC2Vec outperform the state-of-the-art techniques.

</details>

<details>

<summary>2020-03-14 01:25:46 - Boundary Guidance Hierarchical Network for Real-Time Tongue Segmentation</summary>

- *Xinyi Zeng, Qian Zhang, Jia Chen, Guixu Zhang, Aimin Zhou, Yiqin Wang*

- `2003.06529v1` - [abs](http://arxiv.org/abs/2003.06529v1) - [pdf](http://arxiv.org/pdf/2003.06529v1)

> Automated tongue image segmentation in tongue images is a challenging task for two reasons: 1) there are many pathological details on the tongue surface, which affect the extraction of the boundary; 2) the shapes of the tongues captured from various persons (with different diseases) are quite different. To deal with the challenge, a novel end-to-end Boundary Guidance Hierarchical Network (BGHNet) with a new hybrid loss is proposed in this paper. In the new approach, firstly Context Feature Encoder Module (CFEM) is built upon the bottomup pathway to confront with the shrinkage of the receptive field. Secondly, a novel hierarchical recurrent feature fusion module (HRFFM) is adopt to progressively and hierarchically refine object maps to recover image details by integrating local context information. Finally, the proposed hybrid loss in a four hierarchy-pixel, patch, map and boundary guides the network to effectively segment the tongue regions and accurate tongue boundaries. BGHNet is applied to a set of tongue images. The experimental results suggest that the proposed approach can achieve the latest tongue segmentation performance. And in the meantime, the lightweight network contains only 15.45M parameters and performs only 11.22GFLOPS.

</details>

<details>

<summary>2020-03-16 03:43:59 - A Generative Learning Approach for Spatio-temporal Modeling in Connected Vehicular Network</summary>

- *Rong Xia, Yong Xiao, Yingyu Li, Marwan Krunz, Dusit Niyato*

- `2003.07004v1` - [abs](http://arxiv.org/abs/2003.07004v1) - [pdf](http://arxiv.org/pdf/2003.07004v1)

> Spatio-temporal modeling of wireless access latency is of great importance for connected-vehicular systems. The quality of the molded results rely heavily on the number and quality of samples which can vary significantly due to the sensor deployment density as well as traffic volume and density. This paper proposes LaMI (Latency Model Inpainting), a novel framework to generate a comprehensive spatio-temporal of wireless access latency of a connected vehicles across a wide geographical area. LaMI adopts the idea from image inpainting and synthesizing and can reconstruct the missing latency samples by a two-step procedure. In particular, it first discovers the spatial correlation between samples collected in various regions using a patching-based approach and then feeds the original and highly correlated samples into a Variational Autoencoder (VAE), a deep generative model, to create latency samples with similar probability distribution with the original samples. Finally, LaMI establishes the empirical PDF of latency performance and maps the PDFs into the confidence levels of different vehicular service requirements. Extensive performance evaluation has been conducted using the real traces collected in a commercial LTE network in a university campus. Simulation results show that our proposed model can significantly improve the accuracy of latency modeling especially compared to existing popular solutions such as interpolation and nearest neighbor-based methods.

</details>

<details>

<summary>2020-03-18 09:42:02 - Deep Image Spatial Transformation for Person Image Generation</summary>

- *Yurui Ren, Xiaoming Yu, Junming Chen, Thomas H. Li, Ge Li*

- `2003.00696v2` - [abs](http://arxiv.org/abs/2003.00696v2) - [pdf](http://arxiv.org/pdf/2003.00696v2)

> Pose-guided person image generation is to transform a source person image to a target pose. This task requires spatial manipulations of source data. However, Convolutional Neural Networks are limited by the lack of ability to spatially transform the inputs. In this paper, we propose a differentiable global-flow local-attention framework to reassemble the inputs at the feature level. Specifically, our model first calculates the global correlations between sources and targets to predict flow fields. Then, the flowed local patch pairs are extracted from the feature maps to calculate the local attention coefficients. Finally, we warp the source features using a content-aware sampling method with the obtained local attention coefficients. The results of both subjective and objective experiments demonstrate the superiority of our model. Besides, additional results in video animation and view synthesis show that our model is applicable to other tasks requiring spatial transformation. Our source code is available at https://github.com/RenYurui/Global-Flow-Local-Attention.

</details>

<details>

<summary>2020-03-19 18:58:13 - Local Implicit Grid Representations for 3D Scenes</summary>

- *Chiyu Max Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nießner, Thomas Funkhouser*

- `2003.08981v1` - [abs](http://arxiv.org/abs/2003.08981v1) - [pdf](http://arxiv.org/pdf/2003.08981v1)

> Shape priors learned from data are commonly used to reconstruct 3D objects from partial or noisy data. Yet no such shape priors are available for indoor scenes, since typical 3D autoencoders cannot handle their scale, complexity, or diversity. In this paper, we introduce Local Implicit Grid Representations, a new 3D shape representation designed for scalability and generality. The motivating idea is that most 3D surfaces share geometric details at some scale -- i.e., at a scale smaller than an entire object and larger than a small patch. We train an autoencoder to learn an embedding of local crops of 3D shapes at that size. Then, we use the decoder as a component in a shape optimization that solves for a set of latent codes on a regular grid of overlapping crops such that an interpolation of the decoded local shapes matches a partial or noisy observation. We demonstrate the value of this proposed approach for 3D surface reconstruction from sparse point observations, showing significantly better results than alternative approaches.

</details>

<details>

<summary>2020-03-20 08:41:46 - Reinforced Feature Points: Optimizing Feature Detection and Description for a High-Level Task</summary>

- *Aritra Bhowmik, Stefan Gumhold, Carsten Rother, Eric Brachmann*

- `1912.00623v2` - [abs](http://arxiv.org/abs/1912.00623v2) - [pdf](http://arxiv.org/pdf/1912.00623v2)

> We address a core problem of computer vision: Detection and description of 2D feature points for image matching. For a long time, hand-crafted designs, like the seminal SIFT algorithm, were unsurpassed in accuracy and efficiency. Recently, learned feature detectors emerged that implement detection and description using neural networks. Training these networks usually resorts to optimizing low-level matching scores, often pre-defining sets of image patches which should or should not match, or which should or should not contain key points. Unfortunately, increased accuracy for these low-level matching scores does not necessarily translate to better performance in high-level vision tasks. We propose a new training methodology which embeds the feature detector in a complete vision pipeline, and where the learnable parameters are trained in an end-to-end fashion. We overcome the discrete nature of key point selection and descriptor matching using principles from reinforcement learning. As an example, we address the task of relative pose estimation between a pair of images. We demonstrate that the accuracy of a state-of-the-art learning-based feature detector can be increased when trained for the task it is supposed to solve at test time. Our training methodology poses little restrictions on the task to learn, and works for any architecture which predicts key point heat maps, and descriptors for key point locations.

</details>

<details>

<summary>2020-03-20 12:48:39 - Coronavirus (COVID-19) Classification using CT Images by Machine Learning Methods</summary>

- *Mucahid Barstugan, Umut Ozkaya, Saban Ozturk*

- `2003.09424v1` - [abs](http://arxiv.org/abs/2003.09424v1) - [pdf](http://arxiv.org/pdf/2003.09424v1)

> This study presents early phase detection of Coronavirus (COVID-19), which is named by World Health Organization (WHO), by machine learning methods. The detection process was implemented on abdominal Computed Tomography (CT) images. The expert radiologists detected from CT images that COVID-19 shows different behaviours from other viral pneumonia. Therefore, the clinical experts specify that COV\.ID-19 virus needs to be diagnosed in early phase. For detection of the COVID-19, four different datasets were formed by taking patches sized as 16x16, 32x32, 48x48, 64x64 from 150 CT images. The feature extraction process was applied to patches to increase the classification performance. Grey Level Co-occurrence Matrix (GLCM), Local Directional Pattern (LDP), Grey Level Run Length Matrix (GLRLM), Grey-Level Size Zone Matrix (GLSZM), and Discrete Wavelet Transform (DWT) algorithms were used as feature extraction methods. Support Vector Machines (SVM) classified the extracted features. 2-fold, 5-fold and 10-fold cross-validations were implemented during the classification process. Sensitivity, specificity, accuracy, precision, and F-score metrics were used to evaluate the classification performance. The best classification accuracy was obtained as 99.68% with 10-fold cross-validation and GLSZM feature extraction method.

</details>

<details>

<summary>2020-03-21 15:47:22 - Intrinsic dimension estimation for locally undersampled data</summary>

- *Vittorio Erba, Marco Gherardi, Pietro Rotondo*

- `1906.07670v2` - [abs](http://arxiv.org/abs/1906.07670v2) - [pdf](http://arxiv.org/pdf/1906.07670v2)

> High-dimensional data are ubiquitous in contemporary science and finding methods to compress them is one of the primary goals of machine learning. Given a dataset lying in a high-dimensional space (in principle hundreds to several thousands of dimensions), it is often useful to project it onto a lower-dimensional manifold, without loss of information. Identifying the minimal dimension of such manifold is a challenging problem known in the literature as intrinsic dimension estimation (IDE). Traditionally, most IDE algorithms are either based on multiscale principal component analysis (PCA) or on the notion of correlation dimension (and more in general on k-nearest-neighbors distances). These methods are affected, in different ways, by a severe curse of dimensionality. In particular, none of the existing algorithms can provide accurate ID estimates in the extreme locally undersampled regime, i.e. in the limit where the number of samples in any local patch of the manifold is less than (or of the same order of) the ID of the dataset. Here we introduce a new ID estimator that leverages on simple properties of the tangent space of a manifold to overcome these shortcomings. The method is based on the full correlation integral, going beyond the limit of small radius used for the estimation of the correlation dimension. Our estimator alleviates the extreme undersampling problem, intractable with other methods. Based on this insight, we explore a multiscale generalization of the algorithm. We show that it is capable of (i) identifying multiple dimensionalities in a dataset, and (ii) providing accurate estimates of the ID of extremely curved manifolds. In particular, we test the method on manifolds generated from global transformations of high-contrast images, relevant for invariant object recognition and considered a challenge for state-of-the-art ID estimators.

</details>

<details>

<summary>2020-03-24 12:35:23 - Self-Assignment Flows for Unsupervised Data Labeling on Graphs</summary>

- *Matthias Zisler, Artjom Zern, Stefania Petra, Christoph Schnörr*

- `1911.03472v2` - [abs](http://arxiv.org/abs/1911.03472v2) - [pdf](http://arxiv.org/pdf/1911.03472v2)

> This paper extends the recently introduced assignment flow approach for supervised image labeling to unsupervised scenarios where no labels are given. The resulting self-assignment flow takes a pairwise data affinity matrix as input data and maximizes the correlation with a low-rank matrix that is parametrized by the variables of the assignment flow, which entails an assignment of the data to themselves through the formation of latent labels (feature prototypes). A single user parameter, the neighborhood size for the geometric regularization of assignments, drives the entire process. By smooth geodesic interpolation between different normalizations of self-assignment matrices on the positive definite matrix manifold, a one-parameter family of self-assignment flows is defined. Accordingly, our approach can be characterized from different viewpoints, e.g. as performing spatially regularized, rank-constrained discrete optimal transport, or as computing spatially regularized normalized spectral cuts. Regarding combinatorial optimization, our approach successfully determines completely positive factorizations of self-assignments in large-scale scenarios, subject to spatial regularization. Various experiments including the unsupervised learning of patch dictionaries using a locally invariant distance function, illustrate the properties of the approach.

</details>

<details>

<summary>2020-03-25 01:07:06 - Norms and Sanctions as a Basis for Promoting Cybersecurity Practices</summary>

- *Nirav Ajmeri, Shubham Goyal, Munindar P. Singh*

- `2003.11170v1` - [abs](http://arxiv.org/abs/2003.11170v1) - [pdf](http://arxiv.org/pdf/2003.11170v1)

> Many cybersecurity breaches occur due to users not following good cybersecurity practices, chief among them being regulations for applying software patches to operating systems, updating applications, and maintaining strong passwords.   We capture cybersecurity expectations on users as norms. We empirically investigate sanctioning mechanisms in promoting compliance with those norms as well as the detrimental effect of sanctions on the ability of users to complete their work. We realize these ideas in a game that emulates the decision making of workers in a research lab.   Through a human-subject study, we find that whereas individual sanctions are more effective than group sanctions in achieving compliance and less detrimental on the ability of users to complete their work, individual sanctions offer significantly lower resilience especially for organizations comprising risk seekers. Our findings have implications for workforce training in cybersecurity.

</details>

<details>

<summary>2020-03-25 22:40:29 - Patch Quality and Diversity of Invariant-Guided Search-Based Program Repair</summary>

- *Zhen Yu Ding*

- `2003.11667v1` - [abs](http://arxiv.org/abs/2003.11667v1) - [pdf](http://arxiv.org/pdf/2003.11667v1)

> Most automatic program repair techniques rely on test cases to specify correct program behavior. Due to test cases' frequently incomplete coverage of desired behavior, however, patches often overfit and fail to generalize to broader requirements. Moreover, in the absence of perfectly correct outputs, methods to ensure higher patch quality, such as merging together several patches or a human evaluating patch recommendations, benefit from having access to a diverse set of patches, making patch diversity a potentially useful trait. We evaluate the correctness and diversity of patches generated by GenProg and an invariant-based diversity-enhancing extension described in our prior work. We find no evidence that promoting diversity changes the correctness of patches in a positive or negative direction. Using invariant- and test case generation-driven metrics for measuring semantic diversity, we find no observed semantic differences between patches for most bugs, regardless of the repair technique used.

</details>

<details>

<summary>2020-03-29 02:22:54 - Unsupervised Attributed Multiplex Network Embedding</summary>

- *Chanyoung Park, Donghyun Kim, Jiawei Han, Hwanjo Yu*

- `1911.06750v2` - [abs](http://arxiv.org/abs/1911.06750v2) - [pdf](http://arxiv.org/pdf/1911.06750v2)

> Nodes in a multiplex network are connected by multiple types of relations. However, most existing network embedding methods assume that only a single type of relation exists between nodes. Even for those that consider the multiplexity of a network, they overlook node attributes, resort to node labels for training, and fail to model the global properties of a graph. We present a simple yet effective unsupervised network embedding method for attributed multiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that maximizes the mutual information between local patches of a graph, and the global representation of the entire graph. We devise a systematic way to jointly integrate the node embeddings from multiple graphs by introducing 1) the consensus regularization framework that minimizes the disagreements among the relation-type specific node embeddings, and 2) the universal discriminator that discriminates true samples regardless of the relation types. We also show that the attention mechanism infers the importance of each relation type, and thus can be useful for filtering unnecessary relation types as a preprocessing step. Extensive experiments on various downstream tasks demonstrate that DMGI outperforms the state-of-the-art methods, even though DMGI is fully unsupervised.

</details>

<details>

<summary>2020-03-30 11:51:32 - MetNet: A Neural Weather Model for Precipitation Forecasting</summary>

- *Casper Kaae Sønderby, Lasse Espeholt, Jonathan Heek, Mostafa Dehghani, Avital Oliver, Tim Salimans, Shreya Agrawal, Jason Hickey, Nal Kalchbrenner*

- `2003.12140v2` - [abs](http://arxiv.org/abs/2003.12140v2) - [pdf](http://arxiv.org/pdf/2003.12140v2)

> Weather forecasting is a long standing scientific challenge with direct social and economic impact. The task is suitable for deep neural networks due to vast amounts of continuously collected data and a rich spatial and temporal structure that presents long range dependencies. We introduce MetNet, a neural network that forecasts precipitation up to 8 hours into the future at the high spatial resolution of 1 km$^2$ and at the temporal resolution of 2 minutes with a latency in the order of seconds. MetNet takes as input radar and satellite data and forecast lead time and produces a probabilistic precipitation map. The architecture uses axial self-attention to aggregate the global context from a large input patch corresponding to a million square kilometers. We evaluate the performance of MetNet at various precipitation thresholds and find that MetNet outperforms Numerical Weather Prediction at forecasts of up to 7 to 8 hours on the scale of the continental United States.

</details>

<details>

<summary>2020-03-30 17:57:09 - Deep reinforcement learning for large-scale epidemic control</summary>

- *Pieter Libin, Arno Moonens, Timothy Verstraeten, Fabian Perez-Sanjines, Niel Hens, Philippe Lemey, Ann Nowé*

- `2003.13676v1` - [abs](http://arxiv.org/abs/2003.13676v1) - [pdf](http://arxiv.org/pdf/2003.13676v1)

> Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.

</details>

<details>

<summary>2020-03-31 02:07:33 - Y-net: Multi-scale feature aggregation network with wavelet structure similarity loss function for single image dehazing</summary>

- *Hao-Hsiang Yang, Chao-Han Huck Yang, Yi-Chang James Tsai*

- `2003.13912v1` - [abs](http://arxiv.org/abs/2003.13912v1) - [pdf](http://arxiv.org/pdf/2003.13912v1)

> Single image dehazing is the ill-posed two-dimensional signal reconstruction problem. Recently, deep convolutional neural networks (CNN) have been successfully used in many computer vision problems. In this paper, we propose a Y-net that is named for its structure. This network reconstructs clear images by aggregating multi-scale features maps. Additionally, we propose a Wavelet Structure SIMilarity (W-SSIM) loss function in the training step. In the proposed loss function, discrete wavelet transforms are applied repeatedly to divide the image into differently sized patches with different frequencies and scales. The proposed loss function is the accumulation of SSIM loss of various patches with respective ratios. Extensive experimental results demonstrate that the proposed Y-net with the W-SSIM loss function restores high-quality clear images and outperforms state-of-the-art algorithms. Code and models are available at https://github.com/dectrfov/Y-net.

</details>

<details>

<summary>2020-03-31 07:00:59 - Deep semantic gaze embedding and scanpath comparison for expertise classification during OPT viewing</summary>

- *Nora Castner, Thomas Kübler, Katharina Scheiter, Juilane Richter, Thérése Eder, Fabian Hüttig, Constanze Keutel, Enkelejda Kasneci*

- `2003.13987v1` - [abs](http://arxiv.org/abs/2003.13987v1) - [pdf](http://arxiv.org/pdf/2003.13987v1)

> Modeling eye movement indicative of expertise behavior is decisive in user evaluation. However, it is indisputable that task semantics affect gaze behavior. We present a novel approach to gaze scanpath comparison that incorporates convolutional neural networks (CNN) to process scene information at the fixation level. Image patches linked to respective fixations are used as input for a CNN and the resulting feature vectors provide the temporal and spatial gaze information necessary for scanpath similarity comparison.We evaluated our proposed approach on gaze data from expert and novice dentists interpreting dental radiographs using a local alignment similarity score. Our approach was capable of distinguishing experts from novices with 93% accuracy while incorporating the image semantics. Moreover, our scanpath comparison using image patch features has the potential to incorporate task semantics from a variety of tasks

</details>

<details>

<summary>2020-03-31 15:42:21 - RESTORE: Retrospective Fault Localization Enhancing Automated Program Repair</summary>

- *Tongtong Xu, Liushan Chen, Yu Pei, Tian Zhang, Minxue Pan, Carlo A. Furia*

- `1906.01778v3` - [abs](http://arxiv.org/abs/1906.01778v3) - [pdf](http://arxiv.org/pdf/1906.01778v3)

> Fault localization is a crucial step of automated program repair, because accurately identifying program locations that are most closely implicated with a fault greatly affects the effectiveness of the patching process. An ideal fault localization technique would provide precise information while requiring moderate computational resources---to best support an efficient search for correct fixes. In contrast, most automated program repair tools use standard fault localization techniques---which are not tightly integrated with the overall program repair process, and hence deliver only subpar efficiency.   In this paper, we present retrospective fault localization: a novel fault localization technique geared to the requirements of automated program repair. A key idea of retrospective fault localization is to reuse the outcome of failed patch validation to support mutation-based dynamic analysis---providing accurate fault localization information without incurring onerous computational costs.   We implemented retrospective fault localization in a tool called RESTORE---based on the JAID Java program repair system. Experiments involving faults from the Defects4J standard benchmark indicate that retrospective fault localization can boost automated program repair: RESTORE efficiently explores a large fix space, delivering state-of-the-art effectiveness (41 Defects4J bugs correctly fixed, 8 more than any other automated repair tools for Java) while simultaneously boosting performance (speedup over 3 compared to JAID). Retrospective fault localization is applicable to any automated program repair techniques that rely on fault localization and dynamic validation of patches.

</details>


## 2020-04

<details>

<summary>2020-04-01 15:14:40 - Tree bark re-identification using a deep-learning feature descriptor</summary>

- *Martin Robert, Patrick Dallaire, Philippe Giguère*

- `1912.03221v2` - [abs](http://arxiv.org/abs/1912.03221v2) - [pdf](http://arxiv.org/pdf/1912.03221v2)

> The ability to visually re-identify objects is a fundamental capability in vision systems. Oftentimes, it relies on collections of visual signatures based on descriptors, such as SIFT or SURF. However, these traditional descriptors were designed for a certain domain of surface appearances and geometries (limited relief). Consequently, highly-textured surfaces such as tree bark pose a challenge to them. In turn, this makes it more difficult to use trees as identifiable landmarks for navigational purposes (robotics) or to track felled lumber along a supply chain (logistics). We thus propose to use data-driven descriptors trained on bark images for tree surface re-identification. To this effect, we collected a large dataset containing 2,400 bark images with strong illumination changes, annotated by surface and with the ability to pixel-align them. We used this dataset to sample from more than 2 million 64x64 pixel patches to train our novel local descriptors DeepBark and SqueezeBark. Our DeepBark method has shown a clear advantage against the hand-crafted descriptors SIFT and SURF. For instance, we demonstrated that DeepBark can reach a mAP of 87.2% when retrieving 11 relevant bark images, i.e. corresponding to the same physical surface, to a bark query against 7,900 images. Our work thus suggests that re-identifying tree surfaces in a challenging illuminations context is possible. We also make public our dataset, which can be used to benchmark surface re-identification techniques.

</details>

<details>

<summary>2020-04-01 23:14:52 - On adversarial patches: real-world attack on ArcFace-100 face recognition system</summary>

- *Mikhail Pautov, Grigorii Melnikov, Edgar Kaziakhmedov, Klim Kireev, Aleksandr Petiushko*

- `1910.07067v3` - [abs](http://arxiv.org/abs/1910.07067v3) - [pdf](http://arxiv.org/pdf/1910.07067v3)

> Recent works showed the vulnerability of image classifiers to adversarial attacks in the digital domain. However, the majority of attacks involve adding small perturbation to an image to fool the classifier. Unfortunately, such procedures can not be used to conduct a real-world attack, where adding an adversarial attribute to the photo is a more practical approach. In this paper, we study the problem of real-world attacks on face recognition systems. We examine security of one of the best public face recognition systems, LResNet100E-IR with ArcFace loss, and propose a simple method to attack it in the physical world. The method suggests creating an adversarial patch that can be printed, added as a face attribute and photographed; the photo of a person with such attribute is then passed to the classifier such that the classifier's recognized class changes from correct to the desired one. Proposed generating procedure allows projecting adversarial patches not only on different areas of the face, such as nose or forehead but also on some wearable accessory, such as eyeglasses.

</details>

<details>

<summary>2020-04-02 11:22:26 - CORSICA: Cross-Origin Web Service Identification</summary>

- *Christian Dresen, Fabian Ising, Damian Poddebniak, Tobias Kappert, Thorsten Holz, Sebastian Schinzel*

- `2004.00939v1` - [abs](http://arxiv.org/abs/2004.00939v1) - [pdf](http://arxiv.org/pdf/2004.00939v1)

> Vulnerabilities in private networks are difficult to detect for attackers outside of the network. While there are known methods for port scanning internal hosts that work by luring unwitting internal users to an external web page that hosts malicious JavaScript code, no such method for detailed and precise service identification is known. The reason is that the Same Origin Policy (SOP) prevents access to HTTP responses of other origins by default. We perform a structured analysis of loopholes in the SOP that can be used to identify web applications across network boundaries. For this, we analyze HTML5, CSS, and JavaScript features of standard-compliant web browsers that may leak sensitive information about cross-origin content. The results reveal several novel techniques, including leaking JavaScript function names or styles of cross-origin requests that are available in all common browsers. We implement and test these techniques in a tool called CORSICA. It can successfully identify 31 of 42 (74%) of web services running on different IoT devices as well as the version numbers of the four most widely used content management systems WordPress, Drupal, Joomla, and TYPO3. CORSICA can also determine the patch level on average down to three versions (WordPress), six versions (Drupal), two versions (Joomla), and four versions (TYPO3) with only ten requests on average. Furthermore, CORSICA is able to identify 48 WordPress plugins containing 65 vulnerabilities. Finally, we analyze mitigation strategies and show that the proposed but not yet implemented strategies Cross-Origin Resource Policy (CORP)} and Sec-Metadata would prevent our identification techniques.

</details>

<details>

<summary>2020-04-07 18:01:26 - PatchVAE: Learning Local Latent Codes for Recognition</summary>

- *Kamal Gupta, Saurabh Singh, Abhinav Shrivastava*

- `2004.03623v1` - [abs](http://arxiv.org/abs/2004.03623v1) - [pdf](http://arxiv.org/pdf/2004.03623v1)

> Unsupervised representation learning holds the promise of exploiting large amounts of unlabeled data to learn general representations. A promising technique for unsupervised learning is the framework of Variational Auto-encoders (VAEs). However, unsupervised representations learned by VAEs are significantly outperformed by those learned by supervised learning for recognition. Our hypothesis is that to learn useful representations for recognition the model needs to be encouraged to learn about repeating and consistent patterns in data. Drawing inspiration from the mid-level representation discovery work, we propose PatchVAE, that reasons about images at patch level. Our key contribution is a bottleneck formulation that encourages mid-level style representations in the VAE framework. Our experiments demonstrate that representations learned by our method perform much better on the recognition tasks compared to those learned by vanilla VAEs.

</details>

<details>

<summary>2020-04-07 20:43:44 - Coronavirus (COVID-19) Classification using Deep Features Fusion and Ranking Technique</summary>

- *Umut Ozkaya, Saban Ozturk, Mucahid Barstugan*

- `2004.03698v1` - [abs](http://arxiv.org/abs/2004.03698v1) - [pdf](http://arxiv.org/pdf/2004.03698v1)

> Coronavirus (COVID-19) emerged towards the end of 2019. World Health Organization (WHO) was identified it as a global epidemic. Consensus occurred in the opinion that using Computerized Tomography (CT) techniques for early diagnosis of pandemic disease gives both fast and accurate results. It was stated by expert radiologists that COVID-19 displays different behaviours in CT images. In this study, a novel method was proposed as fusing and ranking deep features to detect COVID-19 in early phase. 16x16 (Subset-1) and 32x32 (Subset-2) patches were obtained from 150 CT images to generate sub-datasets. Within the scope of the proposed method, 3000 patch images have been labelled as CoVID-19 and No finding for using in training and testing phase. Feature fusion and ranking method have been applied in order to increase the performance of the proposed method. Then, the processed data was classified with a Support Vector Machine (SVM). According to other pre-trained Convolutional Neural Network (CNN) models used in transfer learning, the proposed method shows high performance on Subset-2 with 98.27% accuracy, 98.93% sensitivity, 97.60% specificity, 97.63% precision, 98.28% F1-score and 96.54% Matthews Correlation Coefficient (MCC) metrics.

</details>

<details>

<summary>2020-04-14 04:53:14 - Robust Modelling of Reflectance Pulse Oximetry for SpO$_2$ Estimation</summary>

- *Sricharan Vijayarangan, Prithvi Suresh, Preejith SP, Jayaraj Joseph, Mohansankar Sivaprakasam*

- `2004.06301v1` - [abs](http://arxiv.org/abs/2004.06301v1) - [pdf](http://arxiv.org/pdf/2004.06301v1)

> Continuous monitoring of blood oxygen saturation levels is vital for patients with pulmonary disorders. Traditionally, SpO$_2$ monitoring has been carried out using transmittance pulse oximeters due to its dependability. However, SpO$_2$ measurement from transmittance pulse oximeters is limited to peripheral regions. This becomes a disadvantage at very low temperatures as blood perfusion to the peripherals decreases. On the other hand, reflectance pulse oximeters can be used at various sites like finger, wrist, chest and forehead. Additionally, reflectance pulse oximeters can be scaled down to affordable patches that do not interfere with the user's diurnal activities. However, accurate SpO$_2$ estimation from reflectance pulse oximeters is challenging due to its patient dependent, subjective nature of measurement. Recently, a Machine Learning (ML) method was used to model reflectance waveforms onto SpO$_2$ obtained from transmittance waveforms. However, the generalizability of the model to new patients was not tested. In light of this, the current work implemented multiple ML based approaches which were subsequently found to be incapable of generalizing to new patients. Furthermore, a minimally calibrated data driven approach was utilized in order to obtain SpO$_2$ from reflectance PPG waveforms. The proposed solution produces an average mean absolute error of 1.81\% on unseen patients which is well within the clinically permissible error of 2\%. Two statistical tests were conducted to establish the effectiveness of the proposed method.

</details>

<details>

<summary>2020-04-16 00:48:32 - Radiologist-Level COVID-19 Detection Using CT Scans with Detail-Oriented Capsule Networks</summary>

- *Aryan Mobiny, Pietro Antonio Cicalese, Samira Zare, Pengyu Yuan, Mohammadsajad Abavisani, Carol C. Wu, Jitesh Ahuja, Patricia M. de Groot, Hien Van Nguyen*

- `2004.07407v1` - [abs](http://arxiv.org/abs/2004.07407v1) - [pdf](http://arxiv.org/pdf/2004.07407v1)

> Radiographic images offer an alternative method for the rapid screening and monitoring of Coronavirus Disease 2019 (COVID-19) patients. This approach is limited by the shortage of radiology experts who can provide a timely interpretation of these images. Motivated by this challenge, our paper proposes a novel learning architecture, called Detail-Oriented Capsule Networks (DECAPS), for the automatic diagnosis of COVID-19 from Computed Tomography (CT) scans. Our network combines the strength of Capsule Networks with several architecture improvements meant to boost classification accuracies. First, DECAPS uses an Inverted Dynamic Routing mechanism which increases model stability by preventing the passage of information from non-descriptive regions. Second, DECAPS employs a Peekaboo training procedure which uses a two-stage patch crop and drop strategy to encourage the network to generate activation maps for every target concept. The network then uses the activation maps to focus on regions of interest and combines both coarse and fine-grained representations of the data. Finally, we use a data augmentation method based on conditional generative adversarial networks to deal with the issue of data scarcity. Our model achieves 84.3% precision, 91.5% recall, and 96.1% area under the ROC curve, significantly outperforming state-of-the-art methods. We compare the performance of the DECAPS model with three experienced, well-trained thoracic radiologists and show that the architecture significantly outperforms them. While further studies on larger datasets are required to confirm this finding, our results imply that architectures like DECAPS can be used to assist radiologists in the CT scan mediated diagnosis of COVID-19.

</details>

<details>

<summary>2020-04-17 05:18:51 - Defining Smart Contract Defects on Ethereum</summary>

- *Jiachi Chen, Xin Xia, David Lo, John Grundy, Daniel Xiapu Luo, Ting Chen*

- `1905.01467v3` - [abs](http://arxiv.org/abs/1905.01467v3) - [pdf](http://arxiv.org/pdf/1905.01467v3)

> Smart contracts are programs running on a blockchain. They are immutable to change, and hence can not be patched for bugs once deployed. Thus it is critical to ensure they are bug-free and well-designed before deployment. A Contract defect is an error, flaw or fault in a smart contract that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. The detection of contract defects is a method to avoid potential bugs and improve the design of existing code. Since smart contracts contain numerous distinctive features, such as the gas system. decentralized, it is important to find smart contract specified defects. To fill this gap, we collected smart-contract-related posts from Ethereum StackExchange, as well as real-world smart contracts. We manually analyzed these posts and contracts; using them to define 20 kinds of contract defects. We categorized them into indicating potential security, availability, performance, maintainability and reusability problems. To validate if practitioners consider these contract as harmful, we created an online survey and received 138 responses from 32 different countries. Feedback showed these contract defects are harmful and removing them would improve the quality and robustness of smart contracts. We manually identified our defined contract defects in 587 real world smart contract and publicly released our dataset. Finally, we summarized 5 impacts caused by contract defects. These help developers better understand the symptoms of the defects and removal priority.

</details>

<details>

<summary>2020-04-17 16:39:26 - Representation Learning of Histopathology Images using Graph Neural Networks</summary>

- *Mohammed Adnan, Shivam Kalra, Hamid R. Tizhoosh*

- `2004.07399v2` - [abs](http://arxiv.org/abs/2004.07399v2) - [pdf](http://arxiv.org/pdf/2004.07399v2)

> Representation learning for Whole Slide Images (WSIs) is pivotal in developing image-based systems to achieve higher precision in diagnostic pathology. We propose a two-stage framework for WSI representation learning. We sample relevant patches using a color-based method and use graph neural networks to learn relations among sampled patches to aggregate the image information into a single vector representation. We introduce attention via graph pooling to automatically infer patches with higher relevance. We demonstrate the performance of our approach for discriminating two sub-types of lung cancers, Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma (LUSC). We collected 1,026 lung cancer WSIs with the 40$\times$ magnification from The Cancer Genome Atlas (TCGA) dataset, the largest public repository of histopathology images and achieved state-of-the-art accuracy of 88.8% and AUC of 0.89 on lung cancer sub-type classification by extracting features from a pre-trained DenseNet

</details>

<details>

<summary>2020-04-18 08:59:41 - sFuzz: An Efficient Adaptive Fuzzer for Solidity Smart Contracts</summary>

- *Tai D. Nguyen, Long H. Pham, Jun Sun, Yun Lin, Quang Tran Minh*

- `2004.08563v1` - [abs](http://arxiv.org/abs/2004.08563v1) - [pdf](http://arxiv.org/pdf/2004.08563v1)

> Smart contracts are Turing-complete programs that execute on the infrastructure of the blockchain, which often manage valuable digital assets. Solidity is one of the most popular programming languages for writing smart contracts on the Ethereum platform. Like traditional programs, smart contracts may contain vulnerabilities. Unlike traditional programs, smart contracts cannot be easily patched once they are deployed. It is thus important that smart contracts are tested thoroughly before deployment. In this work, we present an adaptive fuzzer for smart contracts on the Ethereum platform called sFuzz. Compared to existing Solidity fuzzers, sFuzz combines the strategy in the AFL fuzzer and an efficient lightweight multi-objective adaptive strategy targeting those hard-to-cover branches. sFuzz has been applied to more than 4 thousand smart contracts and the experimental results show that (1) sFuzz is efficient, e.g., two orders of magnitude faster than state-of-the-art tools; (2) sFuzz is effective in achieving high code coverage and discovering vulnerabilities; and (3) the different fuzzing strategies in sFuzz complement each other.

</details>

<details>

<summary>2020-04-19 17:56:05 - Reverse engineering of CAD models via clustering and approximate implicitization</summary>

- *Andrea Raffo, Oliver J. D. Barrowclough, Georg Muntingh*

- `1810.07451v3` - [abs](http://arxiv.org/abs/1810.07451v3) - [pdf](http://arxiv.org/pdf/1810.07451v3)

> In applications like computer aided design, geometric models are often represented numerically as polynomial splines or NURBS, even when they originate from primitive geometry. For purposes such as redesign and isogeometric analysis, it is of interest to extract information about the underlying geometry through reverse engineering. In this work we develop a novel method to determine these primitive shapes by combining clustering analysis with approximate implicitization. The proposed method is automatic and can recover algebraic hypersurfaces of any degree in any dimension. In exact arithmetic, the algorithm returns exact results. All the required parameters, such as the implicit degree of the patches and the number of clusters of the model, are inferred using numerical approaches in order to obtain an algorithm that requires as little manual input as possible. The effectiveness, efficiency and robustness of the method are shown both in a theoretical analysis and in numerical examples implemented in Python.

</details>

<details>

<summary>2020-04-20 02:02:19 - Convolutional Neural Networks for Image-based Corn Kernel Detection and Counting</summary>

- *Saeed Khaki, Hieu Pham, Ye Han, Andy Kuhl, Wade Kent, Lizhi Wang*

- `2003.12025v2` - [abs](http://arxiv.org/abs/2003.12025v2) - [pdf](http://arxiv.org/pdf/2003.12025v2)

> Precise in-season corn grain yield estimates enable farmers to make real-time accurate harvest and grain marketing decisions minimizing possible losses of profitability. A well developed corn ear can have up to 800 kernels, but manually counting the kernels on an ear of corn is labor-intensive, time consuming and prone to human error. From an algorithmic perspective, the detection of the kernels from a single corn ear image is challenging due to the large number of kernels at different angles and very small distance among the kernels. In this paper, we propose a kernel detection and counting method based on a sliding window approach. The proposed method detect and counts all corn kernels in a single corn ear image taken in uncontrolled lighting conditions. The sliding window approach uses a convolutional neural network (CNN) for kernel detection. Then, a non-maximum suppression (NMS) is applied to remove overlapping detections. Finally, windows that are classified as kernel are passed to another CNN regression model for finding the (x,y) coordinates of the center of kernel image patches. Our experiments indicate that the proposed method can successfully detect the corn kernels with a low detection error and is also able to detect kernels on a batch of corn ears positioned at different angles.

</details>

<details>

<summary>2020-04-21 07:38:15 - Inpainting via Generative Adversarial Networks for CMB data analysis</summary>

- *Alireza Vafaei Sadr, Farida Farsian*

- `2004.04177v2` - [abs](http://arxiv.org/abs/2004.04177v2) - [pdf](http://arxiv.org/pdf/2004.04177v2)

> In this work, we propose a new method to inpaint the CMB signal in regions masked out following a point source extraction process. We adopt a modified Generative Adversarial Network (GAN) and compare different combinations of internal (hyper-)parameters and training strategies. We study the performance using a suitable $\mathcal{C}_r$ variable in order to estimate the performance regarding the CMB power spectrum recovery. We consider a test set where one point source is masked out in each sky patch with a 1.83 $\times$ 1.83 squared degree extension, which, in our gridding, corresponds to 64 $\times$ 64 pixels. The GAN is optimized for estimating performance on Planck 2018 total intensity simulations. The training makes the GAN effective in reconstructing a masking corresponding to about 1500 pixels with $1\%$ error down to angular scales corresponding to about 5 arcminutes.

</details>

<details>

<summary>2020-04-25 06:30:13 - Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks</summary>

- *Yuanzhi Li, Colin Wei, Tengyu Ma*

- `1907.04595v2` - [abs](http://arxiv.org/abs/1907.04595v2) - [pdf](http://arxiv.org/pdf/1907.04595v2)

> Stochastic gradient descent with a large initial learning rate is widely used for training modern neural net architectures. Although a small initial learning rate allows for faster training and better test performance initially, the large learning rate achieves better generalization soon after the learning rate is annealed. Towards explaining this phenomenon, we devise a setting in which we can prove that a two layer network trained with large initial learning rate and annealing provably generalizes better than the same network trained with a small learning rate from the start. The key insight in our analysis is that the order of learning different types of patterns is crucial: because the small learning rate model first memorizes easy-to-generalize, hard-to-fit patterns, it generalizes worse on hard-to-generalize, easier-to-fit patterns than its large learning rate counterpart. This concept translates to a larger-scale setting: we demonstrate that one can add a small patch to CIFAR-10 images that is immediately memorizable by a model with small initial learning rate, but ignored by the model with large learning rate until after annealing. Our experiments show that this causes the small learning rate model's accuracy on unmodified images to suffer, as it relies too much on the patch early on.

</details>

<details>

<summary>2020-04-25 18:14:49 - Explainable Deep CNNs for MRI-Based Diagnosis of Alzheimer's Disease</summary>

- *Eduardo Nigri, Nivio Ziviani, Fabio Cappabianco, Augusto Antunes, Adriano Veloso*

- `2004.12204v1` - [abs](http://arxiv.org/abs/2004.12204v1) - [pdf](http://arxiv.org/pdf/2004.12204v1)

> Deep Convolutional Neural Networks (CNNs) are becoming prominent models for semi-automated diagnosis of Alzheimer's Disease (AD) using brain Magnetic Resonance Imaging (MRI). Although being highly accurate, deep CNN models lack transparency and interpretability, precluding adequate clinical reasoning and not complying with most current regulatory demands. One popular choice for explaining deep image models is occluding regions of the image to isolate their influence on the prediction. However, existing methods for occluding patches of brain scans generate images outside the distribution to which the model was trained for, thus leading to unreliable explanations. In this paper, we propose an alternative explanation method that is specifically designed for the brain scan task. Our method, which we refer to as Swap Test, produces heatmaps that depict the areas of the brain that are most indicative of AD, providing interpretability for the model's decisions in a format understandable to clinicians. Experimental results using an axiomatic evaluation show that the proposed method is more suitable for explaining the diagnosis of AD using MRI while the opposite trend was observed when using a typical occlusion test. Therefore, we believe our method may address the inherent black-box nature of deep neural networks that are capable of diagnosing AD.

</details>

<details>

<summary>2020-04-26 09:50:15 - Structure Preserving Compressive Sensing MRI Reconstruction using Generative Adversarial Networks</summary>

- *Puneesh Deora, Bhavya Vasudeva, Saumik Bhattacharya, Pyari Mohan Pradhan*

- `1910.06067v2` - [abs](http://arxiv.org/abs/1910.06067v2) - [pdf](http://arxiv.org/pdf/1910.06067v2)

> Compressive sensing magnetic resonance imaging (CS-MRI) accelerates the acquisition of MR images by breaking the Nyquist sampling limit. In this work, a novel generative adversarial network (GAN) based framework for CS-MRI reconstruction is proposed. Leveraging a combination of patch-based discriminator and structural similarity index based loss, our model focuses on preserving high frequency content as well as fine textural details in the reconstructed image. Dense and residual connections have been incorporated in a U-net based generator architecture to allow easier transfer of information as well as variable network length. We show that our algorithm outperforms state-of-the-art methods in terms of quality of reconstruction and robustness to noise. Also, the reconstruction time, which is of the order of milliseconds, makes it highly suitable for real-time clinical use.

</details>

<details>

<summary>2020-04-26 13:34:57 - Towards Runtime Verification of Programmable Switches</summary>

- *Apoorv Shukla, Kevin Hudemann, Zsolt Vági, Lily Hügerich, Georgios Smaragdakis, Stefan Schmid, Artur Hecker, Anja Feldmann*

- `2004.10887v2` - [abs](http://arxiv.org/abs/2004.10887v2) - [pdf](http://arxiv.org/pdf/2004.10887v2)

> Is it possible to patch software bugs in P4 programs without human involvement? We show that this is partially possible in many cases due to advances in software testing and the structure of P4 programs. Our insight is that runtime verification can detect bugs, even those that are not detected at compile-time, with machine learning-guided fuzzing. This enables a more automated and real-time localization of bugs in P4 programs using software testing techniques like Tarantula. Once the bug in a P4 program is localized, the faulty code can be patched due to the programmable nature of P4. In addition, platform-dependent bugs can be detected. From P4_14 to P4_16 (latest version), our observation is that as the programmable blocks increase, the patchability of P4 programs increases accordingly. To this end, we design, develop, and evaluate P6 that (a) detects, (b) localizes, and (c) patches bugs in P4 programs with minimal human interaction. P6 tests P4 switch non-intrusively, i.e., requires no modification to the P4 program for detecting and localizing bugs. We used a P6 prototype to detect and patch seven existing bugs in eight publicly available P4 application programs deployed on two different switch platforms: behavioral model (bmv2) and Tofino. Our evaluation shows that P6 significantly outperforms bug detection baselines while generating fewer packets and patches bugs in P4 programs such as switch.p4 without triggering any regressions.

</details>

<details>

<summary>2020-04-27 08:34:57 - Interactive Patch Filtering as Debugging Aid</summary>

- *Jingjing Liang, Ruyi Ji, Jiajun Jiang, Yiling Lou, Yingfei Xiong, Gang Huang*

- `2004.08746v2` - [abs](http://arxiv.org/abs/2004.08746v2) - [pdf](http://arxiv.org/pdf/2004.08746v2)

> It is widely recognized that program repair tools need to have a high precision to be useful, i.e., the generated patches need to have a high probability to be correct. However, it is fundamentally difficult to ensure the correctness of the patches, and many tools compromise other aspects of repair performance such as recall for an acceptable precision.   In this paper we ask a question: can a repair tool with a low precision be still useful? To explore this question, we propose an interactive filtering approach to patch review, which filters out incorrect patches by asking questions to the developers. Our intuition is that incorrect patches can still help understand the bug. With proper tool support, the benefit outweighs the cost even if there are many incorrect patches.   We implemented the approach as an Eclipse plugin tool, InPaFer, and evaluated it with a simulated experiment and a user study with 30 developers. The results show that our approach improve the repair performance of developers, with 62.5% more successfully repaired bugs and 25.3% less debugging time in average. In particular, even if the generated patches are all incorrect, the performance of the developers would not be significantly reduced, and could be improved when some patches provide useful information for repairing, such as the faulty location and a partial fix.

</details>

<details>

<summary>2020-04-28 12:16:16 - MuonTrap: Preventing Cross-Domain Spectre-Like Attacks by Capturing Speculative State</summary>

- *Sam Ainsworth, Timothy M. Jones*

- `1911.08384v2` - [abs](http://arxiv.org/abs/1911.08384v2) - [pdf](http://arxiv.org/pdf/1911.08384v2)

> The disclosure of the Spectre speculative-execution attacks in January 2018 has left a severe vulnerability that systems are still struggling with how to patch. The solutions that currently exist tend to have incomplete coverage, perform badly, or have highly undesirable edge cases that cause application domains to break.   MuonTrap allows processors to continue to speculate, avoiding significant reductions in performance, without impacting security. We instead prevent the propagation of any state based on speculative execution, by placing the results of speculative cache accesses into a small, fast L0 filter cache, that is non-inclusive, non-exclusive with the rest of the cache hierarchy. This isolates all parts of the system that can't be quickly cleared on any change in threat domain.   MuonTrap uses these speculative filter caches, which are cleared on context and protection-domain switches, along with a series of extensions to the cache coherence protocol and prefetcher. This renders systems immune to cross-domain information leakage via Spectre and a host of similar attacks based on speculative execution, with low performance impact and few changes to the CPU design.

</details>

<details>

<summary>2020-04-28 20:11:18 - Minority Reports Defense: Defending Against Adversarial Patches</summary>

- *Michael McCoyd, Won Park, Steven Chen, Neil Shah, Ryan Roggenkemper, Minjune Hwang, Jason Xinyu Liu, David Wagner*

- `2004.13799v1` - [abs](http://arxiv.org/abs/2004.13799v1) - [pdf](http://arxiv.org/pdf/2004.13799v1)

> Deep learning image classification is vulnerable to adversarial attack, even if the attacker changes just a small patch of the image. We propose a defense against patch attacks based on partially occluding the image around each candidate patch location, so that a few occlusions each completely hide the patch. We demonstrate on CIFAR-10, Fashion MNIST, and MNIST that our defense provides certified security against patch attacks of a certain size.

</details>

<details>

<summary>2020-04-29 18:29:49 - FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow Estimation</summary>

- *Matias Tassano, Julie Delon, Thomas Veit*

- `1907.01361v2` - [abs](http://arxiv.org/abs/1907.01361v2) - [pdf](http://arxiv.org/pdf/1907.01361v2)

> In this paper, we propose a state-of-the-art video denoising algorithm based on a convolutional neural network architecture. Until recently, video denoising with neural networks had been a largely under explored domain, and existing methods could not compete with the performance of the best patch-based methods. The approach we introduce in this paper, called FastDVDnet, shows similar or better performance than other state-of-the-art competitors with significantly lower computing times. In contrast to other existing neural network denoisers, our algorithm exhibits several desirable properties such as fast runtimes, and the ability to handle a wide range of noise levels with a single network model. The characteristics of its architecture make it possible to avoid using a costly motion compensation stage while achieving excellent performance. The combination between its denoising performance and lower computational load makes this algorithm attractive for practical denoising applications. We compare our method with different state-of-art algorithms, both visually and with respect to objective quality metrics.

</details>


## 2020-05

<details>

<summary>2020-05-01 23:50:37 - Jacks of All Trades, Masters Of None: Addressing Distributional Shift and Obtrusiveness via Transparent Patch Attacks</summary>

- *Neil Fendley, Max Lennon, I-Jeng Wang, Philippe Burlina, Nathan Drenkow*

- `2005.00656v1` - [abs](http://arxiv.org/abs/2005.00656v1) - [pdf](http://arxiv.org/pdf/2005.00656v1)

> We focus on the development of effective adversarial patch attacks and -- for the first time -- jointly address the antagonistic objectives of attack success and obtrusiveness via the design of novel semi-transparent patches. This work is motivated by our pursuit of a systematic performance analysis of patch attack robustness with regard to geometric transformations. Specifically, we first elucidate a) key factors underpinning patch attack success and b) the impact of distributional shift between training and testing/deployment when cast under the Expectation over Transformation (EoT) formalism. By focusing our analysis on three principal classes of transformations (rotation, scale, and location), our findings provide quantifiable insights into the design of effective patch attacks and demonstrate that scale, among all factors, significantly impacts patch attack success. Working from these findings, we then focus on addressing how to overcome the principal limitations of scale for the deployment of attacks in real physical settings: namely the obtrusiveness of large patches. Our strategy is to turn to the novel design of irregularly-shaped, semi-transparent partial patches which we construct via a new optimization process that jointly addresses the antagonistic goals of mitigating obtrusiveness and maximizing effectiveness. Our study -- we hope -- will help encourage more focus in the community on the issues of obtrusiveness, scale, and success in patch attacks.

</details>

<details>

<summary>2020-05-04 20:03:21 - Neural Subdivision</summary>

- *Hsueh-Ti Derek Liu, Vladimir G. Kim, Siddhartha Chaudhuri, Noam Aigerman, Alec Jacobson*

- `2005.01819v1` - [abs](http://arxiv.org/abs/2005.01819v1) - [pdf](http://arxiv.org/pdf/2005.01819v1)

> This paper introduces Neural Subdivision, a novel framework for data-driven coarse-to-fine geometry modeling. During inference, our method takes a coarse triangle mesh as input and recursively subdivides it to a finer geometry by applying the fixed topological updates of Loop Subdivision, but predicting vertex positions using a neural network conditioned on the local geometry of a patch. This approach enables us to learn complex non-linear subdivision schemes, beyond simple linear averaging used in classical techniques. One of our key contributions is a novel self-supervised training setup that only requires a set of high-resolution meshes for learning network weights. For any training shape, we stochastically generate diverse low-resolution discretizations of coarse counterparts, while maintaining a bijective mapping that prescribes the exact target position of every new vertex during the subdivision process. This leads to a very efficient and accurate loss function for conditional mesh generation, and enables us to train a method that generalizes across discretizations and favors preserving the manifold structure of the output. During training we optimize for the same set of network weights across all local mesh patches, thus providing an architecture that is not constrained to a specific input mesh, fixed genus, or category. Our network encodes patch geometry in a local frame in a rotation- and translation-invariant manner. Jointly, these design choices enable our method to generalize well, and we demonstrate that even when trained on a single high-resolution mesh our method generates reasonable subdivisions for novel shapes.

</details>

<details>

<summary>2020-05-05 15:35:08 - Discriminative Pattern Mining for Breast Cancer Histopathology Image Classification via Fully Convolutional Autoencoder</summary>

- *Xingyu Li, Marko Radulovic, Ksenija Kanjer, Konstantinos N. Plataniotis*

- `1902.08670v3` - [abs](http://arxiv.org/abs/1902.08670v3) - [pdf](http://arxiv.org/pdf/1902.08670v3)

> Accurate diagnosis of breast cancer in histopathology images is challenging due to the heterogeneity of cancer cell growth as well as of a variety of benign breast tissue proliferative lesions. In this paper, we propose a practical and self-interpretable invasive cancer diagnosis solution. With minimum annotation information, the proposed method mines contrast patterns between normal and malignant images in unsupervised manner and generates a probability map of abnormalities to verify its reasoning. Particularly, a fully convolutional autoencoder is used to learn the dominant structural patterns among normal image patches. Patches that do not share the characteristics of this normal population are detected and analyzed by one-class support vector machine and 1-layer neural network. We apply the proposed method to a public breast cancer image set. Our results, in consultation with a senior pathologist, demonstrate that the proposed method outperforms existing methods. The obtained probability map could benefit the pathology practice by providing visualized verification data and potentially leads to a better understanding of data-driven diagnosis solutions.

</details>

<details>

<summary>2020-05-05 16:07:25 - Deep Learning COVID-19 Features on CXR using Limited Training Data Sets</summary>

- *Yujin Oh, Sangjoon Park, Jong Chul Ye*

- `2004.05758v2` - [abs](http://arxiv.org/abs/2004.05758v2) - [pdf](http://arxiv.org/pdf/2004.05758v2)

> Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of the CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage.

</details>

<details>

<summary>2020-05-06 00:36:16 - An Annotated Dataset of Stack Overflow Post Edits</summary>

- *Sebastian Baltes, Markus Wagner*

- `2004.08193v2` - [abs](http://arxiv.org/abs/2004.08193v2) - [pdf](http://arxiv.org/pdf/2004.08193v2)

> To improve software engineering, software repositories have been mined for code snippets and bug fixes. Typically, this mining takes place at the level of files or commits. To be able to dig deeper and to extract insights at a higher resolution, we hereby present an annotated dataset that contains over 7 million edits of code and text on Stack Overflow. Our preliminary study indicates that these edits might be a treasure trove for mining information about fine-grained patches, e.g., for the optimisation of non-functional properties.

</details>

<details>

<summary>2020-05-08 01:17:59 - Using Taint Analysis and Reinforcement Learning (TARL) to Repair Autonomous Robot Software</summary>

- *D. M. Lyons, S. Zahra*

- `2005.03813v1` - [abs](http://arxiv.org/abs/2005.03813v1) - [pdf](http://arxiv.org/pdf/2005.03813v1)

> It is important to be able to establish formal performance bounds for autonomous systems. However, formal verification techniques require a model of the environment in which the system operates; a challenge for autonomous systems, especially those expected to operate over longer timescales. This paper describes work in progress to automate the monitor and repair of ROS-based autonomous robot software written for an a-priori partially known and possibly incorrect environment model. A taint analysis method is used to automatically extract the data-flow sequence from input topic to publish topic, and instrument that code. A unique reinforcement learning approximation of MDP utility is calculated, an empirical and non-invasive characterization of the inherent objectives of the software designers. By comparing off-line (a-priori) utility with on-line (deployed system) utility, we show, using a small but real ROS example, that it's possible to monitor a performance criterion and relate violations of the criterion to parts of the software. The software is then patched using automated software repair techniques and evaluated against the original off-line utility.

</details>

<details>

<summary>2020-05-09 05:19:33 - Building and Maintaining a Third-Party Library Supply Chain for Productive and Secure SGX Enclave Development</summary>

- *Pei Wang, Yu Ding, Mingshen Sun, Huibo Wang, Tongxin Li, Rundong Zhou, Zhaofeng Chen, Yiming Jing*

- `2005.04367v1` - [abs](http://arxiv.org/abs/2005.04367v1) - [pdf](http://arxiv.org/pdf/2005.04367v1)

> The big data industry is facing new challenges as concerns about privacy leakage soar. One of the remedies to privacy breach incidents is to encapsulate computations over sensitive data within hardware-assisted Trusted Execution Environments (TEE). Such TEE-powered software is called secure enclaves. Secure enclaves hold various advantages against competing for privacy-preserving computation solutions. However, enclaves are much more challenging to build compared with ordinary software. The reason is that the development of TEE software must follow a restrictive programming model to make effective use of strong memory encryption and segregation enforced by hardware. These constraints transitively apply to all third-party dependencies of the software. If these dependencies do not officially support TEE hardware, TEE developers have to spend additional engineering effort in porting them. High development and maintenance cost is one of the major obstacles against adopting TEE-based privacy protection solutions in production. In this paper, we present our experience and achievements with regard to constructing and continuously maintaining a third-party library supply chain for TEE developers. In particular, we port a large collection of Rust third-party libraries into Intel SGX, one of the most mature trusted computing platforms. Our supply chain accepts upstream patches in a timely manner with SGX-specific security auditing. We have been able to maintain the SGX ports of 159 open-source Rust libraries with reasonable operational costs. Our work can effectively reduce the engineering cost of developing SGX enclaves for privacy-preserving data processing and exchange.

</details>

<details>

<summary>2020-05-09 08:34:57 - SentiNet: Detecting Localized Universal Attacks Against Deep Learning Systems</summary>

- *Edward Chou, Florian Tramèr, Giancarlo Pellegrino*

- `1812.00292v4` - [abs](http://arxiv.org/abs/1812.00292v4) - [pdf](http://arxiv.org/pdf/1812.00292v4)

> SentiNet is a novel detection framework for localized universal attacks on neural networks. These attacks restrict adversarial noise to contiguous portions of an image and are reusable with different images -- constraints that prove useful for generating physically-realizable attacks. Unlike most other works on adversarial detection, SentiNet does not require training a model or preknowledge of an attack prior to detection. Our approach is appealing due to the large number of possible mechanisms and attack-vectors that an attack-specific defense would have to consider. By leveraging the neural network's susceptibility to attacks and by using techniques from model interpretability and object detection as detection mechanisms, SentiNet turns a weakness of a model into a strength. We demonstrate the effectiveness of SentiNet on three different attacks -- i.e., data poisoning attacks, trojaned networks, and adversarial patches (including physically realizable attacks) -- and show that our defense is able to achieve very competitive performance metrics for all three threats. Finally, we show that SentiNet is robust against strong adaptive adversaries, who build adversarial patches that specifically target the components of SentiNet's architecture.

</details>

<details>

<summary>2020-05-09 12:13:43 - Multi-Task Learning in Histo-pathology for Widely Generalizable Model</summary>

- *Jevgenij Gamper, Navid Alemi Kooohbanani, Nasir Rajpoot*

- `2005.08645v1` - [abs](http://arxiv.org/abs/2005.08645v1) - [pdf](http://arxiv.org/pdf/2005.08645v1)

> In this work we show preliminary results of deep multi-task learning in the area of computational pathology. We combine 11 tasks ranging from patch-wise oral cancer classification, one of the most prevalent cancers in the developing world, to multi-tissue nuclei instance segmentation and classification.

</details>

<details>

<summary>2020-05-12 11:54:56 - RetinotopicNet: An Iterative Attention Mechanism Using Local Descriptors with Global Context</summary>

- *Thomas Kurbiel, Shahrzad Khaleghian*

- `2005.05701v1` - [abs](http://arxiv.org/abs/2005.05701v1) - [pdf](http://arxiv.org/pdf/2005.05701v1)

> Convolutional Neural Networks (CNNs) were the driving force behind many advancements in Computer Vision research in recent years. This progress has spawned many practical applications and we see an increased need to efficiently move CNNs to embedded systems today. However traditional CNNs lack the property of scale and rotation invariance: two of the most frequently encountered transformations in natural images. As a consequence CNNs have to learn different features for same objects at different scales. This redundancy is the main reason why CNNs need to be very deep in order to achieve the desired accuracy. In this paper we develop an efficient solution by reproducing how nature has solved the problem in the human brain. To this end we let our CNN operate on small patches extracted using the log-polar transform, which is known to be scale and rotation equivariant. Patches extracted in this way have the nice property of magnifying the central field and compressing the periphery. Hence we obtain local descriptors with global context information. However the processing of a single patch is usually not sufficient to achieve high accuracies in e.g. classification tasks. We therefore successively jump to several different locations, called saccades, thus building an understanding of the whole image. Since log-polar patches contain global context information, we can efficiently calculate following saccades using only the small patches. Saccades efficiently compensate for the lack of translation equivariance of the log-polar transform.

</details>

<details>

<summary>2020-05-13 22:01:47 - Extended 2D Consensus Hippocampus Segmentation</summary>

- *Diedre Carmo, Bruna Silva, Clarissa Yasuda, Letícia Rittner, Roberto Lotufo*

- `1902.04487v5` - [abs](http://arxiv.org/abs/1902.04487v5) - [pdf](http://arxiv.org/pdf/1902.04487v5)

> Hippocampus segmentation plays a key role in diagnosing various brain disorders such as Alzheimer's disease, epilepsy, multiple sclerosis, cancer, depression and others. Nowadays, segmentation is still mainly performed manually by specialists. Segmentation done by experts is considered to be a gold-standard when evaluating automated methods, buts it is a time consuming and arduos task, requiring specialized personnel. In recent years, efforts have been made to achieve reliable automated segmentation. For years the best performing authomatic methods were multi atlas based with around 80-85% Dice coefficient and very time consuming, but machine learning methods are recently rising with promising time and accuracy performance. A method for volumetric hippocampus segmentation is presented, based on the consensus of tri-planar U-Net inspired fully convolutional networks (FCNNs), with some modifications, including residual connections, VGG weight transfers, batch normalization and a patch extraction technique employing data from neighbor patches. A study on the impact of our modifications to the classical U-Net architecture was performed. Our method achieves cutting edge performance in our dataset, with around 96% volumetric Dice accuracy in our test data. In a public validation dataset, HARP, we achieve 87.48% DICE. GPU execution time is in the order of seconds per volume, and source code is publicly available. Also, masks are shown to be similar to other recent state-of-the-art hippocampus segmentation methods in a third dataset, without manual annotations.

</details>

<details>

<summary>2020-05-14 16:17:39 - A Novel CNet-assisted Evolutionary Level Repairer and Its Applications to Super Mario Bros</summary>

- *Tianye Shu, Ziqi Wang, Jialin Liu, Xin Yao*

- `2005.06148v2` - [abs](http://arxiv.org/abs/2005.06148v2) - [pdf](http://arxiv.org/pdf/2005.06148v2)

> Applying latent variable evolution to game level design has become more and more popular as little human expert knowledge is required. However, defective levels with illegal patterns may be generated due to the violation of constraints for level design. A traditional way of repairing the defective levels is programming specific rule-based repairers to patch the flaw. However, programming these constraints is sometimes complex and not straightforward. An autonomous level repairer which is capable of learning the constraints is needed. In this paper, we propose a novel approach, CNet, to learn the probability distribution of tiles giving its surrounding tiles on a set of real levels, and then detect the illegal tiles in generated new levels. Then, an evolutionary repairer is designed to search for optimal replacement schemes equipped with a novel search space being constructed with the help of CNet and a novel heuristic function. The proposed approaches are proved to be effective in our case study of repairing GAN-generated and artificially destroyed levels of Super Mario Bros. game. Our CNet-assisted evolutionary repairer can also be easily applied to other games of which the levels can be represented by a matrix of objects or tiles.

</details>

<details>

<summary>2020-05-15 23:33:41 - Precise XSS detection and mitigation with Client-side Templates</summary>

- *Jose Carlos Pazos, Jean-Sebastien Legare, Ivan Beschastnikh, William Aiello*

- `2005.07826v1` - [abs](http://arxiv.org/abs/2005.07826v1) - [pdf](http://arxiv.org/pdf/2005.07826v1)

> We present XSnare, a fully client-side XSS solution, implemented as a Firefox extension. Our approach takes advantage of available previous knowledge of a web application's HTML template content, as well as the rich context available in the DOM to block XSS attacks. XSnare prevents XSS exploits by using a database of exploit descriptions, which are written with the help of previously recorded CVEs. CVEs for XSS are widely available and are one of the main ways to tackle zero-day exploits. XSnare effectively singles out potential injection points for exploits in the HTML and sanitizes content to prevent malicious payloads from appearing in the DOM.   XSnare can protect application users before application developers release patches and before server operators apply them.   We evaluated XSnare on 81 recent CVEs related to XSS attacks, and found that it defends against 94.2% of these exploits. To the best of our knowledge, XSnare is the first protection mechanism for XSS that is application-specific, and based on publicly available CVE information. We show that XSnare's specificity protects users against exploits which evade other, more generic, anti-XSS approaches.   Our performance evaluation shows that our extension's overhead on web page loading time is less than 10% for 72.6% of the sites in the Moz Top 500 list.

</details>

<details>

<summary>2020-05-18 18:22:36 - Patch based Colour Transfer using SIFT Flow</summary>

- *Hana Alghamdi, Rozenn Dahyot*

- `2005.09015v1` - [abs](http://arxiv.org/abs/2005.09015v1) - [pdf](http://arxiv.org/pdf/2005.09015v1)

> We propose a new colour transfer method with Optimal Transport (OT) to transfer the colour of a sourceimage to match the colour of a target image of the same scene that may exhibit large motion changes betweenimages. By definition OT does not take into account any available information about correspondences whencomputing the optimal solution. To tackle this problem we propose to encode overlapping neighborhoodsof pixels using both their colour and spatial correspondences estimated using motion estimation. We solvethe high dimensional problem in 1D space using an iterative projection approach. We further introducesmoothing as part of the iterative algorithms for solving optimal transport namely Iterative DistributionTransport (IDT) and its variant the Sliced Wasserstein Distance (SWD). Experiments show quantitative andqualitative improvements over previous state of the art colour transfer methods.

</details>

<details>

<summary>2020-05-20 13:52:13 - Smart Contract Repair</summary>

- *Xiao Liang Yu, Omar Al-Bataineh, David Lo, Abhik Roychoudhury*

- `1912.05823v3` - [abs](http://arxiv.org/abs/1912.05823v3) - [pdf](http://arxiv.org/pdf/1912.05823v3)

> Smart contracts are automated or self-enforcing contracts that can be used to exchange assets without having to place trust in third parties. Many commercial transactions use smart contracts due to their potential benefits in terms of secure peer-to-peer transactions independent of external parties. Experience shows that many commonly used smart contracts are vulnerable to serious malicious attacks which may enable attackers to steal valuable assets of involving parties. There is therefore a need to apply analysis and automated repair techniques to detect and repair bugs in smart contracts before being deployed. In this work, we present the first general-purpose automated smart contract repair approach that is also gas-aware. Our repair method is search-based and searches among mutations of the buggy contract. Our method also considers the gas usage of the candidate patches by leveraging our novel notion of gas dominance relationship. We have made our smart contract repair tool SCRepair available open-source, for investigation by the wider community.

</details>

<details>

<summary>2020-05-22 07:36:08 - DevReplay: Automatic Repair with Editable Fix Pattern</summary>

- *Yuki Ueda, Takashi Ishio, Akinori Ihara, Kenichi Matsumoto*

- `2005.11040v1` - [abs](http://arxiv.org/abs/2005.11040v1) - [pdf](http://arxiv.org/pdf/2005.11040v1)

> Static analysis tools, or linters, detect violation of source code conventions to maintain project readability. Those tools automatically fix specific violations while developers edit the source code. However, existing tools are designed for the general conventions of programming languages. These tools do not check the project/API-specific conventions. We propose a novel static analysis tool DevReplay that generates code change patterns by mining the code change history, and we recommend changes using the matched patterns. Using DevReplay, developers can automatically detect and fix project/API-specific problems in the code editor and code review. Also, we evaluate the accuracy of DevReplay using automatic program repair tool benchmarks and real software. We found that DevReplay resolves more bugs than state-of-the-art APR tools. Finally, we submitted patches to the most popular open-source projects that are implemented by different languages, and project reviewers accepted 80% (8 of 10) patches. DevReplay is available on https://devreplay.github.io.

</details>

<details>

<summary>2020-05-24 08:20:04 - Synergistic Learning of Lung Lobe Segmentation and Hierarchical Multi-Instance Classification for Automated Severity Assessment of COVID-19 in CT Images</summary>

- *Kelei He, Wei Zhao, Xingzhi Xie, Wen Ji, Mingxia Liu, Zhenyu Tang, Feng Shi, Yang Gao, Jun Liu, Junfeng Zhang, Dinggang Shen*

- `2005.03832v2` - [abs](http://arxiv.org/abs/2005.03832v2) - [pdf](http://arxiv.org/pdf/2005.03832v2)

> Understanding chest CT imaging of the coronavirus disease 2019 (COVID-19) will help detect infections early and assess the disease progression. Especially, automated severity assessment of COVID-19 in CT images plays an essential role in identifying cases that are in great need of intensive clinical care. However, it is often challenging to accurately assess the severity of this disease in CT images, due to variable infection regions in the lungs, similar imaging biomarkers, and large inter-case variations. To this end, we propose a synergistic learning framework for automated severity assessment of COVID-19 in 3D CT images, by jointly performing lung lobe segmentation and multi-instance classification. Considering that only a few infection regions in a CT image are related to the severity assessment, we first represent each input image by a bag that contains a set of 2D image patches (with each cropped from a specific slice). A multi-task multi-instance deep network (called M$^2$UNet) is then developed to assess the severity of COVID-19 patients and also segment the lung lobe simultaneously. Our M$^2$UNet consists of a patch-level encoder, a segmentation sub-network for lung lobe segmentation, and a classification sub-network for severity assessment (with a unique hierarchical multi-instance learning strategy). Here, the context information provided by segmentation can be implicitly employed to improve the performance of severity assessment. Extensive experiments were performed on a real COVID-19 CT image dataset consisting of 666 chest CT images, with results suggesting the effectiveness of our proposed method compared to several state-of-the-art methods.

</details>

<details>

<summary>2020-05-25 06:28:24 - CNN-based Patch Matching for Optical Flow with Thresholded Hinge Embedding Loss</summary>

- *Christian Bailer, Kiran Varanasi, Didier Stricker*

- `1607.08064v4` - [abs](http://arxiv.org/abs/1607.08064v4) - [pdf](http://arxiv.org/pdf/1607.08064v4)

> Learning based approaches have not yet achieved their full potential in optical flow estimation, where their performance still trails heuristic approaches. In this paper, we present a CNN based patch matching approach for optical flow estimation. An important contribution of our approach is a novel thresholded loss for Siamese networks. We demonstrate that our loss performs clearly better than existing losses. It also allows to speed up training by a factor of 2 in our tests. Furthermore, we present a novel way for calculating CNN based features for different image scales, which performs better than existing methods. We also discuss new ways of evaluating the robustness of trained features for the application of patch matching for optical flow. An interesting discovery in our paper is that low-pass filtering of feature maps can increase the robustness of features created by CNNs. We proved the competitive performance of our approach by submitting it to the KITTI 2012, KITTI 2015 and MPI-Sintel evaluation portals where we obtained state-of-the-art results on all three datasets.

</details>

<details>

<summary>2020-05-25 19:10:56 - Secure and User-Friendly Over-the-Air Firmware Distribution in a Portable Faraday Cage</summary>

- *Martin Striegel, Florian Jakobsmeier, Yacov Matveev, Johann Heyszl, Georg Sigl*

- `2005.12347v1` - [abs](http://arxiv.org/abs/2005.12347v1) - [pdf](http://arxiv.org/pdf/2005.12347v1)

> Setting up a large-scale wireless sensor network is challenging, as firmware must be distributed and trust between sensor nodes and a backend needs to be established. To perform this task efficiently, we propose an approach named Box, which utilizes an intelligent Faraday cage (FC). The FC acquires firmware images and secret keys from a backend, patches the firmware with the keys and deploys those customized images over the air to sensor nodes placed in the FC. Electromagnetic shielding protects this exchange against passive attackers. We place few demands on the sensor node, not requiring additional hardware components or firmware customized by the manufacturer. We describe this novel workflow, implement the Box and a backend system and demonstrate the feasibility of our approach by batch-deploying firmware to multiple commercial off-the-shelf sensor nodes. We conduct a user-study with 31 participants with diverse backgrounds and find, that our approach is both faster and more user-friendly than firmware distribution over a wired connection.

</details>

<details>

<summary>2020-05-27 08:48:48 - Self-Supervised Representation Learning on Document Images</summary>

- *Adrian Cosma, Mihai Ghidoveanu, Michael Panaitescu-Liess, Marius Popescu*

- `2004.10605v2` - [abs](http://arxiv.org/abs/2004.10605v2) - [pdf](http://arxiv.org/pdf/2004.10605v2)

> This work analyses the impact of self-supervised pre-training on document images in the context of document image classification. While previous approaches explore the effect of self-supervision on natural images, we show that patch-based pre-training performs poorly on document images because of their different structural properties and poor intra-sample semantic information. We propose two context-aware alternatives to improve performance on the Tobacco-3482 image classification task. We also propose a novel method for self-supervision, which makes use of the inherent multi-modality of documents (image and text), which performs better than other popular self-supervised methods, including supervised ImageNet pre-training, on document image classification scenarios with a limited amount of data.

</details>

<details>

<summary>2020-05-27 21:21:46 - Live Trojan Attacks on Deep Neural Networks</summary>

- *Robby Costales, Chengzhi Mao, Raphael Norwitz, Bryan Kim, Junfeng Yang*

- `2004.11370v2` - [abs](http://arxiv.org/abs/2004.11370v2) - [pdf](http://arxiv.org/pdf/2004.11370v2)

> Like all software systems, the execution of deep learning models is dictated in part by logic represented as data in memory. For decades, attackers have exploited traditional software programs by manipulating this data. We propose a live attack on deep learning systems that patches model parameters in memory to achieve predefined malicious behavior on a certain set of inputs. By minimizing the size and number of these patches, the attacker can reduce the amount of network communication and memory overwrites, with minimal risk of system malfunctions or other detectable side effects. We demonstrate the feasibility of this attack by computing efficient patches on multiple deep learning models. We show that the desired trojan behavior can be induced with a few small patches and with limited access to training data. We describe the details of how this attack is carried out on real systems and provide sample code for patching TensorFlow model parameters in Windows and in Linux. Lastly, we present a technique for effectively manipulating entropy on perturbed inputs to bypass STRIP, a state-of-the-art run-time trojan detection technique.

</details>

<details>

<summary>2020-05-29 05:56:10 - FashionBERT: Text and Image Matching with Adaptive Loss for Cross-modal Retrieval</summary>

- *Dehong Gao, Linbo Jin, Ben Chen, Minghui Qiu, Peng Li, Yi Wei, Yi Hu, Hao Wang*

- `2005.09801v2` - [abs](http://arxiv.org/abs/2005.09801v2) - [pdf](http://arxiv.org/pdf/2005.09801v2)

> In this paper, we address the text and image matching in cross-modal retrieval of the fashion industry. Different from the matching in the general domain, the fashion matching is required to pay much more attention to the fine-grained information in the fashion images and texts. Pioneer approaches detect the region of interests (i.e., RoIs) from images and use the RoI embeddings as image representations. In general, RoIs tend to represent the "object-level" information in the fashion images, while fashion texts are prone to describe more detailed information, e.g. styles, attributes. RoIs are thus not fine-grained enough for fashion text and image matching. To this end, we propose FashionBERT, which leverages patches as image features. With the pre-trained BERT model as the backbone network, FashionBERT learns high level representations of texts and images. Meanwhile, we propose an adaptive loss to trade off multitask learning in the FashionBERT modeling. Two tasks (i.e., text and image matching and cross-modal retrieval) are incorporated to evaluate FashionBERT. On the public dataset, experiments demonstrate FashionBERT achieves significant improvements in performances than the baseline and state-of-the-art approaches. In practice, FashionBERT is applied in a concrete cross-modal retrieval application. We provide the detailed matching performance and inference efficiency analysis.

</details>

<details>

<summary>2020-05-30 14:59:07 - On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location</summary>

- *Osman Semih Kayhan, Jan C. van Gemert*

- `2003.07064v2` - [abs](http://arxiv.org/abs/2003.07064v2) - [pdf](http://arxiv.org/pdf/2003.07064v2)

> In this paper we challenge the common assumption that convolutional layers in modern CNNs are translation invariant. We show that CNNs can and will exploit the absolute spatial location by learning filters that respond exclusively to particular absolute locations by exploiting image boundary effects. Because modern CNNs filters have a huge receptive field, these boundary effects operate even far from the image boundary, allowing the network to exploit absolute spatial location all over the image. We give a simple solution to remove spatial location encoding which improves translation invariance and thus gives a stronger visual inductive bias which particularly benefits small data sets. We broadly demonstrate these benefits on several architectures and various applications such as image classification, patch matching, and two video classification datasets.

</details>

<details>

<summary>2020-05-31 01:47:33 - Deep Cerebellar Nuclei Segmentation via Semi-Supervised Deep Context-Aware Learning from 7T Diffusion MRI</summary>

- *Jinyoung Kim, Remi Patriat, Jordan Kaplan, Oren Solomon, Noam Harel*

- `2004.09788v3` - [abs](http://arxiv.org/abs/2004.09788v3) - [pdf](http://arxiv.org/pdf/2004.09788v3)

> Deep cerebellar nuclei are a key structure of the cerebellum that are involved in processing motor and sensory information. It is thus a crucial step to accurately segment deep cerebellar nuclei for the understanding of the cerebellum system and its utility in deep brain stimulation treatment. However, it is challenging to clearly visualize such small nuclei under standard clinical magnetic resonance imaging (MRI) protocols and therefore precise segmentation is not feasible. Recent advances in 7 Tesla (T) MRI technology and great potential of deep neural networks facilitate automatic patient-specific segmentation. In this paper, we propose a novel deep learning framework (referred to as DCN-Net) for fast, accurate, and robust patient-specific segmentation of deep cerebellar dentate and interposed nuclei on 7T diffusion MRI. DCN-Net effectively encodes contextual information on the patch images without consecutive pooling operations and adding complexity via proposed dilated dense blocks. During the end-to-end training, label probabilities of dentate and interposed nuclei are independently learned with a hybrid loss, handling highly imbalanced data. Finally, we utilize self-training strategies to cope with the problem of limited labeled data. To this end, auxiliary dentate and interposed nuclei labels are created on unlabeled data by using DCN-Net trained on manual labels. We validate the proposed framework using 7T B0 MRIs from 60 subjects. Experimental results demonstrate that DCN-Net provides better segmentation than atlas-based deep cerebellar nuclei segmentation tools and other state-of-the-art deep neural networks in terms of accuracy and consistency. We further prove the effectiveness of the proposed components within DCN-Net in dentate and interposed nuclei segmentation.

</details>


## 2020-06

<details>

<summary>2020-06-01 01:39:56 - Convolutional Neural Networks for Classification of Alzheimer's Disease: Overview and Reproducible Evaluation</summary>

- *Junhao Wen, Elina Thibeau-Sutre, Mauricio Diaz-Melo, Jorge Samper-Gonzalez, Alexandre Routier, Simona Bottani, Didier Dormont, Stanley Durrleman, Ninon Burgos, Olivier Colliot*

- `1904.07773v6` - [abs](http://arxiv.org/abs/1904.07773v6) - [pdf](http://arxiv.org/pdf/1904.07773v6)

> Over 30 papers have proposed to use convolutional neural network (CNN) for AD classification from anatomical MRI. However, the classification performance is difficult to compare across studies due to variations in components such as participant selection, image preprocessing or validation procedure. Moreover, these studies are hardly reproducible because their frameworks are not publicly accessible and because implementation details are lacking. Lastly, some of these papers may report a biased performance due to inadequate or unclear validation or model selection procedures. In the present work, we aim to address these limitations through three main contributions. First, we performed a systematic literature review and found that more than half of the surveyed papers may have suffered from data leakage. Our second contribution is the extension of our open-source framework for classification of AD using CNN and T1-weighted MRI. Finally, we used this framework to rigorously compare different CNN architectures. The data was split into training/validation/test sets at the very beginning and only the training/validation sets were used for model selection. To avoid any overfitting, the test sets were left untouched until the end of the peer-review process. Overall, the different 3D approaches (3D-subject, 3D-ROI, 3D-patch) achieved similar performances while that of the 2D slice approach was lower. Of note, the different CNN approaches did not perform better than a SVM with voxel-based features. The different approaches generalized well to similar populations but not to datasets with different inclusion criteria or demographical characteristics.

</details>

<details>

<summary>2020-06-01 10:27:42 - Multi-scale Cloud Detection in Remote Sensing Images using a Dual Convolutional Neural Network</summary>

- *Markku Luotamo, Sari Metsämäki, Arto Klami*

- `2006.00836v1` - [abs](http://arxiv.org/abs/2006.00836v1) - [pdf](http://arxiv.org/pdf/2006.00836v1)

> Semantic segmentation by convolutional neural networks (CNN) has advanced the state of the art in pixel-level classification of remote sensing images. However, processing large images typically requires analyzing the image in small patches, and hence features that have large spatial extent still cause challenges in tasks such as cloud masking. To support a wider scale of spatial features while simultaneously reducing computational requirements for large satellite images, we propose an architecture of two cascaded CNN model components successively processing undersampled and full resolution images. The first component distinguishes between patches in the inner cloud area from patches at the cloud's boundary region. For the cloud-ambiguous edge patches requiring further segmentation, the framework then delegates computation to a fine-grained model component. We apply the architecture to a cloud detection dataset of complete Sentinel-2 multispectral images, approximately annotated for minimal false negatives in a land use application. On this specific task and data, we achieve a 16\% relative improvement in pixel accuracy over a CNN baseline based on patching.

</details>

<details>

<summary>2020-06-06 09:07:15 - BHN: A Brain-like Heterogeneous Network</summary>

- *Tao Liu*

- `2005.12826v2` - [abs](http://arxiv.org/abs/2005.12826v2) - [pdf](http://arxiv.org/pdf/2005.12826v2)

> The human brain works in an unsupervised way, and more than one brain region is essential for lighting up intelligence. Inspired by this, we propose a brain-like heterogeneous network (BHN), which can cooperatively learn a lot of distributed representations and one global attention representation. By optimizing distributed, self-supervised, and gradient-isolated objective functions in a minimax fashion, our model improves its representations, which are generated from patches of pictures or frames of videos in experiments.

</details>

<details>

<summary>2020-06-06 20:25:07 - Tuning a variational autoencoder for data accountability problem in the Mars Science Laboratory ground data system</summary>

- *Dounia Lakhmiri, Ryan Alimo, Sebastien Le Digabel*

- `2006.03962v1` - [abs](http://arxiv.org/abs/2006.03962v1) - [pdf](http://arxiv.org/pdf/2006.03962v1)

> The Mars Curiosity rover is frequently sending back engineering and science data that goes through a pipeline of systems before reaching its final destination at the mission operations center making it prone to volume loss and data corruption. A ground data system analysis (GDSA) team is charged with the monitoring of this flow of information and the detection of anomalies in that data in order to request a re-transmission when necessary. This work presents $\Delta$-MADS, a derivative-free optimization method applied for tuning the architecture and hyperparameters of a variational autoencoder trained to detect the data with missing patches in order to assist the GDSA team in their mission.

</details>

<details>

<summary>2020-06-07 18:41:56 - Self-supervised classification of dynamic obstacles using the temporal information provided by videos</summary>

- *Sid Ali Hamideche, Florent Chiaroni, Mohamed-Cherif Rahal*

- `1910.09094v2` - [abs](http://arxiv.org/abs/1910.09094v2) - [pdf](http://arxiv.org/pdf/1910.09094v2)

> Nowadays, autonomous driving systems can detect, segment, and classify the surrounding obstacles using a monocular camera. However, state-of-the-art methods solving these tasks generally perform a fully supervised learning process and require a large amount of training labeled data. On another note, some self-supervised learning approaches can deal with detection and segmentation of dynamic obstacles using the temporal information available in video sequences. In this work, we propose to classify the detected obstacles depending on their motion pattern. We present a novel self-supervised framework consisting of learning offline clusters from temporal patch sequences and considering these clusters as labeled sets to train a real-time image classifier. The presented model outperforms state-of-the-art unsupervised image classification methods on large-scale diverse driving video dataset BDD100K.

</details>

<details>

<summary>2020-06-08 19:58:58 - ObjSim: Lightweight Automatic Patch Prioritization via Object Similarity</summary>

- *Ali Ghanbari*

- `2006.04911v1` - [abs](http://arxiv.org/abs/2006.04911v1) - [pdf](http://arxiv.org/pdf/2006.04911v1)

> In the context of test case based automatic program repair (APR), patches that pass all the test cases but fail to fix the bug are called overfitted patches. Currently, patches generated by APR tools get inspected manually by the users to find and adopt genuine fixes. Being a laborious activity hindering widespread adoption of APR, automatic identification of overfitted patches has lately been the topic of active research. This paper presents engineering details of ObjSim: a fully automatic, lightweight similarity-based patch prioritization tool for JVM-based languages. The tool works by comparing the system state at the exit point(s) of patched method before and after patching and prioritizing patches that result in state that is more similar to that of original, unpatched version on passing tests while less similar on failing ones. Our experiments with patches generated by the recent APR tool PraPR for fixable bugs from Defects4J v1.4.0 show that ObjSim prioritizes 16.67% more genuine fixes in top-1 place. A demo video of the tool is located at https://bit.ly/2K8gnYV.

</details>

<details>

<summary>2020-06-09 15:55:31 - A Tree-based Dictionary Learning Framework</summary>

- *Renato Budinich, Gerlind Plonka*

- `1909.03267v2` - [abs](http://arxiv.org/abs/1909.03267v2) - [pdf](http://arxiv.org/pdf/1909.03267v2)

> We propose a new outline for adaptive dictionary learning methods for sparse encoding based on a hierarchical clustering of the training data. Through recursive application of a clustering method, the data is organized into a binary partition tree representing a multiscale structure. The dictionary atoms are defined adaptively based on the data clusters in the partition tree. This approach can be interpreted as a generalization of a discrete Haar wavelet transform. Furthermore, any prior knowledge on the wanted structure of the dictionary elements can be simply incorporated. The computational complexity of our proposed algorithm depends on the employed clustering method and on the chosen similarity measure between data points. Thanks to the multiscale properties of the partition tree, our dictionary is structured: when using Orthogonal Matching Pursuit to reconstruct patches from a natural image, dictionary atoms corresponding to nodes being closer to the root node in the tree have a tendency to be used with greater coefficients.

</details>

<details>

<summary>2020-06-10 01:42:40 - Using an expert deviation carrying the knowledge of climate data in usual clustering algorithms</summary>

- *Emmanuel Biabiany, Vincent Page, Didier Bernard, Hélène Paugam-Moisy*

- `2006.05603v1` - [abs](http://arxiv.org/abs/2006.05603v1) - [pdf](http://arxiv.org/pdf/2006.05603v1)

> In order to help physicists to expand their knowledge of the climate in the Lesser Antilles, we aim to identify the spatio-temporal configurations using clustering analysis on wind speed and cumulative rainfall datasets. But we show that using the L2 norm in conventional clustering methods as K-Means (KMS) and Hierarchical Agglomerative Clustering (HAC) can induce undesirable effects. So, we propose to replace Euclidean distance (L2) by a dissimilarity measure named Expert Deviation (ED). Based on the symmetrized Kullback-Leibler divergence, the ED integrates the properties of the observed physical parameters and climate knowledge. This measure helps comparing histograms of four patches, corresponding to geographical zones, that are influenced by atmospheric structures. The combined evaluation of the internal homogeneity and the separation of the clusters obtained using ED and L2 was performed. The results, which are compared using the silhouette index, show five clusters with high indexes. For the two available datasets one can see that, unlike KMS-L2, KMS-ED discriminates the daily situations favorably, giving more physical meaning to the clusters discovered by the algorithm. The effect of patches is observed in the spatial analysis of representative elements for KMS-ED. The ED is able to produce different configurations which makes the usual atmospheric structures clearly identifiable. Atmospheric physicists can interpret the locations of the impact of each cluster on a specific zone according to atmospheric structures. KMS-L2 does not lead to such an interpretability, because the situations represented are spatially quite smooth. This climatological study illustrates the advantage of using ED as a new approach.

</details>

<details>

<summary>2020-06-12 05:58:56 - PFCNN: Convolutional Neural Networks on 3D Surfaces Using Parallel Frames</summary>

- *Yuqi Yang, Shilin Liu, Hao Pan, Yang Liu, Xin Tong*

- `1808.04952v2` - [abs](http://arxiv.org/abs/1808.04952v2) - [pdf](http://arxiv.org/pdf/1808.04952v2)

> Surface meshes are widely used shape representations and capture finer geometry data than point clouds or volumetric grids, but are challenging to apply CNNs directly due to their non-Euclidean structure. We use parallel frames on surface to define PFCNNs that enable effective feature learning on surface meshes by mimicking standard convolutions faithfully. In particular, the convolution of PFCNN not only maps local surface patches onto flat tangent planes, but also aligns the tangent planes such that they locally form a flat Euclidean structure, thus enabling recovery of standard convolutions. The alignment is achieved by the tool of locally flat connections borrowed from discrete differential geometry, which can be efficiently encoded and computed by parallel frame fields. In addition, the lack of canonical axis on surface is handled by sampling with the frame directions. Experiments show that for tasks including classification, segmentation and registration on deformable geometric domains, as well as semantic scene segmentation on rigid domains, PFCNNs achieve robust and superior performances without using sophisticated input features than state-of-the-art surface based CNNs.

</details>

<details>

<summary>2020-06-12 08:30:04 - Spatial Firewalls: Quarantining Malware Epidemics in Large Scale Massive Wireless Networks</summary>

- *Hesham Elsawy, Mustafa A. Kishk, Mohamed-Slim Alouini*

- `2006.05059v2` - [abs](http://arxiv.org/abs/2006.05059v2) - [pdf](http://arxiv.org/pdf/2006.05059v2)

> Billions of wireless devices are foreseen to participate in big data aggregation and smart automation in order to interface the cyber and physical worlds. Such large-scale ultra-dense wireless connectivity is vulnerable to malicious software (malware) epidemics. Malware worms can exploit multi-hop wireless connectivity to stealthily diffuse throughout the wireless network without being noticed to security servers at the core network. Compromised devices can then be used by adversaries to remotely launch cyber attacks that cause large-scale critical physical damage and threaten public safety. This article overviews the types, threats, and propagation models for malware epidemics in large-scale wireless networks (LSWN). Then, the article proposes a novel and cost efficient countermeasure against malware epidemics in LSWN, denoted as spatial firewalls. It is shown that equipping a strategically selected small portion (i.e., less than 10\%) of the devices with state-of-the-art security mechanisms is sufficient to create spatially secured zones that quarantine malware epidemics. Quarantined infected devices are then cured by on-demand localized software patching. To this end, several firewall deployment strategies are discussed and compared.

</details>

<details>

<summary>2020-06-16 15:43:12 - Structured and Localized Image Restoration</summary>

- *Thomas Eboli, Alex Nowak-Vila, Jian Sun, Francis Bach, Jean Ponce, Alessandro Rudi*

- `2006.09261v1` - [abs](http://arxiv.org/abs/2006.09261v1) - [pdf](http://arxiv.org/pdf/2006.09261v1)

> We present a novel approach to image restoration that leverages ideas from localized structured prediction and non-linear multi-task learning. We optimize a penalized energy function regularized by a sum of terms measuring the distance between patches to be restored and clean patches from an external database gathered beforehand. The resulting estimator comes with strong statistical guarantees leveraging local dependency properties of overlapping patches. We derive the corresponding algorithms for energies based on the mean-squared and Euclidean norm errors. Finally, we demonstrate the practical effectiveness of our model on different image restoration problems using standard benchmarks.

</details>

<details>

<summary>2020-06-16 16:51:53 - Lung Segmentation and Nodule Detection in Computed Tomography Scan using a Convolutional Neural Network Trained Adversarially using Turing Test Loss</summary>

- *Rakshith Sathish, Rachana Sathish, Ramanathan Sethuraman, Debdoot Sheet*

- `2006.09308v1` - [abs](http://arxiv.org/abs/2006.09308v1) - [pdf](http://arxiv.org/pdf/2006.09308v1)

> Lung cancer is the most common form of cancer found worldwide with a high mortality rate. Early detection of pulmonary nodules by screening with a low-dose computed tomography (CT) scan is crucial for its effective clinical management. Nodules which are symptomatic of malignancy occupy about 0.0125 - 0.025\% of volume in a CT scan of a patient. Manual screening of all slices is a tedious task and presents a high risk of human errors. To tackle this problem we propose a computationally efficient two stage framework. In the first stage, a convolutional neural network (CNN) trained adversarially using Turing test loss segments the lung region. In the second stage, patches sampled from the segmented region are then classified to detect the presence of nodules. The proposed method is experimentally validated on the LUNA16 challenge dataset with a dice coefficient of $0.984\pm0.0007$ for 10-fold cross-validation.

</details>

<details>

<summary>2020-06-17 16:33:01 - IGLOO: Slicing the Features Space to Represent Sequences</summary>

- *Vsevolod Sourkov*

- `1807.03402v3` - [abs](http://arxiv.org/abs/1807.03402v3) - [pdf](http://arxiv.org/pdf/1807.03402v3)

> Historically, Recurrent neural networks (RNNs) and its variants such as LSTM and GRU and more recently Transformers have been the standard go-to components when processing sequential data with neural networks. One notable issue is the relative difficulty to deal with long sequences (i.e. more than 20,000 steps). We introduce IGLOO, a new neural network architecture which aims at being efficient for short sequences but also at being able to deal with long sequences. IGLOOs core idea is to use the relationships between non-local patches sliced out of the features maps of successively applied convolutions to build a representation for the sequence. We show that the model can deal with dependencies of more than 20,000 steps in a reasonable time frame. We stress test IGLOO on the copy-memory and addition tasks, as well as permuted MNIST (98.4%). For a larger task we apply this new structure to the Wikitext-2 dataset Merity et al. (2017b) and achieve a perplexity in line with baseline Transformers but lower than baseline AWD-LSTM. We also present how IGLOO is already used today in production for bioinformatics tasks.

</details>

<details>

<summary>2020-06-17 17:16:38 - Fast Object Classification and Meaningful Data Representation of Segmented Lidar Instances</summary>

- *Lukas Hahn, Frederik Hasecke, Anton Kummert*

- `2006.10011v1` - [abs](http://arxiv.org/abs/2006.10011v1) - [pdf](http://arxiv.org/pdf/2006.10011v1)

> Object detection algorithms for Lidar data have seen numerous publications in recent years, reporting good results on dataset benchmarks oriented towards automotive requirements. Nevertheless, many of these are not deployable to embedded vehicle systems, as they require immense computational power to be executed close to real time. In this work, we propose a way to facilitate real-time Lidar object classification on CPU. We show how our approach uses segmented object instances to extract important features, enabling a computationally efficient batch-wise classification. For this, we introduce a data representation which translates three-dimensional information into small image patches, using decomposed normal vector images. We couple this with dedicated object statistics to handle edge cases. We apply our method on the tasks of object detection and semantic segmentation, as well as the relatively new challenge of panoptic segmentation. Through evaluation, we show, that our algorithm is capable of producing good results on public data, while running in real time on CPU without using specific optimisation.

</details>

<details>

<summary>2020-06-18 21:05:27 - Deep Image Translation for Enhancing Simulated Ultrasound Images</summary>

- *Lin Zhang, Tiziano Portenier, Christoph Paulus, Orcun Goksel*

- `2006.10850v1` - [abs](http://arxiv.org/abs/2006.10850v1) - [pdf](http://arxiv.org/pdf/2006.10850v1)

> Ultrasound simulation based on ray tracing enables the synthesis of highly realistic images. It can provide an interactive environment for training sonographers as an educational tool. However, due to high computational demand, there is a trade-off between image quality and interactivity, potentially leading to sub-optimal results at interactive rates. In this work we introduce a deep learning approach based on adversarial training that mitigates this trade-off by improving the quality of simulated images with constant computation time. An image-to-image translation framework is utilized to translate low quality images into high quality versions. To incorporate anatomical information potentially lost in low quality images, we additionally provide segmentation maps to image translation. Furthermore, we propose to leverage information from acoustic attenuation maps to better preserve acoustic shadows and directional artifacts, an invaluable feature for ultrasound image interpretation. The proposed method yields an improvement of 7.2% in Fr\'{e}chet Inception Distance and 8.9% in patch-based Kullback-Leibler divergence.

</details>

<details>

<summary>2020-06-21 11:07:37 - Patch Based Classification of Remote Sensing Data: A Comparison of 2D-CNN, SVM and NN Classifiers</summary>

- *Mahesh Pal, Akshay, Himanshu Rohilla, B. Charan Teja*

- `2006.11767v1` - [abs](http://arxiv.org/abs/2006.11767v1) - [pdf](http://arxiv.org/pdf/2006.11767v1)

> Pixel based algorithms including back propagation neural networks (NN) and support vector machines (SVM) have been widely used for remotely sensed image classifications. Within last few years, deep learning based image classifier like convolution neural networks (2D-CNN) are becoming popular alternatives to these classifiers. In this paper, we compare performance of patch based SVM and NN with that of a deep learning algorithms comprising of 2D-CNN and fully connected layers. Similar to CNN which utilise image patches to derive features for further classification, we propose to use patches as an input in place of individual pixel with both SVM and NN classifiers. Two datasets, one multispectral and other hyperspectral data was used to compare the performance of different classifiers. Results with both datasets suggest the effectiveness of patch based SVM and NN classifiers in comparison to state of art 2D-CNN classifier.

</details>

<details>

<summary>2020-06-22 07:17:57 - Folding-based compression of point cloud attributes</summary>

- *Maurice Quach, Giuseppe Valenzise, Frederic Dufaux*

- `2002.04439v3` - [abs](http://arxiv.org/abs/2002.04439v3) - [pdf](http://arxiv.org/pdf/2002.04439v3)

> Existing techniques to compress point cloud attributes leverage either geometric or video-based compression tools. We explore a radically different approach inspired by recent advances in point cloud representation learning. Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we fold a 2D grid onto a point cloud and we map attributes from the point cloud onto the folded 2D grid using a novel optimized mapping method. This mapping results in an image, which opens a way to apply existing image processing techniques on point cloud attributes. However, as this mapping process is lossy in nature, we propose several strategies to refine it so that attributes can be mapped to the 2D grid with minimal distortion. Moreover, this approach can be flexibly applied to point cloud patches in order to better adapt to local geometric complexity. In this work, we consider point cloud attribute compression; thus, we compress this image with a conventional 2D image codec. Our preliminary results show that the proposed folding-based coding scheme can already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC) codec.

</details>

<details>

<summary>2020-06-24 17:29:26 - Automated Chest CT Image Segmentation of COVID-19 Lung Infection based on 3D U-Net</summary>

- *Dominik Müller, Iñaki Soto Rey, Frank Kramer*

- `2007.04774v1` - [abs](http://arxiv.org/abs/2007.04774v1) - [pdf](http://arxiv.org/pdf/2007.04774v1)

> The coronavirus disease 2019 (COVID-19) affects billions of lives around the world and has a significant impact on public healthcare. Due to rising skepticism towards the sensitivity of RT-PCR as screening method, medical imaging like computed tomography offers great potential as alternative. For this reason, automated image segmentation is highly desired as clinical decision support for quantitative assessment and disease monitoring. However, publicly available COVID-19 imaging data is limited which leads to overfitting of traditional approaches. To address this problem, we propose an innovative automated segmentation pipeline for COVID-19 infected regions, which is able to handle small datasets by utilization as variant databases. Our method focuses on on-the-fly generation of unique and random image patches for training by performing several preprocessing methods and exploiting extensive data augmentation. For further reduction of the overfitting risk, we implemented a standard 3D U-Net architecture instead of new or computational complex neural network architectures. Through a 5-fold cross-validation on 20 CT scans of COVID-19 patients, we were able to develop a highly accurate as well as robust segmentation model for lungs and COVID-19 infected regions without overfitting on the limited data. Our method achieved Dice similarity coefficients of 0.956 for lungs and 0.761 for infection. We demonstrated that the proposed method outperforms related approaches, advances the state-of-the-art for COVID-19 segmentation and improves medical image analysis with limited data. The code and model are available under the following link: https://github.com/frankkramer-lab/covid19.MIScnn

</details>

<details>

<summary>2020-06-25 21:10:04 - Deep Q-Network-Driven Catheter Segmentation in 3D US by Hybrid Constrained Semi-Supervised Learning and Dual-UNet</summary>

- *Hongxu Yang, Caifeng Shan, Alexander F. Kolen, Peter H. N. de With*

- `2006.14702v1` - [abs](http://arxiv.org/abs/2006.14702v1) - [pdf](http://arxiv.org/pdf/2006.14702v1)

> Catheter segmentation in 3D ultrasound is important for computer-assisted cardiac intervention. However, a large amount of labeled images are required to train a successful deep convolutional neural network (CNN) to segment the catheter, which is expensive and time-consuming. In this paper, we propose a novel catheter segmentation approach, which requests fewer annotations than the supervised learning method, but nevertheless achieves better performance. Our scheme considers a deep Q learning as the pre-localization step, which avoids voxel-level annotation and which can efficiently localize the target catheter. With the detected catheter, patch-based Dual-UNet is applied to segment the catheter in 3D volumetric data. To train the Dual-UNet with limited labeled images and leverage information of unlabeled images, we propose a novel semi-supervised scheme, which exploits unlabeled images based on hybrid constraints from predictions. Experiments show the proposed scheme achieves a higher performance than state-of-the-art semi-supervised methods, while it demonstrates that our method is able to learn from large-scale unlabeled images.

</details>

<details>

<summary>2020-06-26 16:38:28 - CrackGAN: Pavement Crack Detection Using Partially Accurate Ground Truths Based on Generative Adversarial Learning</summary>

- *Kaige Zhang, Yingtao Zhang, Heng-Da Cheng*

- `1909.08216v2` - [abs](http://arxiv.org/abs/1909.08216v2) - [pdf](http://arxiv.org/pdf/1909.08216v2)

> Fully convolutional network is a powerful tool for per-pixel semantic segmentation/detection. However, it is problematic when coping with crack detection using partially accurate ground truths (GTs): the network may easily converge to the status that treats all the pixels as background (BG) and still achieves a very good loss, named "All Black" phenomenon, due to the unavailability of accurate GTs and the data imbalance. To tackle this problem, we propose crack-patch-only (CPO) supervised generative adversarial learning for end-to-end training, which forces the network to always produce crack-GT images while reserves both crack and BG-image translation abilities by feeding a larger-size crack image into an asymmetric U-shape generator to overcome the "All Black" issue. The proposed approach is validated using four crack datasets; and achieves state-of-the-art performance comparing with that of the recently published works in efficiency and accuracy.

</details>

<details>

<summary>2020-06-27 03:57:48 - XI Commandments of Kubernetes Security: A Systematization of Knowledge Related to Kubernetes Security Practices</summary>

- *Md. Shazibul Islam Shamim, Farzana Ahamed Bhuiyan, Akond Rahman*

- `2006.15275v1` - [abs](http://arxiv.org/abs/2006.15275v1) - [pdf](http://arxiv.org/pdf/2006.15275v1)

> Kubernetes is an open-source software for automating management of computerized services. Organizations, such as IBM, Capital One and Adidas use Kubernetes to deploy and manage their containers, and have reported benefits related to deployment frequency. Despite reported benefits, Kubernetes deployments are susceptible to security vulnerabilities, such as those that occurred at Tesla in 2018. A systematization of Kubernetes security practices can help practitioners mitigate vulnerabilities in their Kubernetes deployments. The goal of this paper is to help practitioners in securing their Kubernetes installations through a systematization of knowledge related to Kubernetes security practices. We systematize knowledge by applying qualitative analysis on 104 Internet artifacts. We identify 11 security practices that include (i) implementation of role-based access control (RBAC) authorization to provide least privilege, (ii) applying security patches to keep Kubernetes updated, and (iii) implementing pod and network specific security policies.

</details>

<details>

<summary>2020-06-30 02:16:21 - Invariant Diffs</summary>

- *Ashwin Kallingal Joshy, Wei Le*

- `1911.07988v2` - [abs](http://arxiv.org/abs/1911.07988v2) - [pdf](http://arxiv.org/pdf/1911.07988v2)

> Software development is inherently incremental. Nowadays, many software companies adopt an agile process and a shorter release cycle, where software needs to be delivered faster with quality assurances. On the other hand, the majority of existing program analysis tools still target single versions of programs and are slow and inflexible to handle changes. In the popular version control systems such as git, the program changes are still presented using source code diffs. It is hard to understand what program conditions are changed and which source code lines cause them. In this paper, we propose to compute "invariant diffs" to specify changes. Similar to source diffs that report common code and code churns, we define version invariants to represent program conditions that are common across versions, and invariant churns to show the changes of program conditions between versions. We designed a static demand-driven, path-sensitive analysis to compute and compare invariants for multiple versions of programs using multiversion control flow graphs. We report invariant diffs at the matched program points where comparing invariants are meaningful. Importantly, our analysis correlates source diffs with invariant diffs to explain what source code changes lead to the property changes. We implemented our algorithms in a tool called $H_2$ and performed experiments on 104 versions of programs. Our results show that we are able to compute invariant diffs correctly within reasonable amount of time. The version invariants can capture the common properties of program versions even constructed by different persons, and the invariant churns can specify the semantics of changes such as how a patch changed a buggy condition to a correct condition.

</details>

<details>

<summary>2020-06-30 09:36:21 - BitMix: Data Augmentation for Image Steganalysis</summary>

- *In-Jae Yu, Wonhyuk Ahn, Seung-Hun Nam, Heung-Kyu Lee*

- `2006.16625v1` - [abs](http://arxiv.org/abs/2006.16625v1) - [pdf](http://arxiv.org/pdf/2006.16625v1)

> Convolutional neural networks (CNN) for image steganalysis demonstrate better performances with employing concepts from high-level vision tasks. The major employed concept is to use data augmentation to avoid overfitting due to limited data. To augment data without damaging the message embedding, only rotating multiples of 90 degrees or horizontally flipping are used in steganalysis, which generates eight fixed results from one sample. To overcome this limitation, we propose BitMix, a data augmentation method for spatial image steganalysis. BitMix mixes a cover and stego image pair by swapping the random patch and generates an embedding adaptive label with the ratio of the number of pixels modified in the swapped patch to those in the cover-stego pair. We explore optimal hyperparameters, the ratio of applying BitMix in the mini-batch, and the size of the bounding box for swapping patch. The results reveal that using BitMix improves the performance of spatial image steganalysis and better than other data augmentation methods.

</details>

<details>

<summary>2020-06-30 19:36:38 - Deep Geometric Texture Synthesis</summary>

- *Amir Hertz, Rana Hanocka, Raja Giryes, Daniel Cohen-Or*

- `2007.00074v1` - [abs](http://arxiv.org/abs/2007.00074v1) - [pdf](http://arxiv.org/pdf/2007.00074v1)

> Recently, deep generative adversarial networks for image generation have advanced rapidly; yet, only a small amount of research has focused on generative models for irregular structures, particularly meshes. Nonetheless, mesh generation and synthesis remains a fundamental topic in computer graphics. In this work, we propose a novel framework for synthesizing geometric textures. It learns geometric texture statistics from local neighborhoods (i.e., local triangular patches) of a single reference 3D model. It learns deep features on the faces of the input triangulation, which is used to subdivide and generate offsets across multiple scales, without parameterization of the reference or target mesh. Our network displaces mesh vertices in any direction (i.e., in the normal and tangential direction), enabling synthesis of geometric textures, which cannot be expressed by a simple 2D displacement map. Learning and synthesizing on local geometric patches enables a genus-oblivious framework, facilitating texture transfer between shapes of different genus.

</details>


## 2020-07

<details>

<summary>2020-07-03 16:27:23 - Learning Permutation Invariant Representations using Memory Networks</summary>

- *Shivam Kalra, Mohammed Adnan, Graham Taylor, Hamid Tizhoosh*

- `1911.07984v2` - [abs](http://arxiv.org/abs/1911.07984v2) - [pdf](http://arxiv.org/pdf/1911.07984v2)

> Many real-world tasks such as classification of digital histopathology images and 3D object detection involve learning from a set of instances. In these cases, only a group of instances or a set, collectively, contains meaningful information and therefore only the sets have labels, and not individual data instances. In this work, we present a permutation invariant neural network called Memory-based Exchangeable Model (MEM) for learning set functions. The MEM model consists of memory units that embed an input sequence to high-level features enabling the model to learn inter-dependencies among instances through a self-attention mechanism. We evaluated the learning ability of MEM on various toy datasets, point cloud classification, and classification of lung whole slide images (WSIs) into two subtypes of lung cancer---Lung Adenocarcinoma, and Lung Squamous Cell Carcinoma. We systematically extracted patches from lung WSIs downloaded from The Cancer Genome Atlas~(TCGA) dataset, the largest public repository of WSIs, achieving a competitive accuracy of 84.84\% for classification of two sub-types of lung cancer. The results on other datasets are promising as well, and demonstrate the efficacy of our model.

</details>

<details>

<summary>2020-07-05 12:12:09 - Challenges in Designing Exploit Mitigations for Deeply Embedded Systems</summary>

- *Ali Abbasi, Jos Wetzels, Thorsten Holz, Sandro Etalle*

- `2007.02307v1` - [abs](http://arxiv.org/abs/2007.02307v1) - [pdf](http://arxiv.org/pdf/2007.02307v1)

> Memory corruption vulnerabilities have been around for decades and rank among the most prevalent vulnerabilities in embedded systems. Yet this constrained environment poses unique design and implementation challenges that significantly complicate the adoption of common hardening techniques. Combined with the irregular and involved nature of embedded patch management, this results in prolonged vulnerability exposure windows and vulnerabilities that are relatively easy to exploit. Considering the sensitive and critical nature of many embedded systems, this situation merits significant improvement. In this work, we present the first quantitative study of exploit mitigation adoption in 42 embedded operating systems, showing the embedded world to significantly lag behind the general-purpose world. To improve the security of deeply embedded systems, we subsequently present {\mu}Armor, an approach to address some of the key gaps identified in our quantitative analysis. {\mu}Armor raises the bar for exploitation of embedded memory corruption vulnerabilities, while being adoptable on the short term without incurring prohibitive extra performance or storage costs.

</details>

<details>

<summary>2020-07-06 03:06:26 - Adversarial T-shirt! Evading Person Detectors in A Physical World</summary>

- *Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin*

- `1910.11099v3` - [abs](http://arxiv.org/abs/1910.11099v3) - [pdf](http://arxiv.org/pdf/1910.11099v3)

> It is known that deep neural networks (DNNs) are vulnerable to adversarial attacks. The so-called physical adversarial examples deceive DNN-based decisionmakers by attaching adversarial patches to real objects. However, most of the existing works on physical adversarial attacks focus on static objects such as glass frames, stop signs and images attached to cardboard. In this work, we proposed adversarial T-shirts, a robust physical adversarial example for evading person detectors even if it could undergo non-rigid deformation due to a moving person's pose changes. To the best of our knowledge, this is the first work that models the effect of deformation for designing physical adversarial examples with respect to-rigid objects such as T-shirts. We show that the proposed method achieves74% and 57% attack success rates in the digital and physical worlds respectively against YOLOv2. In contrast, the state-of-the-art physical attack method to fool a person detector only achieves 18% attack success rate. Furthermore, by leveraging min-max optimization, we extend our method to the ensemble attack setting against two object detectors YOLO-v2 and Faster R-CNN simultaneously.

</details>

<details>

<summary>2020-07-06 14:59:31 - An Exploratory Analysis of Microcode as a Building Block for System Defenses</summary>

- *Benjamin Kollenda, Philipp Koppe, Marc Fyrbiak, Christian Kison, Christof Paar, Thorsten Holz*

- `2007.03549v1` - [abs](http://arxiv.org/abs/2007.03549v1) - [pdf](http://arxiv.org/pdf/2007.03549v1)

> Microcode is an abstraction layer used by modern x86 processors that interprets user-visible CISC instructions to hardware-internal RISC instructions. The capability to update x86 microcode enables a vendor to modify CPU behavior in-field, and thus patch erroneous microarchitectural processes or even implement new features. Most prominently, the recent Spectre and Meltdown vulnerabilities were mitigated by Intel via microcode updates. Unfortunately, microcode is proprietary and closed source, and there is little publicly available information on its inner workings.   In this paper, we present new reverse engineering results that extend and complement the public knowledge of proprietary microcode. Based on these novel insights, we show how modern system defenses and tools can be realized in microcode on a commercial, off-the-shelf AMD x86 CPU. We demonstrate how well-established system security defenses such as timing attack mitigations, hardware-assisted address sanitization, and instruction set randomization can be realized in microcode. We also present a proof-of-concept implementation of a microcode-assisted instrumentation framework. Finally, we show how a secure microcode update mechanism and enclave functionality can be implemented in microcode to realize a small trusted execution environment. All microcode programs and the whole infrastructure needed to reproduce and extend our results are publicly available.

</details>

<details>

<summary>2020-07-08 11:29:18 - A Data and Compute Efficient Design for Limited-Resources Deep Learning</summary>

- *Mirgahney Mohamed, Gabriele Cesa, Taco S. Cohen, Max Welling*

- `2004.09691v2` - [abs](http://arxiv.org/abs/2004.09691v2) - [pdf](http://arxiv.org/pdf/2004.09691v2)

> Thanks to their improved data efficiency, equivariant neural networks have gained increased interest in the deep learning community. They have been successfully applied in the medical domain where symmetries in the data can be effectively exploited to build more accurate and robust models. To be able to reach a much larger body of patients, mobile, on-device implementations of deep learning solutions have been developed for medical applications. However, equivariant models are commonly implemented using large and computationally expensive architectures, not suitable to run on mobile devices. In this work, we design and test an equivariant version of MobileNetV2 and further optimize it with model quantization to enable more efficient inference. We achieve close-to state of the art performance on the Patch Camelyon (PCam) medical dataset while being more computationally efficient.

</details>

<details>

<summary>2020-07-15 01:48:03 - Data Sampling on MDS-resistant 10th Generation Intel Core (Ice Lake)</summary>

- *Daniel Moghimi*

- `2007.07428v1` - [abs](http://arxiv.org/abs/2007.07428v1) - [pdf](http://arxiv.org/pdf/2007.07428v1)

> Microarchitectural Data Sampling (MDS) is a set of hardware vulnerabilities in Intel CPUs that allows an attacker to leak bytes of data from memory loads and stores across various security boundaries. On affected CPUs, some of these vulnerabilities were patched via microcode updates. Additionally, Intel announced that the newest microarchitectures, namely Cascade Lake and Ice Lake, were not affected by MDS. While Cascade Lake turned out to be vulnerable to the ZombieLoad v2 MDS attack (also known as TAA), Ice Lake was not affected by this attack.   In this technical report, we show a variant of MSBDS (CVE2018-12126), an MDS attack, also known as Fallout, that works on Ice Lake CPUs. This variant was automatically synthesized using Transynther, a tool to find new variants of Meltdown-type attacks. Based on the findings of Transynther, we analyze different microcodes regarding this issue, showing that only microcode versions after January 2020 prevent exploitation of the vulnerability. These results show that Transynther is a valuable tool to find new variants, and also to test for regressions possibly introduced with microcode updates.

</details>

<details>

<summary>2020-07-16 12:33:28 - Deep ahead-of-threat virtual patching</summary>

- *Fady Copty, Andre Kassis, Sharon Keidar-Barner, Dov Murik*

- `2007.08296v1` - [abs](http://arxiv.org/abs/2007.08296v1) - [pdf](http://arxiv.org/pdf/2007.08296v1)

> Many applications have security vulnerabilities that can be exploited. It is practically impossible to find all of them due to the NP-complete nature of the testing problem. Security solutions provide defenses against these attacks through continuous application testing, fast-patching of vulnerabilities, automatic deployment of patches, and virtual patching detection techniques deployed in network and endpoint security tools. These techniques are limited by the need to find vulnerabilities before the black-hats. We propose an innovative technique to virtually patch vulnerabilities before they are found. We leverage testing techniques for supervised-learning data generation, and show how artificial intelligence techniques can use this data to create predictive deep neural-network models that read an application's input and predict in real time whether it is a potential malicious input. We set up an ahead-of-threat experiment in which we generated data on old versions of an application, and then evaluated the predictive model accuracy on vulnerabilities found years later. Our experiments show ahead-of-threat detection on LibXML2 and LibTIFF vulnerabilities with 91.3% and 93.7% accuracy, respectively. We expect to continue work on this field of research and provide ahead-of-threat virtual patching for more libraries. Success in this research can change the current state of endless racing after application vulnerabilities and put the defenders one step ahead of the attackers

</details>

<details>

<summary>2020-07-17 09:37:37 - Design and Interpretation of Universal Adversarial Patches in Face Detection</summary>

- *Xiao Yang, Fangyun Wei, Hongyang Zhang, Jun Zhu*

- `1912.05021v3` - [abs](http://arxiv.org/abs/1912.05021v3) - [pdf](http://arxiv.org/pdf/1912.05021v3)

> We consider universal adversarial patches for faces -- small visual elements whose addition to a face image reliably destroys the performance of face detectors. Unlike previous work that mostly focused on the algorithmic design of adversarial examples in terms of improving the success rate as an attacker, in this work we show an interpretation of such patches that can prevent the state-of-the-art face detectors from detecting the real faces. We investigate a phenomenon: patches designed to suppress real face detection appear face-like. This phenomenon holds generally across different initialization, locations, scales of patches, backbones, and state-of-the-art face detection frameworks. We propose new optimization-based approaches to automatic design of universal adversarial patches for varying goals of the attack, including scenarios in which true positives are suppressed without introducing false positives. Our proposed algorithms perform well on real-world datasets, deceiving state-of-the-art face detectors in terms of multiple precision/recall metrics and transferability.

</details>

<details>

<summary>2020-07-17 15:58:05 - Generating Person Images with Appearance-aware Pose Stylizer</summary>

- *Siyu Huang, Haoyi Xiong, Zhi-Qi Cheng, Qingzhong Wang, Xingran Zhou, Bihan Wen, Jun Huan, Dejing Dou*

- `2007.09077v1` - [abs](http://arxiv.org/abs/2007.09077v1) - [pdf](http://arxiv.org/pdf/2007.09077v1)

> Generation of high-quality person images is challenging, due to the sophisticated entanglements among image factors, e.g., appearance, pose, foreground, background, local details, global structures, etc. In this paper, we present a novel end-to-end framework to generate realistic person images based on given person poses and appearances. The core of our framework is a novel generator called Appearance-aware Pose Stylizer (APS) which generates human images by coupling the target pose with the conditioned person appearance progressively. The framework is highly flexible and controllable by effectively decoupling various complex person image factors in the encoding phase, followed by re-coupling them in the decoding phase. In addition, we present a new normalization method named adaptive patch normalization, which enables region-specific normalization and shows a good performance when adopted in person image generation model. Experiments on two benchmark datasets show that our method is capable of generating visually appealing and realistic-looking results using arbitrary image and pose inputs.

</details>

<details>

<summary>2020-07-19 07:34:18 - Self-similarity Student for Partial Label Histopathology Image Segmentation</summary>

- *Hsien-Tzu Cheng, Chun-Fu Yeh, Po-Chen Kuo, Andy Wei, Keng-Chi Liu, Mong-Chi Ko, Kuan-Hua Chao, Yu-Ching Peng, Tyng-Luh Liu*

- `2007.09610v1` - [abs](http://arxiv.org/abs/2007.09610v1) - [pdf](http://arxiv.org/pdf/2007.09610v1)

> Delineation of cancerous regions in gigapixel whole slide images (WSIs) is a crucial diagnostic procedure in digital pathology. This process is time-consuming because of the large search space in the gigapixel WSIs, causing chances of omission and misinterpretation at indistinct tumor lesions. To tackle this, the development of an automated cancerous region segmentation method is imperative. We frame this issue as a modeling problem with partial label WSIs, where some cancerous regions may be misclassified as benign and vice versa, producing patches with noisy labels. To learn from these patches, we propose Self-similarity Student, combining teacher-student model paradigm with similarity learning. Specifically, for each patch, we first sample its similar and dissimilar patches according to spatial distance. A teacher-student model is then introduced, featuring the exponential moving average on both student model weights and teacher predictions ensemble. While our student model takes patches, teacher model takes all their corresponding similar and dissimilar patches for learning robust representation against noisy label patches. Following this similarity learning, our similarity ensemble merges similar patches' ensembled predictions as the pseudo-label of a given patch to counteract its noisy label. On the CAMELYON16 dataset, our method substantially outperforms state-of-the-art noise-aware learning methods by 5$\%$ and the supervised-trained baseline by 10$\%$ in various degrees of noise. Moreover, our method is superior to the baseline on our TVGH TURP dataset with 2$\%$ improvement, demonstrating the generalizability to more clinical histopathology segmentation tasks.

</details>

<details>

<summary>2020-07-22 08:00:15 - Editable Neural Networks</summary>

- *Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov, Artem Babenko*

- `2004.00345v2` - [abs](http://arxiv.org/abs/2004.00345v2) - [pdf](http://arxiv.org/pdf/2004.00345v2)

> These days deep neural networks are ubiquitously used in a wide range of tasks, from image classification and machine translation to face identification and self-driving cars. In many applications, a single model error can lead to devastating financial, reputational and even life-threatening consequences. Therefore, it is crucially important to correct model mistakes quickly as they appear. In this work, we investigate the problem of neural network editing $-$ how one can efficiently patch a mistake of the model on a particular sample, without influencing the model behavior on other samples. Namely, we propose Editable Training, a model-agnostic training technique that encourages fast editing of the trained model. We empirically demonstrate the effectiveness of this method on large-scale image classification and machine translation tasks.

</details>

<details>

<summary>2020-07-22 14:08:33 - Fast and Precise On-the-fly Patch Validation for All</summary>

- *Lingchao Chen, Lingming Zhang*

- `2007.11449v1` - [abs](http://arxiv.org/abs/2007.11449v1) - [pdf](http://arxiv.org/pdf/2007.11449v1)

> Generate-and-validate (G&V) automated program repair (APR) techniques have been extensively studied during the past decade. Meanwhile, such techniques can be extremely time-consuming due to manipulation of the program code to fabricate a large number of patches and also repeated executions of tests on patches to identify potential fixes. PraPR, a recent G&V APR technique, reduces these costs by modifying program code directly at the level of compiled bytecode, and further performing on-the-fly patching by allowing multiple patches to be tested within the same JVM session. However, PraPR is limited due to its pattern-based, bytecode-level nature and it is basically unsound/imprecise as it assumes that patch executions do not change global JVM state and affect later patch executions on the same JVM session. Inspired by the PraPR work, we propose a unified patch validation framework, named UniAPR, which aims to speed up the patch validation for both bytecode and source-code APR via on-the-fly patching; furthermore, UniAPR addresses the imprecise patch validation issue by resetting the JVM global state via runtime bytecode transformation. We have implemented UniAPR as a fully automated Maven Plugin. We have also performed the first study of on-the-fly patch validation for state-of-the-art source-code-level APR. Our experiments show the first empirical evidence that vanilla on-the-fly patch validation can be imprecise/unsound; in contrast, our UniAPR framework can speed up state-of-the-art APR by over an order of magnitude without incurring any imprecision in patch validation, enabling all existing APR techniques to explore a larger search space to fix more bugs in the near future. Furthermore, UniAPR directly enables hybrid source and bytecode APR to fix substantially more bugs than all state-of-the-art APR techniques (under the same time limit) in the near future.

</details>

<details>

<summary>2020-07-22 17:59:49 - Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors</summary>

- *Zuxuan Wu, Ser-Nam Lim, Larry Davis, Tom Goldstein*

- `1910.14667v2` - [abs](http://arxiv.org/abs/1910.14667v2) - [pdf](http://arxiv.org/pdf/1910.14667v2)

> We present a systematic study of adversarial attacks on state-of-the-art object detection frameworks. Using standard detection datasets, we train patterns that suppress the objectness scores produced by a range of commonly used detectors, and ensembles of detectors. Through extensive experiments, we benchmark the effectiveness of adversarially trained patches under both white-box and black-box settings, and quantify transferability of attacks between datasets, object classes, and detector models. Finally, we present a detailed study of physical world attacks using printed posters and wearable clothes, and rigorously quantify the performance of such attacks with different metrics.

</details>

<details>

<summary>2020-07-23 10:11:43 - Harnessing spatial homogeneity of neuroimaging data: patch individual filter layers for CNNs</summary>

- *Fabian Eitel, Jan Philipp Albrecht, Martin Weygandt, Friedemann Paul, Kerstin Ritter*

- `2007.11899v1` - [abs](http://arxiv.org/abs/2007.11899v1) - [pdf](http://arxiv.org/pdf/2007.11899v1)

> Neuroimaging data, e.g. obtained from magnetic resonance imaging (MRI), is comparably homogeneous due to (1) the uniform structure of the brain and (2) additional efforts to spatially normalize the data to a standard template using linear and non-linear transformations. Convolutional neural networks (CNNs), in contrast, have been specifically designed for highly heterogeneous data, such as natural images, by sliding convolutional filters over different positions in an image. Here, we suggest a new CNN architecture that combines the idea of hierarchical abstraction in neural networks with a prior on the spatial homogeneity of neuroimaging data: Whereas early layers are trained globally using standard convolutional layers, we introduce for higher, more abstract layers patch individual filters (PIF). By learning filters in individual image regions (patches) without sharing weights, PIF layers can learn abstract features faster and with fewer samples. We thoroughly evaluated PIF layers for three different tasks and data sets, namely sex classification on UK Biobank data, Alzheimer's disease detection on ADNI data and multiple sclerosis detection on private hospital data. We demonstrate that CNNs using PIF layers result in higher accuracies, especially in low sample size settings, and need fewer training epochs for convergence. To the best of our knowledge, this is the first study which introduces a prior on brain MRI for CNN learning.

</details>

<details>

<summary>2020-07-23 19:07:06 - Efficient Residue Number System Based Winograd Convolution</summary>

- *Zhi-Gang Liu, Matthew Mattina*

- `2007.12216v1` - [abs](http://arxiv.org/abs/2007.12216v1) - [pdf](http://arxiv.org/pdf/2007.12216v1)

> Prior research has shown that Winograd algorithm can reduce the computational complexity of convolutional neural networks (CNN) with weights and activations represented in floating point. However it is difficult to apply the scheme to the inference of low-precision quantized (e.g. INT8) networks. Our work extends the Winograd algorithm to Residue Number System (RNS). The minimal complexity convolution is computed precisely over large transformation tile (e.g. 10 x 10 to 16 x 16) of filters and activation patches using the Winograd transformation and low cost (e.g. 8-bit) arithmetic without degrading the prediction accuracy of the networks during inference. The arithmetic complexity reduction is up to 7.03x while the performance improvement is up to 2.30x to 4.69x for 3 x 3 and 5 x 5 filters respectively.

</details>

<details>

<summary>2020-07-24 02:03:55 - Validation of Automatically Generated Patches: An Appetizer</summary>

- *Ali Ghanbari*

- `1912.00117v2` - [abs](http://arxiv.org/abs/1912.00117v2) - [pdf](http://arxiv.org/pdf/1912.00117v2)

> In the context of test case based automated program repair (APR), the research community call the patches that pass all the test cases but fail to actually fix the bug test case overfitted patches. Currently, overfitted patches has to be manually inspected by the users. Being a labor intensive activity that hinders widespread adoption of APR tools, automatic validation of APR-generated patches has been the topic of research in recent years. In this paper, we point out the limitations of the existing techniques/methodologies that call for further research, and introduce two promising directions toward effective automatic patch validation: (1) motivated by the relative effectiveness of anti-patterns, we propose to use statistical techniques to avoid the uncomputability of applying some of the anti-pattern rules and automate the technique. Our results show that we achieve at least 57% precision. (2) We present a proposal for a semi-automatic technique that helps the programmers in finding properties of the patched methods and stress testing the patches based on those properties so as to filter out overfitted ones as many as possible.

</details>

<details>

<summary>2020-07-25 20:42:21 - HATNet: An End-to-End Holistic Attention Network for Diagnosis of Breast Biopsy Images</summary>

- *Sachin Mehta, Ximing Lu, Donald Weaver, Joann G. Elmore, Hannaneh Hajishirzi, Linda Shapiro*

- `2007.13007v1` - [abs](http://arxiv.org/abs/2007.13007v1) - [pdf](http://arxiv.org/pdf/2007.13007v1)

> Training end-to-end networks for classifying gigapixel size histopathological images is computationally intractable. Most approaches are patch-based and first learn local representations (patch-wise) before combining these local representations to produce image-level decisions. However, dividing large tissue structures into patches limits the context available to these networks, which may reduce their ability to learn representations from clinically relevant structures. In this paper, we introduce a novel attention-based network, the Holistic ATtention Network (HATNet) to classify breast biopsy images. We streamline the histopathological image classification pipeline and show how to learn representations from gigapixel size images end-to-end. HATNet extends the bag-of-words approach and uses self-attention to encode global information, allowing it to learn representations from clinically relevant tissue structures without any explicit supervision. It outperforms the previous best network Y-Net, which uses supervision in the form of tissue-level segmentation masks, by 8%. Importantly, our analysis reveals that HATNet learns representations from clinically relevant structures, and it matches the classification accuracy of human pathologists for this challenging test set. Our source code is available at \url{https://github.com/sacmehta/HATNet}

</details>

<details>

<summary>2020-07-28 01:27:14 - Representation Learning with Video Deep InfoMax</summary>

- *R Devon Hjelm, Philip Bachman*

- `2007.13278v2` - [abs](http://arxiv.org/abs/2007.13278v2) - [pdf](http://arxiv.org/pdf/2007.13278v2)

> Self-supervised learning has made unsupervised pretraining relevant again for difficult computer vision tasks. The most effective self-supervised methods involve prediction tasks based on features extracted from diverse views of the data. DeepInfoMax (DIM) is a self-supervised method which leverages the internal structure of deep networks to construct such views, forming prediction tasks between local features which depend on small patches in an image and global features which depend on the whole image. In this paper, we extend DIM to the video domain by leveraging similar structure in spatio-temporal networks, producing a method we call Video Deep InfoMax(VDIM). We find that drawing views from both natural-rate sequences and temporally-downsampled sequences yields results on Kinetics-pretrained action recognition tasks which match or outperform prior state-of-the-art methods that use more costly large-time-scale transformer models. We also examine the effects of data augmentation and fine-tuning methods, accomplishingSoTA by a large margin when training only on the UCF-101 dataset.

</details>

<details>

<summary>2020-07-31 15:08:14 - On Package Freshness in Linux Distributions</summary>

- *Damien Legay, Alexandre Decan, Tom Mens*

- `2007.16123v1` - [abs](http://arxiv.org/abs/2007.16123v1) - [pdf](http://arxiv.org/pdf/2007.16123v1)

> The open-source Linux operating system is available through a wide variety of distributions, each containing a collection of installable software packages. It can be important to keep these packages as fresh as possible to benefit from new features, bug fixes and security patches. However, not all distributions place the same emphasis on package freshness. We conducted a survey in the first half of 2020 with 170 Linux users to gauge their perception of package freshness in the distributions they use, the value they place on package freshness and the reasons why they do so, and the methods they use to update packages. The results of this survey reveal that, for the aforementioned reasons, keeping packages up to date is an important concern to Linux users and that they install and update packages through their distribution's official repositories whenever possible, but often resort to third-party repositories and package managers for proprietary software and programming language libraries. Some distributions are perceived to be much quicker in deploying package updates than others. These results are valuable to assess the requirements and expectations of Linux users in terms of package freshness.

</details>

<details>

<summary>2020-07-31 16:53:18 - Foveation for Segmentation of Ultra-High Resolution Images</summary>

- *Chen Jin, Ryutaro Tanno, Moucheng Xu, Thomy Mertzanidou, Daniel C. Alexander*

- `2007.15124v2` - [abs](http://arxiv.org/abs/2007.15124v2) - [pdf](http://arxiv.org/pdf/2007.15124v2)

> Segmentation of ultra-high resolution images is challenging because of their enormous size, consisting of millions or even billions of pixels. Typical solutions include dividing input images into patches of fixed size and/or down-sampling to meet memory constraints. Such operations incur information loss in the field-of-view (FoV) i.e., spatial coverage and the image resolution. The impact on segmentation performance is, however, as yet understudied. In this work, we start with a motivational experiment which demonstrates that the trade-off between FoV and resolution affects the segmentation performance on ultra-high resolution images---and furthermore, its influence also varies spatially according to the local patterns in different areas. We then introduce foveation module, a learnable "dataloader" which, for a given ultra-high resolution image, adaptively chooses the appropriate configuration (FoV/resolution trade-off) of the input patch to feed to the downstream segmentation model at each spatial location of the image. The foveation module is jointly trained with the segmentation network to maximise the task performance. We demonstrate on three publicly available high-resolution image datasets that the foveation module consistently improves segmentation performance over the cases trained with patches of fixed FoV/resolution trade-off. Our approach achieves the SoTA performance on the DeepGlobe aerial image dataset. On the Gleason2019 histopathology dataset, our model achieves better segmentation accuracy for the two most clinically important and ambiguous classes (Gleason Grade 3 and 4) than the top performers in the challenge by 13.1% and 7.5%, and improves on the average performance of 6 human experts by 6.5% and 7.5%. Our code and trained models are available at $\text{https://github.com/lxasqjc/Foveation-Segmentation}$.

</details>


## 2020-08

<details>

<summary>2020-08-03 13:06:03 - Bias-based Universal Adversarial Patch Attack for Automatic Check-out</summary>

- *Aishan Liu, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang, Hang Yu*

- `2005.09257v3` - [abs](http://arxiv.org/abs/2005.09257v3) - [pdf](http://arxiv.org/pdf/2005.09257v3)

> Adversarial examples are inputs with imperceptible perturbations that easily misleading deep neural networks(DNNs). Recently, adversarial patch, with noise confined to a small and localized patch, has emerged for its easy feasibility in real-world scenarios. However, existing strategies failed to generate adversarial patches with strong generalization ability. In other words, the adversarial patches were input-specific and failed to attack images from all classes, especially unseen ones during training. To address the problem, this paper proposes a bias-based framework to generate class-agnostic universal adversarial patches with strong generalization ability, which exploits both the perceptual and semantic bias of models. Regarding the perceptual bias, since DNNs are strongly biased towards textures, we exploit the hard examples which convey strong model uncertainties and extract a textural patch prior from them by adopting the style similarities. The patch prior is more close to decision boundaries and would promote attacks. To further alleviate the heavy dependency on large amounts of data in training universal attacks, we further exploit the semantic bias. As the class-wise preference, prototypes are introduced and pursued by maximizing the multi-class margin to help universal training. Taking AutomaticCheck-out (ACO) as the typical scenario, extensive experiments including white-box and black-box settings in both digital-world(RPC, the largest ACO related dataset) and physical-world scenario(Taobao and JD, the world' s largest online shopping platforms) are conducted. Experimental results demonstrate that our proposed framework outperforms state-of-the-art adversarial patch attack methods.

</details>

<details>

<summary>2020-08-03 14:47:41 - On the Efficiency of Test Suite based Program Repair: A Systematic Assessment of 16 Automated Repair Systems for Java Programs</summary>

- *Kui Liu, Shangwen Wang, Anil Koyuncu, Kisub Kim, Tegawendé F. Bissyandé, Dongsun Kim, Peng Wu, Jacques Klein, Xiaoguang Mao, Yves Le Traon*

- `2008.00914v1` - [abs](http://arxiv.org/abs/2008.00914v1) - [pdf](http://arxiv.org/pdf/2008.00914v1)

> Test-based automated program repair has been a prolific field of research in software engineering in the last decade. Many approaches have indeed been proposed, which leverage test suites as a weak, but affordable, approximation to program specifications. Although the literature regularly sets new records on the number of benchmark bugs that can be fixed, several studies increasingly raise concerns about the limitations and biases of state-of-the-art approaches. For example, the correctness of generated patches has been questioned in a number of studies, while other researchers pointed out that evaluation schemes may be misleading with respect to the processing of fault localization results. Nevertheless, there is little work addressing the efficiency of patch generation, with regard to the practicality of program repair. In this paper, we fill this gap in the literature, by providing an extensive review on the efficiency of test suite based program repair. Our objective is to assess the number of generated patch candidates, since this information is correlated to (1) the strategy to traverse the search space efficiently in order to select sensical repair attempts, (2) the strategy to minimize the test effort for identifying a plausible patch, (3) as well as the strategy to prioritize the generation of a correct patch. To that end, we perform a large-scale empirical study on the efficiency, in terms of quantity of generated patch candidates of the 16 open-source repair tools for Java programs. The experiments are carefully conducted under the same fault localization configurations to limit biases.

</details>

<details>

<summary>2020-08-03 20:51:01 - Generative Adversarial Networks for Synthesizing InSAR Patches</summary>

- *Philipp Sibler, Yuanyuan Wang, Stefan Auer, Mohsin Ali, Xiao Xiang Zhu*

- `2008.01184v1` - [abs](http://arxiv.org/abs/2008.01184v1) - [pdf](http://arxiv.org/pdf/2008.01184v1)

> Generative Adversarial Networks (GANs) have been employed with certain success for image translation tasks between optical and real-valued SAR intensity imagery. Applications include aiding interpretability of SAR scenes with their optical counterparts by artificial patch generation and automatic SAR-optical scene matching. The synthesis of artificial complex-valued InSAR image stacks asks for, besides good perceptual quality, more stringent quality metrics like phase noise and phase coherence. This paper provides a signal processing model of generative CNN structures, describes effects influencing those quality metrics and presents a mapping scheme of complex-valued data to given CNN structures based on popular Deep Learning frameworks.

</details>

<details>

<summary>2020-08-04 08:37:35 - Self-Augmentation: Generalizing Deep Networks to Unseen Classes for Few-Shot Learning</summary>

- *Jin-Woo Seo, Hong-Gyu Jung, Seong-Whan Lee*

- `2004.00251v3` - [abs](http://arxiv.org/abs/2004.00251v3) - [pdf](http://arxiv.org/pdf/2004.00251v3)

> Few-shot learning aims to classify unseen classes with a few training examples. While recent works have shown that standard mini-batch training with a carefully designed training strategy can improve generalization ability for unseen classes, well-known problems in deep networks such as memorizing training statistics have been less explored for few-shot learning. To tackle this issue, we propose self-augmentation that consolidates self-mix and self-distillation. Specifically, we exploit a regional dropout technique called self-mix, in which a patch of an image is substituted into other values in the same image. Then, we employ a backbone network that has auxiliary branches with its own classifier to enforce knowledge sharing. Lastly, we present a local representation learner to further exploit a few training examples for unseen classes. Experimental results show that the proposed method outperforms the state-of-the-art methods for prevalent few-shot benchmarks and improves the generalization ability.

</details>

<details>

<summary>2020-08-05 10:13:41 - Extracting and Leveraging Nodule Features with Lung Inpainting for Local Feature Augmentation</summary>

- *Sebastian Guendel, Arnaud Arindra Adiyoso Setio, Sasa Grbic, Andreas Maier, Dorin Comaniciu*

- `2008.02030v1` - [abs](http://arxiv.org/abs/2008.02030v1) - [pdf](http://arxiv.org/pdf/2008.02030v1)

> Chest X-ray (CXR) is the most common examination for fast detection of pulmonary abnormalities. Recently, automated algorithms have been developed to classify multiple diseases and abnormalities in CXR scans. However, because of the limited availability of scans containing nodules and the subtle properties of nodules in CXRs, state-of-the-art methods do not perform well on nodule classification. To create additional data for the training process, standard augmentation techniques are applied. However, the variance introduced by these methods are limited as the images are typically modified globally. In this paper, we propose a method for local feature augmentation by extracting local nodule features using a generative inpainting network. The network is applied to generate realistic, healthy tissue and structures in patches containing nodules. The nodules are entirely removed in the inpainted representation. The extraction of the nodule features is processed by subtraction of the inpainted patch from the nodule patch. With arbitrary displacement of the extracted nodules in the lung area across different CXR scans and further local modifications during training, we significantly increase the nodule classification performance and outperform state-of-the-art augmentation methods.

</details>

<details>

<summary>2020-08-07 01:28:59 - Hierarchical Deep Convolutional Neural Networks for Multi-category Diagnosis of Gastrointestinal Disorders on Histopathological Images</summary>

- *Rasoul Sali, Sodiq Adewole, Lubaina Ehsan, Lee A. Denson, Paul Kelly, Beatrice C. Amadi, Lori Holtz, Syed Asad Ali, Sean R. Moore, Sana Syed, Donald E. Brown*

- `2005.03868v2` - [abs](http://arxiv.org/abs/2005.03868v2) - [pdf](http://arxiv.org/pdf/2005.03868v2)

> Deep convolutional neural networks(CNNs) have been successful for a wide range of computer vision tasks, including image classification. A specific area of the application lies in digital pathology for pattern recognition in the tissue-based diagnosis of gastrointestinal(GI) diseases. This domain can utilize CNNs to translate histopathological images into precise diagnostics. This is challenging since these complex biopsies are heterogeneous and require multiple levels of assessment. This is mainly due to structural similarities in different parts of the GI tract and shared features among different gut diseases. Addressing this problem with a flat model that assumes all classes (parts of the gut and their diseases) are equally difficult to distinguish leads to an inadequate assessment of each class. Since the hierarchical model restricts classification error to each sub-class, it leads to a more informative model than a flat model. In this paper, we propose to apply the hierarchical classification of biopsy images from different parts of the GI tract and the receptive diseases within each. We embedded a class hierarchy into the plain VGGNet to take advantage of its layers' hierarchical structure. The proposed model was evaluated using an independent set of image patches from 373 whole slide images. The results indicate that the hierarchical model can achieve better results than the flat model for multi-category diagnosis of GI disorders using histopathological images.

</details>

<details>

<summary>2020-08-07 01:49:40 - Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair</summary>

- *Haoye Tian, Kui Liu, Abdoul Kader Kaboreé, Anil Koyuncu, Li Li, Jacques Klein, Tegawendé F. Bissyandé*

- `2008.02944v1` - [abs](http://arxiv.org/abs/2008.02944v1) - [pdf](http://arxiv.org/pdf/2008.02944v1)

> A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations to learn deep features that may encode the properties of patch correctness. Our work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in predicting patch correctness on a deduplicated dataset of 1000 labeled patches. Our study shows that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature.

</details>

<details>

<summary>2020-08-09 00:40:54 - Consumer UAV Cybersecurity Vulnerability Assessment Using Fuzzing Tests</summary>

- *David Rudo, Kai Zeng*

- `2008.03621v1` - [abs](http://arxiv.org/abs/2008.03621v1) - [pdf](http://arxiv.org/pdf/2008.03621v1)

> Unmanned Aerial Vehicles (UAVs) are remote-controlled vehicles capable of flight and are present in a variety of environments from military operations to domestic enjoyment. These vehicles are great assets, but just as their pilot can control them remotely, cyberattacks can be executed in a similar manner. Cyber attacks on UAVs can bring a plethora of issues to physical and virtual systems. Such malfunctions are capable of giving an attacker the ability to steal data, incapacitate the UAV, or hijack the UAV. To mitigate such attacks, it is necessary to identify and patch vulnerabilities that may be maliciously exploited. In this paper, a new UAV vulnerability is explored with related UAV security practices identified for possible exploitation using large streams of data sent at specific ports. The more in-depth model involves strings of data involving FTP-specific keywords sent to the UAV's FTP port in the form of a fuzzing test and launching thousands of packets at other ports on the UAV as well. During these tests, virtual and physical systems are monitored extensively to identify specific patterns and vulnerabilities. This model is applied to a Parrot Bebop 2, which accurately portrays a UAV that had their network compromised by an attacker and portrays many lower-end UAV models for domestic use. During testings, the Parrot Bebop 2 is monitored for degradation in GPS performance, video speed, the UAV's reactivity to the pilot, motor function, and the accuracy of the UAV's sensor data. All these points of monitoring give a comprehensive view of the UAV's reaction to each individual test. In this paper, countermeasures to combat the exploitation of this vulnerability will be discussed as well as possible attacks that can branch from the fuzzing tests.

</details>

<details>

<summary>2020-08-10 04:32:32 - IF-Net: An Illumination-invariant Feature Network</summary>

- *Po-Heng Chen, Zhao-Xu Luo, Zu-Kuan Huang, Chun Yang, Kuan-Wen Chen*

- `2008.03897v1` - [abs](http://arxiv.org/abs/2008.03897v1) - [pdf](http://arxiv.org/pdf/2008.03897v1)

> Feature descriptor matching is a critical step is many computer vision applications such as image stitching, image retrieval and visual localization. However, it is often affected by many practical factors which will degrade its performance. Among these factors, illumination variations are the most influential one, and especially no previous descriptor learning works focus on dealing with this problem. In this paper, we propose IF-Net, aimed to generate a robust and generic descriptor under crucial illumination changes conditions. We find out not only the kind of training data important but also the order it is presented. To this end, we investigate several dataset scheduling methods and propose a separation training scheme to improve the matching accuracy. Further, we propose a ROI loss and hard-positive mining strategy along with the training scheme, which can strengthen the ability of generated descriptor dealing with large illumination change conditions. We evaluate our approach on public patch matching benchmark and achieve the best results compared with several state-of-the-arts methods. To show the practicality, we further evaluate IF-Net on the task of visual localization under large illumination changes scenes, and achieves the best localization accuracy.

</details>

<details>

<summary>2020-08-11 05:22:11 - Localizing Patch Points From One Exploit</summary>

- *Shiqi Shen, Aashish Kolluri, Zhen Dong, Prateek Saxena, Abhik Roychoudhury*

- `2008.04516v1` - [abs](http://arxiv.org/abs/2008.04516v1) - [pdf](http://arxiv.org/pdf/2008.04516v1)

> Automatic patch generation can significantly reduce the window of exposure after a vulnerability is disclosed. Towards this goal, a long-standing problem has been that of patch localization: to find a program point at which a patch can be synthesized. We present PatchLoc, one of the first systems which automatically identifies such a location in a vulnerable binary, given just one exploit, with high accuracy. PatchLoc does not make any assumptions about the availability of source code, test suites, or specialized knowledge of the vulnerability. PatchLoc pinpoints valid patch locations in large real-world applications with high accuracy for about 88% of 43 CVEs we study. These results stem from a novel approach to automatically synthesizing a test-suite which enables probabilistically ranking and effectively differentiating between candidate program patch locations.

</details>

<details>

<summary>2020-08-12 11:44:01 - Learning to Learn from Mistakes: Robust Optimization for Adversarial Noise</summary>

- *Alex Serban, Erik Poll, Joost Visser*

- `2008.05247v1` - [abs](http://arxiv.org/abs/2008.05247v1) - [pdf](http://arxiv.org/pdf/2008.05247v1)

> Sensitivity to adversarial noise hinders deployment of machine learning algorithms in security-critical applications. Although many adversarial defenses have been proposed, robustness to adversarial noise remains an open problem. The most compelling defense, adversarial training, requires a substantial increase in processing time and it has been shown to overfit on the training data. In this paper, we aim to overcome these limitations by training robust models in low data regimes and transfer adversarial knowledge between different models. We train a meta-optimizer which learns to robustly optimize a model using adversarial examples and is able to transfer the knowledge learned to new models, without the need to generate new adversarial examples. Experimental results show the meta-optimizer is consistent across different architectures and data sets, suggesting it is possible to automatically patch adversarial vulnerabilities.

</details>

<details>

<summary>2020-08-13 16:45:51 - Déjà Vu: Side-Channel Analysis of Mozilla's NSS</summary>

- *Sohaib ul Hassan, Iaroslav Gridin, Ignacio M. Delgado-Lozano, Cesar Pereida García, Jesús-Javier Chi-Domínguez, Alejandro Cabrera Aldaya, Billy Bob Brumley*

- `2008.06004v1` - [abs](http://arxiv.org/abs/2008.06004v1) - [pdf](http://arxiv.org/pdf/2008.06004v1)

> Recent work on Side Channel Analysis (SCA) targets old, well-known vulnerabilities, even previously exploited, reported, and patched in high-profile cryptography libraries. Nevertheless, researchers continue to find and exploit the same vulnerabilities in old and new products, highlighting a big issue among vendors: effectively tracking and fixing security vulnerabilities when disclosure is not done directly to them. In this work, we present another instance of this issue by performing the first library-wide SCA security evaluation of Mozilla's NSS security library. We use a combination of two independently-developed SCA security frameworks to identify and test security vulnerabilities. Our evaluation uncovers several new vulnerabilities in NSS affecting DSA, ECDSA, and RSA cryptosystems. We exploit said vulnerabilities and implement key recovery attacks using signals---extracted through different techniques such as timing, microarchitecture, and EM---and improved lattice methods.

</details>

<details>

<summary>2020-08-15 20:01:23 - Model Patching: Closing the Subgroup Performance Gap with Data Augmentation</summary>

- *Karan Goel, Albert Gu, Yixuan Li, Christopher Ré*

- `2008.06775v1` - [abs](http://arxiv.org/abs/2008.06775v1) - [pdf](http://arxiv.org/pdf/2008.06775v1)

> Classifiers in machine learning are often brittle when deployed. Particularly concerning are models with inconsistent performance on specific subgroups of a class, e.g., exhibiting disparities in skin cancer classification in the presence or absence of a spurious bandage. To mitigate these performance differences, we introduce model patching, a two-stage framework for improving robustness that encourages the model to be invariant to subgroup differences, and focus on class information shared by subgroups. Model patching first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroup features. We instantiate model patching with CAMEL, which (1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and (2) balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. We demonstrate CAMEL's effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real-world skin cancer dataset.

</details>

<details>

<summary>2020-08-17 08:33:50 - Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities</summary>

- *Manh-Dung Nguyen, Sébastien Bardin, Richard Bonichon, Roland Groz, Matthieu Lemerre*

- `2002.10751v2` - [abs](http://arxiv.org/abs/2002.10751v2) - [pdf](http://arxiv.org/pdf/2002.10751v2)

> Directed fuzzing focuses on automatically testing specific parts of the code by taking advantage of additional information such as (partial) bug stack trace, patches or risky operations. Key applications include bug reproduction, patch testing and static analysis report verification. Although directed fuzzing has received a lot of attention recently, hard-to-detect vulnerabilities such as Use-After-Free (UAF) are still not well addressed, especially at the binary level. We propose UAFuzz, the first (binary-level) directed greybox fuzzer dedicated to UAF bugs. The technique features a fuzzing engine tailored to UAF specifics, a lightweight code instrumentation and an efficient bug triage step. Experimental evaluation for bug reproduction on real cases demonstrates that UAFuzz significantly outperforms state-of-the-art directed fuzzers in terms of fault detection rate, time to exposure and bug triaging. UAFuzz has also been proven effective in patch testing, leading to the discovery of 30 new bugs (7 CVEs) in programs such as Perl, GPAC and GNU Patch. Finally, we provide to the community a large fuzzing benchmark dedicated to UAF, built on both real codes and real bugs.

</details>

<details>

<summary>2020-08-17 15:49:30 - Siloed Federated Learning for Multi-Centric Histopathology Datasets</summary>

- *Mathieu Andreux, Jean Ogier du Terrail, Constance Beguier, Eric W. Tramel*

- `2008.07424v1` - [abs](http://arxiv.org/abs/2008.07424v1) - [pdf](http://arxiv.org/pdf/2008.07424v1)

> While federated learning is a promising approach for training deep learning models over distributed sensitive datasets, it presents new challenges for machine learning, especially when applied in the medical domain where multi-centric data heterogeneity is common. Building on previous domain adaptation works, this paper proposes a novel federated learning approach for deep learning architectures via the introduction of local-statistic batch normalization (BN) layers, resulting in collaboratively-trained, yet center-specific models. This strategy improves robustness to data heterogeneity while also reducing the potential for information leaks by not sharing the center-specific layer activation statistics. We benchmark the proposed method on the classification of tumorous histopathology image patches extracted from the Camelyon16 and Camelyon17 datasets. We show that our approach compares favorably to previous state-of-the-art methods, especially for transfer learning across datasets.

</details>

<details>

<summary>2020-08-20 15:11:11 - A stabilized finite element method for delamination analysis of composites using cohesive elements</summary>

- *Gourab Ghosh, Ravindra Duddu, Chandrasekhar Annavarapu*

- `2008.09015v1` - [abs](http://arxiv.org/abs/2008.09015v1) - [pdf](http://arxiv.org/pdf/2008.09015v1)

> We demonstrate the ability of a stabilized finite element method, inspired by the weighted Nitsche approach, to alleviate spurious traction oscillations at interlaminar interfaces in multi-ply multi-directional composite laminates. In contrast with the standard (penalty-like) method, the stabilized method allows the use of arbitrarily large values of cohesive stiffness and obviates the need for engineering approaches to estimate minimum cohesive stiffness necessary for accurate delamination analysis. This is achieved by defining a weighted interface traction in the stabilized method, which allows a gradual transition from penalty-like method for soft elastic contact to Nitsche-like method for rigid contact. We conducted several simulation studies involving constant strain patch tests and benchmark delamination tests under mode-I, mode-II and mixed-mode loadings. Our results show clear evidence of traction oscillations with the standard method with structured and perturbed finite element meshes, and that the stabilized method alleviates these oscillations, thus illustrating its robustness.

</details>

<details>

<summary>2020-08-20 17:33:08 - Contrastive Learning for Unpaired Image-to-Image Translation</summary>

- *Taesung Park, Alexei A. Efros, Richard Zhang, Jun-Yan Zhu*

- `2007.15651v3` - [abs](http://arxiv.org/abs/2007.15651v3) - [pdf](http://arxiv.org/pdf/2007.15651v3)

> In image-to-image translation, each patch in the output should reflect the content of the corresponding patch in the input, independent of domain. We propose a straightforward method for doing so -- maximizing mutual information between the two, using a framework based on contrastive learning. The method encourages two elements (corresponding patches) to map to a similar point in a learned feature space, relative to other elements (other patches) in the dataset, referred to as negatives. We explore several critical design choices for making contrastive learning effective in the image synthesis setting. Notably, we use a multilayer, patch-based approach, rather than operate on entire images. Furthermore, we draw negatives from within the input image itself, rather than from the rest of the dataset. We demonstrate that our framework enables one-sided translation in the unpaired image-to-image translation setting, while improving quality and reducing training time. In addition, our method can even be extended to the training setting where each "domain" is only a single image.

</details>

<details>

<summary>2020-08-25 22:33:24 - CODIT: Code Editing with Tree-Based Neural Models</summary>

- *Saikat Chakraborty, Yangruibo Ding, Miltiadis Allamanis, Baishakhi Ray*

- `1810.00314v3` - [abs](http://arxiv.org/abs/1810.00314v3) - [pdf](http://arxiv.org/pdf/1810.00314v3)

> The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of deep neural networks and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, deep neural network based modeling for code changes and code in general introduces some specific problems that needs specific attention from research community. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art neural network models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel tree-based neural network system to model source code changes and learn code change patterns from the wild. Specifically, we propose a tree-based neural machine translation model to learn the probability distribution of changes in code. We realize our model with a change suggestion engine, CODIT, and train the model with more than 24k real-world changes and evaluate it on 5k patches. Our evaluation shows the effectiveness of CODITin learning and suggesting patches. CODIT can also learn specific bug fix pattern from bug fixing patches and can fix 25 bugs out of 80 bugs in Defects4J.

</details>

<details>

<summary>2020-08-27 08:32:51 - Cloze Test Helps: Effective Video Anomaly Detection via Learning to Complete Video Events</summary>

- *Guang Yu, Siqi Wang, Zhiping Cai, En Zhu, Chuanfu Xu, Jianping Yin, Marius Kloft*

- `2008.11988v1` - [abs](http://arxiv.org/abs/2008.11988v1) - [pdf](http://arxiv.org/pdf/2008.11988v1)

> As a vital topic in media content interpretation, video anomaly detection (VAD) has made fruitful progress via deep neural network (DNN). However, existing methods usually follow a reconstruction or frame prediction routine. They suffer from two gaps: (1) They cannot localize video activities in a both precise and comprehensive manner. (2) They lack sufficient abilities to utilize high-level semantics and temporal context information. Inspired by frequently-used cloze test in language study, we propose a brand-new VAD solution named Video Event Completion (VEC) to bridge gaps above: First, we propose a novel pipeline to achieve both precise and comprehensive enclosure of video activities. Appearance and motion are exploited as mutually complimentary cues to localize regions of interest (RoIs). A normalized spatio-temporal cube (STC) is built from each RoI as a video event, which lays the foundation of VEC and serves as a basic processing unit. Second, we encourage DNN to capture high-level semantics by solving a visual cloze test. To build such a visual cloze test, a certain patch of STC is erased to yield an incomplete event (IE). The DNN learns to restore the original video event from the IE by inferring the missing patch. Third, to incorporate richer motion dynamics, another DNN is trained to infer erased patches' optical flow. Finally, two ensemble strategies using different types of IE and modalities are proposed to boost VAD performance, so as to fully exploit the temporal context and modality information for VAD. VEC can consistently outperform state-of-the-art methods by a notable margin (typically 1.5%-5% AUROC) on commonly-used VAD benchmarks. Our codes and results can be verified at github.com/yuguangnudt/VEC_VAD.

</details>

<details>

<summary>2020-08-31 04:14:46 - Invisible Backdoor Attacks on Deep Neural Networks via Steganography and Regularization</summary>

- *Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng Zhang*

- `1909.02742v3` - [abs](http://arxiv.org/abs/1909.02742v3) - [pdf](http://arxiv.org/pdf/1909.02742v3)

> Deep neural networks (DNNs) have been proven vulnerable to backdoor attacks, where hidden features (patterns) trained to a normal model, which is only activated by some specific input (called triggers), trick the model into producing unexpected behavior. In this paper, we create covert and scattered triggers for backdoor attacks, invisible backdoors, where triggers can fool both DNN models and human inspection. We apply our invisible backdoors through two state-of-the-art methods of embedding triggers for backdoor attacks. The first approach on Badnets embeds the trigger into DNNs through steganography. The second approach of a trojan attack uses two types of additional regularization terms to generate the triggers with irregular shape and size. We use the Attack Success Rate and Functionality to measure the performance of our attacks. We introduce two novel definitions of invisibility for human perception; one is conceptualized by the Perceptual Adversarial Similarity Score (PASS) and the other is Learned Perceptual Image Patch Similarity (LPIPS). We show that the proposed invisible backdoors can be fairly effective across various DNN models as well as four datasets MNIST, CIFAR-10, CIFAR-100, and GTSRB, by measuring their attack success rates for the adversary, functionality for the normal users, and invisibility scores for the administrators. We finally argue that the proposed invisible backdoor attacks can effectively thwart the state-of-the-art trojan backdoor detection approaches, such as Neural Cleanse and TABOR.

</details>

<details>

<summary>2020-08-31 15:21:50 - Adversarial Patch Camouflage against Aerial Detection</summary>

- *Ajaya Adhikari, Richard den Hollander, Ioannis Tolios, Michael van Bekkum, Anneloes Bal, Stijn Hendriks, Maarten Kruithof, Dennis Gross, Nils Jansen, Guillermo Pérez, Kit Buurman, Stephan Raaijmakers*

- `2008.13671v1` - [abs](http://arxiv.org/abs/2008.13671v1) - [pdf](http://arxiv.org/pdf/2008.13671v1)

> Detection of military assets on the ground can be performed by applying deep learning-based object detectors on drone surveillance footage. The traditional way of hiding military assets from sight is camouflage, for example by using camouflage nets. However, large assets like planes or vessels are difficult to conceal by means of traditional camouflage nets. An alternative type of camouflage is the direct misleading of automatic object detectors. Recently, it has been observed that small adversarial changes applied to images of the object can produce erroneous output by deep learning-based detectors. In particular, adversarial attacks have been successfully demonstrated to prohibit person detections in images, requiring a patch with a specific pattern held up in front of the person, thereby essentially camouflaging the person for the detector. Research into this type of patch attacks is still limited and several questions related to the optimal patch configuration remain open.   This work makes two contributions. First, we apply patch-based adversarial attacks for the use case of unmanned aerial surveillance, where the patch is laid on top of large military assets, camouflaging them from automatic detectors running over the imagery. The patch can prevent automatic detection of the whole object while only covering a small part of it. Second, we perform several experiments with different patch configurations, varying their size, position, number and saliency. Our results show that adversarial patch attacks form a realistic alternative to traditional camouflage activities, and should therefore be considered in the automated analysis of aerial surveillance imagery.

</details>


## 2020-09

<details>

<summary>2020-09-01 02:33:19 - Patching as Translation: the Data and the Metaphor</summary>

- *Yangruibo Ding, Baishakhi Ray, Premkumar Devanbu, Vincent J. Hellendoorn*

- `2008.10707v2` - [abs](http://arxiv.org/abs/2008.10707v2) - [pdf](http://arxiv.org/pdf/2008.10707v2)

> Machine Learning models from other fields, like Computational Linguistics, have been transplanted to Software Engineering tasks, often quite successfully. Yet a transplanted model's initial success at a given task does not necessarily mean it is well-suited for the task. In this work, we examine a common example of this phenomenon: the conceit that "software patching is like language translation". We demonstrate empirically that there are subtle, but critical distinctions between sequence-to-sequence models and translation model: while program repair benefits greatly from the former, general modeling architecture, it actually suffers from design decisions built into the latter, both in terms of translation accuracy and diversity. Given these findings, we demonstrate how a more principled approach to model design, based on our empirical findings and general knowledge of software development, can lead to better solutions. Our findings also lend strong support to the recent trend towards synthesizing edits of code conditional on the buggy context, to repair bugs. We implement such models ourselves as "proof-of-concept" tools and empirically confirm that they behave in a fundamentally different, more effective way than the studied translation-based architectures. Overall, our results demonstrate the merit of studying the intricacies of machine learned models in software engineering: not only can this help elucidate potential issues that may be overshadowed by increases in accuracy; it can also help innovate on these models to raise the state-of-the-art further. We will publicly release our replication data and materials at https://github.com/ARiSE-Lab/Patch-as-translation.

</details>

<details>

<summary>2020-09-04 03:41:50 - DeepSun: Machine-Learning-as-a-Service for Solar Flare Prediction</summary>

- *Yasser Abduallah, Jason T. L. Wang, Yang Nie, Chang Liu, Haimin Wang*

- `2009.04238v1` - [abs](http://arxiv.org/abs/2009.04238v1) - [pdf](http://arxiv.org/pdf/2009.04238v1)

> Solar flare prediction plays an important role in understanding and forecasting space weather. The main goal of the Helioseismic and Magnetic Imager (HMI), one of the instruments on NASA's Solar Dynamics Observatory, is to study the origin of solar variability and characterize the Sun's magnetic activity. HMI provides continuous full-disk observations of the solar vector magnetic field with high cadence data that lead to reliable predictive capability; yet, solar flare prediction effort utilizing these data is still limited. In this paper, we present a machine-learning-as-a-service (MLaaS) framework, called DeepSun, for predicting solar flares on the Web based on HMI's data products. Specifically, we construct training data by utilizing the physical parameters provided by the Space-weather HMI Active Region Patches (SHARP) and categorize solar flares into four classes, namely B, C, M, X, according to the X-ray flare catalogs available at the National Centers for Environmental Information (NCEI). Thus, the solar flare prediction problem at hand is essentially a multi-class (i.e., four-class) classification problem. The DeepSun system employs several machine learning algorithms to tackle this multi-class prediction problem and provides an application programming interface (API) for remote programming users. To our knowledge, DeepSun is the first MLaaS tool capable of predicting solar flares through the Internet.

</details>

<details>

<summary>2020-09-04 08:37:58 - A Framework and DataSet for Bugs in Ethereum Smart Contracts</summary>

- *Pengcheng Zhang, Feng Xiao, Xiapu Luo*

- `2009.02066v1` - [abs](http://arxiv.org/abs/2009.02066v1) - [pdf](http://arxiv.org/pdf/2009.02066v1)

> Ethereum is the largest blockchain platform that supports smart contracts. Users deploy smart contracts by publishing the smart contract's bytecode to the blockchain. Since the data in the blockchain cannot be modified, even if these contracts contain bugs, it is not possible to patch deployed smart contracts with code updates. Moreover, there is currently neither a comprehensive classification framework for Ethereum smart contract bugs, nor detailed criteria for detecting bugs in smart contracts, making it difficult for developers to fully understand the negative effects of bugs and design new approaches to detect bugs. In this paper, to fill the gap, we first collect as many smart contract bugs as possible from multiple sources and divide these bugs into 9 categories by extending the IEEE Standard Classification for Software Anomalies. Then, we design the criteria for detecting each kind of bugs, and construct a dataset of smart contracts covering all kinds of bugs. With our framework and dataset, developers can learn smart contract bugs and develop new tools to detect and locate bugs in smart contracts. Moreover, we evaluate the state-of-the-art tools for smart contract analysis with our dataset and obtain some interesting findings: 1) Mythril, Slither and Remix are the most worthwhile combination of analysis tools. 2) There are still 10 kinds of bugs that cannot be detected by any analysis tool.

</details>

<details>

<summary>2020-09-04 14:20:46 - SketchPatch: Sketch Stylization via Seamless Patch-level Synthesis</summary>

- *Noa Fish, Lilach Perry, Amit Bermano, Daniel Cohen-Or*

- `2009.02216v1` - [abs](http://arxiv.org/abs/2009.02216v1) - [pdf](http://arxiv.org/pdf/2009.02216v1)

> The paradigm of image-to-image translation is leveraged for the benefit of sketch stylization via transfer of geometric textural details. Lacking the necessary volumes of data for standard training of translation systems, we advocate for operation at the patch level, where a handful of stylized sketches provide ample mining potential for patches featuring basic geometric primitives. Operating at the patch level necessitates special consideration of full sketch translation, as individual translation of patches with no regard to neighbors is likely to produce visible seams and artifacts at patch borders. Aligned pairs of styled and plain primitives are combined to form input hybrids containing styled elements around the border and plain elements within, and given as input to a seamless translation (ST) generator, whose output patches are expected to reconstruct the fully styled patch. An adversarial addition promotes generalization and robustness to diverse geometries at inference time, forming a simple and effective system for arbitrary sketch stylization, as demonstrated upon a variety of styles and sketches.

</details>

<details>

<summary>2020-09-05 17:24:23 - Max-Fusion U-Net for Multi-Modal Pathology Segmentation with Attention and Dynamic Resampling</summary>

- *Haochuan Jiang, Chengjia Wang, Agisilaos Chartsias, Sotirios A. Tsaftaris*

- `2009.02569v1` - [abs](http://arxiv.org/abs/2009.02569v1) - [pdf](http://arxiv.org/pdf/2009.02569v1)

> Automatic segmentation of multi-sequence (multi-modal) cardiac MR (CMR) images plays a significant role in diagnosis and management for a variety of cardiac diseases. However, the performance of relevant algorithms is significantly affected by the proper fusion of the multi-modal information. Furthermore, particular diseases, such as myocardial infarction, display irregular shapes on images and occupy small regions at random locations. These facts make pathology segmentation of multi-modal CMR images a challenging task. In this paper, we present the Max-Fusion U-Net that achieves improved pathology segmentation performance given aligned multi-modal images of LGE, T2-weighted, and bSSFP modalities. Specifically, modality-specific features are extracted by dedicated encoders. Then they are fused with the pixel-wise maximum operator. Together with the corresponding encoding features, these representations are propagated to decoding layers with U-Net skip-connections. Furthermore, a spatial-attention module is applied in the last decoding layer to encourage the network to focus on those small semantically meaningful pathological regions that trigger relatively high responses by the network neurons. We also use a simple image patch extraction strategy to dynamically resample training examples with varying spacial and batch sizes. With limited GPU memory, this strategy reduces the imbalance of classes and forces the model to focus on regions around the interested pathology. It further improves segmentation accuracy and reduces the mis-classification of pathology. We evaluate our methods using the Myocardial pathology segmentation (MyoPS) combining the multi-sequence CMR dataset which involves three modalities. Extensive experiments demonstrate the effectiveness of the proposed model which outperforms the related baselines.

</details>

<details>

<summary>2020-09-10 14:09:02 - Efficient Binary-Level Coverage Analysis</summary>

- *M. Ammar Ben Khadra, Dominik Stoffel, Wolfgang Kunz*

- `2004.14191v3` - [abs](http://arxiv.org/abs/2004.14191v3) - [pdf](http://arxiv.org/pdf/2004.14191v3)

> Code coverage analysis plays an important role in the software testing process. More recently, the remarkable effectiveness of coverage feedback has triggered a broad interest in feedback-guided fuzzing. In this work, we introduce bcov, a tool for binary-level coverage analysis. Our tool statically instruments x86-64 binaries in the ELF format without compiler support. We implement several techniques to improve efficiency and scale to large real-world software. First, we bring Agrawal's probe pruning technique to binary-level instrumentation and effectively leverage its superblocks to reduce overhead. Second, we introduce sliced microexecution, a robust technique for jump table analysis which improves CFG precision and enables us to instrument jump table entries. Additionally, smaller instructions in x86-64 pose a challenge for inserting detours. To address this challenge, we aggressively exploit padding bytes and systematically host detours in neighboring basic blocks. We evaluate bcov on a corpus of 95 binaries compiled from eight popular and well-tested packages like FFmpeg and LLVM. Two instrumentation policies, with different edge-level precision, are used to patch all functions in this corpus - over 1.6 million functions. Our precise policy has average performance and memory overheads of 14% and 22% respectively. Instrumented binaries do not introduce any test regressions. The reported coverage is highly accurate with an average F-score of 99.86%. Finally, our jump table analysis is comparable to that of IDA Pro on gcc binaries and outperforms it on clang binaries.

</details>

<details>

<summary>2020-09-10 17:41:03 - Learning Shape Features and Abstractions in 3D Convolutional Neural Networks for Detecting Alzheimer's Disease</summary>

- *Md Motiur Rahman Sagar, Martin Dyrba*

- `2009.05023v1` - [abs](http://arxiv.org/abs/2009.05023v1) - [pdf](http://arxiv.org/pdf/2009.05023v1)

> Deep Neural Networks - especially Convolutional Neural Network (ConvNet) has become the state-of-the-art for image classification, pattern recognition and various computer vision tasks. ConvNet has a huge potential in medical domain for analyzing medical data to diagnose diseases in an efficient way. Based on extracted features by ConvNet model from MRI data, early diagnosis is very crucial for preventing progress and treating the Alzheimer's disease. Despite having the ability to deliver great performance, absence of interpretability of the model's decision can lead to misdiagnosis which can be life threatening. In this thesis, learned shape features and abstractions by 3D ConvNets for detecting Alzheimer's disease were investigated using various visualization techniques. How changes in network structures, used filters sizes and filters shapes affects the overall performance and learned features of the model were also inspected. LRP relevance map of different models revealed which parts of the brain were more relevant for the classification decision. Comparing the learned filters by Activation Maximization showed how patterns were encoded in different layers of the network. Finally, transfer learning from a convolutional autoencoder was implemented to check whether increasing the number of training samples with patches of input to extract the low-level features improves learned features and the model performance.

</details>

<details>

<summary>2020-09-15 03:07:53 - PRF: A Framework for Building Automatic Program Repair Prototypes for JVM-Based Languages</summary>

- *Ali Ghanbari, Andrian Marcus*

- `2009.06848v1` - [abs](http://arxiv.org/abs/2009.06848v1) - [pdf](http://arxiv.org/pdf/2009.06848v1)

> PRF is a Java-based framework that allows researchers to build prototypes of test-based generate-and-validate automatic program repair techniques for JVM languages by simply extending it with their patch generation plugins. The framework also provides other useful components for constructing automatic program repair tools, e.g., a fault localization component that provides spectrum-based fault localization information at different levels of granularity, a configurable and safe patch validation component that is 11+X faster than vanilla testing, and a customizable post-processing component to generate fix reports. A demo video of PRF is available at https://bit.ly/3ehduSS.

</details>

<details>

<summary>2020-09-15 17:51:41 - LAMP: Large Deep Nets with Automated Model Parallelism for Image Segmentation</summary>

- *Wentao Zhu, Can Zhao, Wenqi Li, Holger Roth, Ziyue Xu, Daguang Xu*

- `2006.12575v3` - [abs](http://arxiv.org/abs/2006.12575v3) - [pdf](http://arxiv.org/pdf/2006.12575v3)

> Deep Learning (DL) models are becoming larger, because the increase in model size might offer significant accuracy gain. To enable the training of large deep networks, data parallelism and model parallelism are two well-known approaches for parallel training. However, data parallelism does not help reduce memory footprint per device. In this work, we introduce Large deep 3D ConvNets with Automated Model Parallelism (LAMP) and investigate the impact of both input's and deep 3D ConvNets' size on segmentation accuracy. Through automated model parallelism, it is feasible to train large deep 3D ConvNets with a large input patch, even the whole image. Extensive experiments demonstrate that, facilitated by the automated model parallelism, the segmentation accuracy can be improved through increasing model size and input context size, and large input yields significant inference speedup compared with sliding window of small patches in the inference. Code is available\footnote{https://monai.io/research/lamp-automated-model-parallelism}.

</details>

<details>

<summary>2020-09-16 09:14:59 - Brain tumour segmentation using cascaded 3D densely-connected U-net</summary>

- *Mina Ghaffari, Arcot Sowmya, Ruth Oliver*

- `2009.07563v1` - [abs](http://arxiv.org/abs/2009.07563v1) - [pdf](http://arxiv.org/pdf/2009.07563v1)

> Accurate brain tumour segmentation is a crucial step towards improving disease diagnosis and proper treatment planning. In this paper, we propose a deep-learning based method to segment a brain tumour into its subregions: whole tumour, tumour core and enhancing tumour. The proposed architecture is a 3D convolutional neural network based on a variant of the U-Net architecture of Ronneberger et al. [17] with three main modifications: (i) a heavy encoder, light decoder structure using residual blocks (ii) employment of dense blocks instead of skip connections, and (iii) utilization of self-ensembling in the decoder part of the network. The network was trained and tested using two different approaches: a multitask framework to segment all tumour subregions at the same time and a three-stage cascaded framework to segment one sub-region at a time. An ensemble of the results from both frameworks was also computed. To address the class imbalance issue, appropriate patch extraction was employed in a pre-processing step. The connected component analysis was utilized in the post-processing step to reduce false positive predictions. Experimental results on the BraTS20 validation dataset demonstrates that the proposed model achieved average Dice Scores of 0.90, 0.82, and 0.78 for whole tumour, tumour core and enhancing tumour respectively.

</details>

<details>

<summary>2020-09-17 02:36:52 - Cross-Modal Alignment with Mixture Experts Neural Network for Intral-City Retail Recommendation</summary>

- *Po Li, Lei Li, Yan Fu, Jun Rong, Yu Zhang*

- `2009.09926v1` - [abs](http://arxiv.org/abs/2009.09926v1) - [pdf](http://arxiv.org/pdf/2009.09926v1)

> In this paper, we introduce Cross-modal Alignment with mixture experts Neural Network (CameNN) recommendation model for intral-city retail industry, which aims to provide fresh foods and groceries retailing within 5 hours delivery service arising for the outbreak of Coronavirus disease (COVID-19) pandemic around the world. We propose CameNN, which is a multi-task model with three tasks including Image to Text Alignment (ITA) task, Text to Image Alignment (TIA) task and CVR prediction task. We use pre-trained BERT to generate the text embedding and pre-trained InceptionV4 to generate image patch embedding (each image is split into small patches with the same pixels and treat each patch as an image token). Softmax gating networks follow to learn the weight of each transformer expert output and choose only a subset of experts conditioned on the input. Then transformer encoder is applied as the share-bottom layer to learn all input features' shared interaction. Next, mixture of transformer experts (MoE) layer is implemented to model different aspects of tasks. At top of the MoE layer, we deploy a transformer layer for each task as task tower to learn task-specific information. On the real word intra-city dataset, experiments demonstrate CameNN outperform baselines and achieve significant improvements on the image and text representation. In practice, we applied CameNN on CVR prediction in our intra-city recommender system which is one of the leading intra-city platforms operated in China.

</details>

<details>

<summary>2020-09-17 15:59:57 - A novel highly efficient Lagrangian model for massively multidomain simulations: parallel context</summary>

- *Sebastian Florez, Julien Fausty, Karen Alvarado, Brayan Murgas, Marc Bernacki*

- `2009.04424v2` - [abs](http://arxiv.org/abs/2009.04424v2) - [pdf](http://arxiv.org/pdf/2009.04424v2)

> A new method for the simulation of evolving multi-domains problems has been introduced in a previous work (RealIMotion), Florez et al. (2020). In this article further developments of the model will be presented. The main focus here is a robust parallel implementation using a distributed-memory approach with the Message Passing Interface (MPI) library OpenMPI. The original 2D sequential methodology consists in a modified front-tracking approach where the main originality is that not only interfaces between domains are discretized but their interiors are also meshed. The interfaces are tracked based on the topological degree of each node on the mesh and the remeshing and topological changes of the domains are driven by selective local operations performed over an element patch. The accuracy and the performance of the sequential method has proven very promising in Florez et al. (2020). In this article a parallel implementation will be discussed and tested in context of motion by curvature flow for polycrystals, i.e. by considering Grain Growth (GG) mechanism. Results of the performance of the model are given and comparisons with other approaches in the literature are discussed.

</details>

<details>

<summary>2020-09-18 07:20:44 - Multi-species Seagrass Detection and Classification from Underwater Images</summary>

- *Scarlett Raine, Ross Marchant, Peyman Moghadam, Frederic Maire, Brett Kettle, Brano Kusy*

- `2009.09924v1` - [abs](http://arxiv.org/abs/2009.09924v1) - [pdf](http://arxiv.org/pdf/2009.09924v1)

> Underwater surveys conducted using divers or robots equipped with customized camera payloads can generate a large number of images. Manual review of these images to extract ecological data is prohibitive in terms of time and cost, thus providing strong incentive to automate this process using machine learning solutions. In this paper, we introduce a multi-species detector and classifier for seagrasses based on a deep convolutional neural network (achieved an overall accuracy of 92.4%). We also introduce a simple method to semi-automatically label image patches and therefore minimize manual labelling requirement. We describe and release publicly the dataset collected in this study as well as the code and pre-trained models to replicate our experiments at: https://github.com/csiro-robotics/deepseagrass

</details>

<details>

<summary>2020-09-19 18:54:01 - Reducing false-positive biopsies with deep neural networks that utilize local and global information in screening mammograms</summary>

- *Nan Wu, Zhe Huang, Yiqiu Shen, Jungkyu Park, Jason Phang, Taro Makino, S. Gene Kim, Kyunghyun Cho, Laura Heacock, Linda Moy, Krzysztof J. Geras*

- `2009.09282v1` - [abs](http://arxiv.org/abs/2009.09282v1) - [pdf](http://arxiv.org/pdf/2009.09282v1)

> Breast cancer is the most common cancer in women, and hundreds of thousands of unnecessary biopsies are done around the world at a tremendous cost. It is crucial to reduce the rate of biopsies that turn out to be benign tissue. In this study, we build deep neural networks (DNNs) to classify biopsied lesions as being either malignant or benign, with the goal of using these networks as second readers serving radiologists to further reduce the number of false positive findings. We enhance the performance of DNNs that are trained to learn from small image patches by integrating global context provided in the form of saliency maps learned from the entire image into their reasoning, similar to how radiologists consider global context when evaluating areas of interest. Our experiments are conducted on a dataset of 229,426 screening mammography exams from 141,473 patients. We achieve an AUC of 0.8 on a test set consisting of 464 benign and 136 malignant lesions.

</details>

<details>

<summary>2020-09-22 16:05:16 - ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds</summary>

- *Gopal Sharma, Difan Liu, Subhransu Maji, Evangelos Kalogerakis, Siddhartha Chaudhuri, Radomír Měch*

- `2003.12181v5` - [abs](http://arxiv.org/abs/2003.12181v5) - [pdf](http://arxiv.org/pdf/2003.12181v5)

> We propose a novel, end-to-end trainable, deep network called ParSeNet that decomposes a 3D point cloud into parametric surface patches, including B-spline patches as well as basic geometric primitives. ParSeNet is trained on a large-scale dataset of man-made 3D shapes and captures high-level semantic priors for shape decomposition. It handles a much richer class of primitives than prior work, and allows us to represent surfaces with higher fidelity. It also produces repeatable and robust parametrizations of a surface compared to purely geometric approaches. We present extensive experiments to validate our approach against analytical and learning-based alternatives. Our source code is publicly available at: https://hippogriff.github.io/parsenet.

</details>

<details>

<summary>2020-09-22 19:09:17 - Deep Generalized Convolutional Sum-Product Networks</summary>

- *Jos van de Wolfshaar, Andrzej Pronobis*

- `1902.06155v4` - [abs](http://arxiv.org/abs/1902.06155v4) - [pdf](http://arxiv.org/pdf/1902.06155v4)

> Sum-Product Networks (SPNs) are hierarchical, graphical models that combine benefits of deep learning and probabilistic modeling. SPNs offer unique advantages to applications demanding exact probabilistic inference over high-dimensional, noisy inputs. Yet, compared to convolutional neural nets, they struggle with capturing complex spatial relationships in image data. To alleviate this issue, we introduce Deep Generalized Convolutional Sum-Product Networks (DGC-SPNs), which encode spatial features in a way similar to CNNs, while preserving the validity of the probabilistic SPN model. As opposed to existing SPN-based image representations, DGC-SPNs allow for overlapping convolution patches through a novel parameterization of dilations and strides, resulting in significantly improved feature coverage and feature resolution. DGC-SPNs substantially outperform other SPN architectures across several visual datasets and for both generative and discriminative tasks, including image inpainting and classification. These contributions are reinforced by the first simple, scalable, and GPU-optimized implementation of SPNs, integrated with the widely used Keras/TensorFlow framework. The resulting model is fully probabilistic and versatile, yet efficient and straightforward to apply in practical applications in place of traditional deep nets.

</details>

<details>

<summary>2020-09-23 18:11:47 - Generative Modelling of 3D in-silico Spongiosa with Controllable Micro-Structural Parameters</summary>

- *Emmanuel Iarussi, Felix Thomsen, Claudio Delrieux*

- `2009.11327v1` - [abs](http://arxiv.org/abs/2009.11327v1) - [pdf](http://arxiv.org/pdf/2009.11327v1)

> Research in vertebral bone micro-structure generally requires costly procedures to obtain physical scans of real bone with a specific pathology under study, since no methods are available yet to generate realistic bone structures in-silico. Here we propose to apply recent advances in generative adversarial networks (GANs) to develop such a method. We adapted style-transfer techniques, which have been largely used in other contexts, in order to transfer style between image pairs while preserving its informational content. In a first step, we trained a volumetric generative model in a progressive manner using a Wasserstein objective and gradient penalty (PWGAN-GP) to create patches of realistic bone structure in-silico. The training set contained 7660 purely spongeous bone samples from twelve human vertebrae (T12 or L1) with isotropic resolution of 164um and scanned with a high resolution peripheral quantitative CT (Scanco XCT). After training, we generated new samples with tailored micro-structure properties by optimizing a vector z in the learned latent space. To solve this optimization problem, we formulated a differentiable goal function that leads to valid samples while compromising the appearance (content) with target 3D properties (style). Properties of the learned latent space effectively matched the data distribution. Furthermore, we were able to simulate the resulting bone structure after deterioration or treatment effects of osteoporosis therapies based only on expected changes of micro-structural parameters. Our method allows to generate a virtually infinite number of patches of realistic bone micro-structure, and thereby likely serves for the development of bone-biomarkers and to simulate bone therapies in advance.

</details>

<details>

<summary>2020-09-24 10:50:12 - Brain Tumor Segmentation using 3D-CNNs with Uncertainty Estimation</summary>

- *Laura Mora Ballestar, Veronica Vilaplana*

- `2009.12188v1` - [abs](http://arxiv.org/abs/2009.12188v1) - [pdf](http://arxiv.org/pdf/2009.12188v1)

> Automation of brain tumors in 3D magnetic resonance images (MRIs) is key to assess the diagnostic and treatment of the disease. In recent years, convolutional neural networks (CNNs) have shown improved results in the task. However, high memory consumption is still a problem in 3D-CNNs. Moreover, most methods do not include uncertainty information, which is specially critical in medical diagnosis. This work proposes a 3D encoder-decoder architecture, based on V-Net \cite{vnet} which is trained with patching techniques to reduce memory consumption and decrease the effect of unbalanced data. We also introduce voxel-wise uncertainty, both epistemic and aleatoric using test-time dropout and data-augmentation respectively. Uncertainty maps can provide extra information to expert neurologists, useful for detecting when the model is not confident on the provided segmentation.

</details>

<details>

<summary>2020-09-25 15:51:40 - Certified Defenses for Adversarial Patches</summary>

- *Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studer, Tom Goldstein*

- `2003.06693v2` - [abs](http://arxiv.org/abs/2003.06693v2) - [pdf](http://arxiv.org/pdf/2003.06693v2)

> Adversarial patch attacks are among one of the most practical threat models against real-world computer vision systems. This paper studies certified and empirical defenses against patch attacks. We begin with a set of experiments showing that most existing defenses, which work by pre-processing input images to mitigate adversarial patches, are easily broken by simple white-box adversaries. Motivated by this finding, we propose the first certified defense against patch attacks, and propose faster methods for its training. Furthermore, we experiment with different patch shapes for testing, obtaining surprisingly good robustness transfer across shapes, and present preliminary results on certified defense against sparse attacks. Our complete implementation can be found on: https://github.com/Ping-C/certifiedpatchdefense.

</details>

<details>

<summary>2020-09-27 07:44:02 - An Attention-Guided Deep Regression Model for Landmark Detection in Cephalograms</summary>

- *Zhusi Zhong, Jie Li, Zhenxi Zhang, Zhicheng Jiao, Xinbo Gao*

- `1906.07549v3` - [abs](http://arxiv.org/abs/1906.07549v3) - [pdf](http://arxiv.org/pdf/1906.07549v3)

> Cephalometric tracing method is usually used in orthodontic diagnosis and treatment planning. In this paper, we propose a deep learning based framework to automatically detect anatomical landmarks in cephalometric X-ray images. We train the deep encoder-decoder for landmark detection, and combine global landmark configuration with local high-resolution feature responses. The proposed frame-work is based on 2-stage u-net, regressing the multi-channel heatmaps for land-mark detection. In this framework, we embed attention mechanism with global stage heatmaps, guiding the local stage inferring, to regress the local heatmap patches in a high resolution. Besides, the Expansive Exploration strategy improves robustness while inferring, expanding the searching scope without increasing model complexity. We have evaluated our framework in the most widely-used public dataset of landmark detection in cephalometric X-ray images. With less computation and manually tuning, our framework achieves state-of-the-art results.

</details>

<details>

<summary>2020-09-28 04:32:23 - Gotta Catch 'Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks</summary>

- *Shawn Shan, Emily Wenger, Bolun Wang, Bo Li, Haitao Zheng, Ben Y. Zhao*

- `1904.08554v6` - [abs](http://arxiv.org/abs/1904.08554v6) - [pdf](http://arxiv.org/pdf/1904.08554v6)

> Deep neural networks (DNN) are known to be vulnerable to adversarial attacks. Numerous efforts either try to patch weaknesses in trained models, or try to make it difficult or costly to compute adversarial examples that exploit them. In our work, we explore a new "honeypot" approach to protect DNN models. We intentionally inject trapdoors, honeypot weaknesses in the classification manifold that attract attackers searching for adversarial examples. Attackers' optimization algorithms gravitate towards trapdoors, leading them to produce attacks similar to trapdoors in the feature space. Our defense then identifies attacks by comparing neuron activation signatures of inputs to those of trapdoors. In this paper, we introduce trapdoors and describe an implementation of a trapdoor-enabled defense. First, we analytically prove that trapdoors shape the computation of adversarial attacks so that attack inputs will have feature representations very similar to those of trapdoors. Second, we experimentally show that trapdoor-protected models can detect, with high accuracy, adversarial examples generated by state-of-the-art attacks (PGD, optimization-based CW, Elastic Net, BPDA), with negligible impact on normal classification. These results generalize across classification domains, including image, facial, and traffic-sign recognition. We also present significant results measuring trapdoors' robustness against customized adaptive attacks (countermeasures).

</details>

<details>

<summary>2020-09-28 10:25:24 - A Comprehensive Study of Automatic Program Repair on the QuixBugs Benchmark</summary>

- *He Ye, Matias Martinez, Thomas Durieux, Martin Monperrus*

- `1805.03454v4` - [abs](http://arxiv.org/abs/1805.03454v4) - [pdf](http://arxiv.org/pdf/1805.03454v4)

> Automatic program repair papers tend to repeatedly use the same benchmarks. This poses a threat to the external validity of the findings of the program repair research community. In this paper, we perform an empirical study of automatic repair on a benchmark of bugs called QuixBugs, which has been little studied. In this paper, 1) We report on the characteristics of QuixBugs; 2) We study the effectiveness of 10 program repair tools on it; 3) We apply three patch correctness assessment techniques to comprehensively study the presence of overfitting patches in QuixBugs. Our key results are: 1) 16/40 buggy programs in QuixBugs can be repaired with at least a test suite adequate patch; 2) A total of 338 plausible patches are generated on the QuixBugs by the considered tools, and 53.3% of them are overfitting patches according to our manual assessment; 3) The three automated patch correctness assessment techniques, RGT_Evosuite, RGT_InputSampling and GT_Invariants, achieve an accuracy of 98.2%, 80.8% and 58.3% in overfitting detection, respectively. To our knowledge, this is the largest empirical study of automatic repair on QuixBugs, combining both quantitative and qualitative insights. All our empirical results are publicly available on GitHub in order to facilitate future research on automatic program repair.

</details>

<details>

<summary>2020-09-29 12:42:09 - NXNSAttack: Recursive DNS Inefficiencies and Vulnerabilities</summary>

- *Yehuda Afek, Anat Bremler-Barr, Lior Shafir*

- `2005.09107v2` - [abs](http://arxiv.org/abs/2005.09107v2) - [pdf](http://arxiv.org/pdf/2005.09107v2)

> This paper exposes a new vulnerability and introduces a corresponding attack, the NoneXistent Name Server Attack (NXNSAttack), that disrupts and may paralyze the DNS system, making it difficult or impossible for Internet users to access websites, web e-mail, online video chats, or any other online resource. The NXNSAttack generates a storm of packets between DNS resolvers and DNS authoritative name servers. The storm is produced by the response of resolvers to unrestricted referral response messages of authoritative name servers. The attack is significantly more destructive than NXDomain attacks (e.g., the Mirai attack): i) It reaches an amplification factor of more than 1620x on the number of packets exchanged by the recursive resolver. ii) In addition to the negative cache, the attack also saturates the 'NS' section of the resolver caches. To mitigate the attack impact, we propose an enhancement to the recursive resolver algorithm, MaxFetch(k), that prevents unnecessary proactive fetches. We implemented the MaxFetch(1) mitigation enhancement on a BIND resolver and tested it on real-world DNS query datasets. Our results show that MaxFetch(1) degrades neither the recursive resolver throughput nor its latency. Following the discovery of the attack, a responsible disclosure procedure was carried out, and several DNS vendors and public providers have issued a CVE and patched their systems.

</details>

<details>

<summary>2020-09-30 22:19:40 - Self-Guided Multiple Instance Learning for Weakly Supervised Disease Classification and Localization in Chest Radiographs</summary>

- *Constantin Seibold, Jens Kleesiek, Heinz-Peter Schlemmer, Rainer Stiefelhagen*

- `2010.00127v1` - [abs](http://arxiv.org/abs/2010.00127v1) - [pdf](http://arxiv.org/pdf/2010.00127v1)

> The lack of fine-grained annotations hinders the deployment of automated diagnosis systems, which require human-interpretable justification for their decision process. In this paper, we address the problem of weakly supervised identification and localization of abnormalities in chest radiographs. To that end, we introduce a novel loss function for training convolutional neural networks increasing the \emph{localization confidence} and assisting the overall \emph{disease identification}. The loss leverages both image- and patch-level predictions to generate auxiliary supervision. Rather than forming strictly binary from the predictions as done in previous loss formulations, we create targets in a more customized manner, which allows the loss to account for possible misclassification. We show that the supervision provided within the proposed learning scheme leads to better performance and more precise predictions on prevalent datasets for multiple-instance learning as well as on the NIH~ChestX-Ray14 benchmark for disease recognition than previously used losses.

</details>


## 2020-10

<details>

<summary>2020-10-02 02:54:06 - Deep Learning for Earth Image Segmentation based on Imperfect Polyline Labels with Annotation Errors</summary>

- *Zhe Jiang, Marcus Stephen Kirby, Wenchong He, Arpan Man Sainju*

- `2010.00757v1` - [abs](http://arxiv.org/abs/2010.00757v1) - [pdf](http://arxiv.org/pdf/2010.00757v1)

> In recent years, deep learning techniques (e.g., U-Net, DeepLab) have achieved tremendous success in image segmentation. The performance of these models heavily relies on high-quality ground truth segment labels. Unfortunately, in many real-world problems, ground truth segment labels often have geometric annotation errors due to manual annotation mistakes, GPS errors, or visually interpreting background imagery at a coarse resolution. Such location errors will significantly impact the training performance of existing deep learning algorithms. Existing research on label errors either models ground truth errors in label semantics (assuming label locations to be correct) or models label location errors with simple square patch shifting. These methods cannot fully incorporate the geometric properties of label location errors. To fill the gap, this paper proposes a generic learning framework based on the EM algorithm to update deep learning model parameters and infer hidden true label locations simultaneously. Evaluations on a real-world hydrological dataset in the streamline refinement application show that the proposed framework outperforms baseline methods in classification accuracy (reducing the number of false positives by 67% and reducing the number of false negatives by 55%).

</details>

<details>

<summary>2020-10-02 11:38:36 - EVMPatch: Timely and Automated Patching of Ethereum Smart Contracts</summary>

- *Michael Rodler, Wenting Li, Ghassan O. Karame, Lucas Davi*

- `2010.00341v2` - [abs](http://arxiv.org/abs/2010.00341v2) - [pdf](http://arxiv.org/pdf/2010.00341v2)

> Recent attacks exploiting errors in smart contract code had devastating consequences thereby questioning the benefits of this technology. It is currently highly challenging to fix errors and deploy a patched contract in time. Instant patching is especially important since smart contracts are always online due to the distributed nature of blockchain systems. They also manage considerable amounts of assets, which are at risk and often beyond recovery after an attack. Existing solutions to upgrade smart contracts depend on manual and error-prone processes. This paper presents a framework, called EVMPatch, to instantly and automatically patch faulty smart contracts. EVMPatch features a bytecode rewriting engine for the popular Ethereum blockchain, and transparently/automatically rewrites common off-the-shelf contracts to upgradable contracts. The proof-of-concept implementation of EVMPatch automatically hardens smart contracts that are vulnerable to integer over/underflows and access control errors, but can be easily extended to cover more bug classes. Our extensive evaluation on 14,000 real-world (vulnerable) contracts demonstrate that our approach successfully blocks attack transactions launched on these contracts, while keeping the intended functionality of the contract intact. We perform a study with experienced software developers, showing that EVMPatch is practical, and reduces the time for converting a given Solidity smart contract to an upgradable contract by 97.6 %, while ensuring functional equivalence to the original contract.

</details>

<details>

<summary>2020-10-03 20:56:16 - MagGAN: High-Resolution Face Attribute Editing with Mask-Guided Generative Adversarial Network</summary>

- *Yi Wei, Zhe Gan, Wenbo Li, Siwei Lyu, Ming-Ching Chang, Lei Zhang, Jianfeng Gao, Pengchuan Zhang*

- `2010.01424v1` - [abs](http://arxiv.org/abs/2010.01424v1) - [pdf](http://arxiv.org/pdf/2010.01424v1)

> We present Mask-guided Generative Adversarial Network (MagGAN) for high-resolution face attribute editing, in which semantic facial masks from a pre-trained face parser are used to guide the fine-grained image editing process. With the introduction of a mask-guided reconstruction loss, MagGAN learns to only edit the facial parts that are relevant to the desired attribute changes, while preserving the attribute-irrelevant regions (e.g., hat, scarf for modification `To Bald'). Further, a novel mask-guided conditioning strategy is introduced to incorporate the influence region of each attribute change into the generator. In addition, a multi-level patch-wise discriminator structure is proposed to scale our model for high-resolution ($1024 \times 1024$) face editing. Experiments on the CelebA benchmark show that the proposed method significantly outperforms prior state-of-the-art approaches in terms of both image quality and editing performance.

</details>

<details>

<summary>2020-10-04 19:30:13 - Multi-Resolution Fusion and Multi-scale Input Priors Based Crowd Counting</summary>

- *Usman Sajid, Wenchi Ma, Guanghui Wang*

- `2010.01664v1` - [abs](http://arxiv.org/abs/2010.01664v1) - [pdf](http://arxiv.org/pdf/2010.01664v1)

> Crowd counting in still images is a challenging problem in practice due to huge crowd-density variations, large perspective changes, severe occlusion, and variable lighting conditions. The state-of-the-art patch rescaling module (PRM) based approaches prove to be very effective in improving the crowd counting performance. However, the PRM module requires an additional and compromising crowd-density classification process. To address these issues and challenges, the paper proposes a new multi-resolution fusion based end-to-end crowd counting network. It employs three deep-layers based columns/branches, each catering the respective crowd-density scale. These columns regularly fuse (share) the information with each other. The network is divided into three phases with each phase containing one or more columns. Three input priors are introduced to serve as an efficient and effective alternative to the PRM module, without requiring any additional classification operations. Along with the final crowd count regression head, the network also contains three auxiliary crowd estimation regression heads, which are strategically placed at each phase end to boost the overall performance. Comprehensive experiments on three benchmark datasets demonstrate that the proposed approach outperforms all the state-of-the-art models under the RMSE evaluation metric. The proposed approach also has better generalization capability with the best results during the cross-dataset experiments.

</details>

<details>

<summary>2020-10-05 11:44:09 - Improving Reconstructive Surgery Design using Gaussian Process Surrogates to Capture Material Behavior Uncertainty</summary>

- *Casey Stowers, Taeksang Lee, Ilias Bilionis, Arun Gosain, Adrian Buganza Tepole*

- `2010.02800v1` - [abs](http://arxiv.org/abs/2010.02800v1) - [pdf](http://arxiv.org/pdf/2010.02800v1)

> Excessive loads near wounds produce pathological scarring and other complications. Presently, stress cannot easily be measured by surgeons in the operating room. Instead, surgeons rely on intuition and experience. Predictive computational tools are ideal candidates for surgery planning. Finite element (FE) simulations have shown promise in predicting stress fields on large skin patches and complex cases, helping to identify potential regions of complication. Unfortunately, these simulations are computationally expensive and deterministic. However, running a few, well-selected FE simulations allows us to create Gaussian process (GP) surrogate models of local cutaneous flaps that are computationally efficient and able to predict stress and strain for arbitrary material parameters. Here, we create GP surrogates for the advancement, rotation, and transposition flaps. We then use the predictive capability of these surrogates to perform a global sensitivity analysis, ultimately showing that fiber direction has the most significant impact on strain field variations. We then perform an optimization to determine the optimal fiber direction for each flap for three different objectives driven by clinical guidelines. While material properties are not controlled by the surgeon and are actually a source of uncertainty, the surgeon can in fact control the orientation of the flap. Therefore, fiber direction is the only material parameter that can be optimized clinically. The optimization task relies on the efficiency of the GP surrogates to calculate the expected cost of different strategies when the uncertainty of other material parameters is included. We propose optimal flap orientations for the three cost functions and that can help in reducing stress resulting from the surgery and ultimately reduce complications associated with excessive mechanical loading near wounds.

</details>

<details>

<summary>2020-10-05 16:51:14 - Generative Patch Priors for Practical Compressive Image Recovery</summary>

- *Rushil Anirudh, Suhas Lohit, Pavan Turaga*

- `2006.10873v2` - [abs](http://arxiv.org/abs/2006.10873v2) - [pdf](http://arxiv.org/pdf/2006.10873v2)

> In this paper, we propose the generative patch prior (GPP) that defines a generative prior for compressive image recovery, based on patch-manifold models. Unlike learned, image-level priors that are restricted to the range space of a pre-trained generator, GPP can recover a wide variety of natural images using a pre-trained patch generator. Additionally, GPP retains the benefits of generative priors like high reconstruction quality at extremely low sensing rates, while also being much more generally applicable. We show that GPP outperforms several unsupervised and supervised techniques on three different sensing models -- linear compressive sensing with known, and unknown calibration settings, and the non-linear phase retrieval problem. Finally, we propose an alternating optimization strategy using GPP for joint calibration-and-reconstruction which performs favorably against several baselines on a real world, un-calibrated compressive sensing dataset.

</details>

<details>

<summary>2020-10-06 08:43:27 - Memory-efficient GAN-based Domain Translation of High Resolution 3D Medical Images</summary>

- *Hristina Uzunova, Jan Ehrhardt, Heinz Handels*

- `2010.03396v1` - [abs](http://arxiv.org/abs/2010.03396v1) - [pdf](http://arxiv.org/pdf/2010.03396v1)

> Generative adversarial networks (GANs) are currently rarely applied on 3D medical images of large size, due to their immense computational demand. The present work proposes a multi-scale patch-based GAN approach for establishing unpaired domain translation by generating 3D medical image volumes of high resolution in a memory-efficient way. The key idea to enable memory-efficient image generation is to first generate a low-resolution version of the image followed by the generation of patches of constant sizes but successively growing resolutions. To avoid patch artifacts and incorporate global information, the patch generation is conditioned on patches from previous resolution scales. Those multi-scale GANs are trained to generate realistically looking images from image sketches in order to perform an unpaired domain translation. This allows to preserve the topology of the test data and generate the appearance of the training domain data. The evaluation of the domain translation scenarios is performed on brain MRIs of size 155x240x240 and thorax CTs of size up to 512x512x512. Compared to common patch-based approaches, the multi-resolution scheme enables better image quality and prevents patch artifacts. Also, it ensures constant GPU memory demand independent from the image size, allowing for the generation of arbitrarily large images.

</details>

<details>

<summary>2020-10-06 22:56:22 - Adversarial Patch Attacks on Monocular Depth Estimation Networks</summary>

- *Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, Toshiaki Fujii*

- `2010.03072v1` - [abs](http://arxiv.org/abs/2010.03072v1) - [pdf](http://arxiv.org/pdf/2010.03072v1)

> Thanks to the excellent learning capability of deep convolutional neural networks (CNN), monocular depth estimation using CNNs has achieved great success in recent years. However, depth estimation from a monocular image alone is essentially an ill-posed problem, and thus, it seems that this approach would have inherent vulnerabilities. To reveal this limitation, we propose a method of adversarial patch attack on monocular depth estimation. More specifically, we generate artificial patterns (adversarial patches) that can fool the target methods into estimating an incorrect depth for the regions where the patterns are placed. Our method can be implemented in the real world by physically placing the printed patterns in real scenes. We also analyze the behavior of monocular depth estimation under attacks by visualizing the activation levels of the intermediate layers and the regions potentially affected by the adversarial attack.

</details>

<details>

<summary>2020-10-09 10:15:26 - Contralaterally Enhanced Networks for Thoracic Disease Detection</summary>

- *Gangming Zhao, Chaowei Fang, Guanbin Li, Licheng Jiao, Yizhou Yu*

- `2010.04483v1` - [abs](http://arxiv.org/abs/2010.04483v1) - [pdf](http://arxiv.org/pdf/2010.04483v1)

> Identifying and locating diseases in chest X-rays are very challenging, due to the low visual contrast between normal and abnormal regions, and distortions caused by other overlapping tissues. An interesting phenomenon is that there exist many similar structures in the left and right parts of the chest, such as ribs, lung fields and bronchial tubes. This kind of similarities can be used to identify diseases in chest X-rays, according to the experience of broad-certificated radiologists. Aimed at improving the performance of existing detection methods, we propose a deep end-to-end module to exploit the contralateral context information for enhancing feature representations of disease proposals. First of all, under the guidance of the spine line, the spatial transformer network is employed to extract local contralateral patches, which can provide valuable context information for disease proposals. Then, we build up a specific module, based on both additive and subtractive operations, to fuse the features of the disease proposal and the contralateral patch. Our method can be integrated into both fully and weakly supervised disease detection frameworks. It achieves 33.17 AP50 on a carefully annotated private chest X-ray dataset which contains 31,000 images. Experiments on the NIH chest X-ray dataset indicate that our method achieves state-of-the-art performance in weakly-supervised disease localization.

</details>

<details>

<summary>2020-10-12 10:59:37 - Rethinking Experience Replay: a Bag of Tricks for Continual Learning</summary>

- *Pietro Buzzega, Matteo Boschini, Angelo Porrello, Simone Calderara*

- `2010.05595v1` - [abs](http://arxiv.org/abs/2010.05595v1) - [pdf](http://arxiv.org/pdf/2010.05595v1)

> In Continual Learning, a Neural Network is trained on a stream of data whose distribution shifts over time. Under these assumptions, it is especially challenging to improve on classes appearing later in the stream while remaining accurate on previous ones. This is due to the infamous problem of catastrophic forgetting, which causes a quick performance degradation when the classifier focuses on learning new categories. Recent literature proposed various approaches to tackle this issue, often resorting to very sophisticated techniques. In this work, we show that naive rehearsal can be patched to achieve similar performance. We point out some shortcomings that restrain Experience Replay (ER) and propose five tricks to mitigate them. Experiments show that ER, thus enhanced, displays an accuracy gain of 51.2 and 26.9 percentage points on the CIFAR-10 and CIFAR-100 datasets respectively (memory buffer size 1000). As a result, it surpasses current state-of-the-art rehearsal-based methods.

</details>

<details>

<summary>2020-10-13 10:56:09 - Land Cover Semantic Segmentation Using ResUNet</summary>

- *Vasilis Pollatos, Loukas Kouvaras, Eleni Charou*

- `2010.06285v1` - [abs](http://arxiv.org/abs/2010.06285v1) - [pdf](http://arxiv.org/pdf/2010.06285v1)

> In this paper we present our work on developing an automated system for land cover classification. This system takes a multiband satellite image of an area as input and outputs the land cover map of the area at the same resolution as the input. For this purpose convolutional machine learning models were trained in the task of predicting the land cover semantic segmentation of satellite images. This is a case of supervised learning. The land cover label data were taken from the CORINE Land Cover inventory and the satellite images were taken from the Copernicus hub. As for the model, U-Net architecture variations were applied. Our area of interest are the Ionian islands (Greece). We created a dataset from scratch covering this particular area. In addition, transfer learning from the BigEarthNet dataset [1] was performed. In [1] simple classification of satellite images into the classes of CLC is performed but not segmentation as we do. However, their models have been trained into a dataset much bigger than ours, so we applied transfer learning using their pretrained models as the first part of out network, utilizing the ability these networks have developed to extract useful features from the satellite images (we transferred a pretrained ResNet50 into a U-Res-Net). Apart from transfer learning other techniques were applied in order to overcome the limitations set by the small size of our area of interest. We used data augmentation (cutting images into overlapping patches, applying random transformations such as rotations and flips) and cross validation. The results are tested on the 3 CLC class hierarchy levels and a comparative study is made on the results of different approaches.

</details>

<details>

<summary>2020-10-13 13:21:18 - Deep Evolution for Facial Emotion Recognition</summary>

- *Emmanuel Dufourq, Bruce A. Bassett*

- `2009.14194v2` - [abs](http://arxiv.org/abs/2009.14194v2) - [pdf](http://arxiv.org/pdf/2009.14194v2)

> Deep facial expression recognition faces two challenges that both stem from the large number of trainable parameters: long training times and a lack of interpretability. We propose a novel method based on evolutionary algorithms, that deals with both challenges by massively reducing the number of trainable parameters, whilst simultaneously retaining classification performance, and in some cases achieving superior performance. We are robustly able to reduce the number of parameters on average by 95% (e.g. from 2M to 100k parameters) with no loss in classification accuracy. The algorithm learns to choose small patches from the image, relative to the nose, which carry the most important information about emotion, and which coincide with typical human choices of important features. Our work implements a novel form attention and shows that evolutionary algorithms are a valuable addition to machine learning in the deep learning era, both for reducing the number of parameters for facial expression recognition and for providing interpretable features that can help reduce bias.

</details>

<details>

<summary>2020-10-14 21:22:45 - Improved Approximation Algorithms for Stochastic-Matching Problems</summary>

- *Marek Adamczyk, Brian Brubach, Fabrizio Grandoni, Karthik A. Sankararaman, Aravind Srinivasan, Pan Xu*

- `2010.08142v1` - [abs](http://arxiv.org/abs/2010.08142v1) - [pdf](http://arxiv.org/pdf/2010.08142v1)

> We consider the Stochastic Matching problem, which is motivated by applications in kidney exchange and online dating. In this problem, we are given an undirected graph. Each edge is assigned a known, independent probability of existence and a positive weight (or profit). We must probe an edge to discover whether or not it exists. Each node is assigned a positive integer called a timeout (or a patience). On this random graph we are executing a process, which probes the edges one-by-one and gradually constructs a matching. The process is constrained in two ways. First, if a probed edge exists, it must be added irrevocably to the matching (the query-commit model). Second, the timeout of a node $v$ upper-bounds the number of edges incident to $v$ that can be probed. The goal is to maximize the expected weight of the constructed matching.   For this problem, Bansal et al. (Algorithmica 2012) provided a $0.33$-approximation algorithm for bipartite graphs and a $0.25$-approximation for general graphs. We improve the approximation factors to $0.39$ and $0.269$, respectively.   The main technical ingredient in our result is a novel way of probing edges according to a not-uniformly-random permutation. Patching this method with an algorithm that works best for large-probability edges (plus additional ideas) leads to our improved approximation factors.

</details>

<details>

<summary>2020-10-15 08:08:16 - Approximate Manifold Defense Against Multiple Adversarial Perturbations</summary>

- *Jay Nandy, Wynne Hsu, Mong Li Lee*

- `2004.02183v2` - [abs](http://arxiv.org/abs/2004.02183v2) - [pdf](http://arxiv.org/pdf/2004.02183v2)

> Existing defenses against adversarial attacks are typically tailored to a specific perturbation type. Using adversarial training to defend against multiple types of perturbation requires expensive adversarial examples from different perturbation types at each training step. In contrast, manifold-based defense incorporates a generative network to project an input sample onto the clean data manifold. This approach eliminates the need to generate expensive adversarial examples while achieving robustness against multiple perturbation types. However, the success of this approach relies on whether the generative network can capture the complete clean data manifold, which remains an open problem for complex input domain. In this work, we devise an approximate manifold defense mechanism, called RBF-CNN, for image classification. Instead of capturing the complete data manifold, we use an RBF layer to learn the density of small image patches. RBF-CNN also utilizes a reconstruction layer that mitigates any minor adversarial perturbations. Further, incorporating our proposed reconstruction process for training improves the adversarial robustness of our RBF-CNN models. Experiment results on MNIST and CIFAR-10 datasets indicate that RBF-CNN offers robustness for multiple perturbations without the need for expensive adversarial training.

</details>

<details>

<summary>2020-10-16 04:48:24 - DPAttack: Diffused Patch Attacks against Universal Object Detection</summary>

- *Shudeng Wu, Tao Dai, Shu-Tao Xia*

- `2010.11679v1` - [abs](http://arxiv.org/abs/2010.11679v1) - [pdf](http://arxiv.org/pdf/2010.11679v1)

> Recently, deep neural networks (DNNs) have been widely and successfully used in Object Detection, e.g. Faster RCNN, YOLO, CenterNet. However, recent studies have shown that DNNs are vulnerable to adversarial attacks. Adversarial attacks against object detection can be divided into two categories, whole-pixel attacks and patch attacks. While these attacks add perturbations to a large number of pixels in images, we proposed a diffused patch attack (\textbf{DPAttack}) to successfully fool object detectors by diffused patches of asteroid-shaped or grid-shape, which only change a small number of pixels. Experiments show that our DPAttack can successfully fool most object detectors with diffused patches and we get the second place in the Alibaba Tianchi competition: Alibaba-Tsinghua Adversarial Challenge on Object Detection. Our code can be obtained from https://github.com/Wu-Shudeng/DPAttack.

</details>

<details>

<summary>2020-10-18 16:52:35 - Distribution-Based Invariant Deep Networks for Learning Meta-Features</summary>

- *Gwendoline De Bie, Herilalaina Rakotoarison, Gabriel Peyré, Michèle Sebag*

- `2006.13708v2` - [abs](http://arxiv.org/abs/2006.13708v2) - [pdf](http://arxiv.org/pdf/2006.13708v2)

> Recent advances in deep learning from probability distributions successfully achieve classification or regression from distribution samples, thus invariant under permutation of the samples. The first contribution of the paper is to extend these neural architectures to achieve invariance under permutation of the features, too. The proposed architecture, called Dida, inherits the NN properties of universal approximation, and its robustness w.r.t. Lipschitz-bounded transformations of the input distribution is established. The second contribution is to empirically and comparatively demonstrate the merits of the approach on two tasks defined at the dataset level. On both tasks, Dida learns meta-features supporting the characterization of a (labelled) dataset. The first task consists of predicting whether two dataset patches are extracted from the same initial dataset. The second task consists of predicting whether the learning performance achieved by a hyper-parameter configuration under a fixed algorithm (ranging in k-NN, SVM, logistic regression and linear classifier with SGD) dominates that of another configuration, for a dataset extracted from the OpenML benchmarking suite. On both tasks, Dida outperforms the state of the art: DSS (Maron et al., 2020) and Dataset2Vec (Jomaa et al., 2019) architectures, as well as the models based on the hand-crafted meta-features of the literature.

</details>

<details>

<summary>2020-10-18 19:41:09 - Graphite: GRAPH-Induced feaTure Extraction for Point Cloud Registration</summary>

- *Mahdi Saleh, Shervin Dehghani, Benjamin Busam, Nassir Navab, Federico Tombari*

- `2010.09079v1` - [abs](http://arxiv.org/abs/2010.09079v1) - [pdf](http://arxiv.org/pdf/2010.09079v1)

> 3D Point clouds are a rich source of information that enjoy growing popularity in the vision community. However, due to the sparsity of their representation, learning models based on large point clouds is still a challenge. In this work, we introduce Graphite, a GRAPH-Induced feaTure Extraction pipeline, a simple yet powerful feature transform and keypoint detector. Graphite enables intensive down-sampling of point clouds with keypoint detection accompanied by a descriptor. We construct a generic graph-based learning scheme to describe point cloud regions and extract salient points. To this end, we take advantage of 6D pose information and metric learning to learn robust descriptions and keypoints across different scans. We Reformulate the 3D keypoint pipeline with graph neural networks which allow efficient processing of the point set while boosting its descriptive power which ultimately results in more accurate 3D registrations. We demonstrate our lightweight descriptor on common 3D descriptor matching and point cloud registration benchmarks and achieve comparable results with the state of the art. Describing 100 patches of a point cloud and detecting their keypoints takes only ~0.018 seconds with our proposed network.

</details>

<details>

<summary>2020-10-19 14:03:28 - Gastric histopathology image segmentation using a hierarchical conditional random field</summary>

- *Changhao Sun, Chen Li, Jinghua Zhang, Muhammad Rahaman, Shiliang Ai, Hao Chen, Frank Kulwa, Yixin Li, Xiaoyan Li, Tao Jiang*

- `2003.01302v5` - [abs](http://arxiv.org/abs/2003.01302v5) - [pdf](http://arxiv.org/pdf/2003.01302v5)

> For the Convolutional Neural Networks (CNNs) applied in the intelligent diagnosis of gastric cancer, existing methods mostly focus on individual characteristics or network frameworks without a policy to depict the integral information. Mainly, Conditional Random Field (CRF), an efficient and stable algorithm for analyzing images containing complicated contents, can characterize spatial relation in images. In this paper, a novel Hierarchical Conditional Random Field (HCRF) based Gastric Histopathology Image Segmentation (GHIS) method is proposed, which can automatically localize abnormal (cancer) regions in gastric histopathology images obtained by an optical microscope to assist histopathologists in medical work. This HCRF model is built up with higher order potentials, including pixel-level and patch-level potentials, and graph-based post-processing is applied to further improve its segmentation performance. Especially, a CNN is trained to build up the pixel-level potentials and another three CNNs are fine-tuned to build up the patch-level potentials for sufficient spatial segmentation information. In the experiment, a hematoxylin and eosin (H&E) stained gastric histopathological dataset with 560 abnormal images are divided into training, validation and test sets with a ratio of 1 : 1 : 2. Finally, segmentation accuracy, recall and specificity of 78.91%, 65.59%, and 81.33% are achieved on the test set. Our HCRF model demonstrates high segmentation performance and shows its effectiveness and future potential in the GHIS field.

</details>

<details>

<summary>2020-10-21 05:49:22 - Deep learning algorithms out-perform veterinary pathologists in detecting the mitotically most active tumor region</summary>

- *Marc Aubreville, Christof A. Bertram, Christian Marzahl, Corinne Gurtner, Martina Dettwiler, Anja Schmidt, Florian Bartenschlager, Sophie Merz, Marco Fragoso, Olivia Kershaw, Robert Klopfleisch, Andreas Maier*

- `1902.05414v3` - [abs](http://arxiv.org/abs/1902.05414v3) - [pdf](http://arxiv.org/pdf/1902.05414v3)

> Manual count of mitotic figures, which is determined in the tumor region with the highest mitotic activity, is a key parameter of most tumor grading schemes. It can be, however, strongly dependent on the area selection due to uneven mitotic figure distribution in the tumor section.We aimed to assess the question, how significantly the area selection could impact the mitotic count, which has a known high inter-rater disagreement. On a data set of 32 whole slide images of H&E-stained canine cutaneous mast cell tumor, fully annotated for mitotic figures, we asked eight veterinary pathologists (five board-certified, three in training) to select a field of interest for the mitotic count. To assess the potential difference on the mitotic count, we compared the mitotic count of the selected regions to the overall distribution on the slide.Additionally, we evaluated three deep learning-based methods for the assessment of highest mitotic density: In one approach, the model would directly try to predict the mitotic count for the presented image patches as a regression task. The second method aims at deriving a segmentation mask for mitotic figures, which is then used to obtain a mitotic density. Finally, we evaluated a two-stage object-detection pipeline based on state-of-the-art architectures to identify individual mitotic figures. We found that the predictions by all models were, on average, better than those of the experts. The two-stage object detector performed best and outperformed most of the human pathologists on the majority of tumor cases. The correlation between the predicted and the ground truth mitotic count was also best for this approach (0.963 to 0.979). Further, we found considerable differences in position selection between pathologists, which could partially explain the high variance that has been reported for the manual mitotic count.

</details>

<details>

<summary>2020-10-22 03:48:56 - Rethinking pooling in graph neural networks</summary>

- *Diego Mesquita, Amauri H. Souza, Samuel Kaski*

- `2010.11418v1` - [abs](http://arxiv.org/abs/2010.11418v1) - [pdf](http://arxiv.org/pdf/2010.11418v1)

> Graph pooling is a central component of a myriad of graph neural network (GNN) architectures. As an inheritance from traditional CNNs, most approaches formulate graph pooling as a cluster assignment problem, extending the idea of local patches in regular grids to graphs. Despite the wide adherence to this design choice, no work has rigorously evaluated its influence on the success of GNNs. In this paper, we build upon representative GNNs and introduce variants that challenge the need for locality-preserving representations, either using randomization or clustering on the complement graph. Strikingly, our experiments demonstrate that using these variants does not result in any decrease in performance. To understand this phenomenon, we study the interplay between convolutional layers and the subsequent pooling ones. We show that the convolutions play a leading role in the learned representations. In contrast to the common belief, local pooling is not responsible for the success of GNNs on relevant and widely-used benchmarks.

</details>

<details>

<summary>2020-10-22 11:38:19 - Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample</summary>

- *Shir Gur, Sagie Benaim, Lior Wolf*

- `2006.12226v3` - [abs](http://arxiv.org/abs/2006.12226v3) - [pdf](http://arxiv.org/pdf/2006.12226v3)

> We consider the task of generating diverse and novel videos from a single video sample. Recently, new hierarchical patch-GAN based approaches were proposed for generating diverse images, given only a single sample at training time. Moving to videos, these approaches fail to generate diverse samples, and often collapse into generating samples similar to the training video. We introduce a novel patch-based variational autoencoder (VAE) which allows for a much greater diversity in generation. Using this tool, a new hierarchical video generation scheme is constructed: at coarse scales, our patch-VAE is employed, ensuring samples are of high diversity. Subsequently, at finer scales, a patch-GAN renders the fine details, resulting in high quality videos. Our experiments show that the proposed method produces diverse samples in both the image domain, and the more challenging video domain.

</details>

<details>

<summary>2020-10-22 21:05:24 - RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference</summary>

- *Oindrila Saha, Aditya Kusupati, Harsha Vardhan Simhadri, Manik Varma, Prateek Jain*

- `2002.11921v2` - [abs](http://arxiv.org/abs/2002.11921v2) - [pdf](http://arxiv.org/pdf/2002.11921v2)

> Standard Convolutional Neural Networks (CNNs) designed for computer vision tasks tend to have large intermediate activation maps. These require large working memory and are thus unsuitable for deployment on resource-constrained devices typically used for inference on the edge. Aggressively downsampling the images via pooling or strided convolutions can address the problem but leads to a significant decrease in accuracy due to gross aggregation of the feature map by standard pooling operators. In this paper, we introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efficiently aggregates features over large patches of an image and rapidly downsamples activation maps. Empirical evaluation indicates that an RNNPool layer can effectively replace multiple blocks in a variety of architectures such as MobileNets, DenseNet when applied to standard vision tasks like image classification and face detection. That is, RNNPool can significantly decrease computational complexity and peak memory usage for inference while retaining comparable accuracy. We use RNNPool with the standard S3FD architecture to construct a face detection method that achieves state-of-the-art MAP for tiny ARM Cortex-M4 class microcontrollers with under 256 KB of RAM. Code is released at https://github.com/Microsoft/EdgeML.

</details>

<details>

<summary>2020-10-22 21:40:50 - Getting Passive Aggressive About False Positives: Patching Deployed Malware Detectors</summary>

- *Edward Raff, Bobby Filar, James Holt*

- `2010.12080v1` - [abs](http://arxiv.org/abs/2010.12080v1) - [pdf](http://arxiv.org/pdf/2010.12080v1)

> False positives (FPs) have been an issue of extreme importance for anti-virus (AV) systems for decades. As more security vendors turn to machine learning, alert deluge has hit critical mass with over 20% of all alerts resulting in FPs and, in some organizations, the number reaches half of all alerts. This increase has resulted in fatigue, frustration, and, worst of all, neglect from security workers on SOC teams. A foundational cause for FPs is that vendors must build one global system to try and satisfy all customers, but have no method to adjust to individual local environments. This leads to outrageous, albeit technically correct, characterization of their platforms being 99.9% effective. Once these systems are deployed the idiosyncrasies of individual, local environments expose blind spots that lead to FPs and uncertainty.   We propose a strategy for fixing false positives in production after a model has already been deployed. For too long the industry has tried to combat these problems with inefficient, and at times, dangerous allowlist techniques and excessive model retraining which is no longer enough. We propose using a technique called passive-aggressive learning to alter a malware detection model to an individual's environment, eliminating false positives without sharing any customer sensitive information. We will show how to use passive-aggressive learning to solve a collection of notoriously difficult false positives from a production environment without compromising the malware model's accuracy, reducing the total number of FP alerts by an average of 23x.

</details>

<details>

<summary>2020-10-25 08:55:40 - Dynamic Adversarial Patch for Evading Object Detection Models</summary>

- *Shahar Hoory, Tzvika Shapira, Asaf Shabtai, Yuval Elovici*

- `2010.13070v1` - [abs](http://arxiv.org/abs/2010.13070v1) - [pdf](http://arxiv.org/pdf/2010.13070v1)

> Recent research shows that neural networks models used for computer vision (e.g., YOLO and Fast R-CNN) are vulnerable to adversarial evasion attacks. Most of the existing real-world adversarial attacks against object detectors use an adversarial patch which is attached to the target object (e.g., a carefully crafted sticker placed on a stop sign). This method may not be robust to changes in the camera's location relative to the target object; in addition, it may not work well when applied to nonplanar objects such as cars. In this study, we present an innovative attack method against object detectors applied in a real-world setup that addresses some of the limitations of existing attacks. Our method uses dynamic adversarial patches which are placed at multiple predetermined locations on a target object. An adversarial learning algorithm is applied in order to generate the patches used. The dynamic attack is implemented by switching between optimized patches dynamically, according to the camera's position (i.e., the object detection system's position). In order to demonstrate our attack in a real-world setup, we implemented the patches by attaching flat screens to the target object; the screens are used to present the patches and switch between them, depending on the current camera location. Thus, the attack is dynamic and adjusts itself to the situation to achieve optimal results. We evaluated our dynamic patch approach by attacking the YOLOv2 object detector with a car as the target object and succeeded in misleading it in up to 90% of the video frames when filming the car from a wide viewing angle range. We improved the attack by generating patches that consider the semantic distance between the target object and its classification. We also examined the attack's transferability among different car models and were able to mislead the detector 71% of the time.

</details>

<details>

<summary>2020-10-28 12:53:04 - Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance</summary>

- *Wei Hu, Qianjiang Hu, Zehua Wang, Xiang Gao*

- `2003.08355v3` - [abs](http://arxiv.org/abs/2003.08355v3) - [pdf](http://arxiv.org/pdf/2003.08355v3)

> 3D dynamic point clouds provide a natural discrete representation of real-world objects or scenes in motion, with a wide range of applications in immersive telepresence, autonomous driving, surveillance, \etc. Nevertheless, dynamic point clouds are often perturbed by noise due to hardware, software or other causes. While a plethora of methods have been proposed for static point cloud denoising, few efforts are made for the denoising of dynamic point clouds, which is quite challenging due to the irregular sampling patterns both spatially and temporally. In this paper, we represent dynamic point clouds naturally on spatial-temporal graphs, and exploit the temporal consistency with respect to the underlying surface (manifold). In particular, we define a manifold-to-manifold distance and its discrete counterpart on graphs to measure the variation-based intrinsic distance between surface patches in the temporal domain, provided that graph operators are discrete counterparts of functionals on Riemannian manifolds. Then, we construct the spatial-temporal graph connectivity between corresponding surface patches based on the temporal distance and between points in adjacent patches in the spatial domain. Leveraging the initial graph representation, we formulate dynamic point cloud denoising as the joint optimization of the desired point cloud and underlying graph representation, regularized by both spatial smoothness and temporal consistency. We reformulate the optimization and present an efficient algorithm. Experimental results show that the proposed method significantly outperforms independent denoising of each frame from state-of-the-art static point cloud denoising approaches, on both Gaussian noise and simulated LiDAR noise.

</details>

<details>

<summary>2020-10-28 23:55:00 - No Surprises: Training Robust Lung Nodule Detection for Low-Dose CT Scans by Augmenting with Adversarial Attacks</summary>

- *Siqi Liu, Arnaud Arindra Adiyoso Setio, Florin C. Ghesu, Eli Gibson, Sasa Grbic, Bogdan Georgescu, Dorin Comaniciu*

- `2003.03824v2` - [abs](http://arxiv.org/abs/2003.03824v2) - [pdf](http://arxiv.org/pdf/2003.03824v2)

> Detecting malignant pulmonary nodules at an early stage can allow medical interventions which may increase the survival rate of lung cancer patients. Using computer vision techniques to detect nodules can improve the sensitivity and the speed of interpreting chest CT for lung cancer screening. Many studies have used CNNs to detect nodule candidates. Though such approaches have been shown to outperform the conventional image processing based methods regarding the detection accuracy, CNNs are also known to be limited to generalize on under-represented samples in the training set and prone to imperceptible noise perturbations. Such limitations can not be easily addressed by scaling up the dataset or the models. In this work, we propose to add adversarial synthetic nodules and adversarial attack samples to the training data to improve the generalization and the robustness of the lung nodule detection systems. To generate hard examples of nodules from a differentiable nodule synthesizer, we use projected gradient descent (PGD) to search the latent code within a bounded neighbourhood that would generate nodules to decrease the detector response. To make the network more robust to unanticipated noise perturbations, we use PGD to search for noise patterns that can trigger the network to give over-confident mistakes. By evaluating on two different benchmark datasets containing consensus annotations from three radiologists, we show that the proposed techniques can improve the detection performance on real CT data. To understand the limitations of both the conventional networks and the proposed augmented networks, we also perform stress-tests on the false positive reduction networks by feeding different types of artificially produced patches. We show that the augmented networks are more robust to both under-represented nodules as well as resistant to noise perturbations.

</details>

<details>

<summary>2020-10-29 05:59:14 - Frontiers in Mortar Methods for Isogeometric Analysis</summary>

- *Christian Hesch, Ustim Khristenko, Rolf Krause, Alexander Popp, Alexander Seitz, Wolfgang Wall, Barbara Wohlmuth*

- `2006.06677v3` - [abs](http://arxiv.org/abs/2006.06677v3) - [pdf](http://arxiv.org/pdf/2006.06677v3)

> Complex geometries as common in industrial applications consist of multiple patches, if spline based parametrizations are used. The requirements for the generation of analysis-suitable models are increasing dramatically since isogeometric analysis is directly based on the spline parametrization and nowadays used for the calculation of higher-order partial differential equations. The computational, or more general, the engineering analysis necessitates suitable coupling techniques between the different patches. Mortar methods have been successfully applied for coupling of patches and for contact mechanics in recent years to resolve the arising issues within the interface. We present here current achievements in the design of mortar technologies in isogeometric analysis within the Priority Program SPP 1748, Reliable Simulation Techniques in Solid Mechanics. Development of Non-standard Discretisation Methods, Mechanical and Mathematical Analysis.

</details>

<details>

<summary>2020-10-29 09:14:57 - Convolutional Neural Networks for Global Human Settlements Mapping from Sentinel-2 Satellite Imagery</summary>

- *Christina Corbane, Vasileios Syrris, Filip Sabo, Panagiotis Politis, Michele Melchiorri, Martino Pesaresi, Pierre Soille, Thomas Kemper*

- `2006.03267v2` - [abs](http://arxiv.org/abs/2006.03267v2) - [pdf](http://arxiv.org/pdf/2006.03267v2)

> Spatially consistent and up-to-date maps of human settlements are crucial for addressing policies related to urbanization and sustainability, especially in the era of an increasingly urbanized world.The availability of open and free Sentinel-2 data of the Copernicus Earth Observation program offers a new opportunity for wall-to-wall mapping of human settlements at a global scale.This paper presents a deep-learning-based framework for a fully automated extraction of built-up areas at a spatial resolution of 10 m from a global composite of Sentinel-2 imagery.A multi-neuro modeling methodology building on a simple Convolution Neural Networks architecture for pixel-wise image classification of built-up areas is developed.The core features of the proposed model are the image patch of size 5 x 5 pixels adequate for describing built-up areas from Sentinel-2 imagery and the lightweight topology with a total number of 1,448,578 trainable parameters and 4 2D convolutional layers and 2 flattened layers.The deployment of the model on the global Sentinel-2 image composite provides the most detailed and complete map reporting about built-up areas for reference year 2018. The validation of the results with an independent reference data-set of building footprints covering 277 sites across the world establishes the reliability of the built-up layer produced by the proposed framework and the model robustness.

</details>


## 2020-11

<details>

<summary>2020-11-01 05:15:37 - Two-layer clustering-based sparsifying transform learning for low-dose CT reconstruction</summary>

- *Xikai Yang, Yong Long, Saiprasad Ravishankar*

- `2011.00428v1` - [abs](http://arxiv.org/abs/2011.00428v1) - [pdf](http://arxiv.org/pdf/2011.00428v1)

> Achieving high-quality reconstructions from low-dose computed tomography (LDCT) measurements is of much importance in clinical settings. Model-based image reconstruction methods have been proven to be effective in removing artifacts in LDCT. In this work, we propose an approach to learn a rich two-layer clustering-based sparsifying transform model (MCST2), where image patches and their subsequent feature maps (filter residuals) are clustered into groups with different learned sparsifying filters per group. We investigate a penalized weighted least squares (PWLS) approach for LDCT reconstruction incorporating learned MCST2 priors. Experimental results show the superior performance of the proposed PWLS-MCST2 approach compared to other related recent schemes.

</details>

<details>

<summary>2020-11-02 10:43:10 - 3D Self-Supervised Methods for Medical Imaging</summary>

- *Aiham Taleb, Winfried Loetzsch, Noel Danz, Julius Severin, Thomas Gaertner, Benjamin Bergner, Christoph Lippert*

- `2006.03829v3` - [abs](http://arxiv.org/abs/2006.03829v3) - [pdf](http://arxiv.org/pdf/2006.03829v3)

> Self-supervised learning methods have witnessed a recent surge of interest after proving successful in multiple application fields. In this work, we leverage these techniques, and we propose 3D versions for five different self-supervised methods, in the form of proxy tasks. Our methods facilitate neural network feature learning from unlabeled 3D images, aiming to reduce the required cost for expert annotation. The developed algorithms are 3D Contrastive Predictive Coding, 3D Rotation prediction, 3D Jigsaw puzzles, Relative 3D patch location, and 3D Exemplar networks. Our experiments show that pretraining models with our 3D tasks yields more powerful semantic representations, and enables solving downstream tasks more accurately and efficiently, compared to training the models from scratch and to pretraining them on 2D slices. We demonstrate the effectiveness of our methods on three downstream tasks from the medical imaging domain: i) Brain Tumor Segmentation from 3D MRI, ii) Pancreas Tumor Segmentation from 3D CT, and iii) Diabetic Retinopathy Detection from 2D Fundus images. In each task, we assess the gains in data-efficiency, performance, and speed of convergence. Interestingly, we also find gains when transferring the learned representations, by our methods, from a large unlabeled 3D corpus to a small downstream-specific dataset. We achieve results competitive to state-of-the-art solutions at a fraction of the computational expense. We publish our implementations for the developed algorithms (both 3D and 2D versions) as an open-source library, in an effort to allow other researchers to apply and extend our methods on their datasets.

</details>

<details>

<summary>2020-11-02 19:19:08 - There's No Trick, Its Just a Simple Trick: A Web-Compat and Privacy Improving Approach to Third-party Web Storage</summary>

- *Jordan Jueckstock, Peter Snyder, Shaown Sarker, Alexandros Kapravelos, Benjamin Livshits*

- `2011.01267v1` - [abs](http://arxiv.org/abs/2011.01267v1) - [pdf](http://arxiv.org/pdf/2011.01267v1)

> While much current web privacy research focuses on browser fingerprinting, the boring fact is that the majority of current third-party web tracking is conducted using traditional, persistent-state identifiers. One possible explanation for the privacy community's focus on fingerprinting is that to date browsers have faced a lose-lose dilemma when dealing with third-party stateful identifiers: block state in third-party frames and break a significant number of webpages, or allow state in third-party frames and enable pervasive tracking. The alternative, middle-ground solutions that have been deployed all trade privacy for compatibility, rely on manually curated lists, or depend on the user to manage state and state-access themselves. This work furthers privacy on the web by presenting a novel system for managing the lifetime of third-party storage, "page-length storage". We compare page-length storage to existing approaches for managing third-party state and find that page-length storage has the privacy protections of the most restrictive current option (i.e., blocking third-party storage) but web-compatibility properties mostly similar to the least restrictive option (i.e., allowing all third-party storage). This work further compares page-length storage to an alternative third-party storage partitioning scheme and finds that page-length storage provides superior privacy protections with comparable web-compatibility. We provide a dataset of the privacy and compatibility behaviors observed when applying the compared third-party storage strategies on a crawl of the Tranco 1k and the quantitative metrics used to demonstrate that page-length storage matches or surpasses existing approaches. Finally, we provide an open-source implementation of our page-length storage approach, implemented as patches against Chromium.

</details>

<details>

<summary>2020-11-05 03:07:20 - Understanding the drivers of sustainable land expansion using a patch-generating land use simulation (PLUS) model: A case study in Wuhan, China</summary>

- *Xun Liang, Qingfeng Guan, Keith C. Clarke, Shishi Liu, Bingyu Wang, Yao Yao*

- `2010.11541v3` - [abs](http://arxiv.org/abs/2010.11541v3) - [pdf](http://arxiv.org/pdf/2010.11541v3)

> Cellular Automata (CA) are widely used to model the dynamics within complex land use and land cover (LULC) systems. Past CA model research has focused on improving the technical modeling procedures, and only a few studies have sought to improve our understanding of the nonlinear relationships that underlie LULC change. Many CA models lack the ability to simulate the detailed patch evolution of multiple land use types. This study introduces a patch-generating land use simulation (PLUS) model that integrates a land expansion analysis strategy and a CA model based on multi-type random patch seeds. These were used to understand the drivers of land expansion and to investigate the landscape dynamics in Wuhan, China. The proposed model achieved a higher simulation accuracy and more similar landscape pattern metrics to the true landscape than other CA models tested. The land expansion analysis strategy also uncovered some underlying transition rules, such as that grassland is most likely to be found where it is not strongly impacted by human activities, and that deciduous forest areas tend to grow adjacent to arterial roads. We also projected the structure of land use under different optimizing scenarios for 2035 by combining the proposed model with multi-objective programming. The results indicate that the proposed model can help policymakers to manage future land use dynamics and so to realize more sustainable land use patterns for future development. Software for PLUS has been made available at https://github.com/HPSCIL/Patch-generating_Land_Use_Simulation_Model

</details>

<details>

<summary>2020-11-05 06:04:50 - Reinforcement Learning with Augmented Data</summary>

- *Michael Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, Aravind Srinivas*

- `2004.14990v5` - [abs](http://arxiv.org/abs/2004.14990v5) - [pdf](http://arxiv.org/pdf/2004.14990v5)

> Learning from visual observations is a fundamental yet challenging problem in Reinforcement Learning (RL). Although algorithmic advances combined with convolutional neural networks have proved to be a recipe for success, current methods are still lacking on two fronts: (a) data-efficiency of learning and (b) generalization to new environments. To this end, we present Reinforcement Learning with Augmented Data (RAD), a simple plug-and-play module that can enhance most RL algorithms. We perform the first extensive study of general data augmentations for RL on both pixel-based and state-based inputs, and introduce two new data augmentations - random translate and random amplitude scale. We show that augmentations such as random translate, crop, color jitter, patch cutout, random convolutions, and amplitude scale can enable simple RL algorithms to outperform complex state-of-the-art methods across common benchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and final performance on the DeepMind Control Suite benchmark for pixel-based control as well as OpenAI Gym benchmark for state-based control. We further demonstrate that RAD significantly improves test-time generalization over existing methods on several OpenAI ProcGen benchmarks. Our RAD module and training code are available at https://www.github.com/MishaLaskin/rad.

</details>

<details>

<summary>2020-11-05 21:59:37 - Evaluating the Performance of Twitter-based Exploit Detectors</summary>

- *Daniel Alves de Sousa, Elaine Ribeiro de Faria, Rodrigo Sanches Miani*

- `2011.03113v1` - [abs](http://arxiv.org/abs/2011.03113v1) - [pdf](http://arxiv.org/pdf/2011.03113v1)

> Patch prioritization is a crucial aspect of information systems security, and knowledge of which vulnerabilities were exploited in the wild is a powerful tool to help systems administrators accomplish this task. The analysis of social media for this specific application can enhance the results and bring more agility by collecting data from online discussions and applying machine learning techniques to detect real-world exploits. In this paper, we use a technique that combines Twitter data with public database information to classify vulnerabilities as exploited or not-exploited. We analyze the behavior of different classifying algorithms, investigate the influence of different antivirus data as ground truth, and experiment with various time window sizes. Our findings suggest that using a Light Gradient Boosting Machine (LightGBM) can benefit the results, and for most cases, the statistics related to a tweet and the users who tweeted are more meaningful than the text tweeted. We also demonstrate the importance of using ground-truth data from security companies not mentioned in previous works.

</details>

<details>

<summary>2020-11-06 20:56:21 - Subgraph Neural Networks</summary>

- *Emily Alsentzer, Samuel G. Finlayson, Michelle M. Li, Marinka Zitnik*

- `2006.10538v3` - [abs](http://arxiv.org/abs/2006.10538v3) - [pdf](http://arxiv.org/pdf/2006.10538v3)

> Deep learning methods for graphs achieve remarkable performance on many node-level and graph-level prediction tasks. However, despite the proliferation of the methods and their success, prevailing Graph Neural Networks (GNNs) neglect subgraphs, rendering subgraph prediction tasks challenging to tackle in many impactful applications. Further, subgraph prediction tasks present several unique challenges: subgraphs can have non-trivial internal topology, but also carry a notion of position and external connectivity information relative to the underlying graph in which they exist. Here, we introduce SubGNN, a subgraph neural network to learn disentangled subgraph representations. We propose a novel subgraph routing mechanism that propagates neural messages between the subgraph's components and randomly sampled anchor patches from the underlying graph, yielding highly accurate subgraph representations. SubGNN specifies three channels, each designed to capture a distinct aspect of subgraph topology, and we provide empirical evidence that the channels encode their intended properties. We design a series of new synthetic and real-world subgraph datasets. Empirical results for subgraph classification on eight datasets show that SubGNN achieves considerable performance gains, outperforming strong baseline methods, including node-level and graph-level GNNs, by 19.8% over the strongest baseline. SubGNN performs exceptionally well on challenging biomedical datasets where subgraphs have complex topology and even comprise multiple disconnected components.

</details>

<details>

<summary>2020-11-07 22:41:18 - Online matrix factorization for Markovian data and applications to Network Dictionary Learning</summary>

- *Hanbaek Lyu, Deanna Needell, Laura Balzano*

- `1911.01931v6` - [abs](http://arxiv.org/abs/1911.01931v6) - [pdf](http://arxiv.org/pdf/1911.01931v6)

> Online Matrix Factorization (OMF) is a fundamental tool for dictionary learning problems, giving an approximate representation of complex data sets in terms of a reduced number of extracted features. Convergence guarantees for most of the OMF algorithms in the literature assume independence between data matrices, and the case of dependent data streams remains largely unexplored. In this paper, we show that a non-convex generalization of the well-known OMF algorithm for i.i.d. stream of data in \citep{mairal2010online} converges almost surely to the set of critical points of the expected loss function, even when the data matrices are functions of some underlying Markov chain satisfying a mild mixing condition. This allows one to extract features more efficiently from dependent data streams, as there is no need to subsample the data sequence to approximately satisfy the independence assumption. As the main application, by combining online non-negative matrix factorization and a recent MCMC algorithm for sampling motifs from networks, we propose a novel framework of Network Dictionary Learning, which extracts ``network dictionary patches' from a given network in an online manner that encodes main features of the network. We demonstrate this technique and its application to network denoising problems on real-world network data.

</details>

<details>

<summary>2020-11-10 04:20:49 - Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet Networks</summary>

- *Tareq Tayeh, Sulaiman Aburakhia, Ryan Myers, Abdallah Shami*

- `2011.04121v2` - [abs](http://arxiv.org/abs/2011.04121v2) - [pdf](http://arxiv.org/pdf/2011.04121v2)

> Surface anomaly detection plays an important quality control role in many manufacturing industries to reduce scrap production. Machine-based visual inspections have been utilized in recent years to conduct this task instead of human experts. In particular, deep learning Convolutional Neural Networks (CNNs) have been at the forefront of these image processing-based solutions due to their predictive accuracy and efficiency. Training a CNN on a classification objective requires a sufficiently large amount of defective data, which is often not available. In this paper, we address that challenge by training the CNN on surface texture patches with a distance-based anomaly detection objective instead. A deep residual-based triplet network model is utilized, and defective training samples are synthesized exclusively from non-defective samples via random erasing techniques to directly learn a similarity metric between the same-class samples and out-of-class samples. Evaluation results demonstrate the approach's strength in detecting different types of anomalies, such as bent, broken, or cracked surfaces, for known surfaces that are part of the training data and unseen novel surfaces.

</details>

<details>

<summary>2020-11-10 21:24:42 - Deep machine learning-assisted multiphoton microscopy to reduce light exposure and expedite imaging</summary>

- *Stephen McAleer, Alex Fast, Yuntian Xue, Magdalene Seiler, William Tang, Mihaela Balu, Pierre Baldi, Andrew W. Browne*

- `2011.06408v1` - [abs](http://arxiv.org/abs/2011.06408v1) - [pdf](http://arxiv.org/pdf/2011.06408v1)

> Two-photon excitation fluorescence (2PEF) allows imaging of tissue up to about one millimeter in thickness. Typically, reducing fluorescence excitation exposure reduces the quality of the image. However, using deep learning super resolution techniques, these low-resolution images can be converted to high-resolution images. This work explores improving human tissue imaging by applying deep learning to maximize image quality while reducing fluorescence excitation exposure. We analyze two methods: a method based on U-Net, and a patch-based regression method. Both methods are evaluated on a skin dataset and an eye dataset. The eye dataset includes 1200 paired high power and low power images of retinal organoids. The skin dataset contains multiple frames of each sample of human skin. High-resolution images were formed by averaging 70 frames for each sample and low-resolution images were formed by averaging the first 7 and 15 frames for each sample. The skin dataset includes 550 images for each of the resolution levels. We track two measures of performance for the two methods: mean squared error (MSE) and structural similarity index measure (SSIM). For the eye dataset, the patches method achieves an average MSE of 27,611 compared to 146,855 for the U-Net method, and an average SSIM of 0.636 compared to 0.607 for the U-Net method. For the skin dataset, the patches method achieves an average MSE of 3.768 compared to 4.032 for the U-Net method, and an average SSIM of 0.824 compared to 0.783 for the U-Net method. Despite better performance on image quality, the patches method is worse than the U-Net method when comparing the speed of prediction, taking 303 seconds to predict one image compared to less than one second for the U-Net method.

</details>

<details>

<summary>2020-11-11 00:28:40 - ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep Learning on Satellite Imagery</summary>

- *Jeremy Irvin, Hao Sheng, Neel Ramachandran, Sonja Johnson-Yu, Sharon Zhou, Kyle Story, Rose Rustowicz, Cooper Elsworth, Kemen Austin, Andrew Y. Ng*

- `2011.05479v1` - [abs](http://arxiv.org/abs/2011.05479v1) - [pdf](http://arxiv.org/pdf/2011.05479v1)

> Characterizing the processes leading to deforestation is critical to the development and implementation of targeted forest conservation and management policies. In this work, we develop a deep learning model called ForestNet to classify the drivers of primary forest loss in Indonesia, a country with one of the highest deforestation rates in the world. Using satellite imagery, ForestNet identifies the direct drivers of deforestation in forest loss patches of any size. We curate a dataset of Landsat 8 satellite images of known forest loss events paired with driver annotations from expert interpreters. We use the dataset to train and validate the models and demonstrate that ForestNet substantially outperforms other standard driver classification approaches. In order to support future research on automated approaches to deforestation driver classification, the dataset curated in this study is publicly available at https://stanfordmlgroup.github.io/projects/forestnet .

</details>

<details>

<summary>2020-11-11 10:44:52 - Noise Conscious Training of Non Local Neural Network powered by Self Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising</summary>

- *Sutanu Bera, Prabir Kumar Biswas*

- `2011.05684v1` - [abs](http://arxiv.org/abs/2011.05684v1) - [pdf](http://arxiv.org/pdf/2011.05684v1)

> The explosive rise of the use of Computer tomography (CT) imaging in medical practice has heightened public concern over the patient's associated radiation dose. However, reducing the radiation dose leads to increased noise and artifacts, which adversely degrades the scan's interpretability. Consequently, an advanced image reconstruction algorithm to improve the diagnostic performance of low dose ct arose as the primary concern among the researchers, which is challenging due to the ill-posedness of the problem. In recent times, the deep learning-based technique has emerged as a dominant method for low dose CT(LDCT) denoising. However, some common bottleneck still exists, which hinders deep learning-based techniques from furnishing the best performance. In this study, we attempted to mitigate these problems with three novel accretions. First, we propose a novel convolutional module as the first attempt to utilize neighborhood similarity of CT images for denoising tasks. Our proposed module assisted in boosting the denoising by a significant margin. Next, we moved towards the problem of non-stationarity of CT noise and introduced a new noise aware mean square error loss for LDCT denoising. Moreover, the loss mentioned above also assisted to alleviate the laborious effort required while training CT denoising network using image patches. Lastly, we propose a novel discriminator function for CT denoising tasks. The conventional vanilla discriminator tends to overlook the fine structural details and focus on the global agreement. Our proposed discriminator leverage self-attention and pixel-wise GANs for restoring the diagnostic quality of LDCT images. Our method validated on a publicly available dataset of the 2016 NIH-AAPM-Mayo Clinic Low Dose CT Grand Challenge performed remarkably better than the existing state of the art method.

</details>

<details>

<summary>2020-11-12 01:28:55 - Detecting Adversarial Patches with Class Conditional Reconstruction Networks</summary>

- *Perry Deng, Mohammad Saidur Rahman, Matthew Wright*

- `2011.05850v2` - [abs](http://arxiv.org/abs/2011.05850v2) - [pdf](http://arxiv.org/pdf/2011.05850v2)

> Defending against physical adversarial attacks is a rapidly growing topic in deep learning and computer vision. Prominent forms of physical adversarial attacks, such as overlaid adversarial patches and objects, share similarities with digital attacks, but are easy for humans to notice. This leads us to explore the hypothesis that adversarial detection methods, which have been shown to be ineffective against adaptive digital adversarial examples, can be effective against these physical attacks. We use one such detection method based on autoencoder architectures, and perform adversarial patching experiments on MNIST, SVHN, and CIFAR10 against a CNN architecture and two CapsNet architectures. We also propose two modifications to the EM-Routed CapsNet architecture, Affine Voting and Matrix Capsule Dropout, to improve its classification performance. Our investigation shows that the detector retains some of its effectiveness even against adaptive adversarial patch attacks. In addition, detection performance tends to decrease among all the architectures with the increase of dataset complexity.

</details>

<details>

<summary>2020-11-13 08:54:13 - Shared Prior Learning of Energy-Based Models for Image Reconstruction</summary>

- *Thomas Pinetz, Erich Kobler, Thomas Pock, Alexander Effland*

- `2011.06539v2` - [abs](http://arxiv.org/abs/2011.06539v2) - [pdf](http://arxiv.org/pdf/2011.06539v2)

> We propose a novel learning-based framework for image reconstruction particularly designed for training without ground truth data, which has three major building blocks: energy-based learning, a patch-based Wasserstein loss functional, and shared prior learning. In energy-based learning, the parameters of an energy functional composed of a learned data fidelity term and a data-driven regularizer are computed in a mean-field optimal control problem. In the absence of ground truth data, we change the loss functional to a patch-based Wasserstein functional, in which local statistics of the output images are compared to uncorrupted reference patches. Finally, in shared prior learning, both aforementioned optimal control problems are optimized simultaneously with shared learned parameters of the regularizer to further enhance unsupervised image reconstruction. We derive several time discretization schemes of the gradient flow and verify their consistency in terms of Mosco convergence. In numerous numerical experiments, we demonstrate that the proposed method generates state-of-the-art results for various image reconstruction applications--even if no ground truth images are available for training.

</details>

<details>

<summary>2020-11-16 17:27:35 - Anonymization of labeled TOF-MRA images for brain vessel segmentation using generative adversarial networks</summary>

- *Tabea Kossen, Pooja Subramaniam, Vince I. Madai, Anja Hennemuth, Kristian Hildebrand, Adam Hilbert, Jan Sobesky, Michelle Livne, Ivana Galinovic, Ahmed A. Khalil, Jochen B. Fiebach, Dietmar Frey*

- `2009.04227v3` - [abs](http://arxiv.org/abs/2009.04227v3) - [pdf](http://arxiv.org/pdf/2009.04227v3)

> Anonymization and data sharing are crucial for privacy protection and acquisition of large datasets for medical image analysis. This is a big challenge, especially for neuroimaging. Here, the brain's unique structure allows for re-identification and thus requires non-conventional anonymization. Generative adversarial networks (GANs) have the potential to provide anonymous images while preserving predictive properties. Analyzing brain vessel segmentation, we trained 3 GANs on time-of-flight (TOF) magnetic resonance angiography (MRA) patches for image-label generation: 1) Deep convolutional GAN, 2) Wasserstein-GAN with gradient penalty (WGAN-GP) and 3) WGAN-GP with spectral normalization (WGAN-GP-SN). The generated image-labels from each GAN were used to train a U-net for segmentation and tested on real data. Moreover, we applied our synthetic patches using transfer learning on a second dataset. For an increasing number of up to 15 patients we evaluated the model performance on real data with and without pre-training. The performance for all models was assessed by the Dice Similarity Coefficient (DSC) and the 95th percentile of the Hausdorff Distance (95HD). Comparing the 3 GANs, the U-net trained on synthetic data generated by the WGAN-GP-SN showed the highest performance to predict vessels (DSC/95HD 0.82/28.97) benchmarked by the U-net trained on real data (0.89/26.61). The transfer learning approach showed superior performance for the same GAN compared to no pre-training, especially for one patient only (0.91/25.68 vs. 0.85/27.36). In this work, synthetic image-label pairs retained generalizable information and showed good performance for vessel segmentation. Besides, we showed that synthetic patches can be used in a transfer learning approach with independent data. This paves the way to overcome the challenges of scarce data and anonymization in medical imaging.

</details>

<details>

<summary>2020-11-19 04:51:13 - Open-sourced Dataset Protection via Backdoor Watermarking</summary>

- *Yiming Li, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang, Shu-Tao Xia*

- `2010.05821v3` - [abs](http://arxiv.org/abs/2010.05821v3) - [pdf](http://arxiv.org/pdf/2010.05821v3)

> The rapid development of deep learning has benefited from the release of some high-quality open-sourced datasets ($e.g.$, ImageNet), which allows researchers to easily verify the effectiveness of their algorithms. Almost all existing open-sourced datasets require that they can only be adopted for academic or educational purposes rather than commercial purposes, whereas there is still no good way to protect them. In this paper, we propose a \emph{backdoor embedding based dataset watermarking} method to protect an open-sourced image-classification dataset by verifying whether it is used for training a third-party model. Specifically, the proposed method contains two main processes, including \emph{dataset watermarking} and \emph{dataset verification}. We adopt classical poisoning-based backdoor attacks ($e.g.$, BadNets) for dataset watermarking, ie, generating some poisoned samples by adding a certain trigger ($e.g.$, a local patch) onto some benign samples, labeled with a pre-defined target class. Based on the proposed backdoor-based watermarking, we use a hypothesis test guided method for dataset verification based on the posterior probability generated by the suspicious third-party model of the benign samples and their correspondingly watermarked samples ($i.e.$, images with trigger) on the target class. Experiments on some benchmark datasets are conducted, which verify the effectiveness of the proposed method.

</details>

<details>

<summary>2020-11-19 13:02:36 - P2ExNet: Patch-based Prototype Explanation Network</summary>

- *Dominique Mercier, Andreas Dengel, Sheraz Ahmed*

- `2005.02006v2` - [abs](http://arxiv.org/abs/2005.02006v2) - [pdf](http://arxiv.org/pdf/2005.02006v2)

> Deep learning methods have shown great success in several domains as they process a large amount of data efficiently, capable of solving complex classification, forecast, segmentation, and other tasks. However, they come with the inherent drawback of inexplicability limiting their applicability and trustworthiness. Although there exists work addressing this perspective, most of the existing approaches are limited to the image modality due to the intuitive and prominent concepts. Conversely, the concepts in the time-series domain are more complex and non-comprehensive but these and an explanation for the network decision are pivotal in critical domains like medical, financial, or industry. Addressing the need for an explainable approach, we propose a novel interpretable network scheme, designed to inherently use an explainable reasoning process inspired by the human cognition without the need of additional post-hoc explainability methods. Therefore, class-specific patches are used as they cover local concepts relevant to the classification to reveal similarities with samples of the same class. In addition, we introduce a novel loss concerning interpretability and accuracy that constraints P2ExNet to provide viable explanations of the data including relevant patches, their position, class similarities, and comparison methods without compromising accuracy. Analysis of the results on eight publicly available time-series datasets reveals that P2ExNet reaches comparable performance when compared to its counterparts while inherently providing understandable and traceable decisions.

</details>

<details>

<summary>2020-11-20 19:19:48 - ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos</summary>

- *Yasser Dahou, Marouane Tliba, Kevin McGuinness, Noel O'Connor*

- `2011.10600v1` - [abs](http://arxiv.org/abs/2011.10600v1) - [pdf](http://arxiv.org/pdf/2011.10600v1)

> The spherical domain representation of 360 video/image presents many challenges related to the storage, processing, transmission and rendering of omnidirectional videos (ODV). Models of human visual attention can be used so that only a single viewport is rendered at a time, which is important when developing systems that allow users to explore ODV with head mounted displays (HMD). Accordingly, researchers have proposed various saliency models for 360 video/images. This paper proposes ATSal, a novel attention based (head-eye) saliency model for 360\degree videos. The attention mechanism explicitly encodes global static visual attention allowing expert models to focus on learning the saliency on local patches throughout consecutive frames. We compare the proposed approach to other state-of-the-art saliency models on two datasets: Salient360! and VR-EyeTracking. Experimental results on over 80 ODV videos (75K+ frames) show that the proposed method outperforms the existing state-of-the-art.

</details>

<details>

<summary>2020-11-25 11:10:37 - The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal Vessel Segmentation</summary>

- *Björn Browatzki, Jörn-Philipp Lies, Christian Wallraven*

- `2011.12643v1` - [abs](http://arxiv.org/abs/2011.12643v1) - [pdf](http://arxiv.org/pdf/2011.12643v1)

> We propose an encoder-decoder framework for the segmentation of blood vessels in retinal images that relies on the extraction of large-scale patches at multiple image-scales during training. Experiments on three fundus image datasets demonstrate that this approach achieves state-of-the-art results and can be implemented using a simple and efficient fully-convolutional network with a parameter count of less than 0.8M. Furthermore, we show that this framework - called VLight - avoids overfitting to specific training images and generalizes well across different datasets, which makes it highly suitable for real-world applications where robustness, accuracy as well as low inference time on high-resolution fundus images is required.

</details>

<details>

<summary>2020-11-26 13:28:50 - FlexiRepair: Transparent Program Repair with Generic Patches</summary>

- *Anil Koyuncu, Tegawendé F. Bissyandé, Jacques Klein, Yves Le Traon*

- `2011.13280v1` - [abs](http://arxiv.org/abs/2011.13280v1) - [pdf](http://arxiv.org/pdf/2011.13280v1)

> Template-based program repair research is in need for a common ground to express fix patterns in a standard and reusable manner. We propose to build on the concept of generic patch (also known as semantic patch), which is widely used in the Linux community to automate code evolution. We advocate that generic patches could provide at the same time a unified representation and a specification for fix patterns. Generic patches are indeed formally defined, and there exists a robust, industry-adapted, and extensible engine that processes generic patches to perform control-flow code matching and automatically generates concretes patches based on the specified change operations. In this paper, we present the design and implementation of a repair framework, FLEXIREPAIR, that explores generic patches as the core concept. In particular, we show how concretely generic patches can be inferred and applied in a pipeline of Automated Program Repair (APR). With FLEXIREPAIR, we address an urgent challenge in the template-based APR community to separate implementation details from actual scientific contributions by providing an open, transparent and flexible repair pipeline on top of which all advancements in terms of efficiency, efficacy and usability can be measured and assessed rigorously. Furthermore, because the underlying tools and concepts have already been accepted by a wide practitioner community, we expect FLEXIREPAIR's adoption by industry to be facilitated. Preliminary experiments with a prototype FLEXIREPAIR on the IntroClass and CodeFlaws benchmarks suggest that it already constitutes a solid baseline with comparable performance to some of the state of the art.

</details>

<details>

<summary>2020-11-27 07:18:55 - Can 3D Adversarial Logos Cloak Humans?</summary>

- *Yi Wang, Jingyang Zhou, Tianlong Chen, Sijia Liu, Shiyu Chang, Chandrajit Bajaj, Zhangyang Wang*

- `2006.14655v2` - [abs](http://arxiv.org/abs/2006.14655v2) - [pdf](http://arxiv.org/pdf/2006.14655v2)

> With the trend of adversarial attacks, researchers attempt to fool trained object detectors in 2D scenes. Among many of them, an intriguing new form of attack with potential real-world usage is to append adversarial patches (e.g. logos) to images. Nevertheless, much less have we known about adversarial attacks from 3D rendering views, which is essential for the attack to be persistently strong in the physical world. This paper presents a new 3D adversarial logo attack: we construct an arbitrary shape logo from a 2D texture image and map this image into a 3D adversarial logo via a texture mapping called logo transformation. The resulting 3D adversarial logo is then viewed as an adversarial texture enabling easy manipulation of its shape and position. This greatly extends the versatility of adversarial training for computer graphics synthesized imagery. Contrary to the traditional adversarial patch, this new form of attack is mapped into the 3D object world and back-propagates to the 2D image domain through differentiable rendering. In addition, and unlike existing adversarial patches, our new 3D adversarial logo is shown to fool state-of-the-art deep object detectors robustly under model rotations, leading to one step further for realistic attacks in the physical world. Our codes are available at https://github.com/TAMU-VITA/3D_Adversarial_Logo.

</details>

<details>

<summary>2020-11-27 08:00:54 - An anatomically-informed 3D CNN for brain aneurysm classification with weak labels</summary>

- *Tommaso Di Noto, Guillaume Marie, Sébastien Tourbier, Yasser Alemán-Gómez, Guillaume Saliou, Meritxell Bach Cuadra, Patric Hagmann, Jonas Richiardi*

- `2012.08645v1` - [abs](http://arxiv.org/abs/2012.08645v1) - [pdf](http://arxiv.org/pdf/2012.08645v1)

> A commonly adopted approach to carry out detection tasks in medical imaging is to rely on an initial segmentation. However, this approach strongly depends on voxel-wise annotations which are repetitive and time-consuming to draw for medical experts. An interesting alternative to voxel-wise masks are so-called "weak" labels: these can either be coarse or oversized annotations that are less precise, but noticeably faster to create. In this work, we address the task of brain aneurysm detection as a patch-wise binary classification with weak labels, in contrast to related studies that rather use supervised segmentation methods and voxel-wise delineations. Our approach comes with the non-trivial challenge of the data set creation: as for most focal diseases, anomalous patches (with aneurysm) are outnumbered by those showing no anomaly, and the two classes usually have different spatial distributions. To tackle this frequent scenario of inherently imbalanced, spatially skewed data sets, we propose a novel, anatomically-driven approach by using a multi-scale and multi-input 3D Convolutional Neural Network (CNN). We apply our model to 214 subjects (83 patients, 131 controls) who underwent Time-Of-Flight Magnetic Resonance Angiography (TOF-MRA) and presented a total of 111 unruptured cerebral aneurysms. We compare two strategies for negative patch sampling that have an increasing level of difficulty for the network and we show how this choice can strongly affect the results. To assess whether the added spatial information helps improving performances, we compare our anatomically-informed CNN with a baseline, spatially-agnostic CNN. When considering the more realistic and challenging scenario including vessel-like negative patches, the former model attains the highest classification results (accuracy$\simeq$95\%, AUROC$\simeq$0.95, AUPR$\simeq$0.71), thus outperforming the baseline.

</details>

<details>

<summary>2020-11-27 08:08:46 - Planting trees at the right places: Recommending suitable sites for growing trees using algorithm fusion</summary>

- *Pushpendra Rana, Lav R Varshney*

- `2009.08002v2` - [abs](http://arxiv.org/abs/2009.08002v2) - [pdf](http://arxiv.org/pdf/2009.08002v2)

> Large-scale planting of trees has been proposed as a low-cost natural solution for carbon mitigation, but is hampered by poor selection of plantation sites, especially in developing countries. To aid in site selection, we develop the ePSA (e-Plantation Site Assistant) recommendation system based on algorithm fusion that combines physics-based/traditional forestry science knowledge with machine learning. ePSA assists forest range officers by identifying blank patches inside forest areas and ranking each such patch based on their tree growth potential. Experiments, user studies, and deployment results characterize the utility of the recommender system in shaping the long-term success of tree plantations as a nature climate solution for carbon mitigation in northern India and beyond.

</details>

<details>

<summary>2020-11-29 04:59:08 - 3D Semantic Segmentation of Brain Tumor for Overall Survival Prediction</summary>

- *Rupal Agravat, Mehul S Raval*

- `2008.11576v2` - [abs](http://arxiv.org/abs/2008.11576v2) - [pdf](http://arxiv.org/pdf/2008.11576v2)

> Glioma, the malignant brain tumor, requires immediate treatment to improve the survival of patients. Gliomas heterogeneous nature makes the segmentation difficult, especially for sub-regions like necrosis, enhancing tumor, non-enhancing tumor, and Edema. Deep neural networks like full convolution neural networks and ensemble of fully convolution neural networks are successful for Glioma segmentation. The paper demonstrates the use of a 3D fully convolution neural network with a three layer encoder decoder approach for layer arrangement. The encoder blocks include the dense modules, and decoder blocks include convolution modules. The input to the network is 3D patches. The loss function combines dice loss and focal loss functions. The validation set dice score of the network is 0.74, 0.88, and 0.73 for enhancing tumor, whole tumor, and tumor core, respectively. The Random Forest Regressor uses shape, volumetric, and age features extracted from ground truth for overall survival prediction. The regressor achieves an accuracy of 44.8% on the validation set.

</details>

<details>

<summary>2020-11-30 17:05:58 - Fast, Self Supervised, Fully Convolutional Color Normalization of H&E Stained Images</summary>

- *Abhijeet Patil, Mohd. Talha, Aniket Bhatia, Nikhil Cherian Kurian, Sammed Mangale, Sunil Patel, Amit Sethi*

- `2011.15000v1` - [abs](http://arxiv.org/abs/2011.15000v1) - [pdf](http://arxiv.org/pdf/2011.15000v1)

> Performance of deep learning algorithms decreases drastically if the data distributions of the training and testing sets are different. Due to variations in staining protocols, reagent brands, and habits of technicians, color variation in digital histopathology images is quite common. Color variation causes problems for the deployment of deep learning-based solutions for automatic diagnosis system in histopathology. Previously proposed color normalization methods consider a small patch as a reference for normalization, which creates artifacts on out-of-distribution source images. These methods are also slow as most of the computation is performed on CPUs instead of the GPUs. We propose a color normalization technique, which is fast during its self-supervised training as well as inference. Our method is based on a lightweight fully-convolutional neural network and can be easily attached to a deep learning-based pipeline as a pre-processing block. For classification and segmentation tasks on CAMELYON17 and MoNuSeg datasets respectively, the proposed method is faster and gives a greater increase in accuracy than the state of the art methods.

</details>


## 2020-12

<details>

<summary>2020-12-01 16:37:18 - Overcoming the limitations of patch-based learning to detect cancer in whole slide images</summary>

- *Ozan Ciga, Tony Xu, Sharon Nofech-Mozes, Shawna Noy, Fang-I Lu, Anne L. Martel*

- `2012.00617v1` - [abs](http://arxiv.org/abs/2012.00617v1) - [pdf](http://arxiv.org/pdf/2012.00617v1)

> Whole slide images (WSIs) pose unique challenges when training deep learning models. They are very large which makes it necessary to break each image down into smaller patches for analysis, image features have to be extracted at multiple scales in order to capture both detail and context, and extreme class imbalances may exist. Significant progress has been made in the analysis of these images, thanks largely due to the availability of public annotated datasets. We postulate, however, that even if a method scores well on a challenge task, this success may not translate to good performance in a more clinically relevant workflow. Many datasets consist of image patches which may suffer from data curation bias; other datasets are only labelled at the whole slide level and the lack of annotations across an image may mask erroneous local predictions so long as the final decision is correct. In this paper, we outline the differences between patch or slide-level classification versus methods that need to localize or segment cancer accurately across the whole slide, and we experimentally verify that best practices differ in both cases. We apply a binary cancer detection network on post neoadjuvant therapy breast cancer WSIs to find the tumor bed outlining the extent of cancer, a task which requires sensitivity and precision across the whole slide. We extensively study multiple design choices and their effects on the outcome, including architectures and augmentations. Furthermore, we propose a negative data sampling strategy, which drastically reduces the false positive rate (7% on slide level) and improves each metric pertinent to our problem, with a 15% reduction in the error of tumor extent.

</details>

<details>

<summary>2020-12-03 18:59:03 - Space-Time Correspondence as a Contrastive Random Walk</summary>

- *Allan Jabri, Andrew Owens, Alexei A. Efros*

- `2006.14613v2` - [abs](http://arxiv.org/abs/2006.14613v2) - [pdf](http://arxiv.org/pdf/2006.14613v2)

> This paper proposes a simple self-supervised approach for learning a representation for visual correspondence from raw video. We cast correspondence as prediction of links in a space-time graph constructed from video. In this graph, the nodes are patches sampled from each frame, and nodes adjacent in time can share a directed edge. We learn a representation in which pairwise similarity defines transition probability of a random walk, so that long-range correspondence is computed as a walk along the graph. We optimize the representation to place high probability along paths of similarity. Targets for learning are formed without supervision, by cycle-consistency: the objective is to maximize the likelihood of returning to the initial node when walking along a graph constructed from a palindrome of frames. Thus, a single path-level constraint implicitly supervises chains of intermediate comparisons. When used as a similarity metric without adaptation, the learned representation outperforms the self-supervised state-of-the-art on label propagation tasks involving objects, semantic parts, and pose. Moreover, we demonstrate that a technique we call edge dropout, as well as self-supervised adaptation at test-time, further improve transfer for object-centric correspondence.

</details>

<details>

<summary>2020-12-04 15:42:08 - Accelerating Road Sign Ground Truth Construction with Knowledge Graph and Machine Learning</summary>

- *Ji Eun Kim, Cory Henson, Kevin Huang, Tuan A. Tran, Wan-Yi Lin*

- `2012.02672v1` - [abs](http://arxiv.org/abs/2012.02672v1) - [pdf](http://arxiv.org/pdf/2012.02672v1)

> Having a comprehensive, high-quality dataset of road sign annotation is critical to the success of AI-based Road Sign Recognition (RSR) systems. In practice, annotators often face difficulties in learning road sign systems of different countries; hence, the tasks are often time-consuming and produce poor results. We propose a novel approach using knowledge graphs and a machine learning algorithm - variational prototyping-encoder (VPE) - to assist human annotators in classifying road signs effectively. Annotators can query the Road Sign Knowledge Graph using visual attributes and receive closest matching candidates suggested by the VPE model. The VPE model uses the candidates from the knowledge graph and a real sign image patch as inputs. We show that our knowledge graph approach can reduce sign search space by 98.9%. Furthermore, with VPE, our system can propose the correct single candidate for 75% of signs in the tested datasets, eliminating the human search effort entirely in those cases.

</details>

<details>

<summary>2020-12-04 17:36:57 - Ultrasound Scatterer Density Classification Using Convolutional Neural Networks by Exploiting Patch Statistics</summary>

- *Ali K. Z. Tehrani, Mina Amiri, Ivan M. Rosado-Mendez, Timothy J. Hall, Hassan Rivaz*

- `2012.02738v1` - [abs](http://arxiv.org/abs/2012.02738v1) - [pdf](http://arxiv.org/pdf/2012.02738v1)

> Quantitative ultrasound (QUS) can reveal crucial information on tissue properties such as scatterer density. If the scatterer density per resolution cell is above or below 10, the tissue is considered as fully developed speckle (FDS) or low-density scatterers (LDS), respectively. Conventionally, the scatterer density has been classified using estimated statistical parameters of the amplitude of backscattered echoes. However, if the patch size is small, the estimation is not accurate. These parameters are also highly dependent on imaging settings. In this paper, we propose a convolutional neural network (CNN) architecture for QUS, and train it using simulation data. We further improve the network performance by utilizing patch statistics as additional input channels. We evaluate the network using simulation data, experimental phantoms and in vivo data. We also compare our proposed network with different classic and deep learning models, and demonstrate its superior performance in classification of tissues with different scatterer density values. The results also show that the proposed network is able to work with different imaging parameters with no need for a reference phantom. This work demonstrates the potential of CNNs in classifying scatterer density in ultrasound images.

</details>

<details>

<summary>2020-12-05 09:33:43 - A grid-point detection method based on U-net for a structured light system</summary>

- *Dieuthuy Pham, Minhtuan Ha, Changyan Xiao*

- `2012.08641v1` - [abs](http://arxiv.org/abs/2012.08641v1) - [pdf](http://arxiv.org/pdf/2012.08641v1)

> Accurate detection of the feature points of the projected pattern plays an extremely important role in one-shot 3D reconstruction systems, especially for the ones using a grid pattern. To solve this problem, this paper proposes a grid-point detection method based on U-net. A specific dataset is designed that includes the images captured with the two-shot imaging method and the ones acquired with the one-shot imaging method. Among them, the images in the first group after labeled as the ground truth images and the images captured at the same pose with the one-shot method are cut into small patches with the size of 64x64 pixels then feed to the training set. The remaining of the images in the second group is the test set. The experimental results show that our method can achieve a better detecting performance with higher accuracy in comparison with the previous methods.

</details>

<details>

<summary>2020-12-07 15:57:12 - Vulnerability Forecasting: In theory and practice</summary>

- *Éireann Leverett, Matilda Rhode, Adam Wedgbury*

- `2012.03814v1` - [abs](http://arxiv.org/abs/2012.03814v1) - [pdf](http://arxiv.org/pdf/2012.03814v1)

> Why wait for zero-days when you could predict them in advance? It is possible to predict the volume of CVEs released in the NVD as much as a year in advance. This can be done within 3 percent of the actual value, and different predictive algorithms perform well at different lookahead values. It is also possible to estimate the proportions of that total volumn belonging to specific vendors, software, CVSS scores, or vulnerability types. Strategic patch management should become much easier, with this uncertainty reduction.

</details>

<details>

<summary>2020-12-07 21:19:24 - Dragonblood is Still Leaking: Practical Cache-based Side-Channel in the Wild</summary>

- *Daniel De Almeida Braga, Pierre-Alain Fouque, Mohamed Sabt*

- `2012.02745v2` - [abs](http://arxiv.org/abs/2012.02745v2) - [pdf](http://arxiv.org/pdf/2012.02745v2)

> Recently, the Dragonblood attacks have attracted new interests on the security of WPA-3 implementation and in particular on the Dragonfly code deployed on many open-source libraries. One attack concerns the protection of users passwords during authentication. In the Password Authentication Key Exchange (PAKE) protocol called Dragonfly, the secret, namely the password, is mapped to an elliptic curve point. This operation is sensitive, as it involves the secret password, and therefore its resistance against side-channel attacks is of utmost importance. Following the initial disclosure of Dragonblood, we notice that this particular attack has been partially patched by only a few implementations.   In this work, we show that the patches implemented after the disclosure of Dragonblood are insufficient. We took advantage of state-of-the-art techniques to extend the original attack, demonstrating that we are able to recover the password with only a third of the measurements needed in Dragonblood attack. We mainly apply our attack on two open-source projects: iwd (iNet Wireless Daemon) and FreeRADIUS, in order underline the practicability of our attack. Indeed, the iwd package, written by Intel, is already deployed in the Arch Linux distribution, which is well-known among security experts, and aims to offer an alternative to wpa\_supplicant. As for FreeRADIUS, it is widely deployed and well-maintained upstream open-source project. We publish a full Proof of Concept of our attack, and actively participated in the process of patching the vulnerable code. Here, in a backward compatibility perspective, we advise the use of a branch-free implementation as a mitigation technique, as what was used in hostapd, due to its quite simplicity and its negligible incurred overhead.

</details>

<details>

<summary>2020-12-10 07:57:44 - Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation</summary>

- *Daizong Liu, Shuangjie Xu, Xiao-Yang Liu, Zichuan Xu, Wei Wei, Pan Zhou*

- `2012.05499v1` - [abs](http://arxiv.org/abs/2012.05499v1) - [pdf](http://arxiv.org/pdf/2012.05499v1)

> This paper addresses the task of segmenting class-agnostic objects in semi-supervised setting. Although previous detection based methods achieve relatively good performance, these approaches extract the best proposal by a greedy strategy, which may lose the local patch details outside the chosen candidate. In this paper, we propose a novel spatiotemporal graph neural network (STG-Net) to reconstruct more accurate masks for video object segmentation, which captures the local contexts by utilizing all proposals. In the spatial graph, we treat object proposals of a frame as nodes and represent their correlations with an edge weight strategy for mask context aggregation. To capture temporal information from previous frames, we use a memory network to refine the mask of current frame by retrieving historic masks in a temporal graph. The joint use of both local patch details and temporal relationships allow us to better address the challenges such as object occlusion and missing. Without online learning and fine-tuning, our STG-Net achieves state-of-the-art performance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, and YouTube-Objects), demonstrating the effectiveness of the proposed approach.

</details>

<details>

<summary>2020-12-14 08:00:26 - Adversarial Training against Location-Optimized Adversarial Patches</summary>

- *Sukrut Rao, David Stutz, Bernt Schiele*

- `2005.02313v2` - [abs](http://arxiv.org/abs/2005.02313v2) - [pdf](http://arxiv.org/pdf/2005.02313v2)

> Deep neural networks have been shown to be susceptible to adversarial examples -- small, imperceptible changes constructed to cause mis-classification in otherwise highly accurate image classifiers. As a practical alternative, recent work proposed so-called adversarial patches: clearly visible, but adversarially crafted rectangular patches in images. These patches can easily be printed and applied in the physical world. While defenses against imperceptible adversarial examples have been studied extensively, robustness against adversarial patches is poorly understood. In this work, we first devise a practical approach to obtain adversarial patches while actively optimizing their location within the image. Then, we apply adversarial training on these location-optimized adversarial patches and demonstrate significantly improved robustness on CIFAR10 and GTSRB. Additionally, in contrast to adversarial training on imperceptible adversarial examples, our adversarial patch training does not reduce accuracy.

</details>

<details>

<summary>2020-12-14 09:41:33 - Swapping Autoencoder for Deep Image Manipulation</summary>

- *Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, Eli Shechtman, Alexei A. Efros, Richard Zhang*

- `2007.00653v2` - [abs](http://arxiv.org/abs/2007.00653v2) - [pdf](http://arxiv.org/pdf/2007.00653v2)

> Deep generative models have become increasingly effective at producing realistic images from randomly sampled seeds, but using such models for controllable manipulation of existing images remains challenging. We propose the Swapping Autoencoder, a deep model designed specifically for image manipulation, rather than random sampling. The key idea is to encode an image with two independent components and enforce that any swapped combination maps to a realistic image. In particular, we encourage the components to represent structure and texture, by enforcing one component to encode co-occurrent patch statistics across different parts of an image. As our method is trained with an encoder, finding the latent codes for a new input image becomes trivial, rather than cumbersome. As a result, it can be used to manipulate real input images in various ways, including texture swapping, local and global editing, and latent code vector arithmetic. Experiments on multiple datasets show that our model produces better results and is substantially more efficient compared to recent generative models.

</details>

<details>

<summary>2020-12-14 21:40:59 - Fixing Multiple Type Errors in Model Transformations with Alternative Oracles to Test Cases</summary>

- *Zahra VaraminyBahnemiry, Jessie Galasso, Houari Sahraoui*

- `2012.07953v1` - [abs](http://arxiv.org/abs/2012.07953v1) - [pdf](http://arxiv.org/pdf/2012.07953v1)

> This paper addresses the issue of correcting type errors in model transformations in realistic scenarios where neither predefined patches nor behavior-safe guards such as test suites are available. Instead of using predefined patches targeting isolated errors of specific categories, we propose to explore the space of possible patches by combining basic edit operations for model transformation programs. To guide the search, we define two families of objectives: one to limit the number of type errors and the other to preserve the transformation behavior. To approximate the latter, we study two objectives: minimizing the number of changes and keeping the changes local. Additionally, we define four heuristics to refine candidate patches to increase the likelihood of correcting type errors while preserving the transformation behavior. We implemented our approach for the ATL language using the evolutionary algorithm NSGA-II, and performed an evaluation based on three published case studies. The evaluation results show that our approach was able to automatically correct on average more than82% of type errors for two cases and more than 56% for the third case.

</details>

<details>

<summary>2020-12-17 18:41:44 - Enhancing Fiber Orientation Distributions using convolutional Neural Networks</summary>

- *Oeslle Lucena, Sjoerd B. Vos, Vejay Vakharia, John Duncan, Keyoumars Ashkan, Rachel Sparks, Sebastien Ourselin*

- `2008.05409v2` - [abs](http://arxiv.org/abs/2008.05409v2) - [pdf](http://arxiv.org/pdf/2008.05409v2)

> Accurate local fiber orientation distribution (FOD) modeling based on diffusion magnetic resonance imaging (dMRI) capable of resolving complex fiber configurations benefits from specific acquisition protocols that sample a high number of gradient directions (b-vecs), a high maximum b-value(b-vals), and multiple b-values (multi-shell). However, acquisition time is limited in a clinical setting and commercial scanners may not provide such dMRI sequences. Therefore, dMRI is often acquired as single-shell (single b-value). In this work, we learn improved FODs for commercially acquired MRI. We evaluate patch-based 3D convolutional neural networks (CNNs)on their ability to regress multi-shell FOD representations from single-shell representations, where the representation is a spherical harmonics obtained from constrained spherical deconvolution (CSD) to model FODs. We evaluate U-Net and HighResNet 3D CNN architectures on data from the Human Connectome Project and an in-house dataset. We evaluate how well each CNN model can resolve local fiber orientation 1) when training and testing on datasets with the same dMRI acquisition protocol; 2) when testing on a dataset with a different dMRI acquisition protocol than used to train the CNN models; and 3) when testing on a dataset with a fewer number of gradient directions than used to train the CNN models. Our approach may enable robust CSD model estimation on single-shell dMRI acquisition protocols with few gradient directions, reducing acquisition times, facilitating translation of improved FOD estimation to time-limited clinical environments.

</details>

<details>

<summary>2020-12-18 12:45:03 - Exact Reduction of Huge Action Spaces in General Reinforcement Learning</summary>

- *Sultan Javed Majeed, Marcus Hutter*

- `2012.10200v1` - [abs](http://arxiv.org/abs/2012.10200v1) - [pdf](http://arxiv.org/pdf/2012.10200v1)

> The reinforcement learning (RL) framework formalizes the notion of learning with interactions. Many real-world problems have large state-spaces and/or action-spaces such as in Go, StarCraft, protein folding, and robotics or are non-Markovian, which cause significant challenges to RL algorithms. In this work we address the large action-space problem by sequentializing actions, which can reduce the action-space size significantly, even down to two actions at the expense of an increased planning horizon. We provide explicit and exact constructions and equivalence proofs for all quantities of interest for arbitrary history-based processes. In the case of MDPs, this could help RL algorithms that bootstrap. In this work we show how action-binarization in the non-MDP case can significantly improve Extreme State Aggregation (ESA) bounds. ESA allows casting any (non-MDP, non-ergodic, history-based) RL problem into a fixed-sized non-Markovian state-space with the help of a surrogate Markovian process. On the upside, ESA enjoys similar optimality guarantees as Markovian models do. But a downside is that the size of the aggregated state-space becomes exponential in the size of the action-space. In this work, we patch this issue by binarizing the action-space. We provide an upper bound on the number of states of this binarized ESA that is logarithmic in the original action-space size, a double-exponential improvement.

</details>

<details>

<summary>2020-12-18 21:37:37 - Achieving Operational Scalability Using Razee Continuous Deployment Model and Kubernetes Operators</summary>

- *Srini Bhagavan, Saravanan Balasubramanian, Prasad Reddy Annem, Thuan Ngo, Arun Soundararaj*

- `2012.10526v1` - [abs](http://arxiv.org/abs/2012.10526v1) - [pdf](http://arxiv.org/pdf/2012.10526v1)

> Recent advancements in the cloud computing domain have resulted in huge strides toward simplifying the procurement of hardware and software for diverse needs. By moving enterprise workloads to managed cloud offerings (private, public, hybrid), customers are delegating mundane tasks and labor-intensive maintenance activities related to network connectivity, procurement of cloud resource, application deployment, software patches, and upgrades, etc., This often translates to benefits such as high availability and reduced cost. The popularity of container and micro-services-based deployment has made Kubernetes the de-facto standard to deliver applications. However, even with Kubernetes orchestration, cloud service providers frequently have operational scalability issues due to lack of Continuous Integration and Continuous Deployment (CICD) automation and increased demand for human operators when managing a large number of software deployments across multiple data centers/availability zones. Kubernetes solves this in a novel way by creating and managing custom applications using Operators. Agile methodology advocates incremental CICD which are adopted by cloud providers. However, ironically, it is this same continuous delivery feature of application updates, Kubernetes cluster upgrades, etc., that is also a bane to cloud providers. In this paper, we will demonstrate the use of IBM open-source project Razee as a scalable continuous deployment framework to deploy open-source RStudio and Nginx Operators. We will discuss how IBM Watson SaaS application Operator, Blockchain applications, and Kubernetes resources updates, etc., can be deployed similarly and the use of Operators to perform application life cycle management. We assert that using Razee in conjunction with Operators on Kubernetes simplifies application life cycle management and increases scalability.

</details>

<details>

<summary>2020-12-21 15:34:08 - Generalized Adversarially Learned Inference</summary>

- *Yatin Dandi, Homanga Bharadhwaj, Abhishek Kumar, Piyush Rai*

- `2006.08089v3` - [abs](http://arxiv.org/abs/2006.08089v3) - [pdf](http://arxiv.org/pdf/2006.08089v3)

> Allowing effective inference of latent vectors while training GANs can greatly increase their applicability in various downstream tasks. Recent approaches, such as ALI and BiGAN frameworks, develop methods of inference of latent variables in GANs by adversarially training an image generator along with an encoder to match two joint distributions of image and latent vector pairs. We generalize these approaches to incorporate multiple layers of feedback on reconstructions, self-supervision, and other forms of supervision based on prior or learned knowledge about the desired solutions. We achieve this by modifying the discriminator's objective to correctly identify more than two joint distributions of tuples of an arbitrary number of random variables consisting of images, latent vectors, and other variables generated through auxiliary tasks, such as reconstruction and inpainting or as outputs of suitable pre-trained models. We design a non-saturating maximization objective for the generator-encoder pair and prove that the resulting adversarial game corresponds to a global optimum that simultaneously matches all the distributions. Within our proposed framework, we introduce a novel set of techniques for providing self-supervised feedback to the model based on properties, such as patch-level correspondence and cycle consistency of reconstructions. Through comprehensive experiments, we demonstrate the efficacy, scalability, and flexibility of the proposed approach for a variety of tasks.

</details>

<details>

<summary>2020-12-23 07:47:13 - The Translucent Patch: A Physical and Universal Attack on Object Detectors</summary>

- *Alon Zolfi, Moshe Kravchik, Yuval Elovici, Asaf Shabtai*

- `2012.12528v1` - [abs](http://arxiv.org/abs/2012.12528v1) - [pdf](http://arxiv.org/pdf/2012.12528v1)

> Physical adversarial attacks against object detectors have seen increasing success in recent years. However, these attacks require direct access to the object of interest in order to apply a physical patch. Furthermore, to hide multiple objects, an adversarial patch must be applied to each object. In this paper, we propose a contactless translucent physical patch containing a carefully constructed pattern, which is placed on the camera's lens, to fool state-of-the-art object detectors. The primary goal of our patch is to hide all instances of a selected target class. In addition, the optimization method used to construct the patch aims to ensure that the detection of other (untargeted) classes remains unharmed. Therefore, in our experiments, which are conducted on state-of-the-art object detection models used in autonomous driving, we study the effect of the patch on the detection of both the selected target class and the other classes. We show that our patch was able to prevent the detection of 42.27% of all stop sign instances while maintaining high (nearly 80%) detection of the other classes.

</details>

<details>

<summary>2020-12-30 19:28:53 - MRI brain tumor segmentation and uncertainty estimation using 3D-UNet architectures</summary>

- *Laura Mora Ballestar, Veronica Vilaplana*

- `2012.15294v1` - [abs](http://arxiv.org/abs/2012.15294v1) - [pdf](http://arxiv.org/pdf/2012.15294v1)

> Automation of brain tumor segmentation in 3D magnetic resonance images (MRIs) is key to assess the diagnostic and treatment of the disease. In recent years, convolutional neural networks (CNNs) have shown improved results in the task. However, high memory consumption is still a problem in 3D-CNNs. Moreover, most methods do not include uncertainty information, which is especially critical in medical diagnosis. This work studies 3D encoder-decoder architectures trained with patch-based techniques to reduce memory consumption and decrease the effect of unbalanced data. The different trained models are then used to create an ensemble that leverages the properties of each model, thus increasing the performance. We also introduce voxel-wise uncertainty information, both epistemic and aleatoric using test-time dropout (TTD) and data-augmentation (TTA) respectively. In addition, a hybrid approach is proposed that helps increase the accuracy of the segmentation. The model and uncertainty estimation measurements proposed in this work have been used in the BraTS'20 Challenge for task 1 and 3 regarding tumor segmentation and uncertainty estimation.

</details>

