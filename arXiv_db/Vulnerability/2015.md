# 2015

## TOC

- [2015-01](#2015-01)
- [2015-02](#2015-02)
- [2015-03](#2015-03)
- [2015-04](#2015-04)
- [2015-05](#2015-05)
- [2015-06](#2015-06)
- [2015-07](#2015-07)
- [2015-08](#2015-08)
- [2015-09](#2015-09)
- [2015-10](#2015-10)
- [2015-11](#2015-11)
- [2015-12](#2015-12)

## 2015-01

<details>

<summary>2015-01-03 01:10:43 - Seeking Anonymity in an Internet Panopticon</summary>

- *Joan Feigenbaum, Bryan Ford*

- `1312.5307v3` - [abs](http://arxiv.org/abs/1312.5307v3) - [pdf](http://arxiv.org/pdf/1312.5307v3)

> Obtaining and maintaining anonymity on the Internet is challenging. The state of the art in deployed tools, such as Tor, uses onion routing (OR) to relay encrypted connections on a detour passing through randomly chosen relays scattered around the Internet. Unfortunately, OR is known to be vulnerable at least in principle to several classes of attacks for which no solution is known or believed to be forthcoming soon. Current approaches to anonymity also appear unable to offer accurate, principled measurement of the level or quality of anonymity a user might obtain.   Toward this end, we offer a high-level view of the Dissent project, the first systematic effort to build a practical anonymity system based purely on foundations that offer measurable and formally provable anonymity properties. Dissent builds on two key pre-existing primitives - verifiable shuffles and dining cryptographers - but for the first time shows how to scale such techniques to offer measurable anonymity guarantees to thousands of participants. Further, Dissent represents the first anonymity system designed from the ground up to incorporate some systematic countermeasure for each of the major classes of known vulnerabilities in existing approaches, including global traffic analysis, active attacks, and intersection attacks. Finally, because no anonymity protocol alone can address risks such as software exploits or accidental self-identification, we introduce WiNon, an experimental operating system architecture to harden the uses of anonymity tools such as Tor and Dissent against such attacks.

</details>

<details>

<summary>2015-01-08 03:56:54 - Optimizing Path ORAM for Cloud Storage Applications</summary>

- *Nathan Wolfe, Ethan Zou, Ling Ren, Xiangyao Yu*

- `1501.01721v1` - [abs](http://arxiv.org/abs/1501.01721v1) - [pdf](http://arxiv.org/pdf/1501.01721v1)

> We live in a world where our personal data are both valuable and vulnerable to misappropriation through exploitation of security vulnerabilities in online services. For instance, Dropbox, a popular cloud storage tool, has certain security flaws that can be exploited to compromise a user's data, one of which being that a user's access pattern is unprotected. We have thus created an implementation of Path Oblivious RAM (Path ORAM) for Dropbox users to obfuscate path access information to patch this vulnerability. This implementation differs significantly from the standard usage of Path ORAM, in that we introduce several innovations, including a dynamically growing and shrinking tree architecture, multi-block fetching, block packing and the possibility for multi-client use. Our optimizations together produce about a 77% throughput increase and a 60% reduction in necessary tree size; these numbers vary with file size distribution.

</details>

<details>

<summary>2015-01-08 08:08:50 - Enhance Robustness of Image-in-Image Watermarking through Data Partitioning</summary>

- *Hossein Bakhshi Golestani, Shahrokh Ghaemmaghami*

- `1501.01758v1` - [abs](http://arxiv.org/abs/1501.01758v1) - [pdf](http://arxiv.org/pdf/1501.01758v1)

> Vulnerability of watermarking schemes against intense signal processing attacks is generally a major concern, particularly when there are techniques to reproduce an acceptable copy of the original signal with no chance for detecting the watermark. In this paper, we propose a two-layer, data partitioning (DP) based, image in image watermarking method in the DCT domain to improve the watermark detection performance. Truncated singular value decomposition, binary wavelet decomposition and spatial scalability idea in H.264/SVC are analyzed and employed as partitioning methods. It is shown that the proposed scheme outperforms its two recent competitors in terms of both data payload and robustness to intense attacks.

</details>

<details>

<summary>2015-01-08 16:56:03 - Predictive Cyber-security Analytics Framework: A non-homogenous Markov model for Security Quantification</summary>

- *Subil Abraham, Suku Nair*

- `1501.01901v1` - [abs](http://arxiv.org/abs/1501.01901v1) - [pdf](http://arxiv.org/pdf/1501.01901v1)

> Numerous security metrics have been proposed in the past for protecting computer networks. However we still lack effective techniques to accurately measure the predictive security risk of an enterprise taking into account the dynamic attributes associated with vulnerabilities that can change over time. In this paper we present a stochastic security framework for obtaining quantitative measures of security using attack graphs. Our model is novel as existing research in attack graph analysis do not consider the temporal aspects associated with the vulnerabilities, such as the availability of exploits and patches which can affect the overall network security based on how the vulnerabilities are interconnected and leveraged to compromise the system. Gaining a better understanding of the relationship between vulnerabilities and their lifecycle events can provide security practitioners a better understanding of their state of security. In order to have a more realistic representation of how the security state of the network would vary over time, a nonhomogeneous model is developed which incorporates a time dependent covariate, namely the vulnerability age. The daily transition-probability matrices are estimated using Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS metric domain to analyze how the total exploitability and impact measures evolve over a time period for a given network.

</details>

<details>

<summary>2015-01-08 19:54:03 - Where Graph Topology Matters: The Robust Subgraph Problem</summary>

- *Hau Chan, Shuchu Han, Leman Akoglu*

- `1501.01939v1` - [abs](http://arxiv.org/abs/1501.01939v1) - [pdf](http://arxiv.org/pdf/1501.01939v1)

> Robustness is a critical measure of the resilience of large networked systems, such as transportation and communication networks. Most prior works focus on the global robustness of a given graph at large, e.g., by measuring its overall vulnerability to external attacks or random failures. In this paper, we turn attention to local robustness and pose a novel problem in the lines of subgraph mining: given a large graph, how can we find its most robust local subgraph (RLS)?   We define a robust subgraph as a subset of nodes with high communicability among them, and formulate the RLS-PROBLEM of finding a subgraph of given size with maximum robustness in the host graph. Our formulation is related to the recently proposed general framework for the densest subgraph problem, however differs from it substantially in that besides the number of edges in the subgraph, robustness also concerns with the placement of edges, i.e., the subgraph topology. We show that the RLS-PROBLEM is NP-hard and propose two heuristic algorithms based on top-down and bottom-up search strategies. Further, we present modifications of our algorithms to handle three practical variants of the RLS-PROBLEM. Experiments on synthetic and real-world graphs demonstrate that we find subgraphs with larger robustness than the densest subgraphs even at lower densities, suggesting that the existing approaches are not suitable for the new problem setting.

</details>

<details>

<summary>2015-01-12 11:11:10 - On Vulnerabilities of the Security Association in the IEEE 802.15.6 Standard</summary>

- *Mohsen Toorani*

- `1501.02601v1` - [abs](http://arxiv.org/abs/1501.02601v1) - [pdf](http://arxiv.org/pdf/1501.02601v1)

> Wireless Body Area Networks (WBAN) support a variety of real-time health monitoring and consumer electronics applications. The latest international standard for WBAN is the IEEE 802.15.6. The security association in this standard includes four elliptic curve-based key agreement protocols that are used for generating a master key. In this paper, we challenge the security of the IEEE 802.15.6 standard by showing vulnerabilities of those four protocols to several attacks. We perform a security analysis on the protocols, and show that they all have security problems, and are vulnerable to different attacks.

</details>

<details>

<summary>2015-01-30 06:06:37 - Prioritizing the Components of Vulnerability in a Genetic Algorithms Minimization of Flood Risk</summary>

- *Vena Pearl BoÃ±golan, Karessa Alexandra O. Baritua, Marie Junne Santos*

- `1501.07671v1` - [abs](http://arxiv.org/abs/1501.07671v1) - [pdf](http://arxiv.org/pdf/1501.07671v1)

> We compare two prioritization schemes for the components of flooding vulnerability: urbanized area ration, literacy rate, mortality rate, poverty, radio/tv penetration, non-structural measures and structural measure. We prioritize the components, giving each a weight. We then express the vulnerability function as a weighted sum of its components. This weighted sum serves as the fitness function in a genetic algorithm, which comes up with the optimal design for a flood-resistant city.

</details>


## 2015-02

<details>

<summary>2015-02-04 15:47:56 - A Predictive Framework for Cyber Security Analytics using Attack Graphs</summary>

- *Subil Abraham, Suku Nair*

- `1502.01240v1` - [abs](http://arxiv.org/abs/1502.01240v1) - [pdf](http://arxiv.org/pdf/1502.01240v1)

> Security metrics serve as a powerful tool for organizations to understand the effectiveness of protecting computer networks. However majority of these measurement techniques don't adequately help corporations to make informed risk management decisions. In this paper we present a stochastic security framework for obtaining quantitative measures of security by taking into account the dynamic attributes associated with vulnerabilities that can change over time. Our model is novel as existing research in attack graph analysis do not consider the temporal aspects associated with the vulnerabilities, such as the availability of exploits and patches which can affect the overall network security based on how the vulnerabilities are interconnected and leveraged to compromise the system. In order to have a more realistic representation of how the security state of the network would vary over time, a nonhomogeneous model is developed which incorporates a time dependent covariate, namely the vulnerability age. The daily transition-probability matrices are estimated using Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS metric domain to analyze how the total exploitability and impact measures evolve over a time period for a given network.

</details>

<details>

<summary>2015-02-12 06:50:17 - Applications of Artificial Intelligence Techniques to Combating Cyber Crimes: A Review</summary>

- *Selma Dilek, HÃ¼seyin ÃakÄ±r, Mustafa AydÄ±n*

- `1502.03552v1` - [abs](http://arxiv.org/abs/1502.03552v1) - [pdf](http://arxiv.org/pdf/1502.03552v1)

> With the advances in information technology (IT) criminals are using cyberspace to commit numerous cyber crimes. Cyber infrastructures are highly vulnerable to intrusions and other threats. Physical devices and human intervention are not sufficient for monitoring and protection of these infrastructures; hence, there is a need for more sophisticated cyber defense systems that need to be flexible, adaptable and robust, and able to detect a wide variety of threats and make intelligent real-time decisions. Numerous bio-inspired computing methods of Artificial Intelligence have been increasingly playing an important role in cyber crime detection and prevention. The purpose of this study is to present advances made so far in the field of applying AI techniques for combating cyber crimes, to demonstrate how these techniques can be an effective tool for detection and prevention of cyber attacks, as well as to give the scope for future work.

</details>

<details>

<summary>2015-02-18 12:05:00 - Determining Training Needs for Cloud Infrastructure Investigations using I-STRIDE</summary>

- *Joshua I. James, Ahmed F. Shosha, Pavel Gladyshev*

- `1502.05191v1` - [abs](http://arxiv.org/abs/1502.05191v1) - [pdf](http://arxiv.org/pdf/1502.05191v1)

> As more businesses and users adopt cloud computing services, security vulnerabilities will be increasingly found and exploited. There are many technological and political challenges where investigation of potentially criminal incidents in the cloud are concerned. Security experts, however, must still be able to acquire and analyze data in a methodical, rigorous and forensically sound manner. This work applies the STRIDE asset-based risk assessment method to cloud computing infrastructure for the purpose of identifying and assessing an organization's ability to respond to and investigate breaches in cloud computing environments. An extension to the STRIDE risk assessment model is proposed to help organizations quickly respond to incidents while ensuring acquisition and integrity of the largest amount of digital evidence possible. Further, the proposed model allows organizations to assess the needs and capacity of their incident responders before an incident occurs.

</details>

<details>

<summary>2015-02-19 00:17:13 - Distributed Inference in the Presence of Eavesdroppers: A Survey</summary>

- *Bhavya Kailkhura, V. Sriram Siddhardh Nadendla, Pramod K. Varshney*

- `1502.05448v1` - [abs](http://arxiv.org/abs/1502.05448v1) - [pdf](http://arxiv.org/pdf/1502.05448v1)

> The distributed inference framework comprises of a group of spatially distributed nodes which acquire observations about a phenomenon of interest. Due to bandwidth and energy constraints, the nodes often quantize their observations into a finite-bit local message before sending it to the fusion center (FC). Based on the local summary statistics transmitted by nodes, the FC makes a global decision about the presence of the phenomenon of interest. The distributed and broadcast nature of such systems makes them quite vulnerable to different types of attacks. This paper addresses the problem of secure communication in the presence of eavesdroppers. In particular, we focus on efficient mitigation schemes to mitigate the impact of eavesdropping. We present an overview of the distributed inference schemes under secrecy constraints and describe the currently available approaches in the context of distributed detection and estimation followed by a discussion on avenues for future research.

</details>

<details>

<summary>2015-02-23 13:37:29 - Recommendations on Future Operational Environments Command Control and Cyber Security</summary>

- *Kerim Goztepe*

- `1502.06422v1` - [abs](http://arxiv.org/abs/1502.06422v1) - [pdf](http://arxiv.org/pdf/1502.06422v1)

> It is a well-known fact that today a nation's telecommunication networks, critical infrastructure, and information systems are vulnerable to growing number of attacks in cyberspace. Cyber space contains very different problems involving various sets of threats, targets and costs. Cyber security is not only problem of banking, communication or transportation. It also threatens core systems of army as command control. Some significant recommendations on command control (C2) and cyber security have been suggested for army computing environment in this paper. This study addresses priorities of "what should be done for a better army cyber future" to cyber security researchers.

</details>

<details>

<summary>2015-02-25 10:11:44 - CrowdSurf: Empowering Informed Choices in the Web</summary>

- *Hassan Metwalley, Stefano Traverso, Marco Mellia, Stanislav Miskovic, Mario Baldi*

- `1502.07106v1` - [abs](http://arxiv.org/abs/1502.07106v1) - [pdf](http://arxiv.org/pdf/1502.07106v1)

> When surfing the Internet, individuals leak personal and corporate information to third parties whose (legitimate or not) businesses revolve around the value of collected data. The implications are serious, from a person unwillingly exposing private information to an unknown third party, to a company unable to manage the flow of its information to the outside world. The point is that individuals and companies are more and more kept out of the loop when it comes to control private data. With the goal of empowering informed choices in information leakage through the Internet, we propose CROWDSURF, a system for comprehensive and collaborative auditing of data that flows to Internet services. Similarly to open-source efforts, we enable users to contribute in building awareness and control over privacy and communication vulnerabilities. CROWDSURF provides the core infrastructure and algorithms to let individuals and enterprises regain control on the information exposed on the web. We advocate CROWDSURF as a data processing layer positioned right below HTTP in the host protocol stack. This enables the inspection of clear-text data even when HTTPS is deployed and the application of processing rules that are customizable to fit any need. Preliminary results obtained executing a prototype implementation on ISP traffic traces demonstrate the feasibility of CROWDSURF.

</details>


## 2015-03

<details>

<summary>2015-03-01 00:28:10 - Ensuring a Secure and Resilient Smart Grid: Cyber-Attacks and Countermeasures</summary>

- *Charalambos Konstantinou*

- `1502.00237v2` - [abs](http://arxiv.org/abs/1502.00237v2) - [pdf](http://arxiv.org/pdf/1502.00237v2)

> This paper surveys the latest on Smart Grid security. It focuses on the deep understanding of the risk in terms of threats, vulnerabilities and consequences that arise from cyber-attacks.

</details>

<details>

<summary>2015-03-01 22:58:28 - The Spy in the Sandbox -- Practical Cache Attacks in Javascript</summary>

- *Yossef Oren, Vasileios P. Kemerlis, Simha Sethumadhavan, Angelos D. Keromytis*

- `1502.07373v2` - [abs](http://arxiv.org/abs/1502.07373v2) - [pdf](http://arxiv.org/pdf/1502.07373v2)

> We present the first micro-architectural side-channel attack which runs entirely in the browser. In contrast to other works in this genre, this attack does not require the attacker to install any software on the victim's machine -- to facilitate the attack, the victim needs only to browse to an untrusted webpage with attacker-controlled content. This makes the attack model highly scalable and extremely relevant and practical to today's web, especially since most desktop browsers currently accessing the Internet are vulnerable to this attack. Our attack, which is an extension of the last-level cache attacks of Yarom et al., allows a remote adversary recover information belonging to other processes, other users and even other virtual machines running on the same physical host as the victim web browser. We describe the fundamentals behind our attack, evaluate its performance using a high bandwidth covert channel and finally use it to construct a system-wide mouse/network activity logger. Defending against this attack is possible, but the required countermeasures can exact an impractical cost on other benign uses of the web browser and of the computer.

</details>

<details>

<summary>2015-03-04 16:06:53 - Defending Tor from Network Adversaries: A Case Study of Network Path Prediction</summary>

- *Joshua Juen, Aaron Johnson, Anupam Das, Nikita Borisov, Matthew Caesar*

- `1410.1823v4` - [abs](http://arxiv.org/abs/1410.1823v4) - [pdf](http://arxiv.org/pdf/1410.1823v4)

> The Tor anonymity network has been shown vulnerable to traffic analysis attacks by autonomous systems and Internet exchanges, which can observe different overlay hops belonging to the same circuit. We aim to determine whether network path prediction techniques provide an accurate picture of the threat from such adversaries, and whether they can be used to avoid this threat. We perform a measurement study by running traceroutes from Tor relays to destinations around the Internet. We use the data to evaluate the accuracy of the autonomous systems and Internet exchanges that are predicted to appear on the path using state-of-the-art path inference techniques; we also consider the impact that prediction errors have on Tor security, and whether it is possible to produce a useful overestimate that does not miss important threats. Finally, we evaluate the possibility of using these predictions to actively avoid AS and IX adversaries and the challenges this creates for the design of Tor.

</details>

<details>

<summary>2015-03-13 03:05:32 - RAPTOR: Routing Attacks on Privacy in Tor</summary>

- *Yixin Sun, Anne Edmundson, Laurent Vanbever, Oscar Li, Jennifer Rexford, Mung Chiang, Prateek Mittal*

- `1503.03940v1` - [abs](http://arxiv.org/abs/1503.03940v1) - [pdf](http://arxiv.org/pdf/1503.03940v1)

> The Tor network is a widely used system for anonymous communication. However, Tor is known to be vulnerable to attackers who can observe traffic at both ends of the communication path. In this paper, we show that prior attacks are just the tip of the iceberg. We present a suite of new attacks, called Raptor, that can be launched by Autonomous Systems (ASes) to compromise user anonymity. First, AS-level adversaries can exploit the asymmetric nature of Internet routing to increase the chance of observing at least one direction of user traffic at both ends of the communication. Second, AS-level adversaries can exploit natural churn in Internet routing to lie on the BGP paths for more users over time. Third, strategic adversaries can manipulate Internet routing via BGP hijacks (to discover the users using specific Tor guard nodes) and interceptions (to perform traffic analysis). We demonstrate the feasibility of Raptor attacks by analyzing historical BGP data and Traceroute data as well as performing real-world attacks on the live Tor network, while ensuring that we do not harm real users. In addition, we outline the design of two monitoring frameworks to counter these attacks: BGP monitoring to detect control-plane attacks, and Traceroute monitoring to detect data-plane anomalies. Overall, our work motivates the design of anonymity systems that are aware of the dynamics of Internet routing.

</details>

<details>

<summary>2015-03-13 13:55:20 - Optimal redundancy against disjoint vulnerabilities in networks</summary>

- *Sebastian M. Krause, Michael M. Danziger, Vinko ZlatiÄ*

- `1503.04058v1` - [abs](http://arxiv.org/abs/1503.04058v1) - [pdf](http://arxiv.org/pdf/1503.04058v1)

> Redundancy is commonly used to guarantee continued functionality in networked systems. However, often many nodes are vulnerable to the same failure or adversary. A "backup" path is not sufficient if both paths depend on nodes which share a vulnerability.For example, if two nodes of the Internet cannot be connected without using routers belonging to a given untrusted entity, then all of their communication-regardless of the specific paths utilized-will be intercepted by the controlling entity.In this and many other cases, the vulnerabilities affecting the network are disjoint: each node has exactly one vulnerability but the same vulnerability can affect many nodes. To discover optimal redundancy in this scenario, we describe each vulnerability as a color and develop a "color-avoiding percolation" which uncovers a hidden color-avoiding connectivity. We present algorithms for color-avoiding percolation of general networks and an analytic theory for random graphs with uniformly distributed colors including critical phenomena. We demonstrate our theory by uncovering the hidden color-avoiding connectivity of the Internet. We find that less well-connected countries are more likely able to communicate securely through optimally redundant paths than highly connected countries like the US. Our results reveal a new layer of hidden structure in complex systems and can enhance security and robustness through optimal redundancy in a wide range of systems including biological, economic and communications networks.

</details>

<details>

<summary>2015-03-16 17:03:30 - Skilled Impostor Attacks Against Fingerprint Verification Systems And Its Remedy</summary>

- *Carsten Gottschlich*

- `1503.04729v1` - [abs](http://arxiv.org/abs/1503.04729v1) - [pdf](http://arxiv.org/pdf/1503.04729v1)

> Fingerprint verification systems are becoming ubiquitous in everyday life. This trend is propelled especially by the proliferation of mobile devices with fingerprint sensors such as smartphones and tablet computers, and fingerprint verification is increasingly applied for authenticating financial transactions. In this study we describe a novel attack vector against fingerprint verification systems which we coin skilled impostor attack. We show that existing protocols for performance evaluation of fingerprint verification systems are flawed and as a consequence of this, the system's real vulnerability is systematically underestimated. We examine a scenario in which a fingerprint verification system is tuned to operate at false acceptance rate of 0.1% using the traditional verification protocols with random impostors (zero-effort attacks). We demonstrate that an active and intelligent attacker can achieve a chance of success in the area of 89% or more against this system by performing skilled impostor attacks. We describe a new protocol for evaluating fingerprint verification performance in order to improve the assessment of potential and limitations of fingerprint recognition systems. This new evaluation protocol enables a more informed decision concerning the operating threshold in practical applications and the respective trade-off between security (low false acceptance rates) and usability (low false rejection rates). The skilled impostor attack is a general attack concept which is independent of specific databases or comparison algorithms. The proposed protocol relying on skilled impostor attacks can directly be applied for evaluating the verification performance of other biometric modalities such as e.g. iris, face, ear, finger vein, gait or speaker recognition.

</details>

<details>

<summary>2015-03-20 20:19:16 - Explaining and Harnessing Adversarial Examples</summary>

- *Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy*

- `1412.6572v3` - [abs](http://arxiv.org/abs/1412.6572v3) - [pdf](http://arxiv.org/pdf/1412.6572v3)

> Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.

</details>


## 2015-04

<details>

<summary>2015-04-01 12:32:18 - Analyzing the BrowserID SSO System with Primary Identity Providers Using an Expressive Model of the Web</summary>

- *Daniel Fett, Ralf Kuesters, Guido Schmitz*

- `1411.7210v2` - [abs](http://arxiv.org/abs/1411.7210v2) - [pdf](http://arxiv.org/pdf/1411.7210v2)

> BrowserID is a complex, real-world Single Sign-On (SSO) System for web applications recently developed by Mozilla. It employs new HTML5 features (such as web messaging and web storage) and cryptographic assertions to provide decentralized login, with the intent to respect users' privacy. It can operate in a primary and a secondary identity provider mode. While in the primary mode BrowserID runs with arbitrary identity providers (IdPs), in the secondary mode there is one IdP only, namely Mozilla's default IdP.   We recently proposed an expressive general model for the web infrastructure and, based on this web model, analyzed the security of the secondary IdP mode of BrowserID. The analysis revealed several severe vulnerabilities.   In this paper, we complement our prior work by analyzing the even more complex primary IdP mode of BrowserID. We do not only study authentication properties as before, but also privacy properties. During our analysis we discovered new and practical attacks that do not apply to the secondary mode: an identity injection attack, which violates a central authentication property of SSO systems, and attacks that break an important privacy promise of BrowserID and which do not seem to be fixable without a major redesign of the system. Some of our attacks on privacy make use of a browser side channel that has not gained a lot of attention so far.   For the authentication bug, we propose a fix and formally prove in a slight extension of our general web model that the fixed system satisfies all the requirements we consider. This constitutes the most complex formal analysis of a web application based on an expressive model of the web infrastructure so far.   As another contribution, we identify and prove important security properties of generic web features in the extended web model to facilitate future analysis efforts of web standards and web applications.

</details>

<details>

<summary>2015-04-03 21:27:03 - Penetration Testing in Agile Software Development Projects</summary>

- *Martin Tomanek, Tomas Klima*

- `1504.00942v1` - [abs](http://arxiv.org/abs/1504.00942v1) - [pdf](http://arxiv.org/pdf/1504.00942v1)

> Agile development methods are commonly used to iteratively develop the information systems and they can easily handle ever-changing business requirements. Scrum is one of the most popular agile software development frameworks. The popularity is caused by the simplified process framework and its focus on teamwork. The objective of Scrum is to deliver working software and demonstrate it to the customer faster and more frequent during the software development project. However the security requirements for the developing information systems have often a low priority. This requirements prioritization issue results in the situations where the solution meets all the business requirements but it is vulnerable to potential security threats.   The major benefit of the Scrum framework is the iterative development approach and the opportunity to automate penetration tests. Therefore the security vulnerabilities can be discovered and solved more often which will positively contribute to the overall information system protection against potential hackers. In this research paper the authors propose how the agile software development framework Scrum can be enriched by considering the penetration tests and related security requirements during the software development lifecycle. Authors apply in this paper the knowledge and expertise from their previous work focused on development of the new information system penetration tests methodology PETA with focus on using COBIT 4.1 as the framework for management of these tests, and on previous work focused on tailoring the project management framework PRINCE2 with Scrum.

</details>

<details>

<summary>2015-04-06 02:04:30 - Byzantine Attack and Defense in Cognitive Radio Networks: A Survey</summary>

- *Linyuan Zhang, Guoru Ding, Qihui Wu, Yulong Zou, Zhu Han, Jinlong Wang*

- `1504.01185v1` - [abs](http://arxiv.org/abs/1504.01185v1) - [pdf](http://arxiv.org/pdf/1504.01185v1)

> The Byzantine attack in cooperative spectrum sensing (CSS), also known as the spectrum sensing data falsification (SSDF) attack in the literature, is one of the key adversaries to the success of cognitive radio networks (CRNs). In the past couple of years, the research on the Byzantine attack and defense strategies has gained worldwide increasing attention. In this paper, we provide a comprehensive survey and tutorial on the recent advances in the Byzantine attack and defense for CSS in CRNs. Specifically, we first briefly present the preliminaries of CSS for general readers, including signal detection techniques, hypothesis testing, and data fusion. Second, we analyze the spear and shield relation between Byzantine attack and defense from three aspects: the vulnerability of CSS to attack, the obstacles in CSS to defense, and the games between attack and defense. Then, we propose a taxonomy of the existing Byzantine attack behaviors and elaborate on the corresponding attack parameters, which determine where, who, how, and when to launch attacks. Next, from the perspectives of homogeneous or heterogeneous scenarios, we classify the existing defense algorithms, and provide an in-depth tutorial on the state-of-the-art Byzantine defense schemes, commonly known as robust or secure CSS in the literature. Furthermore, we highlight the unsolved research challenges and depict the future research directions.

</details>

<details>

<summary>2015-04-06 19:10:03 - A Survey of P2P Network Security</summary>

- *Logan Washbourne*

- `1504.01358v1` - [abs](http://arxiv.org/abs/1504.01358v1) - [pdf](http://arxiv.org/pdf/1504.01358v1)

> This paper presents a review of peer-to-peer network security. Popular for sharing of multimedia files, these networks carry risks and vulnerabilities relating to data integrity, spyware, adware, and unwanted files. Further attacks include those of forgery, pollution, repudiation, membership and Eclipse attacks, neighbor selection attacks, Sybil, DoS, and omission attacks. We review some protection mechanisms that have been devised.

</details>

<details>

<summary>2015-04-09 13:03:28 - ROPocop - Dynamic Mitigation of Code-Reuse Attacks</summary>

- *Andreas Follner, Eric Bodden*

- `1504.02288v1` - [abs](http://arxiv.org/abs/1504.02288v1) - [pdf](http://arxiv.org/pdf/1504.02288v1)

> Control-flow attacks, usually achieved by exploiting a buffer-overflow vulnerability, have been a serious threat to system security for over fifteen years. Researchers have answered the threat with various mitigation techniques, but nevertheless, new exploits that successfully bypass these technologies still appear on a regular basis.   In this paper, we propose ROPocop, a novel approach for detecting and preventing the execution of injected code and for mitigating code-reuse attacks such as return-oriented programming (RoP). ROPocop uses dynamic binary instrumentation, requiring neither access to source code nor debug symbols or changes to the operating system. It mitigates attacks by both monitoring the program counter at potentially dangerous points and by detecting suspicious program flows.   We have implemented ROPocop for Windows x86 using PIN, a dynamic program instrumentation framework from Intel. Benchmarks using the SPEC CPU2006 suite show an average overhead of 2.4x, which is comparable to similar approaches, which give weaker guarantees. Real-world applications show only an initially noticeable input lag and no stutter. In our evaluation our tool successfully detected all 11 of the latest real-world code-reuse exploits, with no false alarms. Therefore, despite the overhead, it is a viable, temporary solution to secure critical systems against exploits if a vendor patch is not yet available.

</details>

<details>

<summary>2015-04-14 20:42:35 - On the Requirements of New Software Development</summary>

- *Vincenzo De Florio, Chris Blondia*

- `1504.03715v1` - [abs](http://arxiv.org/abs/1504.03715v1) - [pdf](http://arxiv.org/pdf/1504.03715v1)

> Changes, they use to say, are the only constant in life. Everything changes rapidly around us, and more and more key to survival is the ability to rapidly adapt to changes. This consideration applies to many aspects of our lives. Strangely enough, this nearly self-evident truth is not always considered by software engineers with the seriousness that it calls for: The assumptions we draw for our systems often do not take into due account that e.g., the run-time environments, the operational conditions, or the available resources will vary. Software is especially vulnerable to this threat, and with today's software-dominated systems controlling crucial services in nuclear plants, airborne equipments, health care systems and so forth, it becomes clear how this situation may potentially lead to catastrophes. This paper discusses this problem and defines some of the requirements towards its effective solution, which we call "New Software Development" as a software equivalent of the well-known concept of New Product Development. The paper also introduces and discusses a practical example of a software tool designed taking those requirements into account --- an adaptive data integrity provision in which the degree of redundancy is not fixed once and for all at design time, but rather it changes dynamically with respect to the disturbances experienced during the run time.

</details>

<details>

<summary>2015-04-16 17:26:24 - Towards a relation extraction framework for cyber-security concepts</summary>

- *Corinne L. Jones, Robert A. Bridges, Kelly Huffer, John Goodall*

- `1504.04317v1` - [abs](http://arxiv.org/abs/1504.04317v1) - [pdf](http://arxiv.org/pdf/1504.04317v1)

> In order to assist security analysts in obtaining information pertaining to their network, such as novel vulnerabilities, exploits, or patches, information retrieval methods tailored to the security domain are needed. As labeled text data is scarce and expensive, we follow developments in semi-supervised Natural Language Processing and implement a bootstrapping algorithm for extracting security entities and their relationships from text. The algorithm requires little input data, specifically, a few relations or patterns (heuristics for identifying relations), and incorporates an active learning component which queries the user on the most important decisions to prevent drifting from the desired relations. Preliminary testing on a small corpus shows promising results, obtaining precision of .82.

</details>

<details>

<summary>2015-04-20 10:53:45 - Non-Uniform Robust Network Design in Planar Graphs</summary>

- *David Adjiashvili*

- `1504.05009v1` - [abs](http://arxiv.org/abs/1504.05009v1) - [pdf](http://arxiv.org/pdf/1504.05009v1)

> Robust optimization is concerned with constructing solutions that remain feasible also when a limited number of resources is removed from the solution. Most studies of robust combinatorial optimization to date made the assumption that every resource is equally vulnerable, and that the set of scenarios is implicitly given by a single budget constraint. This paper studies a robustness model of a different kind. We focus on \textbf{bulk-robustness}, a model recently introduced~\cite{bulk} for addressing the need to model non-uniform failure patterns in systems.   We significantly extend the techniques used in~\cite{bulk} to design approximation algorithm for bulk-robust network design problems in planar graphs. Our techniques use an augmentation framework, combined with linear programming (LP) rounding that depends on a planar embedding of the input graph. A connection to cut covering problems and the dominating set problem in circle graphs is established. Our methods use few of the specifics of bulk-robust optimization, hence it is conceivable that they can be adapted to solve other robust network design problems.

</details>

<details>

<summary>2015-04-20 15:15:26 - The Abandoned Side of the Internet: Hijacking Internet Resources When Domain Names Expire</summary>

- *Johann Schlamp, Josef Gustafsson, Matthias WÃ¤hlisch, Thomas C. Schmidt, Georg Carle*

- `1412.5052v2` - [abs](http://arxiv.org/abs/1412.5052v2) - [pdf](http://arxiv.org/pdf/1412.5052v2)

> The vulnerability of the Internet has been demonstrated by prominent IP prefix hijacking events. Major outages such as the China Telecom incident in 2010 stimulate speculations about malicious intentions behind such anomalies. Surprisingly, almost all discussions in the current literature assume that hijacking incidents are enabled by the lack of security mechanisms in the inter-domain routing protocol BGP. In this paper, we discuss an attacker model that accounts for the hijacking of network ownership information stored in Regional Internet Registry (RIR) databases. We show that such threats emerge from abandoned Internet resources (e.g., IP address blocks, AS numbers). When DNS names expire, attackers gain the opportunity to take resource ownership by re-registering domain names that are referenced by corresponding RIR database objects. We argue that this kind of attack is more attractive than conventional hijacking, since the attacker can act in full anonymity on behalf of a victim. Despite corresponding incidents have been observed in the past, current detection techniques are not qualified to deal with these attacks. We show that they are feasible with very little effort, and analyze the risk potential of abandoned Internet resources for the European service region: our findings reveal that currently 73 /24 IP prefixes and 7 ASes are vulnerable to be stealthily abused. We discuss countermeasures and outline research directions towards preventive solutions.

</details>

<details>

<summary>2015-04-21 11:35:07 - Impact assessment for vulnerabilities in open-source software libraries</summary>

- *Henrik Plate, Serena Elisa Ponta, Antonino Sabetta*

- `1504.04971v2` - [abs](http://arxiv.org/abs/1504.04971v2) - [pdf](http://arxiv.org/pdf/1504.04971v2)

> Software applications integrate more and more open-source software (OSS) to benefit from code reuse. As a drawback, each vulnerability discovered in bundled OSS potentially affects the application. Upon the disclosure of every new vulnerability, the application vendor has to decide whether it is exploitable in his particular usage context, hence, whether users require an urgent application patch containing a non-vulnerable version of the OSS. Current decision making is mostly based on high-level vulnerability descriptions and expert knowledge, thus, effort intense and error prone. This paper proposes a pragmatic approach to facilitate the impact assessment, describes a proof-of-concept for Java, and examines one example vulnerability as case study. The approach is independent from specific kinds of vulnerabilities or programming languages and can deliver immediate results.

</details>

<details>

<summary>2015-04-22 20:02:04 - Finding Tizen security bugs through whole-system static analysis</summary>

- *Daniel Song, Jisheng Zhao, Michael Burke, DragoÅ SbÃ®rlea, Dan Wallach, Vivek Sarkar*

- `1504.05967v1` - [abs](http://arxiv.org/abs/1504.05967v1) - [pdf](http://arxiv.org/pdf/1504.05967v1)

> Tizen is a new Linux-based open source platform for consumer devices including smartphones, televisions, vehicles, and wearables. While Tizen provides kernel-level mandatory policy enforcement, it has a large collection of libraries, implemented in a mix of C and C++, which make their own security checks. In this research, we describe the design and engineering of a static analysis engine which drives a full information flow analysis for apps and a control flow analysis for the full library stack. We implemented these static analyses as extensions to LLVM, requiring us to improve LLVM's native analysis features to get greater precision and scalability, including knotty issues like the coexistence of C++ inheritance with C function pointer use. With our tools, we found several unexpected behaviors in the Tizen system, including paths through the system libraries that did not have inline security checks. We show how our tools can help the Tizen app store to verify important app properties as well as helping the Tizen development process avoid the accidental introduction of subtle vulnerabilities.

</details>

<details>

<summary>2015-04-26 03:50:07 - Spy vs. Spy: Rumor Source Obfuscation</summary>

- *Giulia Fanti, Peter Kairouz, Sewoong Oh, Pramod Viswanath*

- `1412.8439v3` - [abs](http://arxiv.org/abs/1412.8439v3) - [pdf](http://arxiv.org/pdf/1412.8439v3)

> Anonymous messaging platforms, such as Secret and Whisper, have emerged as important social media for sharing one's thoughts without the fear of being judged by friends, family, or the public. Further, such anonymous platforms are crucial in nations with authoritarian governments; the right to free expression and sometimes the personal safety of the author of the message depend on anonymity. Whether for fear of judgment or personal endangerment, it is crucial to keep anonymous the identity of the user who initially posted a sensitive message. In this paper, we consider an adversary who observes a snapshot of the spread of a message at a certain time. Recent advances in rumor source detection shows that the existing messaging protocols are vulnerable against such an adversary. We introduce a novel messaging protocol, which we call adaptive diffusion, and show that it spreads the messages fast and achieves a perfect obfuscation of the source when the underlying contact network is an infinite regular tree: all users with the message are nearly equally likely to have been the origin of the message. Experiments on a sampled Facebook network show that it effectively hides the location of the source even when the graph is finite, irregular and has cycles. We further consider a stronger adversarial model where a subset of colluding users track the reception of messages. We show that the adaptive diffusion provides a strong protection of the anonymity of the source even under this scenario.

</details>

<details>

<summary>2015-04-30 00:42:18 - A Case Study on Quality Attribute Measurement using MARF and GIPSY</summary>

- *Masoud Bozorgi, Rohan Nayak, Arslan Zaffar, Mohammad Iftekharul Hoque, Saad Anwer Ghouri, Harmeet Singh, Parminder Singh Kalshan*

- `1505.00005v1` - [abs](http://arxiv.org/abs/1505.00005v1) - [pdf](http://arxiv.org/pdf/1505.00005v1)

> This literature focuses on doing a comparative analysis between Modular Audio Recognition Framework (MARF) and the General Intentional Programming System (GIPSY) with the help of different software metrics. At first, we understand the general principles, architecture and working of MARF and GIPSY by looking at their frameworks and running them in the Eclipse environment. Then, we study some of the important metrics including a few state of the art metrics and rank them in terms of their usefulness and their influence on the different quality attributes of a software. The quality attributes are viewed and computed with the help of the Logiscope and McCabe IQ tools. These tools perform a comprehensive analysis on the case studies and generate a quality report at the factor level, criteria level and metrics level. In next step, we identify the worst code at each of these levels, extract the worst code and provide recommendations to improve the quality. We implement and test some of the metrics which are ranked as the most useful metrics with a set of test cases in JDeodorant. Finally, we perform an analysis on both MARF and GIPSY by doing a fuzzy code scan using MARFCAT to find the list of weak and vulnerable classes.

</details>


## 2015-05

<details>

<summary>2015-05-04 10:50:26 - Danger is My Middle Name: Experimenting with SSL Vulnerabilities in Android Apps</summary>

- *Lucky Onwuzurike, Emiliano De Cristofaro*

- `1505.00589v1` - [abs](http://arxiv.org/abs/1505.00589v1) - [pdf](http://arxiv.org/pdf/1505.00589v1)

> This paper presents a measurement study of information leakage and SSL vulnerabilities in popular Android apps. We perform static and dynamic analysis on 100 apps, downloaded at least 10M times, that request full network access. Our experiments show that, although prior work has drawn a lot of attention to SSL implementations on mobile platforms, several popular apps (32/100) accept all certificates and all hostnames, and four actually transmit sensitive data unencrypted. We set up an experimental testbed simulating man-in-the-middle attacks and find that many apps (up to 91% when the adversary has a certificate installed on the victim's device) are vulnerable, allowing the attacker to access sensitive information, including credentials, files, personal details, and credit card numbers. Finally, we provide a few recommendations to app developers and highlight several open research problems.

</details>

<details>

<summary>2015-05-07 20:24:14 - Multiplayer Games and their Need for Scalable and Secure State Management</summary>

- *Zakaria Alomari*

- `1505.01864v1` - [abs](http://arxiv.org/abs/1505.01864v1) - [pdf](http://arxiv.org/pdf/1505.01864v1)

> In recent years, massively multiplayer online games (MMOGs) have become very popular by providing more entertainment, therefore millions of players now participate may interact with each other in a shared environment, even though these players may be separated by huge geographic distances. Peer to Peer (P2P) architectures become very popular in MMOG recently, due to their distributed and collaborative nature, have low infrastructure costs, achieve fast response times by creating direct connections between players and can achieve high scalability. However, P2P architectures face many challenges and tend to be vulnerable to cheating. Game distribution between peers makes maintaining control of the game becomes more complicated. Therefore, broadcasting all state changes to every player is not a viable solution to maintain a consistent game state in a MMOGs. To successfully overcome the challenge of scale, MMOGs have to employ sophisticated interest management techniques that only send relevant state changes to each player. In this paper, In order to prevent cheaters to gain unfair advantages in P2P-based MMOGs, several cheat-proof schemes have been proposed that utilize a range of techniques such as cryptographic mechanisms, Commitment and agreement protocols, and proxy architecture.

</details>

<details>

<summary>2015-05-12 08:42:28 - Factors Influencing the Adoption of Cloud Incident Handling Strategy: A Preliminary Study in Malaysia</summary>

- *Nurul Hidayah Ab Rahman, Kim-Kwang Raymond Choo*

- `1505.02908v1` - [abs](http://arxiv.org/abs/1505.02908v1) - [pdf](http://arxiv.org/pdf/1505.02908v1)

> This study seeks to understand the factors influencing the adoption of an incident handling strategy by organisational cloud service users. We propose a conceptual model that draws upon the Situation Awareness (SA) model and Protection Motivation Theory (PMT) to guide this research. 40 organisational cloud service users in Malaysia were surveyed. We also conduct face-to-face interviews with participants from four of the organisations. Findings from the study indicate that four PMT factors (Perceived Vulnerability, Self-Efficacy, Response Efficacy, and Perceived Severity) have a significantly influence on the adoption of cloud incident handling strategy within the organisations. We, therefore, suggest a successful adoption cloud incident handling strategy by organisational cloud service users involves the nexus between these four PMT factors. We also outline future research required to validate the model.

</details>

<details>

<summary>2015-05-12 13:16:51 - A Survey on Detection of Sinkhole Attack in Wireless Sensor Network</summary>

- *George W. Kibirige, Camilius Sanga*

- `1505.01941v2` - [abs](http://arxiv.org/abs/1505.01941v2) - [pdf](http://arxiv.org/pdf/1505.01941v2)

> Wireless Sensor Network (WSN) consists of large number of low-cost, resource-constrained sensor nodes. The constraints of the wireless sensor node is their characteristics which include low memory, low computation power, they are deployed in hostile area and left unattended, small range of communication capability and low energy capabilities. Base on those characteristics makes this network vulnerable to several attacks, such as sinkhole attack. Sinkhole attack is a type of attack were compromised node tries to attract network traffic by advertise its fake routing update. One of the impacts of sinkhole attack is that, it can be used to launch other attacks like selective forwarding attack, acknowledge spoofing attack and drops or altered routing information. It can also used to send bogus information to base station. This paper is focus on exploring and analyzing the existing solutions which used to detect and identify sinkhole attack in wireless sensor network. The analysis is based on advantages and limitation of the proposed solutions.

</details>

<details>

<summary>2015-05-17 20:04:20 - Device-independent quantum key distribution based on measurement inputs</summary>

- *Ramij Rahaman, Matthew G. Parker, Piotr Mironowicz, Marcin PawÅowski*

- `1308.6447v3` - [abs](http://arxiv.org/abs/1308.6447v3) - [pdf](http://arxiv.org/pdf/1308.6447v3)

> We provide an analysis of a new family of device independent quantum key distribution (QKD) protocols with several novel features: (a) The bits used for the secret key do not come from the results of the measurements on an entangled state but from the choices of settings; (b) Instead of a single security parameter (a violation of some Bell inequality) a set of them is used to estimate the level of trust in the secrecy of the key. The main advantage of these protocols is a smaller vulnerability to imperfect random number generators made possible by feature (a). We prove the security and the robustness of such protocols. We show that using our method it is possible to construct a QKD protocol which retains its security even if the source of randomness used by communicating parties is strongly biased. As a proof of principle, an explicit example of a protocol based on the Hardy's paradox is presented. Moreover, in the noiseless case, the protocol is secure in a natural way against any type of memory attack, and thus allows to reuse the device in subsequent rounds. We also analyse the robustness of the protocol using semi-definite programming methods. Finally, we present a post-processing method, and observe a paradoxical property that rejecting some random part of the private data can increase the key rate of the protocol.

</details>

<details>

<summary>2015-05-18 10:18:45 - Synthesising Interprocedural Bit-Precise Termination Proofs (extended version)</summary>

- *Hong-Yi Chen, Cristina David, Daniel Kroening, Peter Schrammel, BjÃ¶rn Wachter*

- `1505.04581v1` - [abs](http://arxiv.org/abs/1505.04581v1) - [pdf](http://arxiv.org/pdf/1505.04581v1)

> Proving program termination is key to guaranteeing absence of undesirable behaviour, such as hanging programs and even security vulnerabilities such as denial-of-service attacks. To make termination checks scale to large systems, interprocedural termination analysis seems essential, which is a largely unexplored area of research in termination analysis, where most effort has focussed on difficult single-procedure problems. We present a modular termination analysis for C programs using template-based interprocedural summarisation. Our analysis combines a context-sensitive, over-approximating forward analysis with the inference of under-approximating preconditions for termination. Bit-precise termination arguments are synthesised over lexicographic linear ranking function templates. Our experimental results show that our tool 2LS outperforms state-of-the-art alternatives, and demonstrate the clear advantage of interprocedural reasoning over monolithic analysis in terms of efficiency, while retaining comparable precision.

</details>

<details>

<summary>2015-05-26 07:50:43 - Unauthorized Cross-App Resource Access on MAC OS X and iOS</summary>

- *Luyi Xing, Xiaolong Bai, Tongxin Li, XiaoFeng Wang, Kai Chen, Xiaojing Liao, Shi-Min Hu, Xinhui Han*

- `1505.06836v1` - [abs](http://arxiv.org/abs/1505.06836v1) - [pdf](http://arxiv.org/pdf/1505.06836v1)

> On modern operating systems, applications under the same user are separated from each other, for the purpose of protecting them against malware and compromised programs. Given the complexity of today's OSes, less clear is whether such isolation is effective against different kind of cross-app resource access attacks (called XARA in our research). To better understand the problem, on the less-studied Apple platforms, we conducted a systematic security analysis on MAC OS~X and iOS. Our research leads to the discovery of a series of high-impact security weaknesses, which enable a sandboxed malicious app, approved by the Apple Stores, to gain unauthorized access to other apps' sensitive data. More specifically, we found that the inter-app interaction services, including the keychain, WebSocket and NSConnection on OS~X and URL Scheme on the MAC OS and iOS, can all be exploited by the malware to steal such confidential information as the passwords for iCloud, email and bank, and the secret token of Evernote. Further, the design of the app sandbox on OS~X was found to be vulnerable, exposing an app's private directory to the sandboxed malware that hijacks its Apple Bundle ID. As a result, sensitive user data, like the notes and user contacts under Evernote and photos under WeChat, have all been disclosed. Fundamentally, these problems are caused by the lack of app-to-app and app-to-OS authentications. To better understand their impacts, we developed a scanner that automatically analyzes the binaries of MAC OS and iOS apps to determine whether proper protection is missing in their code. Running it on hundreds of binaries, we confirmed the pervasiveness of the weaknesses among high-impact Apple apps. Since the issues may not be easily fixed, we built a simple program that detects exploit attempts on OS~X, helping protect vulnerable apps before the problems can be fully addressed.

</details>


## 2015-06

<details>

<summary>2015-06-04 22:12:31 - CloRoFor: Cloud Robust Forensics</summary>

- *Roberto Battistoni, Roberto Di Pietro, Flavio Lombardi*

- `1506.01739v1` - [abs](http://arxiv.org/abs/1506.01739v1) - [pdf](http://arxiv.org/pdf/1506.01739v1)

> The malicious alteration of machine time is a big challenge in computer forensics. Detecting such changes and reconstructing the actual timeline of events is of paramount importance. However, this can be difficult since the attacker has many opportunities and means to hide such changes. In particular, cloud computing, host and guest machine time can be manipulated in various ways by an attacker. Guest virtual machines are especially vulnerable to attacks coming from their (more privileged) host. As such, it is important to guarantee the timeline integrity of both hosts and guests in a cloud, or at least to ensure that the alteration of such timeline does not go undetected. In this paper we survey the issues related to host and guest machine time integrity in the cloud. Further, we describe a novel architecture for host and guest time alteration detection and correction/resilience with respect to compromised hosts and guests. The proposed framework has been implemented on an especially built simulator. Collected results are evaluated and discussed. Performance figures show the feasibility of our proposal.

</details>

<details>

<summary>2015-06-05 19:17:31 - The New South Wales iVote System: Security Failures and Verification Flaws in a Live Online Election</summary>

- *J. Alex Halderman, Vanessa Teague*

- `1504.05646v2` - [abs](http://arxiv.org/abs/1504.05646v2) - [pdf](http://arxiv.org/pdf/1504.05646v2)

> In the world's largest-ever deployment of online voting, the iVote Internet voting system was trusted for the return of 280,000 ballots in the 2015 state election in New South Wales, Australia. During the election, we performed an independent security analysis of parts of the live iVote system and uncovered severe vulnerabilities that could be leveraged to manipulate votes, violate ballot privacy, and subvert the verification mechanism. These vulnerabilities do not seem to have been detected by the election authorities before we disclosed them, despite a pre-election security review and despite the system having run in a live state election for five days. One vulnerability, the result of including analytics software from an insecure external server, exposed some votes to complete compromise of privacy and integrity. At least one parliamentary seat was decided by a margin much smaller than the number of votes taken while the system was vulnerable. We also found protocol flaws, including vote verification that was itself susceptible to manipulation. This incident underscores the difficulty of conducting secure elections online and carries lessons for voters, election officials, and the e-voting research community.

</details>

<details>

<summary>2015-06-10 14:30:21 - BREW: A Breakable Web Application for IT-Security Classroom Use</summary>

- *Christoph Pohl, Kathrin Schlierkamp, Hans-Joachim Hof*

- `1506.03325v1` - [abs](http://arxiv.org/abs/1506.03325v1) - [pdf](http://arxiv.org/pdf/1506.03325v1)

> This paper presents BREW (Breakable Web Application), a tool for teaching IT Security. BREWs main teaching targets are identification and exploitation of vulnerabilities, using technologies and methodologies for software auditing and testing, and bug detection, fixation, and writing of secure code. Main advantages of BREW include that it is easy to apply in practice, it is a perfect tool to create and retain motivation, it corresponds to the demands of the psychology of learning, and it can be used for a heterogeneous group of students. BREW has been success- fully used for teaching IT Security in Germany as well as on an Erasmus Project with international student groups.

</details>

<details>

<summary>2015-06-11 18:51:40 - Vulnerability Analysis and Consequences of False Data Injection Attack on Power System State Estimation</summary>

- *Jingwen Liang, Lalitha Sankar, Oliver Kosut*

- `1506.03774v1` - [abs](http://arxiv.org/abs/1506.03774v1) - [pdf](http://arxiv.org/pdf/1506.03774v1)

> An unobservable false data injection (FDI) attack on AC state estimation (SE) is introduced and its consequences on the physical system are studied. With a focus on understanding the physical consequences of FDI attacks, a bi-level optimization problem is introduced whose objective is to maximize the physical line flows subsequent to an FDI attack on DC SE. The maximization is subject to constraints on both attacker resources (size of attack) and attack detection (limiting load shifts) as well as those required by DC optimal power flow (OPF) following SE. The resulting attacks are tested on a more realistic non-linear system model using AC state estimation and ACOPF, and it is shown that, with an appropriately chosen sub-network, the attacker can overload transmission lines with moderate shifts of load.

</details>

<details>

<summary>2015-06-11 20:44:15 - Ciberseguridad Inteligente</summary>

- *Juan Manuel R. Mosso*

- `1506.03830v1` - [abs](http://arxiv.org/abs/1506.03830v1) - [pdf](http://arxiv.org/pdf/1506.03830v1)

> The Internet Economy has a strong dependency on cyberspace. This raises security risk scenarios due to the increasing number of vulnerabilities and the increased frequency and sophistication of cyber attacks, especially with the advent of advanced threats of APT type. This paper presents a model of Intelligent Cybersecurity (ICS) for detect, deny, disrupt, degrade, deceive and destroy enemy capabilities in cyberspace. This is achieved through the conceptual and technical development of a Capacity for Cyber Intelligence (CCI) which aims to interfere destructively C2 capabilities of the adversary, penetrating its decision loops with the speed necessary to displace him to a reactive posture. Finally, unlike the security models raised classically, the concept of ICSI suggests that the advantage in the conflict can be obtained by defense and not always by the attacker. As theoretical support, the "Offensive System Reference Model" (OSRM) is presented, which is used to think cyber conflict at all levels, from a perspective coordinated and synchronized with the rest of the traditional forces under the present set; and a justification of the capacity from the modern perspective C2.

</details>

<details>

<summary>2015-06-11 21:37:58 - The Meaning of Attack-Resistant Systems</summary>

- *Vijay Ganesh, Sebastian Banescu, MartÃ­n Ochoa*

- `1502.04023v3` - [abs](http://arxiv.org/abs/1502.04023v3) - [pdf](http://arxiv.org/pdf/1502.04023v3)

> In this paper, we introduce a formal notion of partial compliance, called Attack-resistance, of a computer program running together with a defense mechanism w.r.t a non-exploitability specification. In our setting, a program may contain exploitable vulnerabilities, such as buffer overflows, but appropriate defense mechanisms built into the program or the operating system render such vulnerabilities hard to exploit by certain attackers, usually relying on the strength of the randomness of a probabilistic transformation of the environment or the program and some knowledge on the attacker's goals and attack strategy. We are motivated by the reality that most large-scale programs have vulnerabilities despite our best efforts to get rid of them. Security researchers have responded to this state of affairs by coming up with ingenious defense mechanisms such as address space layout randomization (ASLR) or instruction set randomization (ISR) that provide some protection against exploitation. However, implementations of such mechanism have been often shown to be insecure, even against the attacks they were designed to prevent. By formalizing this notion of attack-resistance we pave the way towards addressing the questions: "How do we formally analyze defense mechanisms? Is there a mathematical way of distinguishing effective defense mechanisms from ineffective ones? Can we quantify and show that these defense mechanisms provide formal security guarantees, albeit partial, even in the presence of exploitable vulnerabilities?". To illustrate our approach we discuss under which circumstances ISR implementations comply with the Attack-resistance definition.

</details>

<details>

<summary>2015-06-12 18:48:50 - Breaking Bad: Detecting malicious domains using word segmentation</summary>

- *Wei Wang, Kenneth Shirley*

- `1506.04111v1` - [abs](http://arxiv.org/abs/1506.04111v1) - [pdf](http://arxiv.org/pdf/1506.04111v1)

> In recent years, vulnerable hosts and maliciously registered domains have been frequently involved in mobile attacks. In this paper, we explore the feasibility of detecting malicious domains visited on a cellular network based solely on lexical characteristics of the domain names. In addition to using traditional quantitative features of domain names, we also use a word segmentation algorithm to segment the domain names into individual words to greatly expand the size of the feature set. Experiments on a sample of real-world data from a large cellular network show that using word segmentation improves our ability to detect malicious domains relative to approaches without segmentation, as measured by misclassification rates and areas under the ROC curve. Furthermore, the results are interpretable, allowing one to discover (with little supervision or tuning required) which words are used most often to attract users to malicious domains. Such a lightweight approach could be performed in near-real time when a device attempts to visit a domain. This approach can complement (rather than substitute) other more expensive and time-consuming approaches to similar problems that use richer feature sets.

</details>

<details>

<summary>2015-06-12 18:57:15 - No SQL, No Injection? Examining NoSQL Security</summary>

- *Aviv Ron, Alexandra Shulman-Peleg, Emanuel Bronshtein*

- `1506.04082v1` - [abs](http://arxiv.org/abs/1506.04082v1) - [pdf](http://arxiv.org/pdf/1506.04082v1)

> NoSQL data storage systems have become very popular due to their scalability and ease of use. This paper examines the maturity of security measures for NoSQL databases, addressing their new query and access mechanisms. For example the emergence of new query formats makes the old SQL injection techniques irrelevant, but are NoSQL databases immune to injection in general? The answer is NO. Here we present a few techniques for attacking NoSQL databases such as injections and CSRF. We analyze the source of these vulnerabilities and present methodologies to mitigate the attacks. We show that this new vibrant technological area lacks the security measures and awareness which have developed over the years in traditional RDBMS SQL systems.

</details>

<details>

<summary>2015-06-12 19:45:55 - Applying Memory Forensics to Rootkit Detection</summary>

- *Igor Korkin, Ivan Nesterov*

- `1506.04129v1` - [abs](http://arxiv.org/abs/1506.04129v1) - [pdf](http://arxiv.org/pdf/1506.04129v1)

> Volatile memory dump and its analysis is an essential part of digital forensics. Among a number of various software and hardware approaches for memory dumping there are authors who point out that some of these approaches are not resilient to various anti-forensic techniques, and others that require a reboot or are highly platform dependent. New resilient tools have certain disadvantages such as low speed or vulnerability to rootkits which directly manipulate kernel structures e.g. page tables. A new memory forensic system - Malware Analysis System for Hidden Knotty Anomalies (MASHKA) is described in this paper. It is resilient to popular anti-forensic techniques. The system can be used for doing a wide range of memory forensics tasks. This paper describes how to apply the system for research and detection of kernel mode rootkits and also presents analysis of the most popular anti-rootkit tools.

</details>

<details>

<summary>2015-06-15 11:08:05 - PROP - Patronage of PHP Web Applications</summary>

- *C. Sireesha, G. Jyostna, P. Raghu Varan, P. R. L. Eswari*

- `1506.05071v1` - [abs](http://arxiv.org/abs/1506.05071v1) - [pdf](http://arxiv.org/pdf/1506.05071v1)

> PHP is one of the most commonly used languages to develop web sites because of its simplicity, easy to learn and it can be easily embedded with any of the databases. A web developer with his basic knowledge developing an application without practising secure guidelines, improper validation of user inputs leads to various source code vulnerabilities. Logical flaws while designing, implementing and hosting the web application causes work flow deviation attacks. In this paper, we are analyzing the complete behaviour of a web application through static and dynamic analysis methodologies.

</details>

<details>

<summary>2015-06-15 13:07:52 - Re-scale AdaBoost for Attack Detection in Collaborative Filtering Recommender Systems</summary>

- *Zhihai Yang, Lin Xu, Zhongmin Cai*

- `1506.04584v1` - [abs](http://arxiv.org/abs/1506.04584v1) - [pdf](http://arxiv.org/pdf/1506.04584v1)

> Collaborative filtering recommender systems (CFRSs) are the key components of successful e-commerce systems. Actually, CFRSs are highly vulnerable to attacks since its openness. However, since attack size is far smaller than that of genuine users, conventional supervised learning based detection methods could be too "dull" to handle such imbalanced classification. In this paper, we improve detection performance from following two aspects. First, we extract well-designed features from user profiles based on the statistical properties of the diverse attack models, making hard classification task becomes easier to perform. Then, refer to the general idea of re-scale Boosting (RBoosting) and AdaBoost, we apply a variant of AdaBoost, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features. RAdaBoost is comparable to the optimal Boosting-type algorithm and can effectively improve the performance in some hard scenarios. Finally, a series of experiments on the MovieLens-100K data set are conducted to demonstrate the outperformance of RAdaBoost comparing with some classical techniques such as SVM, kNN and AdaBoost.

</details>

<details>

<summary>2015-06-23 15:46:37 - The All-Seeing Eye: A Massive-Multi-Sensor Zero-Configuration Intrusion Detection System for Web Applications</summary>

- *Christoph Pohl, Hans-Joachim Hof*

- `1506.07055v1` - [abs](http://arxiv.org/abs/1506.07055v1) - [pdf](http://arxiv.org/pdf/1506.07055v1)

> Timing attacks are a challenge for current intrusion detection solutions. Timing attacks are dangerous for web applications because they may leak information about side channel vulnerabilities. This paper presents a massive-multi-sensor zero-configuration Intrusion Detection System that is especially good at detecting timing attacks. Unlike current solutions, the proposed Intrusion Detection System uses a huge number of sensors for attack detection. These sensors include sensors automatically inserted into web application or into the frameworks used to build web applications. With this approach the Intrusion Detection System is able to detect sophisticated attacks like timing attacks or other brute-force attacks with increased accuracy. The proposed massive-multi-sensor zero-configuration intrusion detection system does not need specific knowledge about the system to protect, hence it offers zero-configuration capability.

</details>

<details>

<summary>2015-06-29 05:49:10 - A New Covert Channel over Cellular Voice Channel in Smartphones</summary>

- *Bushra Aloraini, Daryl Johnson, Bill Stackpole, Sumita Mishra*

- `1504.05647v2` - [abs](http://arxiv.org/abs/1504.05647v2) - [pdf](http://arxiv.org/pdf/1504.05647v2)

> Investigating network covert channels in smartphones has become increasingly important as smartphones have recently replaced the role of traditional computers. Smartphones are subject to traditional computer network covert channel techniques. Smartphones also introduce new sets of covert channel techniques as they add more capabilities and multiple network connections. This work presents a new network covert channel in smartphones. The research studies the ability to leak information from the smartphones applications by reaching the cellular voice stream, and it examines the ability to employ the cellular voice channel to be a potential medium of information leakage through carrying modulated speech-like data covertly. To validate the theory, an Android software audio modem has been developed and it was able to leak data successfully through the cellular voice channel stream by carrying modulated data with a throughput of 13 bps with 0.018% BER. Moreover, Android security policies are investigated and broken in order to implement a user-mode rootkit that opens the voice channels by stealthily answering an incoming voice call. Multiple scenarios are conducted to verify the effectiveness of the proposed covert channel. This study identifies a new potential smartphone covert channel, and discusses some security vulnerabilities in Android OS that allow the use of this channel demonstrating the need to set countermeasures against this kind of breach.

</details>

<details>

<summary>2015-06-29 08:53:29 - Buffer overflow vulnerabilities in CUDA: a preliminary analysis</summary>

- *Andrea Miele*

- `1506.08546v1` - [abs](http://arxiv.org/abs/1506.08546v1) - [pdf](http://arxiv.org/pdf/1506.08546v1)

> We present a preliminary study of buffer overflow vulnerabilities in CUDA software running on GPUs. We show how an attacker can overrun a buffer to corrupt sensitive data or steer the execution flow by overwriting function pointers, e.g., manipulating the virtual table of a C++ object. In view of a potential mass market diffusion of GPU accelerated software this may be a major concern.

</details>


## 2015-07

<details>

<summary>2015-07-11 14:35:48 - Enhancing the Security of Protocols against Actor Key Compromise Problems</summary>

- *Jing Ma, Wenhui Zhang*

- `1507.03109v1` - [abs](http://arxiv.org/abs/1507.03109v1) - [pdf](http://arxiv.org/pdf/1507.03109v1)

> Security of complex systems is an important issue in software engineering. For complex computer systems involving many actors, security protocols are often used for the communication of sensitive data. Actor key compromise (AKC) denotes a situation where the long-term secret key of an actor may be known to an adversary for some reasons. Many protocols are not secure enough for ensuring security in such a situation. In this paper, we further study this problem by looking at potential types of attacks, defining their formal properties and providing solutions to enhance the level of security. As case studies, we analyze the vulnerabilities (with respect to potential AKC attacks) of practical protocols, including PKMv2RSA and Kerberos, and provide solutions to enhance the level of security of such protocols.

</details>

<details>

<summary>2015-07-11 15:00:18 - A Placement Vulnerability Study in Multi-tenant Public Clouds</summary>

- *Venkatanathan Varadarajan, Yinqian Zhang, Thomas Ristenpart, Michael Swift*

- `1507.03114v1` - [abs](http://arxiv.org/abs/1507.03114v1) - [pdf](http://arxiv.org/pdf/1507.03114v1)

> Public infrastructure-as-a-service clouds, such as Amazon EC2, Google Compute Engine (GCE) and Microsoft Azure allow clients to run virtual machines (VMs) on shared physical infrastructure. This practice of multi-tenancy brings economies of scale, but also introduces the risk of sharing a physical server with an arbitrary and potentially malicious VM. Past works have demonstrated how to place a VM alongside a target victim (co-location) in early-generation clouds and how to extract secret information via side- channels. Although there have been numerous works on side-channel attacks, there have been no studies on placement vulnerabilities in public clouds since the adoption of stronger isolation technologies such as Virtual Private Clouds (VPCs).   We investigate this problem of placement vulnerabilities and quantitatively evaluate three popular public clouds for their susceptibility to co-location attacks. We find that adoption of new technologies (e.g., VPC) makes many prior attacks, such as cloud cartography, ineffective. We find new ways to reliably test for co-location across Amazon EC2, Google GCE, and Microsoft Azure. We also found ways to detect co-location with victim web servers in a multi-tiered cloud application located behind a load balancer.   We use our new co-residence tests and multiple customer accounts to launch VM instances under different strategies that seek to maximize the likelihood of co-residency. We find that it is much easier (10x higher success rate) and cheaper (up to $114 less) to achieve co-location in these three clouds when compared to a secure reference placement policy.

</details>

<details>

<summary>2015-07-11 15:56:43 - Apate - A Linux Kernel Module for High Interaction Honeypots</summary>

- *Christoph Pohl, Michael Meier, Hans-Joachim Hof*

- `1507.03117v1` - [abs](http://arxiv.org/abs/1507.03117v1) - [pdf](http://arxiv.org/pdf/1507.03117v1)

> Honeypots are used in IT Security to detect and gather information about ongoing intrusions, e.g., by documenting the approach of an attacker. Honeypots do so by presenting an interactive system that seems just like a valid application to an attacker. One of the main design goals of honeypots is to stay unnoticed by attackers as long as possible. The longer the intruder interacts with the honeypot, the more valuable information about the attack can be collected. Of course, another main goal of honeypots is to not open new vulnerabilities that attackers can exploit. Thus, it is necessary to harden the honeypot and the surrounding environment. This paper presents Apate, a Linux Kernel Module (LKM) that is able to log, block and manipulate system calls based on preconfigurable conditions like Process ID (PID), User Id (UID), and many more. Apate can be used to build and harden High Interaction Honeypots. Apate can be configured using an integrated high level language. Thus, Apate is an important and easy to use building block for upcoming High Interaction Honeypots.

</details>

<details>

<summary>2015-07-13 12:11:18 - A Cross-Layer Security Analysis for Process-Aware Information Systems</summary>

- *Maria Leitner, Zhendong Ma, Stefanie Rinderle-Ma*

- `1507.03415v1` - [abs](http://arxiv.org/abs/1507.03415v1) - [pdf](http://arxiv.org/pdf/1507.03415v1)

> Information security in Process-aware Information System (PAIS) relies on many factors, including security of business process and the underlying system and technologies. Moreover, humans can be the weakest link that creates pathway to vulnerabilities, or the worst enemy that compromises a well-defended system. Since a system is as secure as its weakest link, information security can only be achieved in PAIS if all factors are secure. In this paper, we address two research questions: how to conduct a cross-layer security analysis that couple security concerns at business process layer as well as at the technical layer; and how to include human factor into the security analysis for the identification of human-oriented vulnerabilities and threats. We propose a methodology that supports the tracking of security interdependencies between functional, technical, and human aspects which contribute to establish a holistic approach to information security in PAIS. We demonstrate the applicability with a scenario from the payment card industry.

</details>

<details>

<summary>2015-07-15 05:26:32 - False shares in verifiable secret sharing with finite field commitments</summary>

- *Hua Lu, Jack Peterson*

- `1507.04089v1` - [abs](http://arxiv.org/abs/1507.04089v1) - [pdf](http://arxiv.org/pdf/1507.04089v1)

> Verifiable secret sharing (VSS) is designed to allow parties to collaborate to keep secrets. We describe here a method of fabricating false secret shares that appear to other parties to be legitimate, which can prevent assembly of the decryption key. This vulnerability affects VSS schemes using verification commitments bounded to a finite field.

</details>

<details>

<summary>2015-07-15 16:45:59 - Resistance against brute-force attacks on stateless forwarding in information centric networking</summary>

- *Bander A. Alzahrani, Martin J. Reed, Vassilios G. Vassilakis*

- `1507.04292v1` - [abs](http://arxiv.org/abs/1507.04292v1) - [pdf](http://arxiv.org/pdf/1507.04292v1)

> Line Speed Publish/Subscribe Inter-networking (LIPSIN) is one of the proposed forwarding mechanisms in Information Centric Networking (ICN). It is a stateless source-routing approach based on Bloom filters. However, it has been shown that LIPSIN is vulnerable to brute-force attacks which may lead to distributed denial-of-service (DDoS) attacks and unsolicited messages. In this work, we propose a new forwarding approach that maintains the advantages of Bloom filter based forwarding while allowing forwarding nodes to statelessly verify if packets have been previously authorized, thus preventing attacks on the forwarding mechanism. Analysis of the probability of attack, derived analytically, demonstrates that the technique is highly-resistant to brute-force attacks.

</details>

<details>

<summary>2015-07-16 09:02:42 - Vehicle Authentication via Monolithically Certified Public Key and Attributes</summary>

- *Shlomi Dolev, Åukasz Krzywiecki, Nisha Panwar, Michael Segal*

- `1507.04491v1` - [abs](http://arxiv.org/abs/1507.04491v1) - [pdf](http://arxiv.org/pdf/1507.04491v1)

> Vehicular networks are used to coordinate actions among vehicles in traffic by the use of wireless transceivers (pairs of transmitters and receivers). Unfortunately, the wireless communication among vehicles is vulnerable to security threats that may lead to very serious safety hazards. In this work, we propose a viable solution for coping with Man-in-the-Middle attacks. Conventionally, Public Key Infrastructure (PKI) is utilized for a secure communication with the pre-certified public key. However, a secure vehicle-to-vehicle communication requires additional means of verification in order to avoid impersonation attacks. To the best of our knowledge, this is the first work that proposes to certify both the public key and out-of-band sense-able static attributes to enable mutual authentication of the communicating vehicles. Vehicle owners are bound to preprocess (periodically) a certificate for both a public key and a list of fixed unchangeable attributes of the vehicle. Furthermore, the proposed approach is shown to be adaptable with regards to the existing authentication protocols. We illustrate the security verification of the proposed protocol using a detailed proof in Spi calculus.

</details>

<details>

<summary>2015-07-20 20:29:21 - Security Issues in Data Warehouse</summary>

- *Saiqa Aleem, Luiz Fernando Capretz, Faheem Ahmed*

- `1507.05644v1` - [abs](http://arxiv.org/abs/1507.05644v1) - [pdf](http://arxiv.org/pdf/1507.05644v1)

> Data Warehouse provides storage for huge amounts of historical data from heterogeneous operational sources in the form of multidimensional views, thus supplying sensitive and useful information which help decision-makers to improve the organizations business processes. A data warehouse environment must ensure that data collected and stored in one big repository are not vulnerable. A review of security approaches specifically for data warehouse environment and issues concerning each type of security approach have been provided in this paper.

</details>

<details>

<summary>2015-07-29 15:41:04 - The SYSU System for the Interspeech 2015 Automatic Speaker Verification Spoofing and Countermeasures Challenge</summary>

- *Shitao Weng, Shushan Chen, Lei Yu, Xuewei Wu, Weicheng Cai, Zhi Liu, Ming Li*

- `1507.06711v2` - [abs](http://arxiv.org/abs/1507.06711v2) - [pdf](http://arxiv.org/pdf/1507.06711v2)

> Many existing speaker verification systems are reported to be vulnerable against different spoofing attacks, for example speaker-adapted speech synthesis, voice conversion, play back, etc. In order to detect these spoofed speech signals as a countermeasure, we propose a score level fusion approach with several different i-vector subsystems. We show that the acoustic level Mel-frequency cepstral coefficients (MFCC) features, the phase level modified group delay cepstral coefficients (MGDCC) and the phonetic level phoneme posterior probability (PPP) tandem features are effective for the countermeasure. Furthermore, feature level fusion of these features before i-vector modeling also enhance the performance. A polynomial kernel support vector machine is adopted as the supervised classifier. In order to enhance the generalizability of the countermeasure, we also adopted the cosine similarity and PLDA scoring as one-class classifications methods. By combining the proposed i-vector subsystems with the OpenSMILE baseline which covers the acoustic and prosodic information further improves the final performance. The proposed fusion system achieves 0.29% and 3.26% EER on the development and test set of the database provided by the INTERSPEECH 2015 automatic speaker verification spoofing and countermeasures challenge.

</details>

<details>

<summary>2015-07-29 20:34:06 - Exploring Privacy Preservation in Outsourced K-Nearest Neighbors with Multiple Data Owners</summary>

- *Frank Li, Richard Shin, Vern Paxson*

- `1507.08309v1` - [abs](http://arxiv.org/abs/1507.08309v1) - [pdf](http://arxiv.org/pdf/1507.08309v1)

> The k-nearest neighbors (k-NN) algorithm is a popular and effective classification algorithm. Due to its large storage and computational requirements, it is suitable for cloud outsourcing. However, k-NN is often run on sensitive data such as medical records, user images, or personal information. It is important to protect the privacy of data in an outsourced k-NN system.   Prior works have all assumed the data owners (who submit data to the outsourced k-NN system) are a single trusted party. However, we observe that in many practical scenarios, there may be multiple mutually distrusting data owners. In this work, we present the first framing and exploration of privacy preservation in an outsourced k-NN system with multiple data owners. We consider the various threat models introduced by this modification. We discover that under a particularly practical threat model that covers numerous scenarios, there exists a set of adaptive attacks that breach the data privacy of any exact k-NN system. The vulnerability is a result of the mathematical properties of k-NN and its output. Thus, we propose a privacy-preserving alternative system supporting kernel density estimation using a Gaussian kernel, a classification algorithm from the same family as k-NN. In many applications, this similar algorithm serves as a good substitute for k-NN. We additionally investigate solutions for other threat models, often through extensions on prior single data owner systems.

</details>

<details>

<summary>2015-07-30 21:28:03 - Android Tapjacking Vulnerability</summary>

- *Benjamin Lim*

- `1507.08694v1` - [abs](http://arxiv.org/abs/1507.08694v1) - [pdf](http://arxiv.org/pdf/1507.08694v1)

> Android is an open source mobile operating system that is developed mainly by Google. It is used on a significant portion of mobile devices worldwide. In this paper, I will be looking at an attack commonly known as tapjacking. I will be taking the attack apart and walking through each individual step required to implement the attack. I will then explore the various payload options available to an attacker. Lastly, I will touch on the feasibility of the attack as well as mitigation strategies.

</details>


## 2015-08

<details>

<summary>2015-08-06 08:49:28 - Vehicle to Vehicle Authentication</summary>

- *Shlomi Dolev, Lukasz Krzywiecki, Nisha Panwar, Michael Segal*

- `1508.01324v1` - [abs](http://arxiv.org/abs/1508.01324v1) - [pdf](http://arxiv.org/pdf/1508.01324v1)

> In recent future, vehicles will establish a spontaneous connection over a wireless radio channel, coordinating actions and information. Vehicles will exchange warning messages over the wireless radio channel through Dedicated Short Range Communication (IEEE 1609) over the Wireless Access in Vehicular Environment (802.11p). Unfortunately, the wireless communication among vehicles is vulnerable to security threats that may lead to very serious safety hazards. Therefore, the warning messages being exchanged must incorporate an authentic factor such that recipient is willing to verify and accept the message in a timely manner

</details>

<details>

<summary>2015-08-07 14:33:03 - Analysing the Security of Google's implementation of OpenID Connect</summary>

- *Wanpeng Li, Chris J Mitchell*

- `1508.01707v1` - [abs](http://arxiv.org/abs/1508.01707v1) - [pdf](http://arxiv.org/pdf/1508.01707v1)

> Many millions of users routinely use their Google accounts to log in to relying party (RP) websites supporting the Google OpenID Connect service. OpenID Connect, a newly standardised single-sign-on protocol, builds an identity layer on top of the OAuth 2.0 protocol, which has itself been widely adopted to support identity management services. It adds identity management functionality to the OAuth 2.0 system and allows an RP to obtain assurances regarding the authenticity of an end user. A number of authors have analysed the security of the OAuth 2.0 protocol, but whether OpenID Connect is secure in practice remains an open question. We report on a large-scale practical study of Google's implementation of OpenID Connect, involving forensic examination of 103 RP websites which support its use for sign-in. Our study reveals serious vulnerabilities of a number of types, all of which allow an attacker to log in to an RP website as a victim user. Further examination suggests that these vulnerabilities are caused by a combination of Google's design of its OpenID Connect service and RP developers making design decisions which sacrifice security for simplicity of implementation. We also give practical recommendations for both RPs and OPs to help improve the security of real world OpenID Connect systems.

</details>

<details>

<summary>2015-08-08 18:36:22 - Provably weak instances of Ring-LWE</summary>

- *Yara Elias, Kristin E. Lauter, Ekin Ozman, Katherine E. Stange*

- `1502.03708v2` - [abs](http://arxiv.org/abs/1502.03708v2) - [pdf](http://arxiv.org/pdf/1502.03708v2)

> The ring and polynomial learning with errors problems (Ring-LWE and Poly-LWE) have been proposed as hard problems to form the basis for cryptosystems, and various security reductions to hard lattice problems have been presented. So far these problems have been stated for general (number) rings but have only been closely examined for cyclotomic number rings. In this paper, we state and examine the Ring-LWE problem for general number rings and demonstrate provably weak instances of Ring-LWE. We construct an explicit family of number fields for which we have an efficient attack. We demonstrate the attack in both theory and practice, providing code and running times for the attack. The attack runs in time linear in q, where q is the modulus.   Our attack is based on the attack on Poly-LWE which was presented in [Eisentr\"ager-Hallgren-Lauter]. We extend the EHL-attack to apply to a larger class of number fields, and show how it applies to attack Ring-LWE for a heuristically large class of fields. Certain Ring-LWE instances can be transformed into Poly-LWE instances without distorting the error too much, and thus provide the first weak instances of the Ring-LWE problem. We also provide additional examples of fields which are vulnerable to our attacks on Poly-LWE, including power-of-$2$ cyclotomic fields, presented using the minimal polynomial of $\zeta_{2^n} \pm 1$.

</details>

<details>

<summary>2015-08-09 20:45:50 - Vulnerability Analysis of GWireless</summary>

- *Benjamin Lim*

- `1508.02082v1` - [abs](http://arxiv.org/abs/1508.02082v1) - [pdf](http://arxiv.org/pdf/1508.02082v1)

> Wireless networking has become very popular in recent years due to the increase in adoption of mobile devices. As more and more employees demand for Wi-Fi access for their devices, more companies have been jumping onto the "Bring Your Own Device" (BYOD) bandwagon[1] to appease their employees. One such example of an enterprise wireless infrastructure is the George Washington University's GWireless.   For this project, I will attempt to capture hashes of authentication credentials from users who are connecting to the GWireless network using what is commonly known as the "evil twin" attack. I will document the hardware, software used and steps taken to configure the devices. I will then evaluate the feasibility of such an attack, explore variations of the attack and document measures that can be taken to prevent such an attack.

</details>

<details>

<summary>2015-08-21 09:59:27 - A Case Study on Covert Channel Establishment via Software Caches in High-Assurance Computing Systems</summary>

- *Wolfgang Schmidt, Michael Hanspach, JÃ¶rg Keller*

- `1508.05228v1` - [abs](http://arxiv.org/abs/1508.05228v1) - [pdf](http://arxiv.org/pdf/1508.05228v1)

> Covert channels can be utilized to secretly deliver information from high privileged processes to low privileged processes in the context of a high-assurance computing system. In this case study, we investigate the possibility of covert channel establishment via software caches in the context of a framework for component-based operating systems. While component-based operating systems offer security through the encapsulation of system service processes, complete isolation of these processes is not reasonably feasible. This limitation is practically demonstrated with our concept of a specific covert timing channel based on file system caching. The stability of the covert channel is evaluated and a methodology to disrupt the covert channel transmission is presented. While these kinds of attacks are not limited to high-assurance computing systems, our study practically demonstrates that even security-focused computing systems with a minimal trusted computing base are vulnerable for such kinds of attacks and careful design decisions are necessary for secure operating system architectures.

</details>


## 2015-09

<details>

<summary>2015-09-01 18:14:00 - 2001-2013: Survey and Analysis of Major Cyberattacks</summary>

- *Tavish Vaidya*

- `1507.06673v2` - [abs](http://arxiv.org/abs/1507.06673v2) - [pdf](http://arxiv.org/pdf/1507.06673v2)

> Widespread and extensive use of computers and their interconnections in almost all sectors like communications, finance, transportation, military, governance, education, energy etc., have made them attractive targets for adversaries to spy, disrupt or steal information by pressing of few keystrokes from any part of the world. This paper presents a survey of major cyberattacks from 2001 to 2013 and analyzes these attacks to understand the motivation, targets and technique(s) employed by the attackers. Observed trends in cyberattacks have also been discussed in the paper.

</details>

<details>

<summary>2015-09-04 21:13:16 - Network Structure and Resilience of Mafia Syndicates</summary>

- *Santa Agreste, Salvatore Catanese, Pasquale De Meo, Emilio Ferrara, Giacomo Fiumara*

- `1509.01608v1` - [abs](http://arxiv.org/abs/1509.01608v1) - [pdf](http://arxiv.org/pdf/1509.01608v1)

> In this paper we present the results of the study of Sicilian Mafia organization by using Social Network Analysis. The study investigates the network structure of a Mafia organization, describing its evolution and highlighting its plasticity to interventions targeting membership and its resilience to disruption caused by police operations. We analyze two different datasets about Mafia gangs built by examining different digital trails and judicial documents spanning a period of ten years: the former dataset includes the phone contacts among suspected individuals, the latter is constituted by the relationships among individuals actively involved in various criminal offenses. Our report illustrates the limits of traditional investigation methods like tapping: criminals high up in the organization hierarchy do not occupy the most central positions in the criminal network, and oftentimes do not appear in the reconstructed criminal network at all. However, we also suggest possible strategies of intervention, as we show that although criminal networks (i.e., the network encoding mobsters and crime relationships) are extremely resilient to different kind of attacks, contact networks (i.e., the network reporting suspects and reciprocated phone calls) are much more vulnerable and their analysis can yield extremely valuable insights.

</details>

<details>

<summary>2015-09-14 22:11:40 - Stable Nash Equilibria in the Gale-Shapley Matching Game</summary>

- *Sushmita Gupta, Kazuo Iwama, Shuichi Miyazaki*

- `1509.04344v1` - [abs](http://arxiv.org/abs/1509.04344v1) - [pdf](http://arxiv.org/pdf/1509.04344v1)

> In this article we study the stable marriage game induced by the men-proposing Gale-Shapley algorithm. Our setting is standard: all the lists are complete and the matching mechanism is the men-proposing Gale-Shapley algorithm. It is well known that in this setting, men cannot cheat, but women can. In fact, Teo, Sethuraman and Tan \cite{TST01}, show that there is a polynomial time algorithm to obtain, for a given strategy (the set of all lists) $Q$ and a woman $w$, the best partner attainable by changing her list. However, what if the resulting matching is not stable with respect to $Q$? Obviously, such a matching would be vulnerable to further manipulation, but is not mentioned in \cite{TST01}. In this paper, we consider (safe) manipulation that implies a stable matching in a most general setting. Specifically, our goal is to decide for a given $Q$, if w can manipulate her list to obtain a strictly better partner with respect to the true strategy $P$ (which may be different from $Q$), and also the outcome is a stable matching for $P$.

</details>

<details>

<summary>2015-09-15 16:54:52 - Jamming aided Generalized Data Attacks: Exposing Vulnerabilities in Secure Estimation</summary>

- *Deepjyoti Deka, Ross Baldick, Sriram Vishwanath*

- `1509.04639v1` - [abs](http://arxiv.org/abs/1509.04639v1) - [pdf](http://arxiv.org/pdf/1509.04639v1)

> Jamming refers to the deletion, corruption or damage of meter measurements that prevents their further usage. This is distinct from adversarial data injection that changes meter readings while preserving their utility in state estimation. This paper presents a generalized attack regime that uses jamming of secure and insecure measurements to greatly expand the scope of common 'hidden' and 'detectable' data injection attacks in literature. For 'hidden' attacks, it is shown that with jamming, the optimal attack is given by the minimum feasible cut in a specific weighted graph. More importantly, for 'detectable' data attacks, this paper shows that the entire range of relative costs for adversarial jamming and data injection can be divided into three separate regions, with distinct graph-cut based constructions for the optimal attack. Approximate algorithms for attack design are developed and their performances are demonstrated by simulations on IEEE test cases. Further, it is proved that prevention of such attacks require security of all grid measurements. This work comprehensively quantifies the dual adversarial benefits of jamming: (a) reduced attack cost and (b) increased resilience to secure measurements, that strengthen the potency of data attacks.

</details>

<details>

<summary>2015-09-16 17:17:32 - Improving image watermarking based on Tabu search by Chaos</summary>

- *Mohammad Tafaghodi, Meysam Ghaffari, Alimohammad Latif, Seyed Rasoul Mousavi*

- `1501.01576v3` - [abs](http://arxiv.org/abs/1501.01576v3) - [pdf](http://arxiv.org/pdf/1501.01576v3)

> With the fast development of communication and multimedia technology, the rights of the owners of multimedia products is vulnerable to the unauthorized copies and watermarking is one of the best known methods for proving the ownership of a product. In this paper we prosper the previous watermarking method which was based on Tabu search by Chaos. The modification applied in the permutation step of watermarking and the initial population generation of the Tabu search. We analyze our method on some well known images and experimental results shows the improvement in the quality and speed of the proposed watermarking method.

</details>

<details>

<summary>2015-09-21 02:26:17 - A New Storage Optimized Honeyword Generation Approach for Enhancing Security and Usability</summary>

- *Nilesh Chakraborty, Samrat Mondal*

- `1509.06094v1` - [abs](http://arxiv.org/abs/1509.06094v1) - [pdf](http://arxiv.org/pdf/1509.06094v1)

> Inverting the hash values by performing brute force computation is one of the latest security threats on password based authentication technique. New technologies are being developed for brute force computation and these increase the success rate of inversion attack. Honeyword base authentication protocol can successfully mitigate this threat by making password cracking detectable. However, the existing schemes have several limitations like Multiple System Vulnerability, Weak DoS Resistivity, Storage Overhead, etc. In this paper we have proposed a new honeyword generation approach, identified as Paired Distance Protocol (PDP) which overcomes almost all the drawbacks of previously proposed honeyword generation approaches. The comprehensive analysis shows that PDP not only attains a high detection rate of 97.23% but also reduces the storage cost to a great extent.

</details>

<details>

<summary>2015-09-25 11:27:58 - A Socio-Technical approach to address the Information security: Using the 27001 Manager Artefact</summary>

- *Rui Shantilau, Antonio Goncalves, Anacleto Correia*

- `1511.02903v1` - [abs](http://arxiv.org/abs/1511.02903v1) - [pdf](http://arxiv.org/pdf/1511.02903v1)

> In general, the perspective customer / supplier followed by organizations, regarding information security management, is based mainly on management controls based on standards such as ISO / IEC 27001: 2015, resulting in the production of especially technical analysis reports, rather than a socio-technical approach. This leads to the perception by the customer of the delivery of a product instead of a service.The product concerned is reduced to a set of prescriptions, sometimes unrelated, which materialize in a descriptive and static view of client security management. As a result, the client can hardly use the product continuously, following the dynamics of changes in their organization, therefore recognizing value in the provision made by the supplier. The use of the paradigm Service Dominant Logic (LDS), in the development of a range of security management information, helps to change the focus of tangible resources to the intangible assets. The aspects of tangibility, materialized in a document that describes the client's vulnerabilities and attack vectors are referred to a secondary level, given the importance of the intangible aspects, such as the interaction that is established between the customer specialists and supplier. In this article we propose to analyze in the perspective of a socio-technical theory, the Activity Theory, the service provided by an artifact called 27001 Manager, designed to assist the entire cycle of analysis, development and maintenance of an information security management system (ISMS). The analysis aims at observing the existing interaction between customer / supplier, considering that the service is inherently dynamic and inter-subjective, ie the result of a compromise between the customer and the supplier.

</details>

<details>

<summary>2015-09-25 14:48:43 - A vulnerability in Google AdSense: Automatic extraction of links to ads</summary>

- *Manuel BlÃ¡zquez Ochando*

- `1509.07741v1` - [abs](http://arxiv.org/abs/1509.07741v1) - [pdf](http://arxiv.org/pdf/1509.07741v1)

> On the basis of the XSS (Cross Site Scripting) and Web Crawler techniques it is possible to go through the barriers of the Google Adsense advertising system by obtaining the validated links of the ads published on a website. Such method involves obtaining the source code built for the Google java applet for publishing and handling ads and for the final link retrieval. Once the links of the ads have been obtained, you can use the user sessions visiting other websites to load such links, in the background, by a simple re-direction, through a hidden iframe, so that the IP addresses clicking are different in each case.

</details>


## 2015-10

<details>

<summary>2015-10-06 11:46:42 - High Precision Fault Injections on the Instruction Cache of ARMv7-M Architectures</summary>

- *Lionel RiviÃ¨re, Zakaria Najm, Pablo Rauzy, Jean-Luc Danger, Julien Bringer, Laurent Sauvage*

- `1510.01537v1` - [abs](http://arxiv.org/abs/1510.01537v1) - [pdf](http://arxiv.org/pdf/1510.01537v1)

> Hardware and software of secured embedded systems are prone to physical attacks. In particular, fault injection attacks revealed vulnerabilities on the data and the control flow allowing an attacker to break cryptographic or secured algorithms implementations. While many research studies concentrated on successful attacks on the data flow, only a few targets the instruction flow. In this paper, we focus on electromagnetic fault injection (EMFI) on the control flow, especially on the instruction cache. We target the very widespread (smartphones, tablets, settop-boxes, health-industry monitors and sensors, etc.) ARMv7-M architecture. We describe a practical EMFI platform and present a methodology providing high control level and high reproducibility over fault injections. Indeed, we observe that a precise fault model occurs in up to 96% of the cases. We then characterize and exhibit this practical fault model on the cache that is not yet considered in the literature. We comprehensively describe its effects and show how it can be used to reproduce well known fault attacks. Finally, we describe how it can benefits attackers to mount new powerful attacks or simplify existing ones.

</details>

<details>

<summary>2015-10-07 14:54:09 - Security-aware selection of Web Services for Reliable Composition</summary>

- *Shahedeh Khani, Cristina Gacek, Peter Popov*

- `1510.02391v1` - [abs](http://arxiv.org/abs/1510.02391v1) - [pdf](http://arxiv.org/pdf/1510.02391v1)

> Dependability is an important characteristic that a trustworthy computer system should have. It is a measure of Availability, Reliability, Maintainability, Safety and Security. The focus of our research is on security of web services. Web services enable the composition of independent services with complementary functionalities to produce value-added services, which allows organizations to implement their core business only and outsource other service components over the Internet, either pre-selected or on-the-fly. The selected third party web services may have security vulnerabilities. Vulnerable web services are of limited practical use. We propose to use an intrusion-tolerant composite web service for each functionality that should be fulfilled by a third party web service. The third party services employed in this approach should be selected based on their security vulnerabilities in addition to their performance. The security vulnerabilities of the third party services are assessed using a penetration testing tool. In this paper we present our preliminary research work.

</details>

<details>

<summary>2015-10-14 16:57:32 - A Privacy Preserving Improvement for SRTA in Telecare Systems</summary>

- *Seyed Salman Sajjadi Ghaemmaghami, Mahtab Mirmohseni, Afrooz Haghbin*

- `1510.04197v1` - [abs](http://arxiv.org/abs/1510.04197v1) - [pdf](http://arxiv.org/pdf/1510.04197v1)

> Radio Frequency Identification (RFID) is a modern communication technology, which provides authentication and identification through a nonphysical contact. Recently, the use of this technology is almost developed in healthcare environments. Although RFID technology can prepare sagacity in systems, privacy and security issues ought to be considered before. Recently, in 2015, Li et al. proposed SRTA, a hash-based RFID authentication protocol in medication verification for healthcare. In this paper, we study this protocol and show that SRTA protocol is vulnerable to traceability, impersonation and Dos attacks. So it does not provide the privacy and security of RFID end users. Therefore, we propose an improved secure and efficient RFID authentication protocol to enhance the performance of Li et al. method. Our analyze show that the existing weaknesses of SRTA protocol are eliminated in our proposed protocol.

</details>

<details>

<summary>2015-10-24 19:32:26 - Implementation of Experimental Test Bed to Evaluate Security in Cellular Networks</summary>

- *Nasibeh Mohammadzadeh, Mohsen Hallaj Asghar, Raghu Kisore*

- `1510.07177v1` - [abs](http://arxiv.org/abs/1510.07177v1) - [pdf](http://arxiv.org/pdf/1510.07177v1)

> The wide development of inter connectivity of cellular networks with the internet network has made them to be vulnerable. This exposure of the cellular networks to internet has increased threats to customer end equipment as well as the carrier infrastructure.

</details>

<details>

<summary>2015-10-30 06:30:34 - Towards More Security in Data Exchange: Defining Unparsers with Context-Sensitive Encoders for Context-Free Grammars</summary>

- *Lars Hermerschmidt, Stephan Kugelmann, Bernhard Rumpe*

- `1510.08979v1` - [abs](http://arxiv.org/abs/1510.08979v1) - [pdf](http://arxiv.org/pdf/1510.08979v1)

> To exchange complex data structures in distributed systems, documents written in context-free languages are exchanged among communicating parties. Unparsing these documents correctly is as important as parsing them correctly because errors during unparsing result in injection vulnerabilities such as cross-site scripting (XSS) and SQL injection. Injection attacks are not limited to the web world. Every program that uses input to produce documents in a context-free language may be vulnerable to this class of attack. Even for widely used languages such as HTML and JavaScript, there are few approaches that prevent injection attacks by context-sensitive encoding, and those approaches are tied to the language. Therefore, the aim of this paper is to derive context-sensitive encoder from context-free grammars to provide correct unparsing of maliciously crafted input data for all context-free languages. The presented solution integrates encoder definition into context-free grammars and provides a generator for context-sensitive encoders and decoders that are used during (un)parsing. This unparsing process results in documents where the input data does neither influence the structure of the document nor change their intended semantics. By defining encoding during language definition, developers who use the language are provided with a clean interface for writing and reading documents written in that language, without the need to care about security-relevant encoding.

</details>

<details>

<summary>2015-10-31 17:25:00 - New Threats to SMS-Assisted Mobile Internet Services from 4G LTE: Lessons Learnt from Distributed Mobile-Initiated Attacks towards Facebook and Other Services</summary>

- *Guan-Hua Tu, Yuanjie Li, Chunyi Peng, Chi-Yu Li, Muhammad Taqi Raza, Hsiao-Yun Tseng, Songwu Lu*

- `1510.08531v2` - [abs](http://arxiv.org/abs/1510.08531v2) - [pdf](http://arxiv.org/pdf/1510.08531v2)

> Mobile Internet is becoming the norm. With more personalized mobile devices in hand, many services choose to offer alternative, usually more convenient, approaches to authenticating and delivering the content between mobile users and service providers. One main option is to use SMS (i.e., short messaging service). Such carrier-grade text service has been widely used to assist versatile mobile services, including social networking, banking, to name a few. Though the text service can be spoofed via certain Internet text service providers which cooperated with carriers, such attacks haven well studied and defended by industry due to the efforts of research community. However, as cellular network technology advances to the latest IP-based 4G LTE, we find that these mobile services are somehow exposed to new threats raised by this change, particularly on 4G LTE Text service (via brand-new distributed Mobile-Initiated Spoofed SMS attack which is not available in legacy 2G/3G systems). The reason is that messaging service over LTE shifts from the circuit-switched (CS) design to the packet-switched (PS) paradigm as 4G LTE supports PS only. Due to this change, 4G LTE Text Service becomes open to access. However, its shields to messaging integrity and user authentication are not in place. As a consequence, such weaknesses can be exploited to launch attacks (e.g., hijack Facebook accounts) against a targeted individual, a large scale of mobile users and even service providers, from mobile devices. Current defenses for Internet-Initiated Spoofed SMS attacks cannot defend the unprecedented attack. Our study shows that 53 of 64 mobile services over 27 industries are vulnerable to at least one threat. We validate these proof-of-concept attacks in one major US carrier which supports more than 100 million users. We finally propose quick fixes and discuss security insights and lessons we have learnt.

</details>


## 2015-11

<details>

<summary>2015-11-02 10:41:33 - RiPKI: The Tragic Story of RPKI Deployment in the Web Ecosystem</summary>

- *Matthias WÃ¤hlisch, Robert Schmidt, Thomas C. Schmidt, Olaf Maennel, Steve Uhlig, Gareth Tyson*

- `1408.0391v3` - [abs](http://arxiv.org/abs/1408.0391v3) - [pdf](http://arxiv.org/pdf/1408.0391v3)

> Web content delivery is one of the most important services on the Internet. Access to websites is typically secured via TLS. However, this security model does not account for prefix hijacking on the network layer, which may lead to traffic blackholing or transparent interception. Thus, to achieve comprehensive security and service availability, additional protective mechanisms are necessary such as the RPKI, a recently deployed Resource Public Key Infrastructure to prevent hijacking of traffic by networks. This paper argues two positions. First, that modern web hosting practices make route protection challenging due to the propensity to spread servers across many different networks, often with unpredictable client redirection strategies, and, second, that we need a better understanding why protection mechanisms are not deployed. To initiate this, we empirically explore the relationship between web hosting infrastructure and RPKI deployment. Perversely, we find that less popular websites are more likely to be secured than the prominent sites. Worryingly, we find many large-scale CDNs do not support RPKI, thus making their customers vulnerable. This leads us to explore business reasons why operators are hesitant to deploy RPKI, which may help to guide future research on improving Internet security.

</details>

<details>

<summary>2015-11-02 16:14:10 - Network Security Threats and Protection Models</summary>

- *Amit Kumar, Santosh Malhotra*

- `1511.00568v1` - [abs](http://arxiv.org/abs/1511.00568v1) - [pdf](http://arxiv.org/pdf/1511.00568v1)

> In a brave new age of global connectivity and e-commerce, interconnections via networks have heightened, creating for both individuals and organizations, a state of complete dependence upon vulnerable systems for storage and transfer of information. Never before, have so many people had power in their own hands. The power to deface websites, access personal mail accounts, and worse more the potential to bring down entire governments, and financial corporations through openly documented software codes. This paper discusses the possible exploits on typical network components, it will cite real life scenarios, and propose practical measures that can be taken as safeguard. Then, it describes some of the key efforts done by the research community to prevent such attacks, mainly by using Firewall and Intrusion Detection Systems.

</details>

<details>

<summary>2015-11-02 18:01:32 - Exposing the Hidden Web: An Analysis of Third-Party HTTP Requests on 1 Million Websites</summary>

- *Timothy Libert*

- `1511.00619v1` - [abs](http://arxiv.org/abs/1511.00619v1) - [pdf](http://arxiv.org/pdf/1511.00619v1)

> This article provides a quantitative analysis of privacy-compromising mechanisms on 1 million popular websites. Findings indicate that nearly 9 in 10 websites leak user data to parties of which the user is likely unaware; more than 6 in 10 websites spawn third- party cookies; and more than 8 in 10 websites load Javascript code from external parties onto users' computers. Sites that leak user data contact an average of nine external domains, indicating that users may be tracked by multiple entities in tandem. By tracing the unintended disclosure of personal browsing histories on the Web, it is revealed that a handful of U.S. companies receive the vast bulk of user data. Finally, roughly 1 in 5 websites are potentially vulnerable to known National Security Agency spying techniques at the time of analysis.

</details>

<details>

<summary>2015-11-04 16:36:51 - Protecting Locations with Differential Privacy under Temporal Correlations</summary>

- *Yonghui Xiao, Li Xiong*

- `1410.5919v5` - [abs](http://arxiv.org/abs/1410.5919v5) - [pdf](http://arxiv.org/pdf/1410.5919v5)

> Concerns on location privacy frequently arise with the rapid development of GPS enabled devices and location-based applications. While spatial transformation techniques such as location perturbation or generalization have been studied extensively, most techniques rely on syntactic privacy models without rigorous privacy guarantee. Many of them only consider static scenarios or perturb the location at single timestamps without considering temporal correlations of a moving user's locations, and hence are vulnerable to various inference attacks. While differential privacy has been accepted as a standard for privacy protection, applying differential privacy in location based applications presents new challenges, as the protection needs to be enforced on the fly for a single user and needs to incorporate temporal correlations between a user's locations.   In this paper, we propose a systematic solution to preserve location privacy with rigorous privacy guarantee. First, we propose a new definition, "$\delta$-location set" based differential privacy, to account for the temporal correlations in location data. Second, we show that the well known $\ell_1$-norm sensitivity fails to capture the geometric sensitivity in multidimensional space and propose a new notion, sensitivity hull, based on which the error of differential privacy is bounded. Third, to obtain the optimal utility we present a planar isotropic mechanism (PIM) for location perturbation, which is the first mechanism achieving the lower bound of differential privacy. Experiments on real-world datasets also demonstrate that PIM significantly outperforms baseline approaches in data utility.

</details>

<details>

<summary>2015-11-10 07:15:53 - ELDA: Towards Efficient and Lightweight Detection of Cache Pollution Attacks in NDN</summary>

- *Zhiwei Xu, Bo Chen, Ninghan Wang, Yujun Zhang, Zhongcheng Li*

- `1511.03005v1` - [abs](http://arxiv.org/abs/1511.03005v1) - [pdf](http://arxiv.org/pdf/1511.03005v1)

> As a promising architectural design for future Internet, named data networking (NDN) relies on in-network caching to efficiently deliver name-based content. However, the in-network caching is vulnerable to cache pollution attacks (CPA), which can reduce cache hits by violating cache locality and significantly degrade the overall performance of NDN. To defend against CPA attacks, the most effective way is to first detect the attacks and then throttle them. Since the CPA attack itself has already imposed a huge burden on victims, to avoid exhausting the remaining resources on the victims for detection purpose, we expect a lightweight detection solution. We thus propose ELDA, an Efficient and Lightweight Detection scheme against cache pollution Attacks, in which we design a Lightweight Flajolet-Martin (LFM) sketch to monitor the interest traffic. Our analysis and simulations demonstrate that, by consuming a few computation and memory resources, ELDA can effectively and efficiently detect CPA attacks.

</details>

<details>

<summary>2015-11-11 19:17:38 - Automated Dynamic Firmware Analysis at Scale: A Case Study on Embedded Web Interfaces</summary>

- *Andrei Costin, Apostolis Zarras, AurÃ©lien Francillon*

- `1511.03609v1` - [abs](http://arxiv.org/abs/1511.03609v1) - [pdf](http://arxiv.org/pdf/1511.03609v1)

> Embedded devices are becoming more widespread, interconnected, and web-enabled than ever. However, recent studies showed that these devices are far from being secure. Moreover, many embedded systems rely on web interfaces for user interaction or administration. Unfortunately, web security is known to be difficult, and therefore the web interfaces of embedded systems represent a considerable attack surface.   In this paper, we present the first fully automated framework that applies dynamic firmware analysis techniques to achieve, in a scalable manner, automated vulnerability discovery within embedded firmware images. We apply our framework to study the security of embedded web interfaces running in Commercial Off-The-Shelf (COTS) embedded devices, such as routers, DSL/cable modems, VoIP phones, IP/CCTV cameras. We introduce a methodology and implement a scalable framework for discovery of vulnerabilities in embedded web interfaces regardless of the vendor, device, or architecture. To achieve this goal, our framework performs full system emulation to achieve the execution of firmware images in a software-only environment, i.e., without involving any physical embedded devices. Then, we analyze the web interfaces within the firmware using both static and dynamic tools. We also present some interesting case-studies, and discuss the main challenges associated with the dynamic analysis of firmware images and their web interfaces and network services. The observations we make in this paper shed light on an important aspect of embedded devices which was not previously studied at a large scale.   We validate our framework by testing it on 1925 firmware images from 54 different vendors. We discover important vulnerabilities in 185 firmware images, affecting nearly a quarter of vendors in our dataset. These experimental results demonstrate the effectiveness of our approach.

</details>

<details>

<summary>2015-11-19 16:39:41 - Behavior Query Discovery in System-Generated Temporal Graphs</summary>

- *Bo Zong, Xusheng Xiao, Zhichun Li, Zhenyu Wu, Zhiyun Qian, Xifeng Yan, Ambuj K. Singh, Guofei Jiang*

- `1511.05911v2` - [abs](http://arxiv.org/abs/1511.05911v2) - [pdf](http://arxiv.org/pdf/1511.05911v2)

> Computer system monitoring generates huge amounts of logs that record the interaction of system entities. How to query such data to better understand system behaviors and identify potential system risks and malicious behaviors becomes a challenging task for system administrators due to the dynamics and heterogeneity of the data. System monitoring data are essentially heterogeneous temporal graphs with nodes being system entities and edges being their interactions over time. Given the complexity of such graphs, it becomes time-consuming for system administrators to manually formulate useful queries in order to examine abnormal activities, attacks, and vulnerabilities in computer systems.   In this work, we investigate how to query temporal graphs and treat query formulation as a discriminative temporal graph pattern mining problem. We introduce TGMiner to mine discriminative patterns from system logs, and these patterns can be taken as templates for building more complex queries. TGMiner leverages temporal information in graphs to prune graph patterns that share similar growth trend without compromising pattern quality. Experimental results on real system data show that TGMiner is 6-32 times faster than baseline methods. The discovered patterns were verified by system experts; they achieved high precision (97%) and recall (91%).

</details>

<details>

<summary>2015-11-20 16:12:59 - L1 logistic regression as a feature selection step for training stable classification trees for the prediction of severity criteria in imported malaria</summary>

- *Luca Talenti, Margaux Luck, Anastasia Yartseva, Nicolas Argy, Sandrine HouzÃ©, Cecilia Damon*

- `1511.06663v1` - [abs](http://arxiv.org/abs/1511.06663v1) - [pdf](http://arxiv.org/pdf/1511.06663v1)

> Multivariate classification methods using explanatory and predictive models are necessary for characterizing subgroups of patients according to their risk profiles. Popular methods include logistic regression and classification trees with performances that vary according to the nature and the characteristics of the dataset. In the context of imported malaria, we aimed at classifying severity criteria based on a heterogeneous patient population. We investigated these approaches by implementing two different strategies: L1 logistic regression (L1LR) that models a single global solution and classification trees that model multiple local solutions corresponding to discriminant subregions of the feature space. For each strategy, we built a standard model, and a sparser version of it. As an alternative to pruning, we explore a promising approach that first constrains the tree model with an L1LR-based feature selection, an approach we called L1LR-Tree. The objective is to decrease its vulnerability to small data variations by removing variables corresponding to unstable local phenomena. Our study is twofold: i) from a methodological perspective comparing the performances and the stability of the three previous methods, i.e L1LR, classification trees and L1LR-Tree, for the classification of severe forms of imported malaria, and ii) from an applied perspective improving the actual classification of severe forms of imported malaria by identifying more personalized profiles predictive of several clinical criteria based on variables dismissed for the clinical definition of the disease. The main methodological results show that the combined method L1LR-Tree builds sparse and stable models that significantly predicts the different severity criteria and outperforms all the other methods in terms of accuracy.

</details>

<details>

<summary>2015-11-21 18:40:20 - Countering Social Engineering through Social Media: An Enterprise Security Perspective</summary>

- *H. Wilcox, Maumita Bhattacharya*

- `1511.06915v1` - [abs](http://arxiv.org/abs/1511.06915v1) - [pdf](http://arxiv.org/pdf/1511.06915v1)

> The increasing threat of social engineers targeting social media channels to advance their attack effectiveness on company data has seen many organizations introducing initiatives to better understand these vulnerabilities. This paper examines concerns of social engineering through social media within the enterprise and explores countermeasures undertaken to stem ensuing risk. Also included is an analysis of existing social media security policies and guidelines within the public and private sectors.

</details>

<details>

<summary>2015-11-24 01:07:08 - The Limitations of Deep Learning in Adversarial Settings</summary>

- *Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, Ananthram Swami*

- `1511.07528v1` - [abs](http://arxiv.org/abs/1511.07528v1) - [pdf](http://arxiv.org/pdf/1511.07528v1)

> Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.

</details>

<details>

<summary>2015-11-27 18:54:58 - War of 2050: a Battle for Information, Communications, and Computer Security</summary>

- *Alexander Kott, David S. Alberts, Cliff Wang*

- `1512.00360v1` - [abs](http://arxiv.org/abs/1512.00360v1) - [pdf](http://arxiv.org/pdf/1512.00360v1)

> As envisioned in a recent future-casting workshop, warfare will continue to be transformed by advances in information technologies. In fact, information itself will become the decisive domain of warfare. Four developments will significantly change the nature of the battle. The first of these will be a proliferation of intelligent systems; the second, augmented humans; the third, the decisive battle for the information domain; and the fourth, the introduction of new, networked approaches to command and control. Each of these new capabilities possesses the same critical vulnerability - attacks on the information, communications and computers that will enable human-robot teams to make sense of the battlefield and act decisively. Hence, the largely unseen battle for information, communications and computer security will determine the extent to which adversaries will be able to function and succeed on the battlefield of 2050.

</details>

<details>

<summary>2015-11-30 22:01:17 - Enhancing Infrastructure Security in Real Estate</summary>

- *Kyle Dees, Shawon Rahman*

- `1512.00064v1` - [abs](http://arxiv.org/abs/1512.00064v1) - [pdf](http://arxiv.org/pdf/1512.00064v1)

> As a result of the increased dependency on obtaining information and connecting each computer together for ease of access or communication, organizations risk being attacked and losing private information through breaches or insecure business activities. To help protect organizations and their assets, companies need to develop a strong understanding of the risks imposed on their company and the security solutions designed to prevent or minimize vulnerabilities. To reduce the impact threats have on a network, organizations need to: design a defense layer system that provides multiple instances of protection to prevent unauthorized access to core information, implement a strong network hardware/intrusion prevention system, and create all-inclusive network or security policies that detail user rules and company rights. In order to enhance the overall security of a basic infrastructure, this paper will provide a detailed look into gathering the organizational requirements, designing and implementing a secure physical network layout, and selecting the standards needed to prevent unauthorized access

</details>


## 2015-12

<details>

<summary>2015-12-13 20:16:33 - JoKER: Trusted Detection of Kernel Rootkits in Android Devices via JTAG Interface</summary>

- *Mordechai Guri, Yuri Poliak, Bracha Shapira, Yuval Elovici*

- `1512.04116v1` - [abs](http://arxiv.org/abs/1512.04116v1) - [pdf](http://arxiv.org/pdf/1512.04116v1)

> Smartphones and tablets have become prime targets for malware, due to the valuable private and corporate information they hold. While Anti-Virus (AV) program may successfully detect malicious applications (apps), they remain ineffective against low-level rootkits that evade detection mechanisms by masking their own presence. Furthermore, any detection mechanism run on the same physical device as the monitored OS can be compromised via application, kernel or boot-loader vulnerabilities. Consequentially, trusted detection of kernel rootkits in mobile devices is a challenging task in practice. In this paper we present JoKER - a system which aims at detecting rootkits in the Android kernel by utilizing the hardware's Joint Test Action Group (JTAG) interface for trusted memory forensics. Our framework consists of components that extract areas of a kernel's memory and reconstruct it for further analysis. We present the overall architecture along with its implementation, and demonstrate that the system can successfully detect the presence of stealthy rootkits in the kernel. The results show that although JTAG's main purpose is system testing, it can also be used for malware detection where traditional methods fail.

</details>

<details>

<summary>2015-12-15 21:42:07 - TRAIL: Topology Authentication in RPL</summary>

- *Heiner Perrey, Martin Landsmann, Osman Ugus, Thomas C. Schmidt, Matthias WÃ¤hlisch*

- `1312.0984v2` - [abs](http://arxiv.org/abs/1312.0984v2) - [pdf](http://arxiv.org/pdf/1312.0984v2)

> The IPv6 Routing Protocol for Low-Power and Lossy Networks (RPL) was recently introduced as the new routing standard for the Internet of Things. Although RPL defines basic security modes, it remains vulnerable to topological attacks which facilitate blackholing, interception, and resource exhaustion. We are concerned with analyzing the corresponding threats and protecting future RPL deployments from such attacks.   Our contributions are twofold. First, we analyze the state of the art, in particular the protective scheme VeRA and present two new rank order attacks as well as extensions to mitigate them. Second, we derive and evaluate TRAIL, a generic scheme for topology authentication in RPL. TRAIL solely relies on the basic assumptions of RPL that (1) the root node serves as a trust anchor and (2) each node interconnects to the root as part of a hierarchy. Using proper reachability tests, TRAIL scalably and reliably identifies any topological attacker without strong cryptographic efforts.

</details>

<details>

<summary>2015-12-21 11:19:38 - Fingerprinting Software-defined Networks</summary>

- *Heng Cui, Ghassan O. Karame, Felix Klaedtke, Roberto Bifulco*

- `1512.06585v1` - [abs](http://arxiv.org/abs/1512.06585v1) - [pdf](http://arxiv.org/pdf/1512.06585v1)

> Software-defined networking (SDN) eases network management by centralizing the control plane and separating it from the data plane. The separation of planes in SDN, however, introduces new vulnerabilities in SDN networks since the difference in processing packets at each plane allows an adversary to fingerprint the network's packet-forwarding logic. In this paper, we study the feasibility of fingerprinting the controller-switch interactions by a remote adversary, whose aim is to acquire knowledge about specific flow rules that are installed at the switches. This knowledge empowers the adversary with a better understanding of the network's packet-forwarding logic and exposes the network to a number of threats. In our study, we collect measurements from hosts located across the globe using a realistic SDN network comprising of OpenFlow hardware and software switches. We show that, by leveraging information from the RTT and packet-pair dispersion of the exchanged packets, fingerprinting attacks on SDN networks succeed with overwhelming probability. We also show that these attacks are not restricted to active adversaries, but can be equally mounted by passive adversaries that only monitor traffic exchanged with the SDN network. Finally, we discuss the implications of these attacks on the security of SDN networks, and we present and evaluate an efficient countermeasure to strengthen SDN networks against fingerprinting. Our results demonstrate the effectiveness of our countermeasure in deterring fingerprinting attacks on SDN networks.

</details>

<details>

<summary>2015-12-25 00:18:10 - Towards Approaches to Continuous Assessment of Cyber Risk in Security of Computer Networks</summary>

- *Alexander Kott, Curtis Arnold*

- `1512.07937v1` - [abs](http://arxiv.org/abs/1512.07937v1) - [pdf](http://arxiv.org/pdf/1512.07937v1)

> We review the current status and research challenges in the area of cyber security often called continuous monitoring and risk scoring (CMRS). We focus on two most salient aspects of CMRS. First, continuous collection of data through automated feeds; hence the term continuous monitoring. Typical data collected for continuous monitoring purposes include network traffic information as well as host information from host-based agents. Second, analysis of the collected data in order to assess the risks - the risk scoring. This assessment may include flagging especially egregious vulnerabilities and exposures, or computing metrics that provide an overall characterization of the network's risk level. Currently used risk metrics are often simple sums or counts of vulnerabilities and missing patches.   The research challenges pertaining to CMRS fall mainly into two categories. The first centers on the problem of integrating and fusing highly heterogeneous information. The second group of challenges is the lack of rigorous approaches to computing risk. Existing risk scoring algorithms remain limited to ad hoc heuristics such as simple sums of vulnerability scores or counts of things like missing patches or open ports, etc. Weaknesses and potentially misleading nature of such metrics are well recognized. For example, the individual vulnerability scores are dangerously reliant on subjective, human, qualitative input, potentially inaccurate and expensive to obtain. Further, the total number of vulnerabilities may matters far less than how vulnerabilities are distributed over hosts, or over time. Similarly, neither topology of the network nor the roles and dynamics of inter-host interactions are considered by simple sums of vulnerabilities or missing patches.

</details>

<details>

<summary>2015-12-25 23:05:51 - Using Data Analytics to Detect Anomalous States in Vehicles</summary>

- *Sandeep Nair Narayanan, Sudip Mittal, Anupam Joshi*

- `1512.08048v1` - [abs](http://arxiv.org/abs/1512.08048v1) - [pdf](http://arxiv.org/pdf/1512.08048v1)

> Vehicles are becoming more and more connected, this opens up a larger attack surface which not only affects the passengers inside vehicles, but also people around them. These vulnerabilities exist because modern systems are built on the comparatively less secure and old CAN bus framework which lacks even basic authentication. Since a new protocol can only help future vehicles and not older vehicles, our approach tries to solve the issue as a data analytics problem and use machine learning techniques to secure cars. We develop a Hidden Markov Model to detect anomalous states from real data collected from vehicles. Using this model, while a vehicle is in operation, we are able to detect and issue alerts. Our model could be integrated as a plug-n-play device in all new and old cars.

</details>

<details>

<summary>2015-12-26 18:01:56 - Measuring and mitigating AS-level adversaries against Tor</summary>

- *Rishab Nithyanand, Oleksii Starov, Adva Zair, Phillipa Gill, Michael Schapira*

- `1505.05173v6` - [abs](http://arxiv.org/abs/1505.05173v6) - [pdf](http://arxiv.org/pdf/1505.05173v6)

> The popularity of Tor as an anonymity system has made it a popular target for a variety of attacks. We focus on traffic correlation attacks, which are no longer solely in the realm of academic research with recent revelations about the NSA and GCHQ actively working to implement them in practice.   Our first contribution is an empirical study that allows us to gain a high fidelity snapshot of the threat of traffic correlation attacks in the wild. We find that up to 40% of all circuits created by Tor are vulnerable to attacks by traffic correlation from Autonomous System (AS)-level adversaries, 42% from colluding AS-level adversaries, and 85% from state-level adversaries. In addition, we find that in some regions (notably, China and Iran) there exist many cases where over 95% of all possible circuits are vulnerable to correlation attacks, emphasizing the need for AS-aware relay-selection.   To mitigate the threat of such attacks, we build Astoria--an AS-aware Tor client. Astoria leverages recent developments in network measurement to perform path-prediction and intelligent relay selection. Astoria reduces the number of vulnerable circuits to 2% against AS-level adversaries, under 5% against colluding AS-level adversaries, and 25% against state-level adversaries. In addition, Astoria load balances across the Tor network so as to not overload any set of relays.

</details>

